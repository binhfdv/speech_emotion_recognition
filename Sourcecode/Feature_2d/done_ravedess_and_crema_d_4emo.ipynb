{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "done_ravedess_and_crema_d_4emo.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "YEA9A7xTbVxn",
        "ig1NEjLLQQpD",
        "zy5l6YUakCQp",
        "a24jVsOEbqv-",
        "GSgd7O_vbqw2",
        "2tpfXhgWh0Dz",
        "0zRQZ1nG8Lxk",
        "ZpIh-TaKsLc8",
        "8JPwepBQ2ndF",
        "EmYkQLiis54l",
        "1pr4LcUbtDhd",
        "_7YOAt2TIKPI",
        "TgEIFTMtNvym",
        "jNEbmeonPxXR",
        "vQHiqzXuW3ay",
        "52xgoS68UfhO",
        "Q8JULeSZXNcL"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mXUcOOoprG1n",
        "outputId": "1f0c529f-d24c-4e07-c422-6334f9b5dc87"
      },
      "source": [
        "pip install scikit-plot"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting scikit-plot\n",
            "  Downloading https://files.pythonhosted.org/packages/7c/47/32520e259340c140a4ad27c1b97050dd3254fdc517b1d59974d47037510e/scikit_plot-0.3.7-py3-none-any.whl\n",
            "Requirement already satisfied: matplotlib>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from scikit-plot) (3.2.2)\n",
            "Requirement already satisfied: joblib>=0.10 in /usr/local/lib/python3.7/dist-packages (from scikit-plot) (1.0.1)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.7/dist-packages (from scikit-plot) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy>=0.9 in /usr/local/lib/python3.7/dist-packages (from scikit-plot) (1.4.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.4.0->scikit-plot) (0.10.0)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.4.0->scikit-plot) (1.19.5)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.4.0->scikit-plot) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.4.0->scikit-plot) (1.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.4.0->scikit-plot) (2.8.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib>=1.4.0->scikit-plot) (1.15.0)\n",
            "Installing collected packages: scikit-plot\n",
            "Successfully installed scikit-plot-0.3.7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_I0THbn-pnze",
        "outputId": "5fa1cdf6-f730-4adb-e492-e2c0e020621c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLkhkrErMRrZ"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import librosa\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from keras.utils.np_utils import to_categorical\n",
        "import keras \n",
        "from keras.models import Sequential\n",
        "from keras import optimizers\n",
        "from keras.layers import Conv2D, Conv1D, Dense, Dropout, Flatten, AveragePooling2D, BatchNormalization, MaxPool2D, MaxPooling1D, Activation, MaxPooling2D, LSTM\n",
        "from keras.optimizers import Adam\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "\n",
        "import scipy\n",
        "from sklearn.model_selection import train_test_split\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pE6tduzMMmlX"
      },
      "source": [
        "DATA_PATH = \"/content/drive/MyDrive/Colab Notebooks/speech/dataset/ravdess/audio_speech_actors_01-24/\"\n",
        "\n",
        "Modality = []\n",
        "Vocal_channel = []\n",
        "Emotion  = []\n",
        "Emotional_intensity = []\n",
        "Statement = []\n",
        "Repetition = []\n",
        "Actor = []\n",
        "Paths = []\n",
        "\n",
        "for i, (dirpath, dirnames, filenames) in enumerate(os.walk(DATA_PATH)):\n",
        "  if dirpath is not DATA_PATH:\n",
        "    for f in filenames:\n",
        "      if '(1)' not in f: #eliminate coincidences\n",
        "        file_path = os.path.join(dirpath, f)\n",
        "        Paths.append(file_path)\n",
        "        Modality.append(f.split('.')[0].split('-')[0])\n",
        "        Vocal_channel.append(f.split('.')[0].split('-')[1])\n",
        "        Emotion.append(f.split('.')[0].split('-')[2])\n",
        "        Emotional_intensity.append(f.split('.')[0].split('-')[3])\n",
        "        Statement.append(f.split('.')[0].split('-')[4])\n",
        "        Repetition.append(f.split('.')[0].split('-')[5])\n",
        "        Actor.append(int(f.split('.')[0].split('-')[6]))\n",
        "\n",
        "Ravdess_DF = pd.DataFrame()\n",
        "Ravdess_DF['Paths'] = Paths\n",
        "Ravdess_DF['Modality'] = Modality\n",
        "Ravdess_DF['Vocal_channel'] = Vocal_channel\n",
        "Ravdess_DF['Emotion'] = Emotion\n",
        "Ravdess_DF['Emotional_intensity'] = Emotional_intensity\n",
        "Ravdess_DF['Statement'] = Statement\n",
        "Ravdess_DF['Repetition'] = Repetition\n",
        "Ravdess_DF['Actor'] = Actor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "0yRJcTgRqlxN",
        "outputId": "2a3a2bcd-38f8-4fbc-f910-944ac7f32f42"
      },
      "source": [
        "Ravdess_DF.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Paths</th>\n",
              "      <th>Modality</th>\n",
              "      <th>Vocal_channel</th>\n",
              "      <th>Emotion</th>\n",
              "      <th>Emotional_intensity</th>\n",
              "      <th>Statement</th>\n",
              "      <th>Repetition</th>\n",
              "      <th>Actor</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>/content/drive/MyDrive/Colab Notebooks/speech/...</td>\n",
              "      <td>03</td>\n",
              "      <td>01</td>\n",
              "      <td>02</td>\n",
              "      <td>01</td>\n",
              "      <td>01</td>\n",
              "      <td>02</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>/content/drive/MyDrive/Colab Notebooks/speech/...</td>\n",
              "      <td>03</td>\n",
              "      <td>01</td>\n",
              "      <td>03</td>\n",
              "      <td>02</td>\n",
              "      <td>02</td>\n",
              "      <td>02</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>/content/drive/MyDrive/Colab Notebooks/speech/...</td>\n",
              "      <td>03</td>\n",
              "      <td>01</td>\n",
              "      <td>04</td>\n",
              "      <td>02</td>\n",
              "      <td>02</td>\n",
              "      <td>01</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>/content/drive/MyDrive/Colab Notebooks/speech/...</td>\n",
              "      <td>03</td>\n",
              "      <td>01</td>\n",
              "      <td>05</td>\n",
              "      <td>02</td>\n",
              "      <td>02</td>\n",
              "      <td>01</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>/content/drive/MyDrive/Colab Notebooks/speech/...</td>\n",
              "      <td>03</td>\n",
              "      <td>01</td>\n",
              "      <td>02</td>\n",
              "      <td>01</td>\n",
              "      <td>02</td>\n",
              "      <td>02</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               Paths Modality  ... Repetition Actor\n",
              "0  /content/drive/MyDrive/Colab Notebooks/speech/...       03  ...         02     1\n",
              "1  /content/drive/MyDrive/Colab Notebooks/speech/...       03  ...         02     1\n",
              "2  /content/drive/MyDrive/Colab Notebooks/speech/...       03  ...         01     1\n",
              "3  /content/drive/MyDrive/Colab Notebooks/speech/...       03  ...         01     1\n",
              "4  /content/drive/MyDrive/Colab Notebooks/speech/...       03  ...         02     1\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GjeCq1YbMyjE"
      },
      "source": [
        "DATA_PATH = \"/content/drive/MyDrive/Colab Notebooks/speech/dataset/cremad/AudioWAV/\"\n",
        "\n",
        "ActorID = []\n",
        "Statement = []\n",
        "Emotion  = []\n",
        "Emotional_level = []\n",
        "Paths = []\n",
        "\n",
        "links = os.listdir(DATA_PATH)\n",
        "for f in links:\n",
        "  file_path = os.path.join(DATA_PATH, f)\n",
        "  Paths.append(file_path)\n",
        "  ActorID.append(f.split('.')[0].split('_')[0])\n",
        "  Statement.append(f.split('.')[0].split('_')[1])\n",
        "  Emotion.append(f.split('.')[0].split('_')[2])\n",
        "  Emotional_level.append(f.split('.')[0].split('_')[3])\n",
        "\n",
        "CREMA_D_df = pd.DataFrame()\n",
        "CREMA_D_df['ActorID'] = ActorID\n",
        "CREMA_D_df['Statement'] = Statement\n",
        "CREMA_D_df['Emotion'] = Emotion\n",
        "CREMA_D_df['Emotional_level'] = Emotional_level\n",
        "CREMA_D_df['Paths'] = Paths"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "9ioJNr2Kqrqv",
        "outputId": "a937a44b-dcfd-4f18-c7bc-af3360e79d30"
      },
      "source": [
        "CREMA_D_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ActorID</th>\n",
              "      <th>Statement</th>\n",
              "      <th>Emotion</th>\n",
              "      <th>Emotional_level</th>\n",
              "      <th>Paths</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1079</td>\n",
              "      <td>TIE</td>\n",
              "      <td>HAP</td>\n",
              "      <td>XX</td>\n",
              "      <td>/content/drive/MyDrive/Colab Notebooks/speech/...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1080</td>\n",
              "      <td>DFA</td>\n",
              "      <td>HAP</td>\n",
              "      <td>XX</td>\n",
              "      <td>/content/drive/MyDrive/Colab Notebooks/speech/...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1079</td>\n",
              "      <td>TIE</td>\n",
              "      <td>FEA</td>\n",
              "      <td>XX</td>\n",
              "      <td>/content/drive/MyDrive/Colab Notebooks/speech/...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1079</td>\n",
              "      <td>WSI</td>\n",
              "      <td>FEA</td>\n",
              "      <td>XX</td>\n",
              "      <td>/content/drive/MyDrive/Colab Notebooks/speech/...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1079</td>\n",
              "      <td>TIE</td>\n",
              "      <td>DIS</td>\n",
              "      <td>XX</td>\n",
              "      <td>/content/drive/MyDrive/Colab Notebooks/speech/...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  ActorID  ...                                              Paths\n",
              "0    1079  ...  /content/drive/MyDrive/Colab Notebooks/speech/...\n",
              "1    1080  ...  /content/drive/MyDrive/Colab Notebooks/speech/...\n",
              "2    1079  ...  /content/drive/MyDrive/Colab Notebooks/speech/...\n",
              "3    1079  ...  /content/drive/MyDrive/Colab Notebooks/speech/...\n",
              "4    1079  ...  /content/drive/MyDrive/Colab Notebooks/speech/...\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YEA9A7xTbVxn"
      },
      "source": [
        "# mfcc_13 + basic model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gEzmkE-UbVx8"
      },
      "source": [
        "features = []\n",
        "labels = []\n",
        "\n",
        "for i in range(len(Ravdess_DF['Paths'])):\n",
        "  if ((Ravdess_DF['Emotion'][i] == '03') | (Ravdess_DF['Emotion'][i] == '04') | \n",
        "      (Ravdess_DF['Emotion'][i] == '05') | (Ravdess_DF['Emotion'][i] == '06')):\n",
        "    signal, sr = librosa.load(Ravdess_DF['Paths'][i])\n",
        "    mfcc = np.mean(librosa.feature.mfcc(y=signal, sr=sr, n_mfcc=13).T,axis=0).tolist()\n",
        "    features.append(mfcc)\n",
        "    if Ravdess_DF['Emotion'][i] == '03':\n",
        "      labels.append(0)\n",
        "    elif Ravdess_DF['Emotion'][i] == '04':\n",
        "      labels.append(1)\n",
        "    elif Ravdess_DF['Emotion'][i] == '05':\n",
        "      labels.append(2)\n",
        "    elif Ravdess_DF['Emotion'][i] == '06':\n",
        "      labels.append(3)\n",
        "\n",
        "for i in range(len(CREMA_D_df)):\n",
        "  if ((CREMA_D_df['Emotion'][i] == 'HAP') | (CREMA_D_df['Emotion'][i] == 'SAD') | \n",
        "      (CREMA_D_df['Emotion'][i] == 'ANG') | (CREMA_D_df['Emotion'][i] == 'FEA')):\n",
        "    \n",
        "    if CREMA_D_df['Emotion'][i] == 'HAP':\n",
        "      labels.append(0)\n",
        "    elif CREMA_D_df['Emotion'][i] == 'SAD':\n",
        "      labels.append(1)\n",
        "    elif CREMA_D_df['Emotion'][i] == 'ANG':\n",
        "      labels.append(2)\n",
        "    elif CREMA_D_df['Emotion'][i] == 'FEA':\n",
        "      labels.append(3)\n",
        "\n",
        "\n",
        "    signal, sr =  librosa.load(CREMA_D_df['Paths'][i])\n",
        "    mfcc = np.mean(librosa.feature.mfcc(y=signal, sr=sr, n_mfcc=13).T,axis=0).tolist()\n",
        "    features.append(mfcc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VubNaK5dbVx_"
      },
      "source": [
        "X = features\n",
        "y = labels\n",
        "\n",
        "y = np.array(y)\n",
        "y = to_categorical(y)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=0)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=0)\n",
        "\n",
        "X_train = np.array(X_train)\n",
        "X_test = np.array(X_test)\n",
        "X_val = np.array(X_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zMZHW191bVyB"
      },
      "source": [
        "## basic models:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5a3dWSQBbVyC",
        "outputId": "30568e49-2905-41c9-8082-8ad3eb3023b6"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(13, input_shape=(13, ), activation = 'relu'))\n",
        "#model.add(Dropout(0.1))\n",
        "model.add(Dense(128, activation = 'relu'))\n",
        "#model.add(Dropout(0.25))\n",
        "model.add(Dense(128, activation = 'relu'))\n",
        "#model.add(Dropout(0.2))\n",
        "model.add(Dense(4, activation = 'softmax'))\n",
        "\n",
        "optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
        "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer=optimizer)\n",
        "early_stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=100, verbose=1, mode='auto')\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_4 (Dense)              (None, 13)                182       \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 128)               1792      \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 4)                 516       \n",
            "=================================================================\n",
            "Total params: 19,002\n",
            "Trainable params: 19,002\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tadw5q8EbVyG",
        "outputId": "0dc2363e-682d-40d3-f0a2-d4a63da78fb7"
      },
      "source": [
        "history = model.fit(X_train, y_train, batch_size=64, epochs=200, \n",
        "                    validation_data=(X_val, y_val))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "75/75 [==============================] - 1s 4ms/step - loss: 3.8728 - accuracy: 0.2646 - val_loss: 1.4194 - val_accuracy: 0.3245\n",
            "Epoch 2/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.4099 - accuracy: 0.3368 - val_loss: 1.3773 - val_accuracy: 0.3605\n",
            "Epoch 3/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.3140 - accuracy: 0.3718 - val_loss: 1.2070 - val_accuracy: 0.4042\n",
            "Epoch 4/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.2693 - accuracy: 0.3920 - val_loss: 1.2067 - val_accuracy: 0.4023\n",
            "Epoch 5/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.2806 - accuracy: 0.3861 - val_loss: 1.4198 - val_accuracy: 0.3378\n",
            "Epoch 6/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.3123 - accuracy: 0.3893 - val_loss: 1.3902 - val_accuracy: 0.4118\n",
            "Epoch 7/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.2966 - accuracy: 0.3820 - val_loss: 1.2563 - val_accuracy: 0.3776\n",
            "Epoch 8/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.2313 - accuracy: 0.4079 - val_loss: 1.2124 - val_accuracy: 0.3833\n",
            "Epoch 9/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.2477 - accuracy: 0.3911 - val_loss: 1.1814 - val_accuracy: 0.4080\n",
            "Epoch 10/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.2248 - accuracy: 0.4089 - val_loss: 1.2012 - val_accuracy: 0.3871\n",
            "Epoch 11/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.2156 - accuracy: 0.4220 - val_loss: 1.1737 - val_accuracy: 0.4611\n",
            "Epoch 12/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.2335 - accuracy: 0.4181 - val_loss: 1.1742 - val_accuracy: 0.4307\n",
            "Epoch 13/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.1974 - accuracy: 0.4364 - val_loss: 1.1745 - val_accuracy: 0.4326\n",
            "Epoch 14/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.1988 - accuracy: 0.4293 - val_loss: 1.1980 - val_accuracy: 0.4080\n",
            "Epoch 15/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.2069 - accuracy: 0.4270 - val_loss: 1.1909 - val_accuracy: 0.4288\n",
            "Epoch 16/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.2044 - accuracy: 0.4264 - val_loss: 1.1677 - val_accuracy: 0.4592\n",
            "Epoch 17/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.1830 - accuracy: 0.4423 - val_loss: 1.1447 - val_accuracy: 0.4706\n",
            "Epoch 18/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.1972 - accuracy: 0.4309 - val_loss: 1.1500 - val_accuracy: 0.4383\n",
            "Epoch 19/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.1791 - accuracy: 0.4465 - val_loss: 1.2085 - val_accuracy: 0.4156\n",
            "Epoch 20/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.1882 - accuracy: 0.4480 - val_loss: 1.1527 - val_accuracy: 0.4288\n",
            "Epoch 21/200\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 1.1799 - accuracy: 0.4355 - val_loss: 1.1681 - val_accuracy: 0.4288\n",
            "Epoch 22/200\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 1.1795 - accuracy: 0.4401 - val_loss: 1.1501 - val_accuracy: 0.4573\n",
            "Epoch 23/200\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 1.1638 - accuracy: 0.4618 - val_loss: 1.1397 - val_accuracy: 0.4896\n",
            "Epoch 24/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.1503 - accuracy: 0.4700 - val_loss: 1.1508 - val_accuracy: 0.4459\n",
            "Epoch 25/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.1503 - accuracy: 0.4712 - val_loss: 1.1360 - val_accuracy: 0.4687\n",
            "Epoch 26/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.1434 - accuracy: 0.4665 - val_loss: 1.1401 - val_accuracy: 0.4649\n",
            "Epoch 27/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.1460 - accuracy: 0.4811 - val_loss: 1.1258 - val_accuracy: 0.4649\n",
            "Epoch 28/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.1475 - accuracy: 0.4621 - val_loss: 1.1370 - val_accuracy: 0.4744\n",
            "Epoch 29/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.1313 - accuracy: 0.4783 - val_loss: 1.1575 - val_accuracy: 0.4440\n",
            "Epoch 30/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.1406 - accuracy: 0.4641 - val_loss: 1.1328 - val_accuracy: 0.4668\n",
            "Epoch 31/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.1502 - accuracy: 0.4743 - val_loss: 1.1121 - val_accuracy: 0.4820\n",
            "Epoch 32/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.1369 - accuracy: 0.4780 - val_loss: 1.1134 - val_accuracy: 0.4782\n",
            "Epoch 33/200\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 1.1347 - accuracy: 0.4829 - val_loss: 1.0987 - val_accuracy: 0.4839\n",
            "Epoch 34/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.1358 - accuracy: 0.4792 - val_loss: 1.1029 - val_accuracy: 0.4820\n",
            "Epoch 35/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.1321 - accuracy: 0.4788 - val_loss: 1.1397 - val_accuracy: 0.4687\n",
            "Epoch 36/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.1309 - accuracy: 0.4856 - val_loss: 1.1185 - val_accuracy: 0.4763\n",
            "Epoch 37/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.1195 - accuracy: 0.4824 - val_loss: 1.1137 - val_accuracy: 0.4649\n",
            "Epoch 38/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.1240 - accuracy: 0.4826 - val_loss: 1.0968 - val_accuracy: 0.5104\n",
            "Epoch 39/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.1053 - accuracy: 0.4961 - val_loss: 1.0807 - val_accuracy: 0.4915\n",
            "Epoch 40/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.1120 - accuracy: 0.4921 - val_loss: 1.0999 - val_accuracy: 0.4516\n",
            "Epoch 41/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.1058 - accuracy: 0.4881 - val_loss: 1.0882 - val_accuracy: 0.4820\n",
            "Epoch 42/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0881 - accuracy: 0.4921 - val_loss: 1.0865 - val_accuracy: 0.4953\n",
            "Epoch 43/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.1084 - accuracy: 0.4982 - val_loss: 1.1149 - val_accuracy: 0.4820\n",
            "Epoch 44/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.1424 - accuracy: 0.4884 - val_loss: 1.0967 - val_accuracy: 0.5009\n",
            "Epoch 45/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.1103 - accuracy: 0.4879 - val_loss: 1.0848 - val_accuracy: 0.4820\n",
            "Epoch 46/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0890 - accuracy: 0.5069 - val_loss: 1.0698 - val_accuracy: 0.4991\n",
            "Epoch 47/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0719 - accuracy: 0.5143 - val_loss: 1.0924 - val_accuracy: 0.4858\n",
            "Epoch 48/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0802 - accuracy: 0.4977 - val_loss: 1.0596 - val_accuracy: 0.5009\n",
            "Epoch 49/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0811 - accuracy: 0.5161 - val_loss: 1.0629 - val_accuracy: 0.5256\n",
            "Epoch 50/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0793 - accuracy: 0.5098 - val_loss: 1.0702 - val_accuracy: 0.5047\n",
            "Epoch 51/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.1013 - accuracy: 0.4985 - val_loss: 1.0661 - val_accuracy: 0.5066\n",
            "Epoch 52/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0819 - accuracy: 0.5139 - val_loss: 1.0711 - val_accuracy: 0.5028\n",
            "Epoch 53/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0882 - accuracy: 0.5090 - val_loss: 1.0444 - val_accuracy: 0.5294\n",
            "Epoch 54/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0678 - accuracy: 0.5181 - val_loss: 1.0733 - val_accuracy: 0.4877\n",
            "Epoch 55/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0838 - accuracy: 0.5145 - val_loss: 1.0797 - val_accuracy: 0.5180\n",
            "Epoch 56/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0786 - accuracy: 0.5104 - val_loss: 1.0631 - val_accuracy: 0.5085\n",
            "Epoch 57/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0769 - accuracy: 0.5141 - val_loss: 1.0623 - val_accuracy: 0.4896\n",
            "Epoch 58/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0673 - accuracy: 0.5158 - val_loss: 1.0521 - val_accuracy: 0.5180\n",
            "Epoch 59/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0618 - accuracy: 0.5242 - val_loss: 1.0706 - val_accuracy: 0.5161\n",
            "Epoch 60/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0902 - accuracy: 0.5032 - val_loss: 1.0485 - val_accuracy: 0.5085\n",
            "Epoch 61/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0826 - accuracy: 0.4986 - val_loss: 1.0768 - val_accuracy: 0.5142\n",
            "Epoch 62/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0996 - accuracy: 0.5030 - val_loss: 1.0548 - val_accuracy: 0.5237\n",
            "Epoch 63/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0498 - accuracy: 0.5349 - val_loss: 1.0627 - val_accuracy: 0.5161\n",
            "Epoch 64/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0744 - accuracy: 0.4995 - val_loss: 1.0374 - val_accuracy: 0.5332\n",
            "Epoch 65/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0492 - accuracy: 0.5312 - val_loss: 1.0703 - val_accuracy: 0.5161\n",
            "Epoch 66/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0600 - accuracy: 0.5261 - val_loss: 1.0467 - val_accuracy: 0.5199\n",
            "Epoch 67/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0572 - accuracy: 0.5246 - val_loss: 1.0435 - val_accuracy: 0.5313\n",
            "Epoch 68/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0621 - accuracy: 0.5149 - val_loss: 1.0453 - val_accuracy: 0.5427\n",
            "Epoch 69/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0657 - accuracy: 0.5276 - val_loss: 1.0361 - val_accuracy: 0.5332\n",
            "Epoch 70/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0354 - accuracy: 0.5414 - val_loss: 1.0535 - val_accuracy: 0.5237\n",
            "Epoch 71/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0701 - accuracy: 0.5355 - val_loss: 1.0507 - val_accuracy: 0.5370\n",
            "Epoch 72/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0332 - accuracy: 0.5387 - val_loss: 1.0442 - val_accuracy: 0.5199\n",
            "Epoch 73/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0796 - accuracy: 0.5139 - val_loss: 1.0339 - val_accuracy: 0.5104\n",
            "Epoch 74/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0447 - accuracy: 0.5264 - val_loss: 1.0662 - val_accuracy: 0.5199\n",
            "Epoch 75/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.1125 - accuracy: 0.4920 - val_loss: 1.0537 - val_accuracy: 0.5389\n",
            "Epoch 76/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0628 - accuracy: 0.5188 - val_loss: 1.0695 - val_accuracy: 0.5028\n",
            "Epoch 77/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0826 - accuracy: 0.5017 - val_loss: 1.0605 - val_accuracy: 0.5047\n",
            "Epoch 78/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0669 - accuracy: 0.5133 - val_loss: 1.0497 - val_accuracy: 0.5294\n",
            "Epoch 79/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0320 - accuracy: 0.5431 - val_loss: 1.0546 - val_accuracy: 0.5047\n",
            "Epoch 80/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0616 - accuracy: 0.5134 - val_loss: 1.0394 - val_accuracy: 0.5180\n",
            "Epoch 81/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0301 - accuracy: 0.5369 - val_loss: 1.0313 - val_accuracy: 0.5294\n",
            "Epoch 82/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0634 - accuracy: 0.5166 - val_loss: 1.0631 - val_accuracy: 0.4934\n",
            "Epoch 83/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0547 - accuracy: 0.5279 - val_loss: 1.0630 - val_accuracy: 0.5199\n",
            "Epoch 84/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0496 - accuracy: 0.5227 - val_loss: 1.0281 - val_accuracy: 0.5275\n",
            "Epoch 85/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0443 - accuracy: 0.5216 - val_loss: 1.0363 - val_accuracy: 0.5275\n",
            "Epoch 86/200\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 1.0373 - accuracy: 0.5282 - val_loss: 1.1007 - val_accuracy: 0.5028\n",
            "Epoch 87/200\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 1.0890 - accuracy: 0.5161 - val_loss: 1.0460 - val_accuracy: 0.5275\n",
            "Epoch 88/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0508 - accuracy: 0.5304 - val_loss: 1.0932 - val_accuracy: 0.4991\n",
            "Epoch 89/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0920 - accuracy: 0.5124 - val_loss: 1.0361 - val_accuracy: 0.5199\n",
            "Epoch 90/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0301 - accuracy: 0.5362 - val_loss: 1.0423 - val_accuracy: 0.5180\n",
            "Epoch 91/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0505 - accuracy: 0.5284 - val_loss: 1.0387 - val_accuracy: 0.5294\n",
            "Epoch 92/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0510 - accuracy: 0.5277 - val_loss: 1.0345 - val_accuracy: 0.5294\n",
            "Epoch 93/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0262 - accuracy: 0.5260 - val_loss: 1.0379 - val_accuracy: 0.5408\n",
            "Epoch 94/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0419 - accuracy: 0.5252 - val_loss: 1.0805 - val_accuracy: 0.5085\n",
            "Epoch 95/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0531 - accuracy: 0.5208 - val_loss: 1.0690 - val_accuracy: 0.5294\n",
            "Epoch 96/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0482 - accuracy: 0.5280 - val_loss: 1.0282 - val_accuracy: 0.5294\n",
            "Epoch 97/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0428 - accuracy: 0.5305 - val_loss: 1.0235 - val_accuracy: 0.5484\n",
            "Epoch 98/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0295 - accuracy: 0.5334 - val_loss: 1.0469 - val_accuracy: 0.5351\n",
            "Epoch 99/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0161 - accuracy: 0.5511 - val_loss: 1.0363 - val_accuracy: 0.5199\n",
            "Epoch 100/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0651 - accuracy: 0.5187 - val_loss: 1.0202 - val_accuracy: 0.5408\n",
            "Epoch 101/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0506 - accuracy: 0.5280 - val_loss: 1.0347 - val_accuracy: 0.5218\n",
            "Epoch 102/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0511 - accuracy: 0.5175 - val_loss: 1.0478 - val_accuracy: 0.5237\n",
            "Epoch 103/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0582 - accuracy: 0.5255 - val_loss: 1.0481 - val_accuracy: 0.5047\n",
            "Epoch 104/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0317 - accuracy: 0.5335 - val_loss: 1.0596 - val_accuracy: 0.5161\n",
            "Epoch 105/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0843 - accuracy: 0.4985 - val_loss: 1.0361 - val_accuracy: 0.5104\n",
            "Epoch 106/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0473 - accuracy: 0.5349 - val_loss: 1.0079 - val_accuracy: 0.5503\n",
            "Epoch 107/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0410 - accuracy: 0.5316 - val_loss: 1.0128 - val_accuracy: 0.5237\n",
            "Epoch 108/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0364 - accuracy: 0.5354 - val_loss: 1.0168 - val_accuracy: 0.5332\n",
            "Epoch 109/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0260 - accuracy: 0.5410 - val_loss: 1.0233 - val_accuracy: 0.5294\n",
            "Epoch 110/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0170 - accuracy: 0.5412 - val_loss: 1.0521 - val_accuracy: 0.5085\n",
            "Epoch 111/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0600 - accuracy: 0.5312 - val_loss: 1.0413 - val_accuracy: 0.5180\n",
            "Epoch 112/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0416 - accuracy: 0.5216 - val_loss: 1.0328 - val_accuracy: 0.5408\n",
            "Epoch 113/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0389 - accuracy: 0.5236 - val_loss: 1.0449 - val_accuracy: 0.5199\n",
            "Epoch 114/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0290 - accuracy: 0.5386 - val_loss: 1.0402 - val_accuracy: 0.5199\n",
            "Epoch 115/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0285 - accuracy: 0.5354 - val_loss: 1.0607 - val_accuracy: 0.5180\n",
            "Epoch 116/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0420 - accuracy: 0.5265 - val_loss: 1.0605 - val_accuracy: 0.5142\n",
            "Epoch 117/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0546 - accuracy: 0.5124 - val_loss: 1.0201 - val_accuracy: 0.5389\n",
            "Epoch 118/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0389 - accuracy: 0.5241 - val_loss: 1.0183 - val_accuracy: 0.5332\n",
            "Epoch 119/200\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 1.0140 - accuracy: 0.5547 - val_loss: 1.0195 - val_accuracy: 0.5351\n",
            "Epoch 120/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0301 - accuracy: 0.5344 - val_loss: 1.0186 - val_accuracy: 0.5503\n",
            "Epoch 121/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0257 - accuracy: 0.5437 - val_loss: 1.0464 - val_accuracy: 0.5370\n",
            "Epoch 122/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0358 - accuracy: 0.5330 - val_loss: 1.0084 - val_accuracy: 0.5351\n",
            "Epoch 123/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0261 - accuracy: 0.5314 - val_loss: 1.0449 - val_accuracy: 0.5237\n",
            "Epoch 124/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0532 - accuracy: 0.5314 - val_loss: 1.0836 - val_accuracy: 0.5066\n",
            "Epoch 125/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0301 - accuracy: 0.5315 - val_loss: 1.0141 - val_accuracy: 0.5427\n",
            "Epoch 126/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0261 - accuracy: 0.5502 - val_loss: 1.0364 - val_accuracy: 0.5408\n",
            "Epoch 127/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0161 - accuracy: 0.5436 - val_loss: 1.0209 - val_accuracy: 0.5313\n",
            "Epoch 128/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0217 - accuracy: 0.5377 - val_loss: 1.0663 - val_accuracy: 0.5199\n",
            "Epoch 129/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0451 - accuracy: 0.5295 - val_loss: 1.0296 - val_accuracy: 0.5218\n",
            "Epoch 130/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0269 - accuracy: 0.5310 - val_loss: 1.0598 - val_accuracy: 0.5142\n",
            "Epoch 131/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0357 - accuracy: 0.5376 - val_loss: 1.0162 - val_accuracy: 0.5370\n",
            "Epoch 132/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0528 - accuracy: 0.5216 - val_loss: 1.0219 - val_accuracy: 0.5313\n",
            "Epoch 133/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0383 - accuracy: 0.5343 - val_loss: 1.0156 - val_accuracy: 0.5351\n",
            "Epoch 134/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0123 - accuracy: 0.5563 - val_loss: 1.0207 - val_accuracy: 0.5465\n",
            "Epoch 135/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0140 - accuracy: 0.5470 - val_loss: 1.0377 - val_accuracy: 0.5503\n",
            "Epoch 136/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0244 - accuracy: 0.5385 - val_loss: 1.0578 - val_accuracy: 0.5199\n",
            "Epoch 137/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0201 - accuracy: 0.5376 - val_loss: 1.0170 - val_accuracy: 0.5370\n",
            "Epoch 138/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0098 - accuracy: 0.5433 - val_loss: 1.0308 - val_accuracy: 0.5389\n",
            "Epoch 139/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0298 - accuracy: 0.5332 - val_loss: 1.0486 - val_accuracy: 0.5294\n",
            "Epoch 140/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0258 - accuracy: 0.5408 - val_loss: 1.0271 - val_accuracy: 0.5332\n",
            "Epoch 141/200\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 1.0219 - accuracy: 0.5435 - val_loss: 1.0395 - val_accuracy: 0.5161\n",
            "Epoch 142/200\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 1.0268 - accuracy: 0.5446 - val_loss: 1.0425 - val_accuracy: 0.5275\n",
            "Epoch 143/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0368 - accuracy: 0.5252 - val_loss: 1.0076 - val_accuracy: 0.5142\n",
            "Epoch 144/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0253 - accuracy: 0.5432 - val_loss: 1.0134 - val_accuracy: 0.5370\n",
            "Epoch 145/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0571 - accuracy: 0.5159 - val_loss: 1.0120 - val_accuracy: 0.5370\n",
            "Epoch 146/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0188 - accuracy: 0.5382 - val_loss: 1.0233 - val_accuracy: 0.5237\n",
            "Epoch 147/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0201 - accuracy: 0.5511 - val_loss: 1.0154 - val_accuracy: 0.5313\n",
            "Epoch 148/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0138 - accuracy: 0.5500 - val_loss: 1.0120 - val_accuracy: 0.5313\n",
            "Epoch 149/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0253 - accuracy: 0.5485 - val_loss: 1.0221 - val_accuracy: 0.5351\n",
            "Epoch 150/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0377 - accuracy: 0.5338 - val_loss: 1.0067 - val_accuracy: 0.5370\n",
            "Epoch 151/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0368 - accuracy: 0.5323 - val_loss: 1.0489 - val_accuracy: 0.5028\n",
            "Epoch 152/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.9993 - accuracy: 0.5447 - val_loss: 1.0192 - val_accuracy: 0.5332\n",
            "Epoch 153/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0080 - accuracy: 0.5499 - val_loss: 1.0218 - val_accuracy: 0.5446\n",
            "Epoch 154/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0164 - accuracy: 0.5430 - val_loss: 1.0192 - val_accuracy: 0.5351\n",
            "Epoch 155/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0273 - accuracy: 0.5331 - val_loss: 1.0374 - val_accuracy: 0.5446\n",
            "Epoch 156/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0296 - accuracy: 0.5312 - val_loss: 1.0227 - val_accuracy: 0.5370\n",
            "Epoch 157/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0130 - accuracy: 0.5423 - val_loss: 1.0095 - val_accuracy: 0.5370\n",
            "Epoch 158/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0025 - accuracy: 0.5456 - val_loss: 1.0298 - val_accuracy: 0.5370\n",
            "Epoch 159/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0104 - accuracy: 0.5524 - val_loss: 1.0149 - val_accuracy: 0.5503\n",
            "Epoch 160/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0196 - accuracy: 0.5464 - val_loss: 1.0557 - val_accuracy: 0.5218\n",
            "Epoch 161/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0414 - accuracy: 0.5211 - val_loss: 1.0451 - val_accuracy: 0.5047\n",
            "Epoch 162/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0308 - accuracy: 0.5263 - val_loss: 1.0135 - val_accuracy: 0.5484\n",
            "Epoch 163/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0264 - accuracy: 0.5364 - val_loss: 0.9931 - val_accuracy: 0.5484\n",
            "Epoch 164/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0024 - accuracy: 0.5551 - val_loss: 1.0129 - val_accuracy: 0.5408\n",
            "Epoch 165/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.9967 - accuracy: 0.5561 - val_loss: 1.0243 - val_accuracy: 0.5427\n",
            "Epoch 166/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0136 - accuracy: 0.5407 - val_loss: 0.9875 - val_accuracy: 0.5237\n",
            "Epoch 167/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0065 - accuracy: 0.5515 - val_loss: 1.0547 - val_accuracy: 0.5066\n",
            "Epoch 168/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0231 - accuracy: 0.5377 - val_loss: 1.0213 - val_accuracy: 0.5332\n",
            "Epoch 169/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0293 - accuracy: 0.5278 - val_loss: 1.0389 - val_accuracy: 0.5370\n",
            "Epoch 170/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0255 - accuracy: 0.5361 - val_loss: 1.0162 - val_accuracy: 0.5370\n",
            "Epoch 171/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0188 - accuracy: 0.5529 - val_loss: 1.0300 - val_accuracy: 0.5351\n",
            "Epoch 172/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0205 - accuracy: 0.5290 - val_loss: 1.0169 - val_accuracy: 0.5389\n",
            "Epoch 173/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0245 - accuracy: 0.5428 - val_loss: 0.9886 - val_accuracy: 0.5465\n",
            "Epoch 174/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0334 - accuracy: 0.5317 - val_loss: 1.0129 - val_accuracy: 0.5408\n",
            "Epoch 175/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0079 - accuracy: 0.5418 - val_loss: 1.0169 - val_accuracy: 0.5408\n",
            "Epoch 176/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0116 - accuracy: 0.5506 - val_loss: 1.0188 - val_accuracy: 0.5560\n",
            "Epoch 177/200\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 1.0230 - accuracy: 0.5461 - val_loss: 1.0077 - val_accuracy: 0.5389\n",
            "Epoch 178/200\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 1.0222 - accuracy: 0.5476 - val_loss: 1.0061 - val_accuracy: 0.5408\n",
            "Epoch 179/200\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 1.0246 - accuracy: 0.5446 - val_loss: 1.0700 - val_accuracy: 0.5427\n",
            "Epoch 180/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0211 - accuracy: 0.5404 - val_loss: 0.9972 - val_accuracy: 0.5332\n",
            "Epoch 181/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0155 - accuracy: 0.5360 - val_loss: 0.9957 - val_accuracy: 0.5389\n",
            "Epoch 182/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0309 - accuracy: 0.5421 - val_loss: 1.0079 - val_accuracy: 0.5275\n",
            "Epoch 183/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.9950 - accuracy: 0.5545 - val_loss: 1.0473 - val_accuracy: 0.5332\n",
            "Epoch 184/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0164 - accuracy: 0.5475 - val_loss: 1.0169 - val_accuracy: 0.5313\n",
            "Epoch 185/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.9935 - accuracy: 0.5558 - val_loss: 1.0106 - val_accuracy: 0.5465\n",
            "Epoch 186/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0184 - accuracy: 0.5370 - val_loss: 1.0190 - val_accuracy: 0.5389\n",
            "Epoch 187/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0029 - accuracy: 0.5463 - val_loss: 1.0283 - val_accuracy: 0.5332\n",
            "Epoch 188/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0362 - accuracy: 0.5201 - val_loss: 1.0268 - val_accuracy: 0.5484\n",
            "Epoch 189/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0279 - accuracy: 0.5353 - val_loss: 1.0108 - val_accuracy: 0.5427\n",
            "Epoch 190/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0238 - accuracy: 0.5467 - val_loss: 0.9885 - val_accuracy: 0.5389\n",
            "Epoch 191/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0034 - accuracy: 0.5494 - val_loss: 1.0606 - val_accuracy: 0.5275\n",
            "Epoch 192/200\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 1.0401 - accuracy: 0.5329 - val_loss: 1.0256 - val_accuracy: 0.5465\n",
            "Epoch 193/200\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 1.0081 - accuracy: 0.5486 - val_loss: 1.0532 - val_accuracy: 0.5180\n",
            "Epoch 194/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0026 - accuracy: 0.5546 - val_loss: 1.0663 - val_accuracy: 0.5275\n",
            "Epoch 195/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0463 - accuracy: 0.5323 - val_loss: 1.0295 - val_accuracy: 0.5503\n",
            "Epoch 196/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0079 - accuracy: 0.5423 - val_loss: 1.0309 - val_accuracy: 0.5427\n",
            "Epoch 197/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0166 - accuracy: 0.5465 - val_loss: 1.0259 - val_accuracy: 0.5503\n",
            "Epoch 198/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0200 - accuracy: 0.5408 - val_loss: 1.0078 - val_accuracy: 0.5503\n",
            "Epoch 199/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0189 - accuracy: 0.5490 - val_loss: 1.0341 - val_accuracy: 0.5503\n",
            "Epoch 200/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0039 - accuracy: 0.5483 - val_loss: 1.0168 - val_accuracy: 0.5465\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n16Ua5s7bVyJ"
      },
      "source": [
        "model.save('./basic_mfcc13_merged.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jKKln4F0bVyK"
      },
      "source": [
        "###test_result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v1J6PC5XbVyM",
        "outputId": "b999b23a-1abb-40ef-b431-67f4b34ba505"
      },
      "source": [
        "d = {0: 'happy',\n",
        "     1: 'sad',\n",
        "     2: 'angry',\n",
        "     3: 'fear'}\n",
        "Y_test_pred = np.argmax(model.predict(X_test), axis=-1)\n",
        "Y_test_pred = list(map(lambda x: d[x], Y_test_pred))\n",
        "y_test = np.argmax(y_test, axis=-1)\n",
        "y_test = list(map(lambda x: d[x], y_test))\n",
        "print(classification_report(y_test, Y_test_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.65      0.76      0.70       151\n",
            "        fear       0.50      0.23      0.31       136\n",
            "       happy       0.46      0.43      0.44       140\n",
            "         sad       0.61      0.82      0.70       159\n",
            "\n",
            "    accuracy                           0.58       586\n",
            "   macro avg       0.55      0.56      0.54       586\n",
            "weighted avg       0.56      0.58      0.55       586\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kgN2ObwCbVyN",
        "outputId": "00f37937-ac68-492e-f58e-3125dba87ab1"
      },
      "source": [
        "import scikitplot as skplt\n",
        "\n",
        "skplt.metrics.plot_confusion_matrix(\n",
        "    y_test, \n",
        "    Y_test_pred,\n",
        "    figsize=(8,8))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<AxesSubplot:title={'center':'Confusion Matrix'}, xlabel='Predicted label', ylabel='True label'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ig1NEjLLQQpD"
      },
      "source": [
        "# mfcc_26 + basic model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2I4cBVnBPgzS"
      },
      "source": [
        "features = []\n",
        "labels = []\n",
        "\n",
        "for i in range(len(Ravdess_DF['Paths'])):\n",
        "  if ((Ravdess_DF['Emotion'][i] == '03') | (Ravdess_DF['Emotion'][i] == '04') | \n",
        "      (Ravdess_DF['Emotion'][i] == '05') | (Ravdess_DF['Emotion'][i] == '06')):\n",
        "    signal, sr = librosa.load(Ravdess_DF['Paths'][i])\n",
        "    mfcc = np.mean(librosa.feature.mfcc(y=signal, sr=sr, n_mfcc=26).T,axis=0).tolist()\n",
        "    features.append(mfcc)\n",
        "    if Ravdess_DF['Emotion'][i] == '03':\n",
        "      labels.append(0)\n",
        "    elif Ravdess_DF['Emotion'][i] == '04':\n",
        "      labels.append(1)\n",
        "    elif Ravdess_DF['Emotion'][i] == '05':\n",
        "      labels.append(2)\n",
        "    elif Ravdess_DF['Emotion'][i] == '06':\n",
        "      labels.append(3)\n",
        "\n",
        "for i in range(len(CREMA_D_df)):\n",
        "  if ((CREMA_D_df['Emotion'][i] == 'HAP') | (CREMA_D_df['Emotion'][i] == 'SAD') | \n",
        "      (CREMA_D_df['Emotion'][i] == 'ANG') | (CREMA_D_df['Emotion'][i] == 'FEA')):\n",
        "    \n",
        "    if CREMA_D_df['Emotion'][i] == 'HAP':\n",
        "      labels.append(0)\n",
        "    elif CREMA_D_df['Emotion'][i] == 'SAD':\n",
        "      labels.append(1)\n",
        "    elif CREMA_D_df['Emotion'][i] == 'ANG':\n",
        "      labels.append(2)\n",
        "    elif CREMA_D_df['Emotion'][i] == 'FEA':\n",
        "      labels.append(3)\n",
        "\n",
        "\n",
        "    signal, sr =  librosa.load(CREMA_D_df['Paths'][i])\n",
        "    mfcc = np.mean(librosa.feature.mfcc(y=signal, sr=sr, n_mfcc=26).T,axis=0).tolist()\n",
        "    features.append(mfcc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wG5KiDGuQPWf"
      },
      "source": [
        "X = features\n",
        "y = labels\n",
        "\n",
        "y = np.array(y)\n",
        "y = to_categorical(y)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=0)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=0)\n",
        "\n",
        "X_train = np.array(X_train)\n",
        "X_test = np.array(X_test)\n",
        "X_val = np.array(X_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDxtjQVG2X8w"
      },
      "source": [
        "## basic models:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5p5Od0R2X80",
        "outputId": "76867853-2de1-4752-c4f8-fce7b2a18b8d"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(26, input_shape=(26, ), activation = 'relu'))\n",
        "#model.add(Dropout(0.1))\n",
        "model.add(Dense(128, activation = 'relu'))\n",
        "#model.add(Dropout(0.25))\n",
        "model.add(Dense(128, activation = 'relu'))\n",
        "#model.add(Dropout(0.2))\n",
        "model.add(Dense(4, activation = 'softmax'))\n",
        "\n",
        "optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
        "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer=optimizer)\n",
        "early_stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=100, verbose=1, mode='auto')\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_8 (Dense)              (None, 26)                702       \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 128)               3456      \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 4)                 516       \n",
            "=================================================================\n",
            "Total params: 21,186\n",
            "Trainable params: 21,186\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IUxdvY4H2X81",
        "outputId": "2f5e16a1-931c-4f4c-8110-d0721871c602"
      },
      "source": [
        "history = model.fit(X_train, y_train, batch_size=64, epochs=200, \n",
        "                    validation_data=(X_val, y_val))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "75/75 [==============================] - 1s 5ms/step - loss: 3.4947 - accuracy: 0.3346 - val_loss: 1.7452 - val_accuracy: 0.3643\n",
            "Epoch 2/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.5768 - accuracy: 0.3753 - val_loss: 1.2310 - val_accuracy: 0.4118\n",
            "Epoch 3/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.2860 - accuracy: 0.4254 - val_loss: 1.8742 - val_accuracy: 0.3605\n",
            "Epoch 4/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.4973 - accuracy: 0.4169 - val_loss: 2.3115 - val_accuracy: 0.2486\n",
            "Epoch 5/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.5306 - accuracy: 0.3941 - val_loss: 2.7222 - val_accuracy: 0.2884\n",
            "Epoch 6/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.8006 - accuracy: 0.4068 - val_loss: 1.2695 - val_accuracy: 0.4288\n",
            "Epoch 7/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.2920 - accuracy: 0.4325 - val_loss: 1.6709 - val_accuracy: 0.2581\n",
            "Epoch 8/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.3121 - accuracy: 0.4233 - val_loss: 1.4417 - val_accuracy: 0.4250\n",
            "Epoch 9/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.2540 - accuracy: 0.4656 - val_loss: 2.1168 - val_accuracy: 0.2524\n",
            "Epoch 10/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.3511 - accuracy: 0.4301 - val_loss: 1.8876 - val_accuracy: 0.3112\n",
            "Epoch 11/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.4565 - accuracy: 0.4143 - val_loss: 1.6379 - val_accuracy: 0.3454\n",
            "Epoch 12/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.3098 - accuracy: 0.4528 - val_loss: 1.2115 - val_accuracy: 0.4611\n",
            "Epoch 13/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.2284 - accuracy: 0.4614 - val_loss: 1.5997 - val_accuracy: 0.3776\n",
            "Epoch 14/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.2753 - accuracy: 0.4483 - val_loss: 1.1598 - val_accuracy: 0.4744\n",
            "Epoch 15/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.1615 - accuracy: 0.4820 - val_loss: 1.1425 - val_accuracy: 0.4630\n",
            "Epoch 16/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.1699 - accuracy: 0.4552 - val_loss: 1.1483 - val_accuracy: 0.4839\n",
            "Epoch 17/200\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 1.1859 - accuracy: 0.4651 - val_loss: 1.4328 - val_accuracy: 0.4497\n",
            "Epoch 18/200\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 1.2003 - accuracy: 0.4782 - val_loss: 1.4481 - val_accuracy: 0.4004\n",
            "Epoch 19/200\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 1.1886 - accuracy: 0.4851 - val_loss: 1.1128 - val_accuracy: 0.4896\n",
            "Epoch 20/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.1449 - accuracy: 0.4865 - val_loss: 1.1459 - val_accuracy: 0.4573\n",
            "Epoch 21/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.1905 - accuracy: 0.4743 - val_loss: 1.1837 - val_accuracy: 0.4364\n",
            "Epoch 22/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.1497 - accuracy: 0.4837 - val_loss: 1.1720 - val_accuracy: 0.4478\n",
            "Epoch 23/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.1274 - accuracy: 0.4811 - val_loss: 1.0529 - val_accuracy: 0.5180\n",
            "Epoch 24/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.1005 - accuracy: 0.4978 - val_loss: 1.1101 - val_accuracy: 0.5085\n",
            "Epoch 25/200\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 1.0994 - accuracy: 0.5110 - val_loss: 1.0633 - val_accuracy: 0.5104\n",
            "Epoch 26/200\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 1.0555 - accuracy: 0.5178 - val_loss: 1.1403 - val_accuracy: 0.4497\n",
            "Epoch 27/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.1065 - accuracy: 0.5001 - val_loss: 1.2402 - val_accuracy: 0.4744\n",
            "Epoch 28/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.1499 - accuracy: 0.4904 - val_loss: 1.0570 - val_accuracy: 0.4953\n",
            "Epoch 29/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0639 - accuracy: 0.5293 - val_loss: 1.0533 - val_accuracy: 0.5066\n",
            "Epoch 30/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0602 - accuracy: 0.5163 - val_loss: 1.0712 - val_accuracy: 0.5085\n",
            "Epoch 31/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0831 - accuracy: 0.5199 - val_loss: 1.0767 - val_accuracy: 0.5123\n",
            "Epoch 32/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0570 - accuracy: 0.5351 - val_loss: 1.0982 - val_accuracy: 0.5104\n",
            "Epoch 33/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0611 - accuracy: 0.5313 - val_loss: 1.0225 - val_accuracy: 0.5389\n",
            "Epoch 34/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0477 - accuracy: 0.5177 - val_loss: 1.1461 - val_accuracy: 0.4706\n",
            "Epoch 35/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.1563 - accuracy: 0.5031 - val_loss: 1.1824 - val_accuracy: 0.4763\n",
            "Epoch 36/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0827 - accuracy: 0.5099 - val_loss: 1.0458 - val_accuracy: 0.4896\n",
            "Epoch 37/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0771 - accuracy: 0.5095 - val_loss: 1.1034 - val_accuracy: 0.5066\n",
            "Epoch 38/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0408 - accuracy: 0.5377 - val_loss: 1.1055 - val_accuracy: 0.5028\n",
            "Epoch 39/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0320 - accuracy: 0.5455 - val_loss: 1.1126 - val_accuracy: 0.4991\n",
            "Epoch 40/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0288 - accuracy: 0.5374 - val_loss: 1.0904 - val_accuracy: 0.5161\n",
            "Epoch 41/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0434 - accuracy: 0.5310 - val_loss: 1.0100 - val_accuracy: 0.5161\n",
            "Epoch 42/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0096 - accuracy: 0.5509 - val_loss: 1.0428 - val_accuracy: 0.5294\n",
            "Epoch 43/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.9940 - accuracy: 0.5613 - val_loss: 1.0721 - val_accuracy: 0.5123\n",
            "Epoch 44/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0364 - accuracy: 0.5391 - val_loss: 1.0396 - val_accuracy: 0.5389\n",
            "Epoch 45/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0176 - accuracy: 0.5481 - val_loss: 1.0106 - val_accuracy: 0.5275\n",
            "Epoch 46/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.9949 - accuracy: 0.5588 - val_loss: 1.0305 - val_accuracy: 0.5275\n",
            "Epoch 47/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.9718 - accuracy: 0.5712 - val_loss: 1.0561 - val_accuracy: 0.5351\n",
            "Epoch 48/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.9803 - accuracy: 0.5720 - val_loss: 1.0779 - val_accuracy: 0.5028\n",
            "Epoch 49/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0544 - accuracy: 0.5271 - val_loss: 1.0576 - val_accuracy: 0.5180\n",
            "Epoch 50/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.9939 - accuracy: 0.5673 - val_loss: 1.0281 - val_accuracy: 0.5427\n",
            "Epoch 51/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.9787 - accuracy: 0.5642 - val_loss: 1.0847 - val_accuracy: 0.5237\n",
            "Epoch 52/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.9975 - accuracy: 0.5468 - val_loss: 1.1350 - val_accuracy: 0.4972\n",
            "Epoch 53/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.1260 - accuracy: 0.5463 - val_loss: 1.0493 - val_accuracy: 0.5047\n",
            "Epoch 54/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.9885 - accuracy: 0.5649 - val_loss: 1.0976 - val_accuracy: 0.5123\n",
            "Epoch 55/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.9975 - accuracy: 0.5695 - val_loss: 1.0170 - val_accuracy: 0.5161\n",
            "Epoch 56/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.9883 - accuracy: 0.5597 - val_loss: 1.0491 - val_accuracy: 0.5332\n",
            "Epoch 57/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.9860 - accuracy: 0.5733 - val_loss: 1.0122 - val_accuracy: 0.5389\n",
            "Epoch 58/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.9593 - accuracy: 0.5816 - val_loss: 1.0328 - val_accuracy: 0.5256\n",
            "Epoch 59/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.9731 - accuracy: 0.5758 - val_loss: 1.0007 - val_accuracy: 0.5389\n",
            "Epoch 60/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.9508 - accuracy: 0.5812 - val_loss: 1.0708 - val_accuracy: 0.5256\n",
            "Epoch 61/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.9967 - accuracy: 0.5541 - val_loss: 1.0181 - val_accuracy: 0.5522\n",
            "Epoch 62/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.9736 - accuracy: 0.5639 - val_loss: 1.0191 - val_accuracy: 0.5522\n",
            "Epoch 63/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.9482 - accuracy: 0.5929 - val_loss: 1.0585 - val_accuracy: 0.5161\n",
            "Epoch 64/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.9647 - accuracy: 0.5747 - val_loss: 0.9994 - val_accuracy: 0.5389\n",
            "Epoch 65/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.9500 - accuracy: 0.5911 - val_loss: 1.0181 - val_accuracy: 0.5617\n",
            "Epoch 66/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.9315 - accuracy: 0.5816 - val_loss: 0.9905 - val_accuracy: 0.5522\n",
            "Epoch 67/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.9810 - accuracy: 0.5675 - val_loss: 1.0086 - val_accuracy: 0.5408\n",
            "Epoch 68/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.9851 - accuracy: 0.5654 - val_loss: 1.0192 - val_accuracy: 0.5427\n",
            "Epoch 69/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.9227 - accuracy: 0.5846 - val_loss: 1.0221 - val_accuracy: 0.5560\n",
            "Epoch 70/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.9622 - accuracy: 0.5710 - val_loss: 1.0345 - val_accuracy: 0.5674\n",
            "Epoch 71/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.9513 - accuracy: 0.5888 - val_loss: 1.0405 - val_accuracy: 0.5389\n",
            "Epoch 72/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.9505 - accuracy: 0.5900 - val_loss: 1.0158 - val_accuracy: 0.5465\n",
            "Epoch 73/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.9142 - accuracy: 0.5950 - val_loss: 1.0321 - val_accuracy: 0.5351\n",
            "Epoch 74/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.9035 - accuracy: 0.5965 - val_loss: 1.0068 - val_accuracy: 0.5408\n",
            "Epoch 75/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.9027 - accuracy: 0.6075 - val_loss: 1.0157 - val_accuracy: 0.5389\n",
            "Epoch 76/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.9756 - accuracy: 0.5690 - val_loss: 0.9800 - val_accuracy: 0.5693\n",
            "Epoch 77/200\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.9424 - accuracy: 0.5867 - val_loss: 0.9902 - val_accuracy: 0.5617\n",
            "Epoch 78/200\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.9355 - accuracy: 0.5955 - val_loss: 1.0184 - val_accuracy: 0.5541\n",
            "Epoch 79/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.9568 - accuracy: 0.5849 - val_loss: 0.9990 - val_accuracy: 0.5427\n",
            "Epoch 80/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.9019 - accuracy: 0.6100 - val_loss: 1.0078 - val_accuracy: 0.5446\n",
            "Epoch 81/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.9052 - accuracy: 0.6064 - val_loss: 0.9971 - val_accuracy: 0.5617\n",
            "Epoch 82/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.8766 - accuracy: 0.6105 - val_loss: 1.0079 - val_accuracy: 0.5712\n",
            "Epoch 83/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.8949 - accuracy: 0.6065 - val_loss: 1.1001 - val_accuracy: 0.5351\n",
            "Epoch 84/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.9304 - accuracy: 0.6005 - val_loss: 0.9961 - val_accuracy: 0.5522\n",
            "Epoch 85/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.8795 - accuracy: 0.6161 - val_loss: 1.0307 - val_accuracy: 0.5503\n",
            "Epoch 86/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.8969 - accuracy: 0.5906 - val_loss: 1.0582 - val_accuracy: 0.5579\n",
            "Epoch 87/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.8899 - accuracy: 0.6110 - val_loss: 1.0039 - val_accuracy: 0.5769\n",
            "Epoch 88/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.9040 - accuracy: 0.6029 - val_loss: 1.0479 - val_accuracy: 0.5446\n",
            "Epoch 89/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.8552 - accuracy: 0.6242 - val_loss: 1.0117 - val_accuracy: 0.5579\n",
            "Epoch 90/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.8778 - accuracy: 0.6098 - val_loss: 1.0396 - val_accuracy: 0.5484\n",
            "Epoch 91/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.8415 - accuracy: 0.6230 - val_loss: 1.0270 - val_accuracy: 0.5731\n",
            "Epoch 92/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.8673 - accuracy: 0.6183 - val_loss: 1.0393 - val_accuracy: 0.5579\n",
            "Epoch 93/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.8398 - accuracy: 0.6393 - val_loss: 1.0664 - val_accuracy: 0.5465\n",
            "Epoch 94/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.8504 - accuracy: 0.6341 - val_loss: 1.0674 - val_accuracy: 0.5484\n",
            "Epoch 95/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.8478 - accuracy: 0.6374 - val_loss: 1.0748 - val_accuracy: 0.5636\n",
            "Epoch 96/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.8887 - accuracy: 0.6135 - val_loss: 1.0134 - val_accuracy: 0.5844\n",
            "Epoch 97/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.8491 - accuracy: 0.6388 - val_loss: 1.0609 - val_accuracy: 0.5560\n",
            "Epoch 98/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.8071 - accuracy: 0.6477 - val_loss: 1.0821 - val_accuracy: 0.5598\n",
            "Epoch 99/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.8384 - accuracy: 0.6346 - val_loss: 1.0841 - val_accuracy: 0.5598\n",
            "Epoch 100/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.9213 - accuracy: 0.6047 - val_loss: 1.0821 - val_accuracy: 0.5389\n",
            "Epoch 101/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.8324 - accuracy: 0.6472 - val_loss: 1.1044 - val_accuracy: 0.5522\n",
            "Epoch 102/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.8541 - accuracy: 0.6314 - val_loss: 1.0922 - val_accuracy: 0.5825\n",
            "Epoch 103/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.8103 - accuracy: 0.6472 - val_loss: 1.1025 - val_accuracy: 0.5522\n",
            "Epoch 104/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.8028 - accuracy: 0.6571 - val_loss: 1.0741 - val_accuracy: 0.5522\n",
            "Epoch 105/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.8516 - accuracy: 0.6361 - val_loss: 1.0960 - val_accuracy: 0.5522\n",
            "Epoch 106/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.8145 - accuracy: 0.6551 - val_loss: 1.0723 - val_accuracy: 0.5636\n",
            "Epoch 107/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.7875 - accuracy: 0.6616 - val_loss: 1.0985 - val_accuracy: 0.5560\n",
            "Epoch 108/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.7697 - accuracy: 0.6706 - val_loss: 1.0832 - val_accuracy: 0.5579\n",
            "Epoch 109/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.7755 - accuracy: 0.6694 - val_loss: 1.1115 - val_accuracy: 0.5522\n",
            "Epoch 110/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.7608 - accuracy: 0.6902 - val_loss: 1.1027 - val_accuracy: 0.5598\n",
            "Epoch 111/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.7996 - accuracy: 0.6592 - val_loss: 1.1019 - val_accuracy: 0.5655\n",
            "Epoch 112/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.7871 - accuracy: 0.6761 - val_loss: 1.0643 - val_accuracy: 0.5825\n",
            "Epoch 113/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.7864 - accuracy: 0.6543 - val_loss: 1.0879 - val_accuracy: 0.5750\n",
            "Epoch 114/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.7636 - accuracy: 0.6759 - val_loss: 1.1291 - val_accuracy: 0.5655\n",
            "Epoch 115/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.7533 - accuracy: 0.6797 - val_loss: 1.1273 - val_accuracy: 0.5617\n",
            "Epoch 116/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.7562 - accuracy: 0.6750 - val_loss: 1.1453 - val_accuracy: 0.5389\n",
            "Epoch 117/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.7942 - accuracy: 0.6612 - val_loss: 1.1012 - val_accuracy: 0.5541\n",
            "Epoch 118/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.7549 - accuracy: 0.6770 - val_loss: 1.2196 - val_accuracy: 0.5332\n",
            "Epoch 119/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.7855 - accuracy: 0.6502 - val_loss: 1.1621 - val_accuracy: 0.5446\n",
            "Epoch 120/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.8051 - accuracy: 0.6567 - val_loss: 1.1712 - val_accuracy: 0.5712\n",
            "Epoch 121/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.7204 - accuracy: 0.7000 - val_loss: 1.1190 - val_accuracy: 0.5731\n",
            "Epoch 122/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.7621 - accuracy: 0.6708 - val_loss: 1.1302 - val_accuracy: 0.5750\n",
            "Epoch 123/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.7237 - accuracy: 0.6975 - val_loss: 1.1739 - val_accuracy: 0.5693\n",
            "Epoch 124/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.7399 - accuracy: 0.6835 - val_loss: 1.1748 - val_accuracy: 0.5787\n",
            "Epoch 125/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.7348 - accuracy: 0.6884 - val_loss: 1.2171 - val_accuracy: 0.5693\n",
            "Epoch 126/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.7767 - accuracy: 0.6642 - val_loss: 1.1020 - val_accuracy: 0.5787\n",
            "Epoch 127/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.7056 - accuracy: 0.7010 - val_loss: 1.1369 - val_accuracy: 0.5674\n",
            "Epoch 128/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.7294 - accuracy: 0.6854 - val_loss: 1.1660 - val_accuracy: 0.5693\n",
            "Epoch 129/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.6936 - accuracy: 0.6959 - val_loss: 1.2337 - val_accuracy: 0.5636\n",
            "Epoch 130/200\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.7610 - accuracy: 0.6756 - val_loss: 1.1892 - val_accuracy: 0.5712\n",
            "Epoch 131/200\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.7991 - accuracy: 0.6675 - val_loss: 1.1971 - val_accuracy: 0.5636\n",
            "Epoch 132/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.6901 - accuracy: 0.7048 - val_loss: 1.1953 - val_accuracy: 0.5712\n",
            "Epoch 133/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.6959 - accuracy: 0.7145 - val_loss: 1.2290 - val_accuracy: 0.5636\n",
            "Epoch 134/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.6754 - accuracy: 0.7190 - val_loss: 1.2685 - val_accuracy: 0.5541\n",
            "Epoch 135/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.6689 - accuracy: 0.7147 - val_loss: 1.1984 - val_accuracy: 0.5617\n",
            "Epoch 136/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.6877 - accuracy: 0.7134 - val_loss: 1.2304 - val_accuracy: 0.5636\n",
            "Epoch 137/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.6802 - accuracy: 0.7135 - val_loss: 1.2844 - val_accuracy: 0.5674\n",
            "Epoch 138/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.6550 - accuracy: 0.7281 - val_loss: 1.2311 - val_accuracy: 0.5598\n",
            "Epoch 139/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.6573 - accuracy: 0.7259 - val_loss: 1.2604 - val_accuracy: 0.5560\n",
            "Epoch 140/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.6536 - accuracy: 0.7192 - val_loss: 1.2819 - val_accuracy: 0.5446\n",
            "Epoch 141/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.6286 - accuracy: 0.7317 - val_loss: 1.3019 - val_accuracy: 0.5636\n",
            "Epoch 142/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.6537 - accuracy: 0.7216 - val_loss: 1.2880 - val_accuracy: 0.5465\n",
            "Epoch 143/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.8409 - accuracy: 0.6504 - val_loss: 1.2837 - val_accuracy: 0.5408\n",
            "Epoch 144/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.6784 - accuracy: 0.7127 - val_loss: 1.3093 - val_accuracy: 0.5579\n",
            "Epoch 145/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.6868 - accuracy: 0.7134 - val_loss: 1.2460 - val_accuracy: 0.5674\n",
            "Epoch 146/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.6082 - accuracy: 0.7555 - val_loss: 1.2938 - val_accuracy: 0.5465\n",
            "Epoch 147/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.6880 - accuracy: 0.7145 - val_loss: 1.2758 - val_accuracy: 0.5712\n",
            "Epoch 148/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.6874 - accuracy: 0.7136 - val_loss: 1.3309 - val_accuracy: 0.5674\n",
            "Epoch 149/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.5926 - accuracy: 0.7509 - val_loss: 1.3315 - val_accuracy: 0.5522\n",
            "Epoch 150/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.6003 - accuracy: 0.7507 - val_loss: 1.3716 - val_accuracy: 0.5522\n",
            "Epoch 151/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.7440 - accuracy: 0.6890 - val_loss: 1.3353 - val_accuracy: 0.5275\n",
            "Epoch 152/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.6249 - accuracy: 0.7385 - val_loss: 1.2759 - val_accuracy: 0.5541\n",
            "Epoch 153/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.6247 - accuracy: 0.7443 - val_loss: 1.3317 - val_accuracy: 0.5769\n",
            "Epoch 154/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.6120 - accuracy: 0.7437 - val_loss: 1.3672 - val_accuracy: 0.5389\n",
            "Epoch 155/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.6095 - accuracy: 0.7550 - val_loss: 1.4459 - val_accuracy: 0.5332\n",
            "Epoch 156/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.6375 - accuracy: 0.7387 - val_loss: 1.4640 - val_accuracy: 0.5294\n",
            "Epoch 157/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.6109 - accuracy: 0.7380 - val_loss: 1.4069 - val_accuracy: 0.5617\n",
            "Epoch 158/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.6005 - accuracy: 0.7526 - val_loss: 1.3992 - val_accuracy: 0.5522\n",
            "Epoch 159/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.6171 - accuracy: 0.7457 - val_loss: 1.4463 - val_accuracy: 0.5446\n",
            "Epoch 160/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.5782 - accuracy: 0.7560 - val_loss: 1.4323 - val_accuracy: 0.5427\n",
            "Epoch 161/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.5785 - accuracy: 0.7565 - val_loss: 1.4796 - val_accuracy: 0.5104\n",
            "Epoch 162/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.5779 - accuracy: 0.7592 - val_loss: 1.4640 - val_accuracy: 0.5351\n",
            "Epoch 163/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.5640 - accuracy: 0.7643 - val_loss: 1.4662 - val_accuracy: 0.5427\n",
            "Epoch 164/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.5967 - accuracy: 0.7574 - val_loss: 1.4772 - val_accuracy: 0.5351\n",
            "Epoch 165/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.5889 - accuracy: 0.7462 - val_loss: 1.4953 - val_accuracy: 0.5199\n",
            "Epoch 166/200\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.5646 - accuracy: 0.7676 - val_loss: 1.5470 - val_accuracy: 0.5275\n",
            "Epoch 167/200\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.6245 - accuracy: 0.7364 - val_loss: 1.5687 - val_accuracy: 0.5465\n",
            "Epoch 168/200\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.6181 - accuracy: 0.7415 - val_loss: 1.5156 - val_accuracy: 0.5161\n",
            "Epoch 169/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.5518 - accuracy: 0.7692 - val_loss: 1.4620 - val_accuracy: 0.5389\n",
            "Epoch 170/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.5328 - accuracy: 0.7836 - val_loss: 1.5202 - val_accuracy: 0.5598\n",
            "Epoch 171/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.5122 - accuracy: 0.7891 - val_loss: 1.5577 - val_accuracy: 0.5351\n",
            "Epoch 172/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.5238 - accuracy: 0.7931 - val_loss: 1.6164 - val_accuracy: 0.5560\n",
            "Epoch 173/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.5366 - accuracy: 0.7733 - val_loss: 1.5110 - val_accuracy: 0.5218\n",
            "Epoch 174/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.5521 - accuracy: 0.7665 - val_loss: 1.5333 - val_accuracy: 0.5446\n",
            "Epoch 175/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.5202 - accuracy: 0.7760 - val_loss: 1.5824 - val_accuracy: 0.5446\n",
            "Epoch 176/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.5143 - accuracy: 0.7944 - val_loss: 1.5722 - val_accuracy: 0.5294\n",
            "Epoch 177/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.5623 - accuracy: 0.7615 - val_loss: 1.5674 - val_accuracy: 0.5484\n",
            "Epoch 178/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.5906 - accuracy: 0.7444 - val_loss: 1.7015 - val_accuracy: 0.5351\n",
            "Epoch 179/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.5601 - accuracy: 0.7756 - val_loss: 1.6100 - val_accuracy: 0.5199\n",
            "Epoch 180/200\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.5485 - accuracy: 0.7711 - val_loss: 1.6746 - val_accuracy: 0.5370\n",
            "Epoch 181/200\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.5772 - accuracy: 0.7622 - val_loss: 1.5976 - val_accuracy: 0.5484\n",
            "Epoch 182/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.5411 - accuracy: 0.7761 - val_loss: 1.6902 - val_accuracy: 0.5294\n",
            "Epoch 183/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.4980 - accuracy: 0.8049 - val_loss: 1.6711 - val_accuracy: 0.5389\n",
            "Epoch 184/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.5374 - accuracy: 0.7755 - val_loss: 1.6508 - val_accuracy: 0.5313\n",
            "Epoch 185/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.4501 - accuracy: 0.8152 - val_loss: 1.5925 - val_accuracy: 0.5446\n",
            "Epoch 186/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.4902 - accuracy: 0.8032 - val_loss: 1.6303 - val_accuracy: 0.5503\n",
            "Epoch 187/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.4773 - accuracy: 0.8086 - val_loss: 1.6132 - val_accuracy: 0.5484\n",
            "Epoch 188/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.4863 - accuracy: 0.8037 - val_loss: 1.7508 - val_accuracy: 0.5218\n",
            "Epoch 189/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.5370 - accuracy: 0.7889 - val_loss: 1.6387 - val_accuracy: 0.5503\n",
            "Epoch 190/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.4616 - accuracy: 0.8090 - val_loss: 1.6519 - val_accuracy: 0.5313\n",
            "Epoch 191/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.4579 - accuracy: 0.8153 - val_loss: 1.7177 - val_accuracy: 0.5427\n",
            "Epoch 192/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.4767 - accuracy: 0.8032 - val_loss: 1.7854 - val_accuracy: 0.5313\n",
            "Epoch 193/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.6279 - accuracy: 0.7377 - val_loss: 1.8055 - val_accuracy: 0.5332\n",
            "Epoch 194/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.6704 - accuracy: 0.7505 - val_loss: 1.7862 - val_accuracy: 0.5484\n",
            "Epoch 195/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.5022 - accuracy: 0.7966 - val_loss: 1.6562 - val_accuracy: 0.5465\n",
            "Epoch 196/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.4753 - accuracy: 0.8058 - val_loss: 1.7336 - val_accuracy: 0.5427\n",
            "Epoch 197/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.4525 - accuracy: 0.8211 - val_loss: 1.7860 - val_accuracy: 0.5503\n",
            "Epoch 198/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.6274 - accuracy: 0.7538 - val_loss: 1.7833 - val_accuracy: 0.5218\n",
            "Epoch 199/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.4642 - accuracy: 0.8116 - val_loss: 1.7715 - val_accuracy: 0.5446\n",
            "Epoch 200/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.4373 - accuracy: 0.8211 - val_loss: 1.7251 - val_accuracy: 0.5256\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OcxSAMrpWwn6"
      },
      "source": [
        "model.save('./basic_mfcc26_merged.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zy5l6YUakCQp"
      },
      "source": [
        "###test_result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VyJOB76K5VzA",
        "outputId": "34d9eebd-e494-42fe-f63d-d06ca08105ff"
      },
      "source": [
        "d = {0: 'happy',\n",
        "     1: 'sad',\n",
        "     2: 'angry',\n",
        "     3: 'fear'}\n",
        "Y_test_pred = np.argmax(model.predict(X_test), axis=-1)\n",
        "Y_test_pred = list(map(lambda x: d[x], Y_test_pred))\n",
        "y_test = np.argmax(y_test, axis=-1)\n",
        "y_test = list(map(lambda x: d[x], y_test))\n",
        "print(classification_report(y_test, Y_test_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.71      0.73      0.72       151\n",
            "        fear       0.42      0.33      0.37       136\n",
            "       happy       0.50      0.54      0.52       140\n",
            "         sad       0.63      0.69      0.66       159\n",
            "\n",
            "    accuracy                           0.58       586\n",
            "   macro avg       0.57      0.57      0.57       586\n",
            "weighted avg       0.57      0.58      0.57       586\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmwdO_F15VzC",
        "outputId": "f22182b9-087c-4745-fdfb-6f33ac931aab"
      },
      "source": [
        "import scikitplot as skplt\n",
        "\n",
        "skplt.metrics.plot_confusion_matrix(\n",
        "    y_test, \n",
        "    Y_test_pred,\n",
        "    figsize=(8,8))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<AxesSubplot:title={'center':'Confusion Matrix'}, xlabel='Predicted label', ylabel='True label'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe0AAAHBCAYAAABE2uO2AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8+yak3AAAACXBIWXMAAAsTAAALEwEAmpwYAAA3N0lEQVR4nO3dd7wU1f3/8debIhZQULAXJCIqKgqI3WBvRIkKdjEaWxBLNPYWu7/4tSWWYFfsvSOKECsoRRRsqEikKAJiBBvl8/tjB7xcKZfL7p27h/fTxz7YOTM789ll5bOfM2fOKCIwMzOz2q9O3gGYmZlZ1Thpm5mZlQknbTMzszLhpG1mZlYmnLTNzMzKhJO2mZlZmaiXdwBmZmbFVnf5dSJm/FjUfcaP37wYEXsUdaeLyEnbzMySEzN+pEGrrkXd50/v3ti0qDusBidtMzNLkEDpnQF20jYzs/QIkPKOoujS+xliZmaWKFfaZmaWpgS7x9N7R2ZmZolypW1mZmlK8Jy2k7aZmSUozdHj6b0jMzOzRLnSNjOzNCXYPe5K28zMrEy40jYzs/QIn9M2MzOz/LjSNjOzBCnJc9pO2mZmliZ3j5uZmVleXGmbmVmaEuwed6VtZmZWJlxpm5lZgtKcxtRJ28zM0iPcPW5mZmb5caVtZmZpSrB7PL13ZJYTSctIekbSd5IeWYz9HCqpTzFjy4OkFyR1yzsOs5Q4adsSR9IhkgZJmippfJZctivCrg8AVgFWiogu1d1JRNwXEbsVIZ65SOooKSQ9Uam9Tdbev4r7uUhSr4VtFxF7RsTd1QzXbDFlA9GK+agFakcUZjVE0l+B64DLKSTYtYGbgH2LsPt1gE8iYkYR9lUq3wBbS1qpQls34JNiHUAF/rfF8ldHxX3UAv4fy5YYklYALga6R8TjETEtIqZHxDMR8bdsmwaSrpM0LntcJ6lBtq6jpDGSTpM0IavS/5St+ztwAXBgVsEfXbkildQ8q2jrZctHSvpc0veSRkk6tEL76xVet42kd7Ju93ckbVNhXX9Jl0h6I9tPH0lNF/Ax/AI8CRyUvb4ucCBwX6XP6npJX0r6n6TBkrbP2vcAzqnwPodViOMySW8APwAtsrY/Z+tvlvRYhf1fJamvlODwXrMSctK2JcnWwNLAEwvY5lxgK2AzoA3QATivwvpVgRWANYCjgRslNYmICylU7w9FRMOIuH1BgUhaDrgB2DMiGgHbAO/OY7sVgeeybVcCrgGeq1QpHwL8CVgZWAo4fUHHBu4Bjsie7w4MB8ZV2uYdCp/BisD9wCOSlo6I3pXeZ5sKrzkcOBZoBIyutL/TgE2yHyTbU/jsukVELCRWs+qZfWtOd4+bla2VgIkL6b4+FLg4IiZExDfA3ykko9mmZ+unR8TzwFSgVTXjmQVsLGmZiBgfESPmsc3ewMiIuDciZkTEA8BHwB8qbHNnRHwSET8CD1NItvMVEW8CK0pqRSF53zOPbXpFxKTsmP8HNGDh7/OuiBiRvWZ6pf39QOFzvAboBfSIiDEL2Z+ZVeKkbUuSSUDT2d3T87E6c1eJo7O2OfuolPR/ABouaiARMY1Ct/TxwHhJz0naoArxzI5pjQrLX1UjnnuBE4EdmUfPg6TTJX2YdclPodC7sKBud4AvF7QyIgYCn1OogR6uQoxmi0cq7qMWcNK2JclbwM9A5wVsM47CgLLZ1ua3XcdVNQ1YtsLyqhVXRsSLEbErsBqF6vnWKsQzO6ax1YxptnuBvwDPZ1XwHFn39RlAV6BJRDQGvqOQbAHm16W9wK5uSd0pVOzjsv2blZBHj5uVtYj4jsJgsRsldZa0rKT6kvaU9P+yzR4AzpPULBvQdQGF7tzqeBfYQdLa2SC4s2evkLSKpH2zc9s/U+hmnzWPfTwPrJ9dplZP0oHARsCz1YwJgIgYBfyewjn8yhoBMyiMNK8n6QJg+QrrvwaaL8oIcUnrA5cCh1HoJj9D0mbVi95syeWkbUuU7PzsXykMLvuGQpfuiRRGVEMhsQwC3gPeB4ZkbdU51kvAQ9m+BjN3oq2TxTEOmEwhgZ4wj31MAjpRGMg1iUKF2ikiJlYnpkr7fj0i5tWL8CLQm8JlYKOBn5i763v2xDGTJA1Z2HGy0xG9gKsiYlhEjKQwAv3e2SPzzUoiwe5xefCmmZmlps7ya0aDLXsUdZ8/vXzW4IhoX9SdLiLPPW5mZmmqJeehiym9d2RmZpYoV9pmZpaeWnQeuphcaZuZWZpq+JIvSXdkUxwPr9C2oqSXJI3M/myStUvSDZI+lfSepLZVeUtO2mZmZsVxF7BHpbazgL4R0RLomy0D7Am0zB7HAjdX5QBLVPe46i0TWqpR3mEkbZNWa+UdwhJh+sx5XdJtxbRM/bp5h5C80aO/YOLEiaXrw67h7vGIeFVS80rN+wIds+d3A/2BM7P2e7L59wdIaixptYgYv6BjLFlJe6lGNGjVNe8wkta7/zV5h7BEGPftT3mHkLzWay6/8I1ssWy7Za5XT9WUVSok4q8o3BIYClMRV5z/YEzW5qRtZmZLGpXikq+mkgZVWO4ZET2r+uKICEmLNTmKk7aZmaWp+N3jE6sxucrXs7u9Ja0GTMjaxwIVzyeuSRXuKeCBaGZmZqXzNNAte94NeKpC+xHZKPKtgO8Wdj4bXGmbmVmKRI3PiCbpAQqDzppKGgNcCFwJPCzpaApz+c8eWPU8sBfwKYVb6v6pKsdw0jYzMyuCiDh4Pqt2nse2AXRf1GM4aZuZWYJKMhAtd07aZmaWJk9jamZmZnlxpW1mZmlKsHs8vXdkZmaWKFfaZmaWJp/TNjMzs7y40jYzs/TIl3yZmZmVD3ePm5mZWV5caZuZWZLkStvMzMzy4krbzMySI9KstJ20zcwsPcoeiXH3uJmZWZlwpW1mZglSkt3jrrTNzMzKhCttMzNLUoqVtpO2mZklKcWk7e5xMzOzMuFK28zMkuRK28zMzHLjStvMzNLjyVXMzMwsT660zcwsOUp0chUnbTMzS1KKSdvd42ZmZmXClbaZmSXJlbaZmZnlxpW2mZklKcVK20nbzMzS4+u0zczMLE+utM3MLEkpdo+70s7RLRceyui+VzDokXPmtO23y+YMfvRcpg2+gbYbrT3X9qcftRvDn7qQYU+czy5bb1jT4Sbh1O7Hssl6a7Lj1pvPabv4/LPYfotN2Hmbdhx1aBe+mzIlvwAT8NW4MRx3cCe67NqBrrttyQN33jxn3YN3/Zv9d25P19225Porzs8xynT89NNPbLd1Bzq0bUPbNq255O8X5h2SlZCTdo7ufWYA+3a/ca62EZ+N46DTbuX1IZ/N1b5Bi1Xpsntb2h5wGft0v4nrz+5KnTrp/YostQMPOZz7Hn1mrrYddtyZfm8Npe+bg2mxXkv+ee3/yym6NNSrV49Tz72UR156mzsff5lH7rmVz0d+xKC3XuXVl5/jgeff4OE+Azn8mJPyDjUJDRo0oPdLr/D2kGEMHPQufV7szcABA/IOK3ezZ0Qr5qM2KMukLSmJbv03hnzG5O9+mKvt41FfM3L0hN9s26njpjzy4hB+mT6D0eMm8dmXE9li4+Y1FGk6ttp2e5o0aTJXW8eddqVevcJXql37LRk/bmweoSWj6cqrssHGmwGwXMNGNF+vFRO+GsejvW6n2/GnslSDBgCs2LRZjlGmQxINGzYEYPr06cyYPr3WJJi8OWlXk6QnJQ2WNELSsVnbVEmXSRomaYCkVbL232XL70u6VNLUrL2jpNckPQ18IOliSadUOMZlkk6uifeThzWarcCYr76dszx2wresvvIKOUaUpgd63cVOu+yedxjJGDdmNB9/8B4bb9ae/476jHffeYtunXfi2AP3YsSwwXmHl4yZM2eyZbvNWHv1ldlpl13psOWWeYdkJVJTlfZREdEOaA+cJGklYDlgQES0AV4Fjsm2vR64PiI2AcZU2k9b4OSIWB+4AzgCQFId4CCgV+UDSzpW0iBJg2LGjyV4a5aK66++knr16rFf14PzDiUJP0ybyhknHM5p519Bw0bLM2PmDL6b8i13PdGXk86+hLNPPJKIyDvMJNStW5eBg9/l0y/GMOidtxkxfHjeIdUOKvKjFqippH2SpGHAAGAtoCXwC/Bstn4w0Dx7vjXwSPb8/kr7eTsiRgFExBfAJEmbA7sBQyNiUuUDR0TPiGgfEe1Vb5nivaMaNvab71hz1V+7dddYuQnjJnyXY0Rpeei+e3j5xef5161315pusHI2Y/p0zjjhcPbYtys77bEPAKusujo77fEHJLHxZu1QnTpMmfyb/2VtMTRu3Jjfd9yRPn165x2KlUjJk7akjsAuwNZZVT0UWBqYHr/+zJ5J1S4/m1Zp+TbgSOBPFCrvZD3X/z267N6WperXY53VV2K9tZvxzvAv8g4rCf1efpGbbvg/7nrgMZZddtm8wyl7EcHFZ57Iuuu14rA/nzin/fe77c2gt14DYPTnnzJj+nQar7hSXmEm45tvvmFKdsXDjz/+SN+XX6JVqw3yDao2UJrntGtiQNcKwLcR8YOkDYCtFrL9AGB/4CEKXd4L8gRwMVAfOGRxA61pd19xJNu3a0nTxg35tPclXHLL83z73TSuObMLTZs05PEbjue9j8eyT/cb+fDzr3isz1CGPnYuM2bO4pQrH2bWLHctLqoTjj6ct15/lcmTJtJuoxacdtb5/Ova/8fPv/zCgZ33AqDdFh246tobF7Inm59hgwbw/BMPsl6r1hyy13YA/OVvF7Bvl8O5+IzudN19K+rXr89FV99ca/4hLGdfjR/PMUd1Y+bMmcyKWex/QFf22rtT3mFZiajU55QkNQCepND9/THQGLgIeDYiGmbbHAB0iogjJbWkcG56GaA3cGhErJFV7KdHRKdK+78FmBIRZy0sljrLrhwNWnUtyvuyefu8/zV5h7BEGPftT3mHkLzWay6fdwjJ23bL9gwePKgkv9zqN/tdrNT5qqLu8+vbugyOiPZF3ekiKnmlHRE/A3vOY1XDCts8CjyaLY4FtoqIkHQQ0Crbpj/Qv+IOsgFoWwFdih64mZmVtRR7cmrj9c7tgH+p8GlPAY6a10aSNqIwkO2JiBhZc+GZmZnlo9Yl7Yh4DWhThe0+AFqUPiIzMys3s2dES01ZzohmZma2JKp1lbaZmVlRpFdoO2mbmVmClOZANHePm5mZlQlX2mZmliRX2mZmZpYbV9pmZpakFCttJ20zM0tTejnb3eNmZmblwpW2mZklKcXucVfaZmZmZcKVtpmZJUfy3ONmZmaWI1faZmaWpBQrbSdtMzNLUopJ293jZmZmZcKVtpmZpSm9QtuVtpmZWblwpW1mZklK8Zy2k7aZmaVHaSZtd4+bmZmVCVfaZmaWHAEJFtqutM3MzMqFK20zM0tQmnOPO2mbmVmSEszZ7h43MzMrF660zcwsSSl2j7vSNjMzKxJJp0oaIWm4pAckLS1pXUkDJX0q6SFJS1V3/07aZmaWHhXOaRfzsdBDSmsAJwHtI2JjoC5wEHAVcG1ErAd8Cxxd3bflpG1mZlY89YBlJNUDlgXGAzsBj2br7wY6L87OzczMkiKgTp2aPacdEWMlXQ38F/gR6AMMBqZExIxsszHAGtU9hittMzNLUgm6x5tKGlThcezcx1MTYF9gXWB1YDlgj2K+J1faZmZmVTMxItovYP0uwKiI+AZA0uPAtkBjSfWyantNYGx1A3ClbWZmSZJU1EcV/BfYStKyKrxgZ+ADoB9wQLZNN+Cp6r4nJ20zM7MiiIiBFAacDQHep5BjewJnAn+V9CmwEnB7dY/h7nEzM0tPFS/TKraIuBC4sFLz50CHYux/iUrarddfi6dfujrvMJL21Afj8g5hidCyScO8Q0jew+9+mXcIyZv84y8l23fh1pyeEc3MzMxyskRV2mZmtqRI89acrrTNzMzKhCttMzNLUoKFtpO2mZmlyd3jZmZmlhtX2mZmlp6crtMuNVfaZmZmZcKVtpmZJceTq5iZmVmuXGmbmVmSEiy0nbTNzCxN7h43MzOz3LjSNjOzJCVYaLvSNjMzKxeutM3MLD1K85y2k7aZmSWncJ123lEUn7vHzczMyoQrbTMzS5CS7B53pW1mZlYmXGmbmVmSEiy0nbTNzCxN7h43MzOz3LjSNjOz9CjN7nFX2mZmZmXClbaZmSWnMLlKeqW2K20zM7My4UrbzMySlGKl7aRtZmZJSjBnu3vczMysXLjSNjOzJKXYPe5K28zMrEy40jYzs/QkOrmKk7aZmSVHvjWnmZmZ5cmVtpmZJSnBQtuVtpmZWblwpW1mZkmqk2Cp7aRtZmZJSjBnu3vczMysXLjSriXOOOk4+r30Ais1bUbv1wbPab/71pu4945/U7duXXbcdQ/OuvDyHKNMw6yZM7niqH1o3GxVul99O3dfejojhw5kmYaNADji3KtZa/2Nco6yfP3y80+cevg+TP/lF2bOmMEOu/+Bbj3O5OpzT+aTEcOICNZs3oIzLv8nyyzXMO9wy9qsmTO58IhONFl5Ff567V3cct5JjPrwPerWq0eL1ptx5DlXUK9e/bzDzIWU5oxotSJpSzoJOAEYEhGH5h1PHg446HCOOPp4Tj/xz3Pa3nr9P7zU+1me6/82DRo0YOI3E3KMMB2vPHwnqzZfj5+mTZ3Ttl/3s2m70145RpWO+ks14Oo7H2eZ5RoyY/p0TjmsE1tsvzMnnH0py2U/jG6+8nyevP92Dj7m5JyjLW99HryD1dddjx+nfQ/A1nt25rhLrgfg5vN68J8nH2TnAw7PM0QrstrSPf4XYNfFSdiSasUPkOrqsM12NG6y4lxt993Zk+NPOp0GDRoA0LTZynmElpRvJ4xn+Jv92PYPB+YdSrIkzamgZ8yYzozp05E0J2FHBD//9BMivSqoJk3+ejzDXu/L7/c9aE5bm213QipMKtKi9WZ8O2F8jhHmr46K+6gNck/akm4BWgAvSDpX0h2S3pY0VNK+2TbNJb0maUj22CZr75i1Pw18kOPbKIlRn33KOwPe4I+7b89B++zKsKGD8g6p7D1y3cX8sftZ1Kkz91f/qZ5Xc+nhe/DI9Zcw/Zefc4ouHTNnzuS4P3bkgO02pN02HdmwTTsA/nFOD7ps35ovR42k82F/XvBObIHuu+Yiup50Dqrz23/GZ8yYzpvPP84mW/8+h8hqj9k/YIr1qA1yT9oRcTwwDtgRWA54JSI6ZMv/kLQcMIFCJd4WOBC4ocIu2gInR8T6NRt56c2cOYPvvp3M471f5eyLLqfHnw8jIvIOq2y9/0ZfGjVpyjobbDJXe+fjz+CiB/py5u1PMe1/U+jT6985RZiOunXr8u8n+vNgv/f46P0hjPrkQwD+dvk/eeg/77N2i/Xp/8KT+QZZxt597WWWb9KUdTfcdJ7r77nyXFpt3oFWm29Zw5FZqeWetCvZDThL0rtAf2BpYG2gPnCrpPeBR4CKo4TejohR89uhpGMlDZI0aPKkb0oWeCmsutoa7N6pM5Jo03YL6tSpw+RJE/MOq2x99t5g3nv9Zc7dbztuv6AHHw9+kzsvOoUVmq6MJOov1YBt9u7CFx8MyzvUZDRcfgU267Ad77z+ypy2unXrsuNenXmtz7M5RlbePhk2iKGvvcRp+2zDzeecyIfvvMkt5xfGBzxx67V8P2UyB596Qc5R5k8q7qM2qG3ngQXsHxEfz9UoXQR8DbSh8EPjpwqrpy1ohxHRE+gJsMlm7cqqTN11rz8w4PX/sPV2v+fzz0Yy/ZdfWHGlpnmHVbY6n3AGnU84A4BPhgzgpftv5U8XXcd3EyewQtOViQjefbUPq7dIrtOmRk2ZPJF69erTcPkV+PmnHxn8Vn8OPLoHY0d/zhrrtCAieKvfi6zdomXeoZatrieeRdcTzwLgw8Fv8UKvf3P8JdfT/8kHGP7Wq5x50wO/OQVkaahtSftFoIekHhERkjaPiKHACsCYiJglqRtQN98wi++kY49g4Buv8e3kiWyz6e84+Yzz6XJIN848+Tj22L4d9esvxT/+dVutOa+SkjsuOoWpUyYTEazVckMOPuOyvEMqa5O/+Zqrzj6RWTNnEbNm8fs99mXL3+/KqYd1YtrUqRBBiw1ac/KF/8g71OTcfeU5rLTqGlxyVGcA2u24B52POSXXmPIiSHKwo2rDOVJJXwDtKVTN1wHbUKioR0VEJ0ktgceAAHoD3SOioaSOwOkR0akqx9lks3bx9MtvFD1++9WLI7/KO4QlQssmvr651MZO/THvEJJ34RF7M+qD90qSWRuvs2Fsd849Rd3nc8d3GBwR7Yu600VUKyrtiGheYfG4eawfCVQccXFm1t6fwrlvMzOzudSWy7SKqVYkbTMzs6KqRZdpFZNHKpiZmZUJV9pmZpakBAttV9pmZmblwpW2mZklR0CdBEttJ20zM0tSgjnb3eNmZmblwpW2mZklyZd8mZmZWW5caZuZWXJq0525islJ28zMkpTi6HF3j5uZmZUJV9pmZpak9OpsV9pmZmZlw5W2mZklyZd8mZmZWW5caZuZWXIKc4/nHUXxzTdpS/onEPNbHxEnlSQiMzOzxSUl2T2+oEp7UI1FYWZmZgs136QdEXdXXJa0bET8UPqQzMzMFl+ChfbCB6JJ2lrSB8BH2XIbSTeVPDIzMzObS1VGj18H7A5MAoiIYcAOJYzJzMxssSk7r12sRxWP2VjSo5I+kvRhVviuKOklSSOzP5tU9z1V6ZKviPiyUtPM6h7QzMys1GaPHi/mo4quB3pHxAZAG+BD4Cygb0S0BPpmy9VSlaT9paRtgJBUX9LpWRBmZmaWkbQChZ7o2wEi4peImALsC8weJ3Y30Lm6x6hK0j4e6A6sAYwDNsuWzczMaq0cusfXBb4B7pQ0VNJtkpYDVomI8dk2XwGrVPc9LXRylYiYCBxa3QOYmZkloqmkipdD94yInhWW6wFtgR4RMVDS9VTqCo+IkDTfOVAWZqFJW1ILCn30W1GYbOUt4NSI+Ly6BzUzMyu1ElzxNTEi2i9g/RhgTEQMzJYfpZC0v5a0WkSMl7QaMKG6AVSle/x+4GFgNWB14BHggeoe0MzMrNQkqCMV9bEwEfEVhXFgrbKmnYEPgKeBbllbN+Cp6r6vqsw9vmxE3FthuZekv1X3gGZmZgnrAdwnaSngc+BPFArkhyUdDYwGulZ35wuae3zF7OkLks4CHqTQPX4g8Hx1D2hmZlYT8pgRLSLeBebVhb5zMfa/oEp7MIUkPfttH1cxLuDsYgRgZmZmVbOgucfXrclAzMzMimlJu8vXHJI2BjYClp7dFhH3lCooMzMz+62qXPJ1IdCRQtJ+HtgTeB1w0jYzs1orwUK7SpX2ARTmTx0aEX+StArQq7RhmZmZVZ+o2mVa5aYq12n/GBGzgBmSlqdwUfhapQ3LzMzMKqtKpT1IUmPgVgojyqdSmBXNzMysdtIS2j0eEX/Jnt4iqTewfES8V9qwzMzMrLIFTa7SdkHrImJIaUIyMzNbfEvaJV//t4B1AexU5FhKbtas4H8/TM87jKRtv3bTvENYIhx516CFb2SL5b6jO+QdQvKWq1+lq46rrSqDtsrNgiZX2bEmAzEzM7MFK+3PHDMzsxyINLvHU+w9MDMzS5IrbTMzS1Kd9ArtKk1jKuBQoEVEXCxpbWDViHi75NGZmZlVU4pJuyrd4zcBWwMHZ8vfAzeWLCIzMzObp6p0j28ZEW0lDQWIiG8lLVXiuMzMzKpNWnIHok2XVJfCtdlIagbMKmlUZmZm9htVqbRvAJ4AVpZ0GYW7fp1X0qjMzMwWU4rntKsy9/h9kgYDO1O49K1zRHxY8sjMzMxsLlUZPb428APwTMW2iPhvKQMzMzNbHAme0q5S9/hzFM5nC1gaWBf4GGhdwrjMzMyqTUCdBLN2VbrHN6m4nN396y/z2dzMzMxKZJFnRIuIIZK2LEUwZmZmxZLiPN1VOaf91wqLdYC2wLiSRWRmZmbzVJVKu1GF5zMonON+rDThmJmZFUeCp7QXnLSzSVUaRcTpNRSPmZnZYpOU5EC0+Xb5S6oXETOBbWswHjMzM5uPBVXab1M4f/2upKeBR4Bps1dGxOMljs3MzKzaEiy0q3ROe2lgErATv16vHYCTtpmZWQ1aUNJeORs5Ppxfk/VsUdKozMzMFtOSNvd4XaAhcyfr2Zy0zcys1loSZ0QbHxEX11gkZmZmtkALStrp/UQxM7MlRoKF9gJnedu5xqIwMzOzhZpvpR0Rk2syEDMzs6JRmgPRUpxP3czMLEmLfJcvMzOzcqAEh2Y5aZuZWXIKl3zlHUXxuXvczMysTLjSNjOzJLnSNjMzs9y40jYzsyQpwdlVnLTNzCw5HohmZmZmuXKlbWZm6dGSN/e4mZmZ1SKutM3MLElL2v20zczMylKqA9GctGuJr8aN4bxTj2PyxAkgsf8hR3LoUX+Zs/6env/kmsvOpd/QUTRZcaUcIy1f48eN4ZyTj2XSxAlI4oBD/sThf/4LV19yLv95+QXq1V+KtdZZl0uvuZnlV2icd7hla50Vl+Hy/VrPWV698dL0/M8XNFy6Hp03X40pP0wH4MZ+n/PmZ76ZYHWcferx9H/pBVZq2oxn+w8C4KMR73HhmSfzw7SprLHWOlx94x00bLR8zpFasZXsnLak5pKGl2r/qalbtx6nnXcZj/d9h3uf7MtD99zKZ598BBQS+luv9WW1NdbKOcryVq9uPf52weU83W8Q9z/9Cg/e3ZPPPvmIrXfYiSf6vs0TLw+geYv1uO1f/5d3qGVt9OQfOfS2QRx62yAOv30QP0+fRb+PvwHggYFj5qxzwq6+/boexm33PzlX27mndee0cy7mmX7vsMuef+C2m67LJbbaRCruozbwQLRaotkqq7LhJpsBsFzDRrRYrxUTvh4HwNUXn80pZ19Se741ZarZKquyUcXPuGUrvv5qHNv+fmfq1St0Om3adgu+Hj8uxyjTskXzJoz59ke++t/PeYeSlC223o4Vmqw4V9sXn3/KFltvB8C2O+xMn+eeyiM0K7FSJ+26km6VNEJSH0nLSDpG0juShkl6TNKyAJLuknSLpEGSPpHUKWs/UtJTkvpLGinpwqz9YkmnzD6QpMsknVzi91Mjxn45mo9GvMcmm7WnX5/naLbqarTaaJO8w0rK2C9H8+Hw99h08/ZztT/x0L1st+OuOUWVnt1ar8yLH0yYs9yl/Rrc/+f2nN+pFY2W9tm5YmrZakP69n4WgN7PPM74cWNyjihvok6RH7VBqZN2S+DGiGgNTAH2Bx6PiC0iog3wIXB0he2bAx2AvYFbJC2dtXfIXrsp0EVSe+AO4AgASXWAg4BeJX4/JffDtKmcfvzh/O2CK6lbrx6333g1f/nruXmHlZQfpk3l1GMP48yLrpzrnN+/b/gHdevWo9N+B+YYXTrq1RE7tGxK3w8LSfuxIWP5400DOPS2QUyc+gun7PK7nCNMy2XX3Mz9d/Vkv922Zdq0qSy11FJ5h2QlUOqfuqMi4t3s+WAKSXljSZcCjYGGwIsVtn84ImYBIyV9DmyQtb8UEZMAJD0ObBcR10maJGlzYBVg6OxtKpJ0LHAsUOvPCU+fPp3Tjj+MvTp3Zec992HkRyMY++Vouu65LQATxo/l4L23p9dT/Wi68io5R1uepk+fzinHHsbef+zKrnvtO6f9yYd78erLL3DbQ88mOV9xHrZZb0U++up7Jk8rDDyb/SfAk0PHc21X9x4V0+9atuKOh54BYNRnI+n/cu+cI8qXSPOMYqmTdsUTWTOBZYC7gM4RMUzSkUDHCttEpdfHQtpvA44EVqVQef9GRPQEegK03rRt5f3UGhHB38/ozrrrteLwY04EoOUGrek35PM52+y57cbc/8x/PHq8miKCC07vTov1WtHt2B5z2l/v9xJ33Hwddz36Assss2yOEaZl941Woc+IX7vGV2q4FJOm/gJAx1ZN+eybaXmFlqRJEyewUtOVmTVrFjdfdxUHHXH0wl+UMvmSr2JpBIyXVB84FBhbYV0XSXcD6wItgI+BzYFdJa0I/Ah0Bo7Ktn8CuBioDxxSI9GXyLuDBvDs4w/ScoPWcyrrHn+7gO132j3nyNIx9J23eOaxB2i5QWv2320bAE4+80KuuOAMfvnlZ445uFB5b9p2Cy688vo8Qy17S9evQ4d1m3D5Cx/PaTtppxasv0pDImD8dz9x+Quf5BhhefvrCd14+83X+HbyJHZo25Iep5/HD9Omcv9dPQHYda992P+gI3KO0kohj6R9PjAQ+Cb7s1GFdf8F3gaWB46PiJ+yrsq3gceANYFeETEIICJ+kdQPmBIRM2vuLRTf5ltszbuj/7fAbV54w1fQLY62HbZh+Jjvf9O+w87+YVRsP02fxa7XvjFX24VPf5RTNOm55ua759ne7ZjuNRxJ7eYZ0RZBRHwBbFxh+eoKq2+ez8tejojj59E+JiI6V27MBqBtBXSpfqRmZmbloWyv05a0EfAp0DciRuYdj5mZ1R6zB6KlNrlKrblQMiKOnE/7XRQGr1Vu/4DCeW8zM7PfSLF7vGwrbTMzsyVNram0zczMiinBQtuVtpmZWblwpW1mZskRaValTtpmZpYekeSUxCn+EDEzM0uSK20zM0tSenW2K20zM7Oy4UrbzMySIzy5ipmZmeXIlbaZmSUpvTrbSdvMzBKVYO+4u8fNzMyKSVJdSUMlPZstrytpoKRPJT0kaanq7ttJ28zMEiSk4j4WwcnAhxWWrwKujYj1gG+Bo6v7rpy0zczMikTSmsDewG3ZsoCdgEezTe4GOld3/z6nbWZmySnR3ONNJQ2qsNwzInpW2uY64AygUba8EjAlImZky2OANaobgJO2mZklqQRzj0+MiPYLOF4nYEJEDJbUsdgHBydtMzOzYtkW2EfSXsDSwPLA9UBjSfWyantNYGx1D+Bz2mZmliQV+bEwEXF2RKwZEc2Bg4BXIuJQoB9wQLZZN+Cp6r4nJ20zM7PSOhP4q6RPKZzjvr26O3L3uJmZpSfn+2lHRH+gf/b8c6BDMfbrpG1mZskp0ejx3KX4nszMzJLkStvMzJKUZ/d4qbjSNjMzKxOutM3MLEnp1dmutM3MzMqGK20zM0tSgqe0nbTNzCw9hUu+0sva7h43MzMrE660zcwsSSl2j7vSNjMzKxOutM3MLEFCCZ7TdtI2M7MkuXvczMzMcuNK28zMkuNLvszMzCxXS1Sl3aB+HVqu2jDvMJI2fMz/8g5hifDQsVvmHULyWu/2t7xDSN7PI8eUbudK85z2EpW0zcxsyZFi0nb3uJmZWZlwpW1mZklK8TptV9pmZmZlwpW2mZklR0Cd9AptJ20zM0uTu8fNzMwsN660zcwsSb7ky8zMzHLjStvMzJLkc9pmZmaWG1faZmaWHF/yZWZmVjbk7nEzMzPLjyttMzNLT6K35nSlbWZmViZcaZuZWZISLLSdtM3MLD2F0ePppW13j5uZmZUJV9pmZpak9OpsV9pmZmZlw5W2mZmlKcFS20nbzMyS5BnRzMzMLDeutM3MLEkJXvHlStvMzKxcuNI2M7MkJVhou9I2MzMrF660zcwsTQmW2k7aZmaWHOFLvszMzCxHrrTNzCw98iVfZmZmliNX2mZmlqQEC20nbTMzS1SCWdvd42ZmZmXClbaZmSVIvuTLzMzM8uNK28zMkpTiJV9O2mZmlhyR5Dg0d4/XZjNnzmTrDm3Zv/Mf8g4lCV+PG8MJh3TiwN235KA9tuLBO28G4JMP3uOo/XfhsE7b0W3fjowYNjjnSMvbmScfxxYbrcMeO7Sf09bjmMPptOOWdNpxS3ZotwGddtwyxwjL0y0XHsrovlcw6JFz5rTtt8vmDH70XKYNvoG2G6091/anH7Ubw5+6kGFPnM8uW29Y0+FaiSSRtCU1lzQ87ziK7cZ/Xk+rDfw/W7HUrVePk8+5lIdeHMjtj77Eo71u4/ORH/HPqy7kzz3OpNezr3PsKefwr6suyDvUsrb/QYdz54NPztX2z1vv5dl+A3m230D22Lszu++9bz7BlbF7nxnAvt1vnKttxGfjOOi0W3l9yGdztW/QYlW67N6Wtgdcxj7db+L6s7tSp06KdedCqMiPWiCJpJ2isWPG0PuF5znyT0fnHUoymq68KhtsvBkAyzVsRPP11uebr8cjiWlTvwdg6vf/o+nKq+UYZfnrsPV2NG684jzXRQTPPf0YnfbrWsNRlb83hnzG5O9+mKvt41FfM3L0hN9s26njpjzy4hB+mT6D0eMm8dmXE9li4+Y1FKmVUq06py1pOeBhYE2gLnAJ0Ar4A7AM8CZwXESEpHbAHdlL++QQbkmdcfqpXHbFVXz//fd5h5KkcWNG88mI92ndph2nnncFJx+5PzdccT4Rs7j1kRfzDi9Z7wx4g6bNVmbdFuvlHUrS1mi2AgPf/2LO8tgJ37L6yivkF1BOfMlX6e0BjIuINhGxMdAb+FdEbJEtLwN0yra9E+gREW0WtENJx0oaJGnQxInflDT4YnnhuWdp1qwZm7dtl3coSfph2lTO+ssRnHr+5TRstDyP33c7p5x3Gc+8MYJTzr2cy87qkXeIyXrm8Yf5wx9dZZtVV21L2u8Du0q6StL2EfEdsKOkgZLeB3YCWktqDDSOiFez1907vx1GRM+IaB8R7Zs2bVbyN1AMb731Bs899wwbrr8u3Q4/mP/0f4Wjjjw877CSMGP6dM7qfgR77NuFHXffB4DnHn9wzvOd9+rMiPeG5BlismbMmMGLzz3N3p33zzuU5I395jvWXLXJnOU1Vm7CuAnf5RhRPqTiPmqDWpW0I+IToC2F5H2ppAuAm4ADImIT4FZg6RxDrBEXX3oFIz//kg8/GcXd9z7A7zvuxB13zfd3iVVRRHDpWSfS/Hfrc8jRJ85pb7bKqgwZ+DoAg958lbXWaZFXiEl749VX+F3L9Vlt9TXzDiV5z/V/jy67t2Wp+vVYZ/WVWG/tZrwz/Iu8w6pxCY5Dq3XntFcHJkdEL0lTgD9nqyZKaggcADwaEVMkTZG0XUS8DhyaU8hWRoYNHsALTz7Eeq024rBO2wFwwmkXcPbl13PNxWcxc+YMGjRYmrMvuz7nSMvbycd1Y+Abr/Lt5Els22Y9Tj7jPLoeeiTPPvEof/hjl7zDK1t3X3Ek27drSdPGDfm09yVccsvzfPvdNK45swtNmzTk8RuO572Px7JP9xv58POveKzPUIY+di4zZs7ilCsfZtasyPstWBEoovb8RUraHfgHMAuYDpwAdAYOBr4CPgFGR8RFFQaiBYWBaHtl573nq2279vH6W++U7g0Yw8f8L+8QlghNGy2VdwjJa73b3/IOIXk/f/wws36YUJIitnWbtvHQ868ufMNFsMmajQZHRPuFb1k6tarSjogXgcpDdwcB581j28FAxUFoZ5QwNDMzs9zVqqRtZmZWLCle8uWkbWZmyRG1Z8R3MdWq0eNmZmY2f660zcwsSQkW2q60zczMyoWTtpmZpamGZ1eRtJakfpI+kDRC0slZ+4qSXpI0MvuzycL2NT9O2mZmliQV+b8qmAGcFhEbAVsB3SVtBJwF9I2IlkDfbLlanLTNzMyKICLGR8SQ7Pn3wIfAGsC+wN3ZZndTmDSsWjwQzczMkpTnJV+SmgObAwOBVSJifLbqK2CV6u7XSdvMzKxqmkoaVGG5Z0T0rLxRdq+Mx4BTIuJ/qvDrISJCUrXnD3fSNjOzJJWg0J64sLnHJdWnkLDvi4jHs+avJa0WEeMlrQZMqG4APqdtZmZWBCqU1LcDH0bENRVWPQ10y553A56q7jFcaZuZWZpq/pz2tsDhwPuS3s3azgGuBB6WdDQwGuha3QM4aZuZWXIKl1bXbNaOiNeZ/0+FnYtxDHePm5mZlQlX2mZmlh75Ll9mZmaWI1faZmaWpAQLbSdtMzNLVIJZ293jZmZmZcKVtpmZJajKd+YqK660zczMyoQrbTMzS1KKl3w5aZuZWXJEkuPQ3D1uZmZWLlxpm5lZmhIstV1pm5mZlQlX2mZmliRf8mVmZma5caVtZmZJ8iVfZmZmZSLBnO3ucTMzs3LhStvMzNKjNLvHXWmbmZmVCVfaZmaWqPRKbSdtMzNLjnD3uJmZmeXIlbaZmSUpwULblbaZmVm5WKIq7aFDBk9crkGd0XnHsYiaAhPzDiJx/oxLz59xzSi3z3mdUu48xXPaS1TSjohmecewqCQNioj2eceRMn/GpefPuGb4c56bbxhiZmZmuVmiKm0zM1uCpFdou9IuAz3zDmAJ4M+49PwZ1wx/zolzpV3LRYT/Jywxf8al58+4ZvhznluChbYrbTMzs3LhpG1Jk3SSpA8l3Zd3LCmQ1FzS8LzjsKpbUv/OpOI/agN3j5cxSfUiYkbecdRyfwF2iYgx1d2BP2ez8uRLvmyxSHpS0mBJIyQdm7VNlXSZpGGSBkhaJWv/Xbb8vqRLJU3N2jtKek3S08AHki6WdEqFY1wm6eQ83l9tI+kWoAXwgqRzJd0h6W1JQyXtm23TPPs8h2SPbbL2uT7nHN9GbVRX0q3Z97iPpGUkHSPpnex7/JikZQEk3SXpFkmDJH0iqVPWfqSkpyT1lzRS0oVZu7/P8yFpOUnPZZ/xcEkHSrog+9yHS+opFepBSe2y7YYB3XMO3YrISbtmHRUR7YD2wEmSVgKWAwZERBvgVeCYbNvrgesjYhOgcpXYFjg5ItYH7gCOAJBUBzgI6FXyd1IGIuJ4YBywI4XP+ZWI6JAt/0PScsAEYNeIaAscCNxQYRcVP2f7VUvgxohoDUwB9gcej4gtsu/xh8DRFbZvDnQA9gZukbR01t4he+2mQBdJ7fH3eUH2AMZFRJuI2BjoDfwr+9w3BpYBOmXb3gn0yP4+llwq8qMWcNKuWSdlv3wHAGtR+MfvF+DZbP1gCv/AAWwNPJI9v7/Sft6OiFEAEfEFMEnS5sBuwNCImFSqN1DGdgPOkvQu0B9YGlgbqA/cKul9Cp/3RhVeM+dztrmMioh3s+ezv7MbZz0T7wOHAq0rbP9wRMyKiJHA58AGWftLETEpIn4EHge28/d5gd4HdpV0laTtI+I7YEdJA7PPfSegtaTGQOOIeDV73b05xWsl4HPaNURSR2AXYOuI+EFSfwqJY3pERLbZTKr2dzKt0vJtwJHAqhQqFfstAftHxMdzNUoXAV8DbSj8iP2pwurKn7MV/Fzh+UwKFd5dQOeIGCbpSKBjhW2CucVC2v19noeI+ERSW2Av4FJJfSl0fbePiC+z7/LSC9rHkqaWFMdF5Uq75qwAfJsl7A2ArRay/QAKXYdQ6CJckCcodJ1tAby4WFGm60WgR4Vzfptn7SsA4yNiFnA4UDen+MpdI2C8pPoUKu2KukiqI+l3FMYYzP7htKukFSUtA3QG3sja/X2eB0mrAz9ERC/gHxRO3wBMlNQQOAAgIqYAUyRtl62v/PexxPDocVscvYHjJX1I4R+tAQvZ/hSgl6Rzs9d+N78NI+IXSf2AKRExs0jxpuYS4Drgvexc6SgK5/9uAh6TdASFz9nVdfWcDwwEvsn+bFRh3X+Bt4HlgeMj4qfst9PbwGPAmkCviBgE/j4vwCYUxmLMAqYDJ1D4sTMc+Ap4p8K2fwLukBRAnxqO00pIv/bMWm2Sjb79MSJC0kHAwRGx73y2rQMMAbpk5w3NagVJdwHPRsSjldqPpNCte+I8XuPvsy22zdq2j1deG1jUfa7UsN7gvO+i5u7x2qsd8K6k9yhca3zavDaStBHwKdDX/8BZufP32WzBXGmbmVlyNm/bPl55vbiV9orLudI2MzOzKnLSNjMzKxMePW5mZkmqLZdpFZMrbbOFkDRT0rvZ/M6PzJ5Xu5r7ukvSAdnz27KBV/PbtuPsudAX8RhfSGpa1fZK20xdxGNdJOn0RY3RzKrHSdts4X6MiM2y+Z1/AY6vuFJStXqsIuLPEbGgm5F0BBY5aZtZgYr8X23gpG22aF4D1qt8FzBJdSX9I7vj0nuSjgNQwb8kfSzpZWDl2TvK7nDVPnu+hwp3GRsmqa+k5hR+HJyaVfnbS2qmwh203ske22avXUmFu22NkHQbVZi9UfO441yFdddm7X0lNcvafiepd/aa17JZ/cyshvmctlkVZRX1nhRmToPCNJIbR8SoLPF9FxFbSGoAvCGpD7A50IrCjUhWoXCbzzsq7bcZcCuwQ7avFSNisgq3Fp0aEVdn290PXBsRr0tam8IUnxsCFwKvR8TFkvZm7jtszc9R2TGWAd6R9Fh2Y47lgEERcaqkC7J9nwj0pDCb2UhJW1KYSW6nanyMZjWjFk09WkxO2mYLt4wKdweDQqV9O4Vu64p3AdsN2HT2+WoKc5q3BHYAHsim4xwn6ZV57H8r4NUKd26bPJ84dgE20q//Ei2fzTm9A7Bf9trnJH1bhfd0kqQ/Zs9n33FuEjALeChr7wU8nh1jG+CRCsduUIVjmOWmFt1Ns6ictM0W7seI2KxiQ5a8Ks5TLgr3L36x0nZ7FTGOOsBWEVHxTmRoEcsJzf+Oc/MS2XGnVP4MzKzm+Zy2WXG8CJyQ3eUKSetLWg54FTgwO+e9GrDjPF47ANhB0rrZa1fM2r9n7htv9AF6zF6QtFn29FXgkKxtT6DJQmJd0B3n6pDdLSrb5+sR8T9glKQu2TEkqc1CjmGWPxX5UQs4aZsVx20UzlcPkTQc+DeFnqwngJHZunuAtyq/MCK+AY6l0BU9jF+7p58B/jh7IBpwEtA+G+j2Ab+OYv87haQ/gkI3+X8XEmtvoJ4Kd5y7krnvODcN6JC9h52Ai7P2Q4Gjs/hGAPO8eY2ZlZbnHjczs+S0bdc+Xn3znYVvuAgaLV0n97nHfU7bzMySlOLocXePm5mZlQlX2mZmlqQEC21X2mZmZuXClbaZmaUpwVLbSdvMzJJUW27yUUzuHjczMysTrrTNzCw5wpd8mZmZWY48I5qZmSVHUm+gaZF3OzEi9ijyPheJk7aZmVmZcPe4mZlZmXDSNjMzKxNO2mZmZmXCSdvMzKxMOGmbmZmVif8PhIKpP+f4yRoAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 576x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a24jVsOEbqv-"
      },
      "source": [
        "# mfcc_39 + basic model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "apn5LW1Ybqwt"
      },
      "source": [
        "features = []\n",
        "labels = []\n",
        "\n",
        "for i in range(len(Ravdess_DF['Paths'])):\n",
        "  if ((Ravdess_DF['Emotion'][i] == '03') | (Ravdess_DF['Emotion'][i] == '04') | \n",
        "      (Ravdess_DF['Emotion'][i] == '05') | (Ravdess_DF['Emotion'][i] == '06')):\n",
        "    signal, sr = librosa.load(Ravdess_DF['Paths'][i])\n",
        "    mfcc = np.mean(librosa.feature.mfcc(y=signal, sr=sr, n_mfcc=39).T,axis=0).tolist()\n",
        "    features.append(mfcc)\n",
        "    if Ravdess_DF['Emotion'][i] == '03':\n",
        "      labels.append(0)\n",
        "    elif Ravdess_DF['Emotion'][i] == '04':\n",
        "      labels.append(1)\n",
        "    elif Ravdess_DF['Emotion'][i] == '05':\n",
        "      labels.append(2)\n",
        "    elif Ravdess_DF['Emotion'][i] == '06':\n",
        "      labels.append(3)\n",
        "\n",
        "for i in range(len(CREMA_D_df)):\n",
        "  if ((CREMA_D_df['Emotion'][i] == 'HAP') | (CREMA_D_df['Emotion'][i] == 'SAD') | \n",
        "      (CREMA_D_df['Emotion'][i] == 'ANG') | (CREMA_D_df['Emotion'][i] == 'FEA')):\n",
        "    \n",
        "    if CREMA_D_df['Emotion'][i] == 'HAP':\n",
        "      labels.append(0)\n",
        "    elif CREMA_D_df['Emotion'][i] == 'SAD':\n",
        "      labels.append(1)\n",
        "    elif CREMA_D_df['Emotion'][i] == 'ANG':\n",
        "      labels.append(2)\n",
        "    elif CREMA_D_df['Emotion'][i] == 'FEA':\n",
        "      labels.append(3)\n",
        "\n",
        "\n",
        "    signal, sr =  librosa.load(CREMA_D_df['Paths'][i])\n",
        "    mfcc = np.mean(librosa.feature.mfcc(y=signal, sr=sr, n_mfcc=39).T,axis=0).tolist()\n",
        "    features.append(mfcc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMPt95hhbqww"
      },
      "source": [
        "X = features\n",
        "y = labels\n",
        "\n",
        "y = np.array(y)\n",
        "y = to_categorical(y)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=0)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=0)\n",
        "\n",
        "X_train = np.array(X_train)\n",
        "X_test = np.array(X_test)\n",
        "X_val = np.array(X_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "enxl5cJsbqwy"
      },
      "source": [
        "## basic models:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jaZaG-npbqwz",
        "outputId": "8cb05311-2c33-4cbe-f862-2cd3f2e5c2d6"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(39, input_shape=(39, ), activation = 'relu'))\n",
        "#model.add(Dropout(0.1))\n",
        "model.add(Dense(128, activation = 'relu'))\n",
        "#model.add(Dropout(0.25))\n",
        "model.add(Dense(128, activation = 'relu'))\n",
        "#model.add(Dropout(0.2))\n",
        "model.add(Dense(4, activation = 'softmax'))\n",
        "\n",
        "optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
        "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer=optimizer)\n",
        "early_stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=100, verbose=1, mode='auto')\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_12 (Dense)             (None, 39)                1560      \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 128)               5120      \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 4)                 516       \n",
            "=================================================================\n",
            "Total params: 23,708\n",
            "Trainable params: 23,708\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "co5Sg1e1bqw0",
        "outputId": "0e847c49-92e7-45dd-f9d9-3c5c62ce23bd"
      },
      "source": [
        "history = model.fit(X_train, y_train, batch_size=64, epochs=200, \n",
        "                    validation_data=(X_val, y_val))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "75/75 [==============================] - 1s 5ms/step - loss: 11.3197 - accuracy: 0.2966 - val_loss: 1.9004 - val_accuracy: 0.3966\n",
            "Epoch 2/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.6547 - accuracy: 0.3615 - val_loss: 1.7576 - val_accuracy: 0.2846\n",
            "Epoch 3/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.4076 - accuracy: 0.3915 - val_loss: 1.8049 - val_accuracy: 0.3283\n",
            "Epoch 4/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.4313 - accuracy: 0.3883 - val_loss: 1.5327 - val_accuracy: 0.3662\n",
            "Epoch 5/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.3498 - accuracy: 0.4216 - val_loss: 1.2664 - val_accuracy: 0.4383\n",
            "Epoch 6/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.3054 - accuracy: 0.4290 - val_loss: 1.1931 - val_accuracy: 0.4649\n",
            "Epoch 7/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.2382 - accuracy: 0.4503 - val_loss: 1.5600 - val_accuracy: 0.3757\n",
            "Epoch 8/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.4452 - accuracy: 0.4199 - val_loss: 2.0901 - val_accuracy: 0.3264\n",
            "Epoch 9/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.4368 - accuracy: 0.4357 - val_loss: 1.2296 - val_accuracy: 0.4611\n",
            "Epoch 10/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.2485 - accuracy: 0.4512 - val_loss: 1.3093 - val_accuracy: 0.4250\n",
            "Epoch 11/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.2509 - accuracy: 0.4400 - val_loss: 1.1675 - val_accuracy: 0.4877\n",
            "Epoch 12/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.2691 - accuracy: 0.4537 - val_loss: 1.1318 - val_accuracy: 0.4687\n",
            "Epoch 13/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.1944 - accuracy: 0.4597 - val_loss: 1.1438 - val_accuracy: 0.4516\n",
            "Epoch 14/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.1824 - accuracy: 0.4665 - val_loss: 1.5757 - val_accuracy: 0.4042\n",
            "Epoch 15/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.3384 - accuracy: 0.4393 - val_loss: 1.2655 - val_accuracy: 0.4554\n",
            "Epoch 16/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.1556 - accuracy: 0.4797 - val_loss: 1.1800 - val_accuracy: 0.5009\n",
            "Epoch 17/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.1288 - accuracy: 0.4936 - val_loss: 1.2432 - val_accuracy: 0.4801\n",
            "Epoch 18/200\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 1.1843 - accuracy: 0.4826 - val_loss: 1.2127 - val_accuracy: 0.4231\n",
            "Epoch 19/200\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 1.1413 - accuracy: 0.4878 - val_loss: 1.0644 - val_accuracy: 0.4991\n",
            "Epoch 20/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0803 - accuracy: 0.5164 - val_loss: 1.3535 - val_accuracy: 0.4459\n",
            "Epoch 21/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.2403 - accuracy: 0.4841 - val_loss: 1.0829 - val_accuracy: 0.4953\n",
            "Epoch 22/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.1005 - accuracy: 0.5071 - val_loss: 1.0574 - val_accuracy: 0.5199\n",
            "Epoch 23/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0680 - accuracy: 0.5101 - val_loss: 1.0706 - val_accuracy: 0.5294\n",
            "Epoch 24/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0959 - accuracy: 0.5105 - val_loss: 1.1272 - val_accuracy: 0.4858\n",
            "Epoch 25/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0760 - accuracy: 0.5100 - val_loss: 1.1743 - val_accuracy: 0.4877\n",
            "Epoch 26/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.1037 - accuracy: 0.5191 - val_loss: 1.1166 - val_accuracy: 0.4763\n",
            "Epoch 27/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0941 - accuracy: 0.4970 - val_loss: 1.1898 - val_accuracy: 0.4972\n",
            "Epoch 28/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0857 - accuracy: 0.5098 - val_loss: 1.0057 - val_accuracy: 0.5541\n",
            "Epoch 29/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0368 - accuracy: 0.5457 - val_loss: 1.1461 - val_accuracy: 0.4877\n",
            "Epoch 30/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0929 - accuracy: 0.4976 - val_loss: 1.0277 - val_accuracy: 0.5275\n",
            "Epoch 31/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0488 - accuracy: 0.5239 - val_loss: 1.0675 - val_accuracy: 0.5047\n",
            "Epoch 32/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0715 - accuracy: 0.5261 - val_loss: 1.1317 - val_accuracy: 0.4725\n",
            "Epoch 33/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0509 - accuracy: 0.5300 - val_loss: 1.0749 - val_accuracy: 0.5104\n",
            "Epoch 34/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0448 - accuracy: 0.5388 - val_loss: 1.0417 - val_accuracy: 0.5237\n",
            "Epoch 35/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0397 - accuracy: 0.5255 - val_loss: 1.0381 - val_accuracy: 0.5351\n",
            "Epoch 36/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0326 - accuracy: 0.5566 - val_loss: 1.0119 - val_accuracy: 0.5484\n",
            "Epoch 37/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.9813 - accuracy: 0.5635 - val_loss: 1.0287 - val_accuracy: 0.5294\n",
            "Epoch 38/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.9918 - accuracy: 0.5546 - val_loss: 1.1690 - val_accuracy: 0.5123\n",
            "Epoch 39/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0184 - accuracy: 0.5554 - val_loss: 0.9986 - val_accuracy: 0.5484\n",
            "Epoch 40/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.9747 - accuracy: 0.5693 - val_loss: 1.0580 - val_accuracy: 0.5313\n",
            "Epoch 41/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0054 - accuracy: 0.5421 - val_loss: 1.1210 - val_accuracy: 0.5180\n",
            "Epoch 42/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0223 - accuracy: 0.5461 - val_loss: 1.0433 - val_accuracy: 0.5294\n",
            "Epoch 43/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0200 - accuracy: 0.5459 - val_loss: 1.0097 - val_accuracy: 0.5294\n",
            "Epoch 44/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.9576 - accuracy: 0.5629 - val_loss: 1.0157 - val_accuracy: 0.5351\n",
            "Epoch 45/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.9436 - accuracy: 0.5818 - val_loss: 0.9743 - val_accuracy: 0.5427\n",
            "Epoch 46/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.9433 - accuracy: 0.5865 - val_loss: 1.1159 - val_accuracy: 0.4744\n",
            "Epoch 47/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0307 - accuracy: 0.5404 - val_loss: 1.0655 - val_accuracy: 0.5256\n",
            "Epoch 48/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.9873 - accuracy: 0.5668 - val_loss: 1.0372 - val_accuracy: 0.5465\n",
            "Epoch 49/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.9212 - accuracy: 0.5865 - val_loss: 1.0080 - val_accuracy: 0.5389\n",
            "Epoch 50/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.9397 - accuracy: 0.5839 - val_loss: 1.0739 - val_accuracy: 0.5294\n",
            "Epoch 51/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.9490 - accuracy: 0.5868 - val_loss: 1.0761 - val_accuracy: 0.5313\n",
            "Epoch 52/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.9222 - accuracy: 0.5909 - val_loss: 1.0668 - val_accuracy: 0.5180\n",
            "Epoch 53/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.9549 - accuracy: 0.5733 - val_loss: 0.9884 - val_accuracy: 0.5465\n",
            "Epoch 54/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.9090 - accuracy: 0.5981 - val_loss: 1.0371 - val_accuracy: 0.5218\n",
            "Epoch 55/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.9376 - accuracy: 0.5893 - val_loss: 0.9748 - val_accuracy: 0.5560\n",
            "Epoch 56/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.9421 - accuracy: 0.5906 - val_loss: 1.1096 - val_accuracy: 0.5294\n",
            "Epoch 57/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.9211 - accuracy: 0.5961 - val_loss: 1.0442 - val_accuracy: 0.5484\n",
            "Epoch 58/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.9125 - accuracy: 0.6018 - val_loss: 1.0058 - val_accuracy: 0.5503\n",
            "Epoch 59/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.9145 - accuracy: 0.5949 - val_loss: 1.0256 - val_accuracy: 0.5598\n",
            "Epoch 60/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.9246 - accuracy: 0.5933 - val_loss: 1.0084 - val_accuracy: 0.5617\n",
            "Epoch 61/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.8710 - accuracy: 0.6133 - val_loss: 1.0286 - val_accuracy: 0.5731\n",
            "Epoch 62/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.8908 - accuracy: 0.6147 - val_loss: 1.0446 - val_accuracy: 0.5674\n",
            "Epoch 63/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.8822 - accuracy: 0.6123 - val_loss: 1.0245 - val_accuracy: 0.5655\n",
            "Epoch 64/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.8763 - accuracy: 0.6106 - val_loss: 1.0760 - val_accuracy: 0.5047\n",
            "Epoch 65/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.9394 - accuracy: 0.5824 - val_loss: 1.0289 - val_accuracy: 0.5218\n",
            "Epoch 66/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.9196 - accuracy: 0.5908 - val_loss: 1.0021 - val_accuracy: 0.5655\n",
            "Epoch 67/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.8555 - accuracy: 0.6259 - val_loss: 0.9773 - val_accuracy: 0.5806\n",
            "Epoch 68/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.8930 - accuracy: 0.6103 - val_loss: 1.1071 - val_accuracy: 0.5598\n",
            "Epoch 69/200\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.9864 - accuracy: 0.5743 - val_loss: 1.0486 - val_accuracy: 0.5294\n",
            "Epoch 70/200\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.8941 - accuracy: 0.5966 - val_loss: 0.9914 - val_accuracy: 0.5541\n",
            "Epoch 71/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.8622 - accuracy: 0.6280 - val_loss: 1.0406 - val_accuracy: 0.5332\n",
            "Epoch 72/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.8467 - accuracy: 0.6273 - val_loss: 0.9810 - val_accuracy: 0.5579\n",
            "Epoch 73/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.8549 - accuracy: 0.6336 - val_loss: 1.0069 - val_accuracy: 0.5731\n",
            "Epoch 74/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.8912 - accuracy: 0.6208 - val_loss: 1.0059 - val_accuracy: 0.5332\n",
            "Epoch 75/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.8631 - accuracy: 0.6225 - val_loss: 1.0459 - val_accuracy: 0.5617\n",
            "Epoch 76/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.8666 - accuracy: 0.6285 - val_loss: 1.0437 - val_accuracy: 0.5446\n",
            "Epoch 77/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.8538 - accuracy: 0.6314 - val_loss: 1.0288 - val_accuracy: 0.5731\n",
            "Epoch 78/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.8463 - accuracy: 0.6358 - val_loss: 0.9865 - val_accuracy: 0.5844\n",
            "Epoch 79/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.8293 - accuracy: 0.6396 - val_loss: 1.0021 - val_accuracy: 0.5806\n",
            "Epoch 80/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.8199 - accuracy: 0.6499 - val_loss: 1.0127 - val_accuracy: 0.5787\n",
            "Epoch 81/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.8282 - accuracy: 0.6461 - val_loss: 1.0509 - val_accuracy: 0.5484\n",
            "Epoch 82/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.8032 - accuracy: 0.6592 - val_loss: 1.0343 - val_accuracy: 0.5617\n",
            "Epoch 83/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.8817 - accuracy: 0.6243 - val_loss: 1.0265 - val_accuracy: 0.5636\n",
            "Epoch 84/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.8285 - accuracy: 0.6484 - val_loss: 1.0269 - val_accuracy: 0.5465\n",
            "Epoch 85/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.8054 - accuracy: 0.6484 - val_loss: 1.0376 - val_accuracy: 0.5541\n",
            "Epoch 86/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.7742 - accuracy: 0.6705 - val_loss: 1.1420 - val_accuracy: 0.5237\n",
            "Epoch 87/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.8946 - accuracy: 0.6131 - val_loss: 1.0474 - val_accuracy: 0.5560\n",
            "Epoch 88/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.8172 - accuracy: 0.6400 - val_loss: 1.0220 - val_accuracy: 0.5712\n",
            "Epoch 89/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.8030 - accuracy: 0.6587 - val_loss: 1.0430 - val_accuracy: 0.5522\n",
            "Epoch 90/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.7991 - accuracy: 0.6683 - val_loss: 1.0713 - val_accuracy: 0.5541\n",
            "Epoch 91/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.8407 - accuracy: 0.6444 - val_loss: 1.0359 - val_accuracy: 0.5541\n",
            "Epoch 92/200\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.7643 - accuracy: 0.6771 - val_loss: 1.0686 - val_accuracy: 0.5674\n",
            "Epoch 93/200\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.7761 - accuracy: 0.6677 - val_loss: 1.0678 - val_accuracy: 0.5617\n",
            "Epoch 94/200\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.7655 - accuracy: 0.6748 - val_loss: 1.0340 - val_accuracy: 0.5825\n",
            "Epoch 95/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.7515 - accuracy: 0.6783 - val_loss: 1.0658 - val_accuracy: 0.5712\n",
            "Epoch 96/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.7682 - accuracy: 0.6673 - val_loss: 1.0750 - val_accuracy: 0.5617\n",
            "Epoch 97/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.8467 - accuracy: 0.6290 - val_loss: 1.0876 - val_accuracy: 0.5712\n",
            "Epoch 98/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.8062 - accuracy: 0.6536 - val_loss: 1.1137 - val_accuracy: 0.5446\n",
            "Epoch 99/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.8211 - accuracy: 0.6524 - val_loss: 1.0623 - val_accuracy: 0.5617\n",
            "Epoch 100/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.7612 - accuracy: 0.6768 - val_loss: 1.0988 - val_accuracy: 0.5655\n",
            "Epoch 101/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.7474 - accuracy: 0.6964 - val_loss: 1.1465 - val_accuracy: 0.5351\n",
            "Epoch 102/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.8780 - accuracy: 0.6268 - val_loss: 1.0731 - val_accuracy: 0.5427\n",
            "Epoch 103/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.7553 - accuracy: 0.6661 - val_loss: 1.0615 - val_accuracy: 0.5560\n",
            "Epoch 104/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.7248 - accuracy: 0.6908 - val_loss: 1.0820 - val_accuracy: 0.5712\n",
            "Epoch 105/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.7681 - accuracy: 0.6826 - val_loss: 1.0734 - val_accuracy: 0.5579\n",
            "Epoch 106/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.7934 - accuracy: 0.6663 - val_loss: 1.1254 - val_accuracy: 0.5541\n",
            "Epoch 107/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.7290 - accuracy: 0.6996 - val_loss: 1.1271 - val_accuracy: 0.5484\n",
            "Epoch 108/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.7462 - accuracy: 0.6874 - val_loss: 1.0775 - val_accuracy: 0.5579\n",
            "Epoch 109/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.7345 - accuracy: 0.6926 - val_loss: 1.1137 - val_accuracy: 0.5541\n",
            "Epoch 110/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.6884 - accuracy: 0.7058 - val_loss: 1.0767 - val_accuracy: 0.5825\n",
            "Epoch 111/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.7036 - accuracy: 0.7092 - val_loss: 1.1295 - val_accuracy: 0.5560\n",
            "Epoch 112/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.6751 - accuracy: 0.7215 - val_loss: 1.1190 - val_accuracy: 0.5598\n",
            "Epoch 113/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.7080 - accuracy: 0.7068 - val_loss: 1.1149 - val_accuracy: 0.5693\n",
            "Epoch 114/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.7230 - accuracy: 0.7041 - val_loss: 1.1613 - val_accuracy: 0.5446\n",
            "Epoch 115/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.7143 - accuracy: 0.6918 - val_loss: 1.1311 - val_accuracy: 0.5844\n",
            "Epoch 116/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.6860 - accuracy: 0.7177 - val_loss: 1.1539 - val_accuracy: 0.5598\n",
            "Epoch 117/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.7071 - accuracy: 0.6928 - val_loss: 1.1614 - val_accuracy: 0.5787\n",
            "Epoch 118/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.6816 - accuracy: 0.7075 - val_loss: 1.1659 - val_accuracy: 0.5787\n",
            "Epoch 119/200\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.6827 - accuracy: 0.7164 - val_loss: 1.1475 - val_accuracy: 0.5560\n",
            "Epoch 120/200\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.6739 - accuracy: 0.7187 - val_loss: 1.1776 - val_accuracy: 0.5750\n",
            "Epoch 121/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.6475 - accuracy: 0.7272 - val_loss: 1.2093 - val_accuracy: 0.5579\n",
            "Epoch 122/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.6710 - accuracy: 0.7232 - val_loss: 1.1633 - val_accuracy: 0.5769\n",
            "Epoch 123/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.6192 - accuracy: 0.7516 - val_loss: 1.1203 - val_accuracy: 0.5769\n",
            "Epoch 124/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.6106 - accuracy: 0.7502 - val_loss: 1.1349 - val_accuracy: 0.5712\n",
            "Epoch 125/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.6031 - accuracy: 0.7573 - val_loss: 1.1833 - val_accuracy: 0.5465\n",
            "Epoch 126/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.6341 - accuracy: 0.7339 - val_loss: 1.1927 - val_accuracy: 0.5598\n",
            "Epoch 127/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.6610 - accuracy: 0.7217 - val_loss: 1.1563 - val_accuracy: 0.5693\n",
            "Epoch 128/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.5909 - accuracy: 0.7591 - val_loss: 1.2101 - val_accuracy: 0.5731\n",
            "Epoch 129/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.6197 - accuracy: 0.7394 - val_loss: 1.1742 - val_accuracy: 0.5655\n",
            "Epoch 130/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.6914 - accuracy: 0.7162 - val_loss: 1.2019 - val_accuracy: 0.5560\n",
            "Epoch 131/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.5971 - accuracy: 0.7610 - val_loss: 1.1792 - val_accuracy: 0.5863\n",
            "Epoch 132/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.5924 - accuracy: 0.7604 - val_loss: 1.1843 - val_accuracy: 0.5787\n",
            "Epoch 133/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.5739 - accuracy: 0.7694 - val_loss: 1.2484 - val_accuracy: 0.5598\n",
            "Epoch 134/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.5640 - accuracy: 0.7651 - val_loss: 1.2132 - val_accuracy: 0.5655\n",
            "Epoch 135/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.5568 - accuracy: 0.7789 - val_loss: 1.2060 - val_accuracy: 0.5769\n",
            "Epoch 136/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.5809 - accuracy: 0.7639 - val_loss: 1.2626 - val_accuracy: 0.5655\n",
            "Epoch 137/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.5895 - accuracy: 0.7630 - val_loss: 1.2390 - val_accuracy: 0.5806\n",
            "Epoch 138/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.6038 - accuracy: 0.7554 - val_loss: 1.2996 - val_accuracy: 0.5522\n",
            "Epoch 139/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.5664 - accuracy: 0.7671 - val_loss: 1.2108 - val_accuracy: 0.5674\n",
            "Epoch 140/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.5342 - accuracy: 0.7865 - val_loss: 1.2843 - val_accuracy: 0.5655\n",
            "Epoch 141/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.5482 - accuracy: 0.7749 - val_loss: 1.2619 - val_accuracy: 0.5769\n",
            "Epoch 142/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.5758 - accuracy: 0.7631 - val_loss: 1.3026 - val_accuracy: 0.5636\n",
            "Epoch 143/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.5752 - accuracy: 0.7635 - val_loss: 1.2855 - val_accuracy: 0.5560\n",
            "Epoch 144/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.5565 - accuracy: 0.7761 - val_loss: 1.2675 - val_accuracy: 0.5522\n",
            "Epoch 145/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.5171 - accuracy: 0.7952 - val_loss: 1.3040 - val_accuracy: 0.5313\n",
            "Epoch 146/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.5377 - accuracy: 0.7786 - val_loss: 1.3800 - val_accuracy: 0.5408\n",
            "Epoch 147/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.6544 - accuracy: 0.7433 - val_loss: 1.2741 - val_accuracy: 0.5693\n",
            "Epoch 148/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.7111 - accuracy: 0.7056 - val_loss: 1.2897 - val_accuracy: 0.5541\n",
            "Epoch 149/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.5758 - accuracy: 0.7654 - val_loss: 1.2593 - val_accuracy: 0.5617\n",
            "Epoch 150/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.4964 - accuracy: 0.8025 - val_loss: 1.3852 - val_accuracy: 0.5427\n",
            "Epoch 151/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.6062 - accuracy: 0.7611 - val_loss: 1.3281 - val_accuracy: 0.5617\n",
            "Epoch 152/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.4900 - accuracy: 0.8007 - val_loss: 1.3034 - val_accuracy: 0.5712\n",
            "Epoch 153/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.4919 - accuracy: 0.7997 - val_loss: 1.3204 - val_accuracy: 0.5693\n",
            "Epoch 154/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.4911 - accuracy: 0.8058 - val_loss: 1.3593 - val_accuracy: 0.5787\n",
            "Epoch 155/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.6031 - accuracy: 0.7614 - val_loss: 1.3704 - val_accuracy: 0.5769\n",
            "Epoch 156/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.4979 - accuracy: 0.8059 - val_loss: 1.3850 - val_accuracy: 0.5882\n",
            "Epoch 157/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.4620 - accuracy: 0.8210 - val_loss: 1.4392 - val_accuracy: 0.5825\n",
            "Epoch 158/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.5141 - accuracy: 0.7879 - val_loss: 1.4287 - val_accuracy: 0.5579\n",
            "Epoch 159/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.4764 - accuracy: 0.8129 - val_loss: 1.4023 - val_accuracy: 0.5731\n",
            "Epoch 160/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.5863 - accuracy: 0.7578 - val_loss: 1.3355 - val_accuracy: 0.5693\n",
            "Epoch 161/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.5112 - accuracy: 0.7955 - val_loss: 1.3957 - val_accuracy: 0.5863\n",
            "Epoch 162/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.5611 - accuracy: 0.7769 - val_loss: 1.3859 - val_accuracy: 0.5806\n",
            "Epoch 163/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.5568 - accuracy: 0.7664 - val_loss: 1.4150 - val_accuracy: 0.5712\n",
            "Epoch 164/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.4566 - accuracy: 0.8259 - val_loss: 1.5554 - val_accuracy: 0.5332\n",
            "Epoch 165/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.4409 - accuracy: 0.8325 - val_loss: 1.4476 - val_accuracy: 0.5958\n",
            "Epoch 166/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.4533 - accuracy: 0.8247 - val_loss: 1.5035 - val_accuracy: 0.5655\n",
            "Epoch 167/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.4215 - accuracy: 0.8338 - val_loss: 1.5515 - val_accuracy: 0.5598\n",
            "Epoch 168/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.4348 - accuracy: 0.8320 - val_loss: 1.5413 - val_accuracy: 0.5636\n",
            "Epoch 169/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.4254 - accuracy: 0.8349 - val_loss: 1.4966 - val_accuracy: 0.5579\n",
            "Epoch 170/200\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.4442 - accuracy: 0.8257 - val_loss: 1.5065 - val_accuracy: 0.5617\n",
            "Epoch 171/200\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.4306 - accuracy: 0.8286 - val_loss: 1.5638 - val_accuracy: 0.5693\n",
            "Epoch 172/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.4134 - accuracy: 0.8376 - val_loss: 1.6364 - val_accuracy: 0.5617\n",
            "Epoch 173/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.4531 - accuracy: 0.8195 - val_loss: 1.5506 - val_accuracy: 0.5844\n",
            "Epoch 174/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.4165 - accuracy: 0.8376 - val_loss: 1.6038 - val_accuracy: 0.5541\n",
            "Epoch 175/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.6247 - accuracy: 0.7685 - val_loss: 1.5683 - val_accuracy: 0.5465\n",
            "Epoch 176/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.4007 - accuracy: 0.8470 - val_loss: 1.5666 - val_accuracy: 0.5750\n",
            "Epoch 177/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.4151 - accuracy: 0.8348 - val_loss: 1.5624 - val_accuracy: 0.5484\n",
            "Epoch 178/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.4172 - accuracy: 0.8322 - val_loss: 1.6414 - val_accuracy: 0.5446\n",
            "Epoch 179/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.4608 - accuracy: 0.8114 - val_loss: 1.7223 - val_accuracy: 0.5636\n",
            "Epoch 180/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.4383 - accuracy: 0.8247 - val_loss: 1.5776 - val_accuracy: 0.5503\n",
            "Epoch 181/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.4333 - accuracy: 0.8276 - val_loss: 1.6086 - val_accuracy: 0.5750\n",
            "Epoch 182/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.3696 - accuracy: 0.8604 - val_loss: 1.7177 - val_accuracy: 0.5579\n",
            "Epoch 183/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.5189 - accuracy: 0.7984 - val_loss: 1.5675 - val_accuracy: 0.5693\n",
            "Epoch 184/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.4442 - accuracy: 0.8258 - val_loss: 1.6761 - val_accuracy: 0.5560\n",
            "Epoch 185/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.4745 - accuracy: 0.8028 - val_loss: 1.6201 - val_accuracy: 0.5787\n",
            "Epoch 186/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.3698 - accuracy: 0.8565 - val_loss: 1.6727 - val_accuracy: 0.5769\n",
            "Epoch 187/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.4196 - accuracy: 0.8381 - val_loss: 1.6611 - val_accuracy: 0.5560\n",
            "Epoch 188/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.3469 - accuracy: 0.8675 - val_loss: 1.6752 - val_accuracy: 0.5636\n",
            "Epoch 189/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.4199 - accuracy: 0.8409 - val_loss: 1.7014 - val_accuracy: 0.5598\n",
            "Epoch 190/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.5242 - accuracy: 0.8002 - val_loss: 1.6277 - val_accuracy: 0.5787\n",
            "Epoch 191/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.3576 - accuracy: 0.8619 - val_loss: 1.6165 - val_accuracy: 0.5806\n",
            "Epoch 192/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.6035 - accuracy: 0.7714 - val_loss: 1.7113 - val_accuracy: 0.5674\n",
            "Epoch 193/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.3725 - accuracy: 0.8566 - val_loss: 1.7330 - val_accuracy: 0.5484\n",
            "Epoch 194/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.4165 - accuracy: 0.8320 - val_loss: 1.6641 - val_accuracy: 0.5636\n",
            "Epoch 195/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.3488 - accuracy: 0.8598 - val_loss: 1.7657 - val_accuracy: 0.5731\n",
            "Epoch 196/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.3307 - accuracy: 0.8778 - val_loss: 1.7943 - val_accuracy: 0.5636\n",
            "Epoch 197/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.4024 - accuracy: 0.8440 - val_loss: 1.8750 - val_accuracy: 0.5408\n",
            "Epoch 198/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.3481 - accuracy: 0.8629 - val_loss: 1.7944 - val_accuracy: 0.5617\n",
            "Epoch 199/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.4532 - accuracy: 0.8245 - val_loss: 1.8553 - val_accuracy: 0.5674\n",
            "Epoch 200/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.4157 - accuracy: 0.8327 - val_loss: 1.7594 - val_accuracy: 0.5750\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oezCEfpDbqw1"
      },
      "source": [
        "model.save('./basic_mfcc39_merged.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GSgd7O_vbqw2"
      },
      "source": [
        "###test_result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TiUdjo4Lbqw3",
        "outputId": "9eb19f30-5e09-4a5a-9c0d-d6e02d0de30a"
      },
      "source": [
        "d = {0: 'happy',\n",
        "     1: 'sad',\n",
        "     2: 'angry',\n",
        "     3: 'fear'}\n",
        "Y_test_pred = np.argmax(model.predict(X_test), axis=-1)\n",
        "Y_test_pred = list(map(lambda x: d[x], Y_test_pred))\n",
        "y_test = np.argmax(y_test, axis=-1)\n",
        "y_test = list(map(lambda x: d[x], y_test))\n",
        "print(classification_report(y_test, Y_test_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.67      0.72      0.69       151\n",
            "        fear       0.36      0.43      0.39       136\n",
            "       happy       0.47      0.34      0.40       140\n",
            "         sad       0.62      0.62      0.62       159\n",
            "\n",
            "    accuracy                           0.53       586\n",
            "   macro avg       0.53      0.53      0.52       586\n",
            "weighted avg       0.54      0.53      0.53       586\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CyggCzlTbqw4",
        "outputId": "980bca6c-fc72-4813-b8c4-e7af2f1b928c"
      },
      "source": [
        "import scikitplot as skplt\n",
        "\n",
        "skplt.metrics.plot_confusion_matrix(\n",
        "    y_test, \n",
        "    Y_test_pred,\n",
        "    figsize=(8,8))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<AxesSubplot:title={'center':'Confusion Matrix'}, xlabel='Predicted label', ylabel='True label'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2tpfXhgWh0Dz"
      },
      "source": [
        "# mfcc_13 + conv1D:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHWhYBLWis47"
      },
      "source": [
        "audio_duration = 3\n",
        "sampling_rate = 22050\n",
        "input_length = sampling_rate * audio_duration"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3g-IT-nWh3aS"
      },
      "source": [
        "features = []\n",
        "labels = []\n",
        "for i in range(len(Ravdess_DF['Paths'])):\n",
        "  if ((Ravdess_DF['Emotion'][i] == '03') | (Ravdess_DF['Emotion'][i] == '04') | \n",
        "      (Ravdess_DF['Emotion'][i] == '05') | (Ravdess_DF['Emotion'][i] == '06')):\n",
        "    signal, sr = librosa.load(Ravdess_DF['Paths'][i])\n",
        "\n",
        "    if len(signal) > input_length:\n",
        "      signal = signal[0:input_length]\n",
        "    elif  input_length > len(signal):\n",
        "      max_offset = input_length - len(signal)  \n",
        "      signal = np.pad(signal, (0, max_offset), \"constant\")\n",
        "\n",
        "    mfcc = librosa.feature.mfcc(y=signal, sr=sr, n_mfcc=13).T\n",
        "    mfcc = mfcc.reshape(-1,1)\n",
        "    features.append(mfcc)\n",
        "\n",
        "    if Ravdess_DF['Emotion'][i] == '03':\n",
        "      labels.append(0)\n",
        "    elif Ravdess_DF['Emotion'][i] == '04':\n",
        "      labels.append(1)\n",
        "    elif Ravdess_DF['Emotion'][i] == '05':\n",
        "      labels.append(2)\n",
        "    elif Ravdess_DF['Emotion'][i] == '06':\n",
        "      labels.append(3)\n",
        "    \n",
        "for i in range(len(CREMA_D_df)):\n",
        "  if ((CREMA_D_df['Emotion'][i] == 'HAP') | (CREMA_D_df['Emotion'][i] == 'SAD') | \n",
        "      (CREMA_D_df['Emotion'][i] == 'ANG') | (CREMA_D_df['Emotion'][i] == 'FEA')):\n",
        "    \n",
        "    if CREMA_D_df['Emotion'][i] == 'HAP':\n",
        "      labels.append(0)\n",
        "    elif CREMA_D_df['Emotion'][i] == 'SAD':\n",
        "      labels.append(1)\n",
        "    elif CREMA_D_df['Emotion'][i] == 'ANG':\n",
        "      labels.append(2)\n",
        "    elif CREMA_D_df['Emotion'][i] == 'FEA':\n",
        "      labels.append(3)\n",
        "\n",
        "\n",
        "    signal, sr =  librosa.load(CREMA_D_df['Paths'][i])\n",
        "\n",
        "    if len(signal) > input_length:\n",
        "        signal = signal[0:input_length]\n",
        "    elif  input_length > len(signal):\n",
        "        max_offset = input_length - len(signal)  \n",
        "        signal = np.pad(signal, (0, max_offset), \"constant\")\n",
        "\n",
        "    mfcc = librosa.feature.mfcc(y=signal, sr=sr, n_mfcc=13).T\n",
        "    mfcc = mfcc.reshape(-1,1)\n",
        "    features.append(mfcc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wtQSaQ-BiCct"
      },
      "source": [
        "X = features\n",
        "y = labels\n",
        "\n",
        "y = np.array(y)\n",
        "y = to_categorical(y)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=0)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=0)\n",
        "\n",
        "X_train = np.array(X_train)\n",
        "X_test = np.array(X_test)\n",
        "X_val = np.array(X_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9NR4b-fbi-Mv",
        "outputId": "4345a50b-57b9-441d-f256-e76b25dccab5"
      },
      "source": [
        "X_train.shape,X_test.shape,y_train.shape,y_test.shape\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((4739, 1690, 1), (586, 1690, 1), (4739, 4), (586, 4))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6psnOJE7i-QE"
      },
      "source": [
        "\n",
        "# CNN I/P Config\n",
        "num_classes = 4\n",
        "input_shape = X_train.shape[1:]\n",
        "learning_rate = 0.0001\n",
        "decay = 1e-6\n",
        "momentum = 0.9\n",
        "\n",
        "#LSTM Configuration\n",
        "num_lstm = 256"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZMn8aEojFTC",
        "outputId": "59768620-9700-45d8-e083-cea8b569bf87"
      },
      "source": [
        "model = Sequential(name='Audio_CNN_1D')\n",
        "\n",
        "# LFLB1\n",
        "model.add(Conv1D(filters=64, kernel_size=(3), strides=1, padding='same', data_format='channels_last',input_shape=input_shape))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('elu'))\n",
        "model.add(MaxPooling1D(pool_size=4, strides=4))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "# LFLB2\n",
        "model.add(Conv1D(filters=64, kernel_size=3, strides=1, padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('elu'))\n",
        "model.add(MaxPooling1D(pool_size=4, strides=4))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# LFLB3\n",
        "model.add(Conv1D(filters=128, kernel_size=3, strides=1, padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('elu'))\n",
        "model.add(MaxPooling1D(pool_size=4, strides=4))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# LFLB4\n",
        "model.add(Conv1D(filters=128, kernel_size=3, strides=1, padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('elu'))\n",
        "model.add(MaxPooling1D(pool_size=4, strides=4))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# LSTM\n",
        "model.add(LSTM(units=num_lstm))\n",
        "\n",
        "# FC\n",
        "model.add(Dense(units=num_classes, activation='softmax'))\n",
        "\n",
        "# Model compilation\n",
        "opt= keras.optimizers.Adam(lr=0.01, beta_1=0.9,  beta_2=0.999, amsgrad=False)\n",
        "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
        "\n",
        "model.summary()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"Audio_CNN_1D\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 1690, 64)          256       \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 1690, 64)          256       \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 1690, 64)          0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D) (None, 422, 64)           0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 422, 64)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 422, 64)           12352     \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 422, 64)           256       \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 422, 64)           0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1 (None, 105, 64)           0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 105, 64)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 105, 128)          24704     \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 105, 128)          512       \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 105, 128)          0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_2 (MaxPooling1 (None, 26, 128)           0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 26, 128)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 26, 128)           49280     \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 26, 128)           512       \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 26, 128)           0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_3 (MaxPooling1 (None, 6, 128)            0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 6, 128)            0         \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 256)               394240    \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 4)                 1028      \n",
            "=================================================================\n",
            "Total params: 483,396\n",
            "Trainable params: 482,628\n",
            "Non-trainable params: 768\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4DXFmqfXjFaM",
        "outputId": "3c583c37-928a-4c8d-e4d8-728258f8435b"
      },
      "source": [
        "#Train Config\n",
        "\n",
        "batch_size = 16\n",
        "num_epochs = 200\n",
        "\n",
        "# Model Training\n",
        "lr_reduce = ReduceLROnPlateau(monitor='val_loss', factor=0.9, patience=20, min_lr=0.000001)\n",
        "# Please change the model name accordingly.\n",
        "mcp_save = ModelCheckpoint('/content/Audio_1DCNN.h5', save_best_only=True, monitor='val_categorical_accuracy', mode='max')\n",
        "cnnhistory=model.fit(X_train, y_train, batch_size=batch_size, epochs=num_epochs,validation_data=(X_val, y_val), callbacks=[mcp_save, lr_reduce])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "297/297 [==============================] - 8s 14ms/step - loss: 1.3219 - categorical_accuracy: 0.4430 - val_loss: 1.5611 - val_categorical_accuracy: 0.3416\n",
            "Epoch 2/200\n",
            "297/297 [==============================] - 2s 8ms/step - loss: 1.1022 - categorical_accuracy: 0.5087 - val_loss: 1.1600 - val_categorical_accuracy: 0.4611\n",
            "Epoch 3/200\n",
            "297/297 [==============================] - 2s 8ms/step - loss: 1.1180 - categorical_accuracy: 0.4985 - val_loss: 1.1286 - val_categorical_accuracy: 0.5123\n",
            "Epoch 4/200\n",
            "297/297 [==============================] - 2s 8ms/step - loss: 1.1231 - categorical_accuracy: 0.4992 - val_loss: 1.0743 - val_categorical_accuracy: 0.5180\n",
            "Epoch 5/200\n",
            "297/297 [==============================] - 2s 8ms/step - loss: 1.0611 - categorical_accuracy: 0.5112 - val_loss: 1.0617 - val_categorical_accuracy: 0.5199\n",
            "Epoch 6/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 1.0698 - categorical_accuracy: 0.5123 - val_loss: 1.0867 - val_categorical_accuracy: 0.5332\n",
            "Epoch 7/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 1.0959 - categorical_accuracy: 0.5112 - val_loss: 1.0009 - val_categorical_accuracy: 0.5389\n",
            "Epoch 8/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 1.0757 - categorical_accuracy: 0.5067 - val_loss: 1.0270 - val_categorical_accuracy: 0.5104\n",
            "Epoch 9/200\n",
            "297/297 [==============================] - 2s 8ms/step - loss: 1.0630 - categorical_accuracy: 0.5038 - val_loss: 0.9940 - val_categorical_accuracy: 0.5275\n",
            "Epoch 10/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 1.0933 - categorical_accuracy: 0.5066 - val_loss: 1.0902 - val_categorical_accuracy: 0.5085\n",
            "Epoch 11/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 1.0605 - categorical_accuracy: 0.5334 - val_loss: 1.0386 - val_categorical_accuracy: 0.5332\n",
            "Epoch 12/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 1.0565 - categorical_accuracy: 0.5081 - val_loss: 1.0231 - val_categorical_accuracy: 0.5541\n",
            "Epoch 13/200\n",
            "297/297 [==============================] - 2s 8ms/step - loss: 1.0855 - categorical_accuracy: 0.5019 - val_loss: 1.0061 - val_categorical_accuracy: 0.5294\n",
            "Epoch 14/200\n",
            "297/297 [==============================] - 3s 10ms/step - loss: 1.0711 - categorical_accuracy: 0.5049 - val_loss: 1.0108 - val_categorical_accuracy: 0.5503\n",
            "Epoch 15/200\n",
            "297/297 [==============================] - 2s 8ms/step - loss: 1.0568 - categorical_accuracy: 0.5227 - val_loss: 1.0455 - val_categorical_accuracy: 0.5199\n",
            "Epoch 16/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 1.0457 - categorical_accuracy: 0.5303 - val_loss: 0.9981 - val_categorical_accuracy: 0.5275\n",
            "Epoch 17/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 1.0798 - categorical_accuracy: 0.5235 - val_loss: 0.9888 - val_categorical_accuracy: 0.5522\n",
            "Epoch 18/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 1.0465 - categorical_accuracy: 0.5389 - val_loss: 1.0043 - val_categorical_accuracy: 0.5408\n",
            "Epoch 19/200\n",
            "297/297 [==============================] - 2s 8ms/step - loss: 1.0428 - categorical_accuracy: 0.5381 - val_loss: 1.0220 - val_categorical_accuracy: 0.5598\n",
            "Epoch 20/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 1.0522 - categorical_accuracy: 0.5202 - val_loss: 0.9813 - val_categorical_accuracy: 0.5446\n",
            "Epoch 21/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 1.0538 - categorical_accuracy: 0.5240 - val_loss: 0.9736 - val_categorical_accuracy: 0.5560\n",
            "Epoch 22/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 1.0517 - categorical_accuracy: 0.5502 - val_loss: 0.9944 - val_categorical_accuracy: 0.5636\n",
            "Epoch 23/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 1.0750 - categorical_accuracy: 0.5270 - val_loss: 0.9942 - val_categorical_accuracy: 0.5237\n",
            "Epoch 24/200\n",
            "297/297 [==============================] - 2s 8ms/step - loss: 1.0466 - categorical_accuracy: 0.5245 - val_loss: 1.0371 - val_categorical_accuracy: 0.5199\n",
            "Epoch 25/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 1.0370 - categorical_accuracy: 0.5382 - val_loss: 0.9833 - val_categorical_accuracy: 0.5863\n",
            "Epoch 26/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 1.0339 - categorical_accuracy: 0.5409 - val_loss: 0.9723 - val_categorical_accuracy: 0.5389\n",
            "Epoch 27/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 1.0221 - categorical_accuracy: 0.5538 - val_loss: 0.9688 - val_categorical_accuracy: 0.5712\n",
            "Epoch 28/200\n",
            "297/297 [==============================] - 3s 9ms/step - loss: 1.0175 - categorical_accuracy: 0.5225 - val_loss: 0.9857 - val_categorical_accuracy: 0.5503\n",
            "Epoch 29/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 1.0429 - categorical_accuracy: 0.5251 - val_loss: 0.9675 - val_categorical_accuracy: 0.5750\n",
            "Epoch 30/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 1.0584 - categorical_accuracy: 0.5402 - val_loss: 0.9996 - val_categorical_accuracy: 0.5313\n",
            "Epoch 31/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 1.0459 - categorical_accuracy: 0.5220 - val_loss: 0.9810 - val_categorical_accuracy: 0.5598\n",
            "Epoch 32/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 1.0381 - categorical_accuracy: 0.5282 - val_loss: 0.9925 - val_categorical_accuracy: 0.5484\n",
            "Epoch 33/200\n",
            "297/297 [==============================] - 2s 8ms/step - loss: 1.0369 - categorical_accuracy: 0.5358 - val_loss: 0.9948 - val_categorical_accuracy: 0.5522\n",
            "Epoch 34/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 1.0546 - categorical_accuracy: 0.5232 - val_loss: 1.0552 - val_categorical_accuracy: 0.5180\n",
            "Epoch 35/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 1.0361 - categorical_accuracy: 0.5224 - val_loss: 0.9772 - val_categorical_accuracy: 0.5636\n",
            "Epoch 36/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 1.0169 - categorical_accuracy: 0.5489 - val_loss: 0.9648 - val_categorical_accuracy: 0.5541\n",
            "Epoch 37/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 1.0496 - categorical_accuracy: 0.5338 - val_loss: 0.9751 - val_categorical_accuracy: 0.5693\n",
            "Epoch 38/200\n",
            "297/297 [==============================] - 2s 8ms/step - loss: 1.0238 - categorical_accuracy: 0.5390 - val_loss: 1.0346 - val_categorical_accuracy: 0.4668\n",
            "Epoch 39/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 1.0525 - categorical_accuracy: 0.5283 - val_loss: 0.9623 - val_categorical_accuracy: 0.5825\n",
            "Epoch 40/200\n",
            "297/297 [==============================] - 2s 8ms/step - loss: 0.9989 - categorical_accuracy: 0.5470 - val_loss: 0.9304 - val_categorical_accuracy: 0.5806\n",
            "Epoch 41/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 1.0368 - categorical_accuracy: 0.5299 - val_loss: 1.0247 - val_categorical_accuracy: 0.5332\n",
            "Epoch 42/200\n",
            "297/297 [==============================] - 3s 9ms/step - loss: 1.0232 - categorical_accuracy: 0.5376 - val_loss: 0.9610 - val_categorical_accuracy: 0.5560\n",
            "Epoch 43/200\n",
            "297/297 [==============================] - 2s 8ms/step - loss: 1.0236 - categorical_accuracy: 0.5293 - val_loss: 0.9728 - val_categorical_accuracy: 0.5617\n",
            "Epoch 44/200\n",
            "297/297 [==============================] - 2s 8ms/step - loss: 1.0456 - categorical_accuracy: 0.5411 - val_loss: 1.0104 - val_categorical_accuracy: 0.5275\n",
            "Epoch 45/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 1.0341 - categorical_accuracy: 0.5383 - val_loss: 0.9532 - val_categorical_accuracy: 0.5617\n",
            "Epoch 46/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 1.0239 - categorical_accuracy: 0.5359 - val_loss: 0.9415 - val_categorical_accuracy: 0.5769\n",
            "Epoch 47/200\n",
            "297/297 [==============================] - 2s 8ms/step - loss: 1.0430 - categorical_accuracy: 0.5286 - val_loss: 1.0014 - val_categorical_accuracy: 0.5408\n",
            "Epoch 48/200\n",
            "297/297 [==============================] - 2s 8ms/step - loss: 1.0219 - categorical_accuracy: 0.5411 - val_loss: 0.9624 - val_categorical_accuracy: 0.5920\n",
            "Epoch 49/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 1.0139 - categorical_accuracy: 0.5426 - val_loss: 0.9969 - val_categorical_accuracy: 0.5484\n",
            "Epoch 50/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 1.0087 - categorical_accuracy: 0.5380 - val_loss: 1.0100 - val_categorical_accuracy: 0.5617\n",
            "Epoch 51/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 1.0323 - categorical_accuracy: 0.5359 - val_loss: 1.1034 - val_categorical_accuracy: 0.4934\n",
            "Epoch 52/200\n",
            "297/297 [==============================] - 2s 8ms/step - loss: 1.0453 - categorical_accuracy: 0.5377 - val_loss: 0.9868 - val_categorical_accuracy: 0.5408\n",
            "Epoch 53/200\n",
            "297/297 [==============================] - 2s 8ms/step - loss: 1.0454 - categorical_accuracy: 0.5271 - val_loss: 1.0999 - val_categorical_accuracy: 0.4364\n",
            "Epoch 54/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 1.0100 - categorical_accuracy: 0.5493 - val_loss: 1.0307 - val_categorical_accuracy: 0.5465\n",
            "Epoch 55/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 1.0014 - categorical_accuracy: 0.5562 - val_loss: 1.0199 - val_categorical_accuracy: 0.5389\n",
            "Epoch 56/200\n",
            "297/297 [==============================] - 3s 8ms/step - loss: 1.0392 - categorical_accuracy: 0.5381 - val_loss: 0.9772 - val_categorical_accuracy: 0.5370\n",
            "Epoch 57/200\n",
            "297/297 [==============================] - 2s 8ms/step - loss: 1.0260 - categorical_accuracy: 0.5403 - val_loss: 1.0507 - val_categorical_accuracy: 0.5161\n",
            "Epoch 58/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 1.0359 - categorical_accuracy: 0.5327 - val_loss: 0.9837 - val_categorical_accuracy: 0.5484\n",
            "Epoch 59/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 1.0037 - categorical_accuracy: 0.5586 - val_loss: 1.0400 - val_categorical_accuracy: 0.5275\n",
            "Epoch 60/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.9980 - categorical_accuracy: 0.5571 - val_loss: 0.9998 - val_categorical_accuracy: 0.5104\n",
            "Epoch 61/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 1.0273 - categorical_accuracy: 0.5429 - val_loss: 0.9510 - val_categorical_accuracy: 0.5712\n",
            "Epoch 62/200\n",
            "297/297 [==============================] - 2s 8ms/step - loss: 1.0072 - categorical_accuracy: 0.5467 - val_loss: 0.9563 - val_categorical_accuracy: 0.5579\n",
            "Epoch 63/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 1.0125 - categorical_accuracy: 0.5483 - val_loss: 0.9324 - val_categorical_accuracy: 0.5655\n",
            "Epoch 64/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 1.0006 - categorical_accuracy: 0.5527 - val_loss: 0.9530 - val_categorical_accuracy: 0.5693\n",
            "Epoch 65/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 1.0036 - categorical_accuracy: 0.5634 - val_loss: 0.9330 - val_categorical_accuracy: 0.5750\n",
            "Epoch 66/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 1.0122 - categorical_accuracy: 0.5423 - val_loss: 0.9324 - val_categorical_accuracy: 0.5674\n",
            "Epoch 67/200\n",
            "297/297 [==============================] - 2s 8ms/step - loss: 1.0093 - categorical_accuracy: 0.5415 - val_loss: 0.9300 - val_categorical_accuracy: 0.5750\n",
            "Epoch 68/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 1.0032 - categorical_accuracy: 0.5620 - val_loss: 0.9336 - val_categorical_accuracy: 0.5769\n",
            "Epoch 69/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.9984 - categorical_accuracy: 0.5677 - val_loss: 0.9542 - val_categorical_accuracy: 0.5693\n",
            "Epoch 70/200\n",
            "297/297 [==============================] - 3s 9ms/step - loss: 1.0081 - categorical_accuracy: 0.5391 - val_loss: 0.9264 - val_categorical_accuracy: 0.5655\n",
            "Epoch 71/200\n",
            "297/297 [==============================] - 2s 8ms/step - loss: 0.9803 - categorical_accuracy: 0.5605 - val_loss: 0.9533 - val_categorical_accuracy: 0.5446\n",
            "Epoch 72/200\n",
            "297/297 [==============================] - 2s 8ms/step - loss: 1.0105 - categorical_accuracy: 0.5440 - val_loss: 0.9382 - val_categorical_accuracy: 0.5560\n",
            "Epoch 73/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 1.0120 - categorical_accuracy: 0.5443 - val_loss: 0.9822 - val_categorical_accuracy: 0.5617\n",
            "Epoch 74/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 1.0054 - categorical_accuracy: 0.5525 - val_loss: 0.9594 - val_categorical_accuracy: 0.5863\n",
            "Epoch 75/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.9880 - categorical_accuracy: 0.5645 - val_loss: 0.8772 - val_categorical_accuracy: 0.6072\n",
            "Epoch 76/200\n",
            "297/297 [==============================] - 2s 8ms/step - loss: 0.9888 - categorical_accuracy: 0.5559 - val_loss: 0.9005 - val_categorical_accuracy: 0.6072\n",
            "Epoch 77/200\n",
            "297/297 [==============================] - 2s 8ms/step - loss: 0.9980 - categorical_accuracy: 0.5532 - val_loss: 0.9486 - val_categorical_accuracy: 0.5939\n",
            "Epoch 78/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 1.0050 - categorical_accuracy: 0.5486 - val_loss: 0.9198 - val_categorical_accuracy: 0.5863\n",
            "Epoch 79/200\n",
            "297/297 [==============================] - 2s 8ms/step - loss: 0.9881 - categorical_accuracy: 0.5625 - val_loss: 0.9760 - val_categorical_accuracy: 0.5408\n",
            "Epoch 80/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.9999 - categorical_accuracy: 0.5620 - val_loss: 0.9010 - val_categorical_accuracy: 0.5920\n",
            "Epoch 81/200\n",
            "297/297 [==============================] - 2s 8ms/step - loss: 1.0021 - categorical_accuracy: 0.5426 - val_loss: 0.8921 - val_categorical_accuracy: 0.6015\n",
            "Epoch 82/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.9968 - categorical_accuracy: 0.5455 - val_loss: 0.9512 - val_categorical_accuracy: 0.5693\n",
            "Epoch 83/200\n",
            "297/297 [==============================] - 2s 8ms/step - loss: 1.0046 - categorical_accuracy: 0.5517 - val_loss: 0.9412 - val_categorical_accuracy: 0.5465\n",
            "Epoch 84/200\n",
            "297/297 [==============================] - 3s 9ms/step - loss: 0.9870 - categorical_accuracy: 0.5519 - val_loss: 0.9718 - val_categorical_accuracy: 0.5806\n",
            "Epoch 85/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.9882 - categorical_accuracy: 0.5770 - val_loss: 0.9255 - val_categorical_accuracy: 0.5522\n",
            "Epoch 86/200\n",
            "297/297 [==============================] - 2s 8ms/step - loss: 0.9876 - categorical_accuracy: 0.5600 - val_loss: 0.9802 - val_categorical_accuracy: 0.5389\n",
            "Epoch 87/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 1.0178 - categorical_accuracy: 0.5420 - val_loss: 0.8964 - val_categorical_accuracy: 0.6167\n",
            "Epoch 88/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.9965 - categorical_accuracy: 0.5572 - val_loss: 0.9182 - val_categorical_accuracy: 0.5863\n",
            "Epoch 89/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.9904 - categorical_accuracy: 0.5569 - val_loss: 0.9448 - val_categorical_accuracy: 0.5465\n",
            "Epoch 90/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.9784 - categorical_accuracy: 0.5660 - val_loss: 0.9879 - val_categorical_accuracy: 0.5541\n",
            "Epoch 91/200\n",
            "297/297 [==============================] - 2s 8ms/step - loss: 0.9847 - categorical_accuracy: 0.5691 - val_loss: 0.9846 - val_categorical_accuracy: 0.5541\n",
            "Epoch 92/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 1.0034 - categorical_accuracy: 0.5708 - val_loss: 0.9449 - val_categorical_accuracy: 0.5769\n",
            "Epoch 93/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.9868 - categorical_accuracy: 0.5665 - val_loss: 1.0378 - val_categorical_accuracy: 0.5142\n",
            "Epoch 94/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.9845 - categorical_accuracy: 0.5693 - val_loss: 0.9387 - val_categorical_accuracy: 0.5693\n",
            "Epoch 95/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 1.0000 - categorical_accuracy: 0.5581 - val_loss: 0.9345 - val_categorical_accuracy: 0.5541\n",
            "Epoch 96/200\n",
            "297/297 [==============================] - 2s 8ms/step - loss: 1.0143 - categorical_accuracy: 0.5535 - val_loss: 0.9504 - val_categorical_accuracy: 0.5617\n",
            "Epoch 97/200\n",
            "297/297 [==============================] - 2s 8ms/step - loss: 1.0050 - categorical_accuracy: 0.5542 - val_loss: 0.9403 - val_categorical_accuracy: 0.5769\n",
            "Epoch 98/200\n",
            "297/297 [==============================] - 3s 9ms/step - loss: 1.0104 - categorical_accuracy: 0.5465 - val_loss: 0.9125 - val_categorical_accuracy: 0.5787\n",
            "Epoch 99/200\n",
            "297/297 [==============================] - 2s 8ms/step - loss: 0.9826 - categorical_accuracy: 0.5631 - val_loss: 0.9457 - val_categorical_accuracy: 0.5844\n",
            "Epoch 100/200\n",
            "297/297 [==============================] - 2s 8ms/step - loss: 0.9921 - categorical_accuracy: 0.5592 - val_loss: 0.9244 - val_categorical_accuracy: 0.5655\n",
            "Epoch 101/200\n",
            "297/297 [==============================] - 2s 8ms/step - loss: 0.9635 - categorical_accuracy: 0.5636 - val_loss: 0.9187 - val_categorical_accuracy: 0.5901\n",
            "Epoch 102/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.9869 - categorical_accuracy: 0.5502 - val_loss: 0.9548 - val_categorical_accuracy: 0.5617\n",
            "Epoch 103/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.9874 - categorical_accuracy: 0.5665 - val_loss: 0.9627 - val_categorical_accuracy: 0.5541\n",
            "Epoch 104/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 1.0032 - categorical_accuracy: 0.5515 - val_loss: 0.9213 - val_categorical_accuracy: 0.5844\n",
            "Epoch 105/200\n",
            "297/297 [==============================] - 2s 8ms/step - loss: 0.9804 - categorical_accuracy: 0.5644 - val_loss: 0.9497 - val_categorical_accuracy: 0.5636\n",
            "Epoch 106/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.9865 - categorical_accuracy: 0.5619 - val_loss: 0.9204 - val_categorical_accuracy: 0.5769\n",
            "Epoch 107/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.9900 - categorical_accuracy: 0.5601 - val_loss: 0.9403 - val_categorical_accuracy: 0.5769\n",
            "Epoch 108/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.9712 - categorical_accuracy: 0.5548 - val_loss: 0.9476 - val_categorical_accuracy: 0.5541\n",
            "Epoch 109/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.9798 - categorical_accuracy: 0.5679 - val_loss: 0.9099 - val_categorical_accuracy: 0.5863\n",
            "Epoch 110/200\n",
            "297/297 [==============================] - 2s 8ms/step - loss: 0.9945 - categorical_accuracy: 0.5639 - val_loss: 0.9358 - val_categorical_accuracy: 0.5522\n",
            "Epoch 111/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.9789 - categorical_accuracy: 0.5655 - val_loss: 1.1282 - val_categorical_accuracy: 0.4687\n",
            "Epoch 112/200\n",
            "297/297 [==============================] - 3s 9ms/step - loss: 1.0084 - categorical_accuracy: 0.5456 - val_loss: 0.9184 - val_categorical_accuracy: 0.5806\n",
            "Epoch 113/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.9899 - categorical_accuracy: 0.5607 - val_loss: 0.9308 - val_categorical_accuracy: 0.5655\n",
            "Epoch 114/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 1.0059 - categorical_accuracy: 0.5528 - val_loss: 0.9186 - val_categorical_accuracy: 0.6053\n",
            "Epoch 115/200\n",
            "297/297 [==============================] - 2s 8ms/step - loss: 0.9894 - categorical_accuracy: 0.5641 - val_loss: 0.9622 - val_categorical_accuracy: 0.5825\n",
            "Epoch 116/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.9738 - categorical_accuracy: 0.5678 - val_loss: 0.9366 - val_categorical_accuracy: 0.5731\n",
            "Epoch 117/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.9443 - categorical_accuracy: 0.6003 - val_loss: 0.9190 - val_categorical_accuracy: 0.5693\n",
            "Epoch 118/200\n",
            "297/297 [==============================] - 2s 8ms/step - loss: 0.9762 - categorical_accuracy: 0.5593 - val_loss: 0.9062 - val_categorical_accuracy: 0.5825\n",
            "Epoch 119/200\n",
            "297/297 [==============================] - 2s 8ms/step - loss: 0.9605 - categorical_accuracy: 0.5828 - val_loss: 0.9089 - val_categorical_accuracy: 0.5806\n",
            "Epoch 120/200\n",
            "297/297 [==============================] - 2s 8ms/step - loss: 0.9879 - categorical_accuracy: 0.5641 - val_loss: 0.9191 - val_categorical_accuracy: 0.5636\n",
            "Epoch 121/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.9825 - categorical_accuracy: 0.5634 - val_loss: 0.9063 - val_categorical_accuracy: 0.5920\n",
            "Epoch 122/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.9619 - categorical_accuracy: 0.5762 - val_loss: 0.9581 - val_categorical_accuracy: 0.5522\n",
            "Epoch 123/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.9760 - categorical_accuracy: 0.5634 - val_loss: 0.9283 - val_categorical_accuracy: 0.5731\n",
            "Epoch 124/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.9950 - categorical_accuracy: 0.5425 - val_loss: 0.9984 - val_categorical_accuracy: 0.5294\n",
            "Epoch 125/200\n",
            "297/297 [==============================] - 2s 8ms/step - loss: 0.9907 - categorical_accuracy: 0.5566 - val_loss: 0.9178 - val_categorical_accuracy: 0.5920\n",
            "Epoch 126/200\n",
            "297/297 [==============================] - 3s 9ms/step - loss: 0.9525 - categorical_accuracy: 0.5800 - val_loss: 0.9071 - val_categorical_accuracy: 0.5920\n",
            "Epoch 127/200\n",
            "297/297 [==============================] - 2s 8ms/step - loss: 0.9779 - categorical_accuracy: 0.5625 - val_loss: 0.9289 - val_categorical_accuracy: 0.5465\n",
            "Epoch 128/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.9400 - categorical_accuracy: 0.5864 - val_loss: 0.8998 - val_categorical_accuracy: 0.5579\n",
            "Epoch 129/200\n",
            "297/297 [==============================] - 2s 8ms/step - loss: 0.9742 - categorical_accuracy: 0.5541 - val_loss: 0.8891 - val_categorical_accuracy: 0.6072\n",
            "Epoch 130/200\n",
            "297/297 [==============================] - 2s 8ms/step - loss: 0.9811 - categorical_accuracy: 0.5535 - val_loss: 0.9311 - val_categorical_accuracy: 0.5522\n",
            "Epoch 131/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.9885 - categorical_accuracy: 0.5591 - val_loss: 0.8825 - val_categorical_accuracy: 0.5882\n",
            "Epoch 132/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.9769 - categorical_accuracy: 0.5572 - val_loss: 0.9278 - val_categorical_accuracy: 0.5522\n",
            "Epoch 133/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.9957 - categorical_accuracy: 0.5515 - val_loss: 0.8988 - val_categorical_accuracy: 0.5920\n",
            "Epoch 134/200\n",
            "297/297 [==============================] - 2s 8ms/step - loss: 0.9985 - categorical_accuracy: 0.5553 - val_loss: 0.9036 - val_categorical_accuracy: 0.5787\n",
            "Epoch 135/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.9576 - categorical_accuracy: 0.5782 - val_loss: 0.9380 - val_categorical_accuracy: 0.5712\n",
            "Epoch 136/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.9699 - categorical_accuracy: 0.5745 - val_loss: 0.9136 - val_categorical_accuracy: 0.5750\n",
            "Epoch 137/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.9548 - categorical_accuracy: 0.5740 - val_loss: 0.9732 - val_categorical_accuracy: 0.5180\n",
            "Epoch 138/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.9620 - categorical_accuracy: 0.5830 - val_loss: 0.9233 - val_categorical_accuracy: 0.5750\n",
            "Epoch 139/200\n",
            "297/297 [==============================] - 2s 8ms/step - loss: 0.9617 - categorical_accuracy: 0.5723 - val_loss: 0.9346 - val_categorical_accuracy: 0.5541\n",
            "Epoch 140/200\n",
            "297/297 [==============================] - 3s 9ms/step - loss: 0.9702 - categorical_accuracy: 0.5695 - val_loss: 0.8779 - val_categorical_accuracy: 0.5996\n",
            "Epoch 141/200\n",
            "297/297 [==============================] - 2s 8ms/step - loss: 0.9740 - categorical_accuracy: 0.5786 - val_loss: 0.8749 - val_categorical_accuracy: 0.5863\n",
            "Epoch 142/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.9540 - categorical_accuracy: 0.5769 - val_loss: 0.8763 - val_categorical_accuracy: 0.6110\n",
            "Epoch 143/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.9843 - categorical_accuracy: 0.5727 - val_loss: 0.8842 - val_categorical_accuracy: 0.5939\n",
            "Epoch 144/200\n",
            "297/297 [==============================] - 2s 8ms/step - loss: 0.9368 - categorical_accuracy: 0.5892 - val_loss: 0.8646 - val_categorical_accuracy: 0.6053\n",
            "Epoch 145/200\n",
            "297/297 [==============================] - 2s 8ms/step - loss: 0.9355 - categorical_accuracy: 0.5881 - val_loss: 0.8778 - val_categorical_accuracy: 0.5844\n",
            "Epoch 146/200\n",
            "297/297 [==============================] - 2s 8ms/step - loss: 0.9773 - categorical_accuracy: 0.5650 - val_loss: 0.9244 - val_categorical_accuracy: 0.5787\n",
            "Epoch 147/200\n",
            "297/297 [==============================] - 2s 8ms/step - loss: 0.9464 - categorical_accuracy: 0.5778 - val_loss: 0.8909 - val_categorical_accuracy: 0.5996\n",
            "Epoch 148/200\n",
            "297/297 [==============================] - 2s 8ms/step - loss: 0.9648 - categorical_accuracy: 0.5750 - val_loss: 0.8881 - val_categorical_accuracy: 0.6053\n",
            "Epoch 149/200\n",
            "297/297 [==============================] - 3s 9ms/step - loss: 0.9575 - categorical_accuracy: 0.5861 - val_loss: 0.8764 - val_categorical_accuracy: 0.5996\n",
            "Epoch 150/200\n",
            "297/297 [==============================] - 2s 8ms/step - loss: 0.9807 - categorical_accuracy: 0.5606 - val_loss: 0.8737 - val_categorical_accuracy: 0.5977\n",
            "Epoch 151/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.9717 - categorical_accuracy: 0.5779 - val_loss: 0.8793 - val_categorical_accuracy: 0.6091\n",
            "Epoch 152/200\n",
            "297/297 [==============================] - 2s 8ms/step - loss: 0.9520 - categorical_accuracy: 0.5691 - val_loss: 0.9026 - val_categorical_accuracy: 0.5863\n",
            "Epoch 153/200\n",
            "297/297 [==============================] - 2s 8ms/step - loss: 0.9781 - categorical_accuracy: 0.5644 - val_loss: 0.9214 - val_categorical_accuracy: 0.5882\n",
            "Epoch 154/200\n",
            "297/297 [==============================] - 3s 9ms/step - loss: 0.9527 - categorical_accuracy: 0.5757 - val_loss: 0.9145 - val_categorical_accuracy: 0.5920\n",
            "Epoch 155/200\n",
            "297/297 [==============================] - 2s 8ms/step - loss: 0.9706 - categorical_accuracy: 0.5702 - val_loss: 0.8934 - val_categorical_accuracy: 0.5901\n",
            "Epoch 156/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.9664 - categorical_accuracy: 0.5704 - val_loss: 0.8922 - val_categorical_accuracy: 0.6072\n",
            "Epoch 157/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.9697 - categorical_accuracy: 0.5755 - val_loss: 0.8875 - val_categorical_accuracy: 0.5844\n",
            "Epoch 158/200\n",
            "297/297 [==============================] - 2s 8ms/step - loss: 0.9713 - categorical_accuracy: 0.5692 - val_loss: 0.9010 - val_categorical_accuracy: 0.5882\n",
            "Epoch 159/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.9642 - categorical_accuracy: 0.5691 - val_loss: 0.8658 - val_categorical_accuracy: 0.5920\n",
            "Epoch 160/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.9401 - categorical_accuracy: 0.5892 - val_loss: 0.9339 - val_categorical_accuracy: 0.5579\n",
            "Epoch 161/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.9839 - categorical_accuracy: 0.5684 - val_loss: 0.8873 - val_categorical_accuracy: 0.5787\n",
            "Epoch 162/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.9353 - categorical_accuracy: 0.5822 - val_loss: 0.9230 - val_categorical_accuracy: 0.5693\n",
            "Epoch 163/200\n",
            "297/297 [==============================] - 2s 8ms/step - loss: 0.9581 - categorical_accuracy: 0.5783 - val_loss: 0.9057 - val_categorical_accuracy: 0.5769\n",
            "Epoch 164/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.9512 - categorical_accuracy: 0.5784 - val_loss: 0.9202 - val_categorical_accuracy: 0.5731\n",
            "Epoch 165/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.9462 - categorical_accuracy: 0.5810 - val_loss: 0.9018 - val_categorical_accuracy: 0.5693\n",
            "Epoch 166/200\n",
            "297/297 [==============================] - 2s 8ms/step - loss: 0.9605 - categorical_accuracy: 0.5663 - val_loss: 0.9501 - val_categorical_accuracy: 0.5598\n",
            "Epoch 167/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.9791 - categorical_accuracy: 0.5624 - val_loss: 0.9199 - val_categorical_accuracy: 0.5769\n",
            "Epoch 168/200\n",
            "297/297 [==============================] - 2s 8ms/step - loss: 0.9589 - categorical_accuracy: 0.5706 - val_loss: 0.8655 - val_categorical_accuracy: 0.6053\n",
            "Epoch 169/200\n",
            "297/297 [==============================] - 2s 8ms/step - loss: 0.9745 - categorical_accuracy: 0.5628 - val_loss: 0.9071 - val_categorical_accuracy: 0.5806\n",
            "Epoch 170/200\n",
            "297/297 [==============================] - 3s 8ms/step - loss: 0.9559 - categorical_accuracy: 0.5754 - val_loss: 0.8780 - val_categorical_accuracy: 0.5977\n",
            "Epoch 171/200\n",
            "297/297 [==============================] - 2s 8ms/step - loss: 0.9617 - categorical_accuracy: 0.5797 - val_loss: 0.8876 - val_categorical_accuracy: 0.5901\n",
            "Epoch 172/200\n",
            "297/297 [==============================] - 2s 8ms/step - loss: 0.9691 - categorical_accuracy: 0.5706 - val_loss: 0.8878 - val_categorical_accuracy: 0.5882\n",
            "Epoch 173/200\n",
            "297/297 [==============================] - 2s 8ms/step - loss: 0.9473 - categorical_accuracy: 0.5847 - val_loss: 0.8967 - val_categorical_accuracy: 0.5750\n",
            "Epoch 174/200\n",
            "297/297 [==============================] - 2s 8ms/step - loss: 0.9371 - categorical_accuracy: 0.5789 - val_loss: 0.8918 - val_categorical_accuracy: 0.5750\n",
            "Epoch 175/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.9370 - categorical_accuracy: 0.5777 - val_loss: 0.9093 - val_categorical_accuracy: 0.5693\n",
            "Epoch 176/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.9586 - categorical_accuracy: 0.5762 - val_loss: 0.8844 - val_categorical_accuracy: 0.6053\n",
            "Epoch 177/200\n",
            "297/297 [==============================] - 2s 8ms/step - loss: 0.9411 - categorical_accuracy: 0.5835 - val_loss: 0.9366 - val_categorical_accuracy: 0.5806\n",
            "Epoch 178/200\n",
            "297/297 [==============================] - 2s 8ms/step - loss: 0.9532 - categorical_accuracy: 0.5718 - val_loss: 0.8817 - val_categorical_accuracy: 0.6072\n",
            "Epoch 179/200\n",
            "297/297 [==============================] - 2s 8ms/step - loss: 0.9337 - categorical_accuracy: 0.5867 - val_loss: 0.8741 - val_categorical_accuracy: 0.5901\n",
            "Epoch 180/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.9820 - categorical_accuracy: 0.5606 - val_loss: 0.8748 - val_categorical_accuracy: 0.5977\n",
            "Epoch 181/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.9480 - categorical_accuracy: 0.5843 - val_loss: 0.9184 - val_categorical_accuracy: 0.5901\n",
            "Epoch 182/200\n",
            "297/297 [==============================] - 2s 8ms/step - loss: 0.9593 - categorical_accuracy: 0.5710 - val_loss: 0.8985 - val_categorical_accuracy: 0.6034\n",
            "Epoch 183/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.9368 - categorical_accuracy: 0.5881 - val_loss: 0.9072 - val_categorical_accuracy: 0.5939\n",
            "Epoch 184/200\n",
            "297/297 [==============================] - 3s 9ms/step - loss: 0.9526 - categorical_accuracy: 0.5819 - val_loss: 0.9127 - val_categorical_accuracy: 0.5882\n",
            "Epoch 185/200\n",
            "297/297 [==============================] - 2s 8ms/step - loss: 0.9512 - categorical_accuracy: 0.5773 - val_loss: 0.9092 - val_categorical_accuracy: 0.5939\n",
            "Epoch 186/200\n",
            "297/297 [==============================] - 2s 8ms/step - loss: 0.9489 - categorical_accuracy: 0.5852 - val_loss: 0.9036 - val_categorical_accuracy: 0.5806\n",
            "Epoch 187/200\n",
            "297/297 [==============================] - 2s 8ms/step - loss: 0.9426 - categorical_accuracy: 0.5850 - val_loss: 0.8943 - val_categorical_accuracy: 0.5996\n",
            "Epoch 188/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.9413 - categorical_accuracy: 0.5862 - val_loss: 0.9022 - val_categorical_accuracy: 0.5769\n",
            "Epoch 189/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.9837 - categorical_accuracy: 0.5610 - val_loss: 0.8565 - val_categorical_accuracy: 0.6091\n",
            "Epoch 190/200\n",
            "297/297 [==============================] - 2s 8ms/step - loss: 0.9620 - categorical_accuracy: 0.5837 - val_loss: 0.9370 - val_categorical_accuracy: 0.5750\n",
            "Epoch 191/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.9608 - categorical_accuracy: 0.5720 - val_loss: 0.8753 - val_categorical_accuracy: 0.6015\n",
            "Epoch 192/200\n",
            "297/297 [==============================] - 2s 8ms/step - loss: 0.9436 - categorical_accuracy: 0.5878 - val_loss: 0.8697 - val_categorical_accuracy: 0.6053\n",
            "Epoch 193/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.9579 - categorical_accuracy: 0.5807 - val_loss: 0.9098 - val_categorical_accuracy: 0.5560\n",
            "Epoch 194/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.9342 - categorical_accuracy: 0.5846 - val_loss: 0.8803 - val_categorical_accuracy: 0.6110\n",
            "Epoch 195/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.9383 - categorical_accuracy: 0.5874 - val_loss: 0.8555 - val_categorical_accuracy: 0.5977\n",
            "Epoch 196/200\n",
            "297/297 [==============================] - 2s 8ms/step - loss: 0.9715 - categorical_accuracy: 0.5742 - val_loss: 0.9240 - val_categorical_accuracy: 0.5750\n",
            "Epoch 197/200\n",
            "297/297 [==============================] - 2s 8ms/step - loss: 0.9610 - categorical_accuracy: 0.5733 - val_loss: 0.8764 - val_categorical_accuracy: 0.5996\n",
            "Epoch 198/200\n",
            "297/297 [==============================] - 3s 9ms/step - loss: 0.9548 - categorical_accuracy: 0.5924 - val_loss: 0.8647 - val_categorical_accuracy: 0.5939\n",
            "Epoch 199/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.9408 - categorical_accuracy: 0.5986 - val_loss: 0.8746 - val_categorical_accuracy: 0.5882\n",
            "Epoch 200/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.9650 - categorical_accuracy: 0.5765 - val_loss: 0.9024 - val_categorical_accuracy: 0.5825\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mx09k6qirna2"
      },
      "source": [
        "model.save('./conv1D_mfcc13_merged.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L4jDC7cNsJL1"
      },
      "source": [
        "###test_result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ywGjCaH4sJMK",
        "outputId": "27d15d0d-9c1d-4465-d308-247e8340f631"
      },
      "source": [
        "d = {0: 'happy',\n",
        "     1: 'sad',\n",
        "     2: 'angry',\n",
        "     3: 'fear'}\n",
        "Y_test_pred = np.argmax(model.predict(X_test), axis=-1)\n",
        "Y_test_pred = list(map(lambda x: d[x], Y_test_pred))\n",
        "y_test = np.argmax(y_test, axis=-1)\n",
        "y_test = list(map(lambda x: d[x], y_test))\n",
        "print(classification_report(y_test, Y_test_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.81      0.70      0.75       151\n",
            "        fear       0.41      0.33      0.37       136\n",
            "       happy       0.51      0.39      0.44       140\n",
            "         sad       0.58      0.87      0.70       159\n",
            "\n",
            "    accuracy                           0.59       586\n",
            "   macro avg       0.58      0.57      0.57       586\n",
            "weighted avg       0.58      0.59      0.57       586\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aGj4vva1sJMP",
        "outputId": "f66da6ad-7eb6-42d6-c5be-a5805ec0c3a4"
      },
      "source": [
        "import scikitplot as skplt\n",
        "\n",
        "skplt.metrics.plot_confusion_matrix(\n",
        "    y_test, \n",
        "    Y_test_pred,\n",
        "    figsize=(8,8))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<AxesSubplot:title={'center':'Confusion Matrix'}, xlabel='Predicted label', ylabel='True label'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gc-dIBQIsJMR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0zRQZ1nG8Lxk"
      },
      "source": [
        "# mfcc_26 + conv1D:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDzhXx0B8LyC"
      },
      "source": [
        "audio_duration = 3\n",
        "sampling_rate = 22050\n",
        "input_length = sampling_rate * audio_duration"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lw2cG43e8LyD"
      },
      "source": [
        "features = []\n",
        "labels = []\n",
        "for i in range(len(Ravdess_DF['Paths'])):\n",
        "  if ((Ravdess_DF['Emotion'][i] == '03') | (Ravdess_DF['Emotion'][i] == '04') | \n",
        "      (Ravdess_DF['Emotion'][i] == '05') | (Ravdess_DF['Emotion'][i] == '06')):\n",
        "    signal, sr = librosa.load(Ravdess_DF['Paths'][i])\n",
        "\n",
        "    if len(signal) > input_length:\n",
        "      signal = signal[0:input_length]\n",
        "    elif  input_length > len(signal):\n",
        "      max_offset = input_length - len(signal)  \n",
        "      signal = np.pad(signal, (0, max_offset), \"constant\")\n",
        "\n",
        "    mfcc = librosa.feature.mfcc(y=signal, sr=sr, n_mfcc=26).T\n",
        "    mfcc = mfcc.reshape(-1,1)\n",
        "    features.append(mfcc)\n",
        "\n",
        "    if Ravdess_DF['Emotion'][i] == '03':\n",
        "      labels.append(0)\n",
        "    elif Ravdess_DF['Emotion'][i] == '04':\n",
        "      labels.append(1)\n",
        "    elif Ravdess_DF['Emotion'][i] == '05':\n",
        "      labels.append(2)\n",
        "    elif Ravdess_DF['Emotion'][i] == '06':\n",
        "      labels.append(3)\n",
        "\n",
        "\n",
        "for i in range(len(CREMA_D_df)):\n",
        "  if ((CREMA_D_df['Emotion'][i] == 'HAP') | (CREMA_D_df['Emotion'][i] == 'SAD') | \n",
        "      (CREMA_D_df['Emotion'][i] == 'ANG') | (CREMA_D_df['Emotion'][i] == 'FEA')):\n",
        "    \n",
        "    if CREMA_D_df['Emotion'][i] == 'HAP':\n",
        "      labels.append(0)\n",
        "    elif CREMA_D_df['Emotion'][i] == 'SAD':\n",
        "      labels.append(1)\n",
        "    elif CREMA_D_df['Emotion'][i] == 'ANG':\n",
        "      labels.append(2)\n",
        "    elif CREMA_D_df['Emotion'][i] == 'FEA':\n",
        "      labels.append(3)\n",
        "\n",
        "\n",
        "    signal, sr =  librosa.load(CREMA_D_df['Paths'][i])\n",
        "\n",
        "    if len(signal) > input_length:\n",
        "        signal = signal[0:input_length]\n",
        "    elif  input_length > len(signal):\n",
        "        max_offset = input_length - len(signal)  \n",
        "        signal = np.pad(signal, (0, max_offset), \"constant\")\n",
        "\n",
        "    mfcc = librosa.feature.mfcc(y=signal, sr=sr, n_mfcc=26).T\n",
        "    mfcc = mfcc.reshape(-1,1)\n",
        "    features.append(mfcc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lD55rhfH8LyE"
      },
      "source": [
        "X = features\n",
        "y = labels\n",
        "\n",
        "y = np.array(y)\n",
        "y = to_categorical(y)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=0)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=0)\n",
        "\n",
        "X_train = np.array(X_train)\n",
        "X_test = np.array(X_test)\n",
        "X_val = np.array(X_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TuVcTkxv8LyE",
        "outputId": "51068f51-fea5-421a-b7d9-0c4f31da6cab"
      },
      "source": [
        "X_train.shape,X_test.shape,y_train.shape,y_test.shape\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((4739, 3380, 1), (586, 3380, 1), (4739, 4), (586, 4))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HhVEPOyx8LyG"
      },
      "source": [
        "\n",
        "# CNN I/P Config\n",
        "num_classes = 4\n",
        "input_shape = X_train.shape[1:]\n",
        "learning_rate = 0.0001\n",
        "decay = 1e-6\n",
        "momentum = 0.9\n",
        "\n",
        "#LSTM Configuration\n",
        "num_lstm = 256"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WKPKoL-88LyH",
        "outputId": "35482150-20ab-4eda-c038-008f0ceda37f"
      },
      "source": [
        "model = Sequential(name='Audio_CNN_1D')\n",
        "\n",
        "# LFLB1\n",
        "model.add(Conv1D(filters=64, kernel_size=(3), strides=1, padding='same', data_format='channels_last',input_shape=input_shape))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('elu'))\n",
        "model.add(MaxPooling1D(pool_size=4, strides=4))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "# LFLB2\n",
        "model.add(Conv1D(filters=64, kernel_size=3, strides=1, padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('elu'))\n",
        "model.add(MaxPooling1D(pool_size=4, strides=4))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# LFLB3\n",
        "model.add(Conv1D(filters=128, kernel_size=3, strides=1, padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('elu'))\n",
        "model.add(MaxPooling1D(pool_size=4, strides=4))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# LFLB4\n",
        "model.add(Conv1D(filters=128, kernel_size=3, strides=1, padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('elu'))\n",
        "model.add(MaxPooling1D(pool_size=4, strides=4))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# LSTM\n",
        "model.add(LSTM(units=num_lstm))\n",
        "\n",
        "# FC\n",
        "model.add(Dense(units=num_classes, activation='softmax'))\n",
        "\n",
        "# Model compilation\n",
        "opt= keras.optimizers.Adam(lr=0.01, beta_1=0.9,  beta_2=0.999, amsgrad=False)\n",
        "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
        "\n",
        "model.summary()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"Audio_CNN_1D\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 3380, 64)          256       \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 3380, 64)          256       \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 3380, 64)          0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D) (None, 845, 64)           0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 845, 64)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 845, 64)           12352     \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 845, 64)           256       \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 845, 64)           0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1 (None, 211, 64)           0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 211, 64)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 211, 128)          24704     \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 211, 128)          512       \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 211, 128)          0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_2 (MaxPooling1 (None, 52, 128)           0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 52, 128)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 52, 128)           49280     \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 52, 128)           512       \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 52, 128)           0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_3 (MaxPooling1 (None, 13, 128)           0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 13, 128)           0         \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 256)               394240    \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 4)                 1028      \n",
            "=================================================================\n",
            "Total params: 483,396\n",
            "Trainable params: 482,628\n",
            "Non-trainable params: 768\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aWs3a8Ok8LyI",
        "outputId": "467a84d7-87bf-4c91-ca54-5c63e656fef1"
      },
      "source": [
        "#Train Config\n",
        "\n",
        "batch_size = 16\n",
        "num_epochs = 200\n",
        "\n",
        "# Model Training\n",
        "lr_reduce = ReduceLROnPlateau(monitor='val_loss', factor=0.9, patience=20, min_lr=0.000001)\n",
        "# Please change the model name accordingly.\n",
        "mcp_save = ModelCheckpoint('/content/Audio_1DCNN.h5', save_best_only=True, monitor='val_categorical_accuracy', mode='max')\n",
        "cnnhistory=model.fit(X_train, y_train, batch_size=batch_size, epochs=num_epochs,validation_data=(X_val, y_val), callbacks=[mcp_save, lr_reduce])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "297/297 [==============================] - 55s 16ms/step - loss: 1.3511 - categorical_accuracy: 0.4213 - val_loss: 1.9398 - val_categorical_accuracy: 0.2694\n",
            "Epoch 2/200\n",
            "297/297 [==============================] - 3s 11ms/step - loss: 1.1504 - categorical_accuracy: 0.4752 - val_loss: 1.6491 - val_categorical_accuracy: 0.3567\n",
            "Epoch 3/200\n",
            "297/297 [==============================] - 3s 12ms/step - loss: 1.1243 - categorical_accuracy: 0.4977 - val_loss: 1.1268 - val_categorical_accuracy: 0.4497\n",
            "Epoch 4/200\n",
            "297/297 [==============================] - 3s 12ms/step - loss: 1.1113 - categorical_accuracy: 0.4837 - val_loss: 1.2351 - val_categorical_accuracy: 0.4421\n",
            "Epoch 5/200\n",
            "297/297 [==============================] - 3s 12ms/step - loss: 1.1115 - categorical_accuracy: 0.4904 - val_loss: 1.1691 - val_categorical_accuracy: 0.4649\n",
            "Epoch 6/200\n",
            "297/297 [==============================] - 3s 11ms/step - loss: 1.1297 - categorical_accuracy: 0.4942 - val_loss: 1.0925 - val_categorical_accuracy: 0.5104\n",
            "Epoch 7/200\n",
            "297/297 [==============================] - 3s 12ms/step - loss: 1.0994 - categorical_accuracy: 0.5072 - val_loss: 1.0901 - val_categorical_accuracy: 0.4839\n",
            "Epoch 8/200\n",
            "297/297 [==============================] - 3s 12ms/step - loss: 1.0853 - categorical_accuracy: 0.5126 - val_loss: 1.1133 - val_categorical_accuracy: 0.4953\n",
            "Epoch 9/200\n",
            "297/297 [==============================] - 3s 11ms/step - loss: 1.0810 - categorical_accuracy: 0.5045 - val_loss: 1.1339 - val_categorical_accuracy: 0.4649\n",
            "Epoch 10/200\n",
            "297/297 [==============================] - 3s 12ms/step - loss: 1.0964 - categorical_accuracy: 0.4996 - val_loss: 1.1409 - val_categorical_accuracy: 0.4915\n",
            "Epoch 11/200\n",
            "297/297 [==============================] - 3s 12ms/step - loss: 1.0771 - categorical_accuracy: 0.5188 - val_loss: 1.1029 - val_categorical_accuracy: 0.4611\n",
            "Epoch 12/200\n",
            "297/297 [==============================] - 3s 12ms/step - loss: 1.0782 - categorical_accuracy: 0.5132 - val_loss: 1.0941 - val_categorical_accuracy: 0.5104\n",
            "Epoch 13/200\n",
            "297/297 [==============================] - 3s 11ms/step - loss: 1.0832 - categorical_accuracy: 0.5098 - val_loss: 1.1216 - val_categorical_accuracy: 0.4972\n",
            "Epoch 14/200\n",
            "297/297 [==============================] - 3s 12ms/step - loss: 1.0716 - categorical_accuracy: 0.5165 - val_loss: 1.0760 - val_categorical_accuracy: 0.5256\n",
            "Epoch 15/200\n",
            "297/297 [==============================] - 3s 12ms/step - loss: 1.0681 - categorical_accuracy: 0.5154 - val_loss: 1.0815 - val_categorical_accuracy: 0.5218\n",
            "Epoch 16/200\n",
            "297/297 [==============================] - 3s 12ms/step - loss: 1.0869 - categorical_accuracy: 0.5142 - val_loss: 1.1248 - val_categorical_accuracy: 0.4896\n",
            "Epoch 17/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 1.0813 - categorical_accuracy: 0.5100 - val_loss: 1.0895 - val_categorical_accuracy: 0.5009\n",
            "Epoch 18/200\n",
            "297/297 [==============================] - 3s 12ms/step - loss: 1.0351 - categorical_accuracy: 0.5423 - val_loss: 1.1089 - val_categorical_accuracy: 0.5009\n",
            "Epoch 19/200\n",
            "297/297 [==============================] - 3s 12ms/step - loss: 1.0694 - categorical_accuracy: 0.5286 - val_loss: 1.0934 - val_categorical_accuracy: 0.5009\n",
            "Epoch 20/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 1.0703 - categorical_accuracy: 0.5191 - val_loss: 1.1428 - val_categorical_accuracy: 0.5047\n",
            "Epoch 21/200\n",
            "297/297 [==============================] - 3s 12ms/step - loss: 1.0918 - categorical_accuracy: 0.5129 - val_loss: 1.0696 - val_categorical_accuracy: 0.5275\n",
            "Epoch 22/200\n",
            "297/297 [==============================] - 3s 12ms/step - loss: 1.0503 - categorical_accuracy: 0.5351 - val_loss: 1.0835 - val_categorical_accuracy: 0.5370\n",
            "Epoch 23/200\n",
            "297/297 [==============================] - 3s 12ms/step - loss: 1.0668 - categorical_accuracy: 0.5288 - val_loss: 1.0531 - val_categorical_accuracy: 0.5313\n",
            "Epoch 24/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 1.0440 - categorical_accuracy: 0.5353 - val_loss: 1.1315 - val_categorical_accuracy: 0.5142\n",
            "Epoch 25/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 1.0707 - categorical_accuracy: 0.5163 - val_loss: 1.0683 - val_categorical_accuracy: 0.5161\n",
            "Epoch 26/200\n",
            "297/297 [==============================] - 3s 12ms/step - loss: 1.0544 - categorical_accuracy: 0.5306 - val_loss: 1.1005 - val_categorical_accuracy: 0.4896\n",
            "Epoch 27/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 1.0482 - categorical_accuracy: 0.5239 - val_loss: 1.0534 - val_categorical_accuracy: 0.5408\n",
            "Epoch 28/200\n",
            "297/297 [==============================] - 3s 12ms/step - loss: 1.0400 - categorical_accuracy: 0.5451 - val_loss: 1.0592 - val_categorical_accuracy: 0.5351\n",
            "Epoch 29/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 1.0485 - categorical_accuracy: 0.5331 - val_loss: 1.0240 - val_categorical_accuracy: 0.5617\n",
            "Epoch 30/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 1.0253 - categorical_accuracy: 0.5446 - val_loss: 1.0731 - val_categorical_accuracy: 0.5370\n",
            "Epoch 31/200\n",
            "297/297 [==============================] - 3s 12ms/step - loss: 1.0466 - categorical_accuracy: 0.5313 - val_loss: 1.0819 - val_categorical_accuracy: 0.5351\n",
            "Epoch 32/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 1.0374 - categorical_accuracy: 0.5345 - val_loss: 1.1078 - val_categorical_accuracy: 0.4858\n",
            "Epoch 33/200\n",
            "297/297 [==============================] - 3s 12ms/step - loss: 1.0464 - categorical_accuracy: 0.5350 - val_loss: 1.1194 - val_categorical_accuracy: 0.5237\n",
            "Epoch 34/200\n",
            "297/297 [==============================] - 3s 12ms/step - loss: 1.0281 - categorical_accuracy: 0.5314 - val_loss: 1.0579 - val_categorical_accuracy: 0.5465\n",
            "Epoch 35/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 1.0291 - categorical_accuracy: 0.5395 - val_loss: 1.0732 - val_categorical_accuracy: 0.5541\n",
            "Epoch 36/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 1.0657 - categorical_accuracy: 0.5095 - val_loss: 1.2246 - val_categorical_accuracy: 0.5047\n",
            "Epoch 37/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 1.0381 - categorical_accuracy: 0.5431 - val_loss: 1.1236 - val_categorical_accuracy: 0.5066\n",
            "Epoch 38/200\n",
            "297/297 [==============================] - 3s 12ms/step - loss: 1.0573 - categorical_accuracy: 0.5272 - val_loss: 1.0821 - val_categorical_accuracy: 0.5085\n",
            "Epoch 39/200\n",
            "297/297 [==============================] - 3s 12ms/step - loss: 1.0171 - categorical_accuracy: 0.5446 - val_loss: 1.0752 - val_categorical_accuracy: 0.5218\n",
            "Epoch 40/200\n",
            "297/297 [==============================] - 3s 12ms/step - loss: 1.0523 - categorical_accuracy: 0.5240 - val_loss: 1.0724 - val_categorical_accuracy: 0.5294\n",
            "Epoch 41/200\n",
            "297/297 [==============================] - 3s 12ms/step - loss: 1.0569 - categorical_accuracy: 0.5334 - val_loss: 1.0686 - val_categorical_accuracy: 0.5294\n",
            "Epoch 42/200\n",
            "297/297 [==============================] - 3s 12ms/step - loss: 1.0429 - categorical_accuracy: 0.5353 - val_loss: 1.1723 - val_categorical_accuracy: 0.5085\n",
            "Epoch 43/200\n",
            "297/297 [==============================] - 3s 12ms/step - loss: 1.0407 - categorical_accuracy: 0.5404 - val_loss: 1.0894 - val_categorical_accuracy: 0.5237\n",
            "Epoch 44/200\n",
            "297/297 [==============================] - 3s 12ms/step - loss: 1.0374 - categorical_accuracy: 0.5314 - val_loss: 1.1025 - val_categorical_accuracy: 0.5294\n",
            "Epoch 45/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 1.0315 - categorical_accuracy: 0.5409 - val_loss: 1.0984 - val_categorical_accuracy: 0.5218\n",
            "Epoch 46/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 1.0638 - categorical_accuracy: 0.5272 - val_loss: 1.1264 - val_categorical_accuracy: 0.5199\n",
            "Epoch 47/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 1.0494 - categorical_accuracy: 0.5243 - val_loss: 1.0768 - val_categorical_accuracy: 0.5218\n",
            "Epoch 48/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 1.0855 - categorical_accuracy: 0.5093 - val_loss: 1.1004 - val_categorical_accuracy: 0.4820\n",
            "Epoch 49/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 1.0391 - categorical_accuracy: 0.5276 - val_loss: 1.0893 - val_categorical_accuracy: 0.4839\n",
            "Epoch 50/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 1.0395 - categorical_accuracy: 0.5347 - val_loss: 1.0517 - val_categorical_accuracy: 0.5294\n",
            "Epoch 51/200\n",
            "297/297 [==============================] - 3s 12ms/step - loss: 1.0310 - categorical_accuracy: 0.5401 - val_loss: 1.0873 - val_categorical_accuracy: 0.5199\n",
            "Epoch 52/200\n",
            "297/297 [==============================] - 3s 12ms/step - loss: 1.0056 - categorical_accuracy: 0.5474 - val_loss: 1.0795 - val_categorical_accuracy: 0.5351\n",
            "Epoch 53/200\n",
            "297/297 [==============================] - 3s 12ms/step - loss: 1.0233 - categorical_accuracy: 0.5366 - val_loss: 1.0290 - val_categorical_accuracy: 0.5541\n",
            "Epoch 54/200\n",
            "297/297 [==============================] - 3s 12ms/step - loss: 1.0176 - categorical_accuracy: 0.5256 - val_loss: 1.0569 - val_categorical_accuracy: 0.5199\n",
            "Epoch 55/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 1.0173 - categorical_accuracy: 0.5427 - val_loss: 1.0490 - val_categorical_accuracy: 0.5256\n",
            "Epoch 56/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 1.0244 - categorical_accuracy: 0.5437 - val_loss: 1.0518 - val_categorical_accuracy: 0.5028\n",
            "Epoch 57/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 1.0150 - categorical_accuracy: 0.5467 - val_loss: 1.0721 - val_categorical_accuracy: 0.5237\n",
            "Epoch 58/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 1.0271 - categorical_accuracy: 0.5443 - val_loss: 1.0789 - val_categorical_accuracy: 0.5389\n",
            "Epoch 59/200\n",
            "297/297 [==============================] - 3s 12ms/step - loss: 1.0265 - categorical_accuracy: 0.5383 - val_loss: 1.0678 - val_categorical_accuracy: 0.5351\n",
            "Epoch 60/200\n",
            "297/297 [==============================] - 3s 12ms/step - loss: 1.0317 - categorical_accuracy: 0.5399 - val_loss: 1.0937 - val_categorical_accuracy: 0.5161\n",
            "Epoch 61/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 1.0267 - categorical_accuracy: 0.5369 - val_loss: 1.0801 - val_categorical_accuracy: 0.5161\n",
            "Epoch 62/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 1.0054 - categorical_accuracy: 0.5477 - val_loss: 1.0128 - val_categorical_accuracy: 0.5389\n",
            "Epoch 63/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 1.0208 - categorical_accuracy: 0.5499 - val_loss: 1.0661 - val_categorical_accuracy: 0.5332\n",
            "Epoch 64/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 1.0180 - categorical_accuracy: 0.5452 - val_loss: 1.0510 - val_categorical_accuracy: 0.5370\n",
            "Epoch 65/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 1.0242 - categorical_accuracy: 0.5447 - val_loss: 1.0333 - val_categorical_accuracy: 0.5218\n",
            "Epoch 66/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 0.9967 - categorical_accuracy: 0.5539 - val_loss: 1.0991 - val_categorical_accuracy: 0.5180\n",
            "Epoch 67/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 1.0368 - categorical_accuracy: 0.5431 - val_loss: 1.0183 - val_categorical_accuracy: 0.5370\n",
            "Epoch 68/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 0.9906 - categorical_accuracy: 0.5475 - val_loss: 1.1753 - val_categorical_accuracy: 0.4763\n",
            "Epoch 69/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 1.0144 - categorical_accuracy: 0.5531 - val_loss: 1.0998 - val_categorical_accuracy: 0.5313\n",
            "Epoch 70/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 1.0277 - categorical_accuracy: 0.5478 - val_loss: 1.1059 - val_categorical_accuracy: 0.4991\n",
            "Epoch 71/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 1.0080 - categorical_accuracy: 0.5620 - val_loss: 1.0811 - val_categorical_accuracy: 0.5123\n",
            "Epoch 72/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 1.0003 - categorical_accuracy: 0.5625 - val_loss: 1.0313 - val_categorical_accuracy: 0.5313\n",
            "Epoch 73/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 1.0371 - categorical_accuracy: 0.5186 - val_loss: 1.0231 - val_categorical_accuracy: 0.5370\n",
            "Epoch 74/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 1.0231 - categorical_accuracy: 0.5396 - val_loss: 1.0681 - val_categorical_accuracy: 0.5104\n",
            "Epoch 75/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 1.0243 - categorical_accuracy: 0.5415 - val_loss: 1.1034 - val_categorical_accuracy: 0.4478\n",
            "Epoch 76/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 1.0319 - categorical_accuracy: 0.5286 - val_loss: 1.0385 - val_categorical_accuracy: 0.5275\n",
            "Epoch 77/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 1.0074 - categorical_accuracy: 0.5451 - val_loss: 1.0428 - val_categorical_accuracy: 0.5294\n",
            "Epoch 78/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 1.0073 - categorical_accuracy: 0.5502 - val_loss: 1.0401 - val_categorical_accuracy: 0.5199\n",
            "Epoch 79/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 1.0250 - categorical_accuracy: 0.5306 - val_loss: 1.0117 - val_categorical_accuracy: 0.5522\n",
            "Epoch 80/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 1.0026 - categorical_accuracy: 0.5573 - val_loss: 1.0336 - val_categorical_accuracy: 0.5446\n",
            "Epoch 81/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 1.0176 - categorical_accuracy: 0.5409 - val_loss: 1.0249 - val_categorical_accuracy: 0.5503\n",
            "Epoch 82/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 1.0126 - categorical_accuracy: 0.5418 - val_loss: 1.0401 - val_categorical_accuracy: 0.5446\n",
            "Epoch 83/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 1.0200 - categorical_accuracy: 0.5613 - val_loss: 1.0192 - val_categorical_accuracy: 0.5503\n",
            "Epoch 84/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 1.0239 - categorical_accuracy: 0.5447 - val_loss: 1.0099 - val_categorical_accuracy: 0.5750\n",
            "Epoch 85/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 0.9894 - categorical_accuracy: 0.5620 - val_loss: 1.1193 - val_categorical_accuracy: 0.4858\n",
            "Epoch 86/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 1.0173 - categorical_accuracy: 0.5455 - val_loss: 1.0767 - val_categorical_accuracy: 0.5180\n",
            "Epoch 87/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 1.0077 - categorical_accuracy: 0.5543 - val_loss: 1.0562 - val_categorical_accuracy: 0.5389\n",
            "Epoch 88/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 1.0007 - categorical_accuracy: 0.5589 - val_loss: 1.0551 - val_categorical_accuracy: 0.5009\n",
            "Epoch 89/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 0.9896 - categorical_accuracy: 0.5581 - val_loss: 1.0309 - val_categorical_accuracy: 0.5199\n",
            "Epoch 90/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 1.0058 - categorical_accuracy: 0.5507 - val_loss: 1.0966 - val_categorical_accuracy: 0.4725\n",
            "Epoch 91/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 0.9886 - categorical_accuracy: 0.5479 - val_loss: 1.0246 - val_categorical_accuracy: 0.5484\n",
            "Epoch 92/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 1.0297 - categorical_accuracy: 0.5381 - val_loss: 1.0496 - val_categorical_accuracy: 0.5370\n",
            "Epoch 93/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 1.0333 - categorical_accuracy: 0.5361 - val_loss: 1.0366 - val_categorical_accuracy: 0.5332\n",
            "Epoch 94/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 1.0028 - categorical_accuracy: 0.5611 - val_loss: 1.0208 - val_categorical_accuracy: 0.5408\n",
            "Epoch 95/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 0.9780 - categorical_accuracy: 0.5681 - val_loss: 1.0174 - val_categorical_accuracy: 0.5693\n",
            "Epoch 96/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 1.0294 - categorical_accuracy: 0.5465 - val_loss: 1.0541 - val_categorical_accuracy: 0.5560\n",
            "Epoch 97/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 1.0306 - categorical_accuracy: 0.5450 - val_loss: 1.0596 - val_categorical_accuracy: 0.5427\n",
            "Epoch 98/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 1.0365 - categorical_accuracy: 0.5357 - val_loss: 1.0985 - val_categorical_accuracy: 0.5218\n",
            "Epoch 99/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 1.0028 - categorical_accuracy: 0.5583 - val_loss: 1.1082 - val_categorical_accuracy: 0.4801\n",
            "Epoch 100/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 1.0230 - categorical_accuracy: 0.5426 - val_loss: 1.1102 - val_categorical_accuracy: 0.4782\n",
            "Epoch 101/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 1.0084 - categorical_accuracy: 0.5421 - val_loss: 1.0813 - val_categorical_accuracy: 0.5161\n",
            "Epoch 102/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 0.9866 - categorical_accuracy: 0.5507 - val_loss: 1.0106 - val_categorical_accuracy: 0.5408\n",
            "Epoch 103/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 1.0078 - categorical_accuracy: 0.5565 - val_loss: 1.0547 - val_categorical_accuracy: 0.5332\n",
            "Epoch 104/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 0.9882 - categorical_accuracy: 0.5457 - val_loss: 1.0468 - val_categorical_accuracy: 0.5237\n",
            "Epoch 105/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 1.0041 - categorical_accuracy: 0.5470 - val_loss: 1.0292 - val_categorical_accuracy: 0.5408\n",
            "Epoch 106/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 0.9844 - categorical_accuracy: 0.5626 - val_loss: 1.1221 - val_categorical_accuracy: 0.4991\n",
            "Epoch 107/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 0.9724 - categorical_accuracy: 0.5612 - val_loss: 1.0197 - val_categorical_accuracy: 0.5522\n",
            "Epoch 108/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 0.9999 - categorical_accuracy: 0.5504 - val_loss: 1.0648 - val_categorical_accuracy: 0.5028\n",
            "Epoch 109/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 0.9929 - categorical_accuracy: 0.5659 - val_loss: 1.0176 - val_categorical_accuracy: 0.5560\n",
            "Epoch 110/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 0.9959 - categorical_accuracy: 0.5673 - val_loss: 1.0447 - val_categorical_accuracy: 0.5142\n",
            "Epoch 111/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 1.0251 - categorical_accuracy: 0.5267 - val_loss: 1.0274 - val_categorical_accuracy: 0.5180\n",
            "Epoch 112/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 0.9819 - categorical_accuracy: 0.5702 - val_loss: 0.9956 - val_categorical_accuracy: 0.5522\n",
            "Epoch 113/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 0.9869 - categorical_accuracy: 0.5603 - val_loss: 1.0600 - val_categorical_accuracy: 0.5028\n",
            "Epoch 114/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 0.9999 - categorical_accuracy: 0.5537 - val_loss: 1.0247 - val_categorical_accuracy: 0.5294\n",
            "Epoch 115/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 1.0212 - categorical_accuracy: 0.5318 - val_loss: 1.0131 - val_categorical_accuracy: 0.5674\n",
            "Epoch 116/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 1.0037 - categorical_accuracy: 0.5597 - val_loss: 1.0477 - val_categorical_accuracy: 0.5389\n",
            "Epoch 117/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 1.0026 - categorical_accuracy: 0.5582 - val_loss: 1.2606 - val_categorical_accuracy: 0.4953\n",
            "Epoch 118/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 0.9790 - categorical_accuracy: 0.5673 - val_loss: 1.0340 - val_categorical_accuracy: 0.5446\n",
            "Epoch 119/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 1.0015 - categorical_accuracy: 0.5553 - val_loss: 1.0028 - val_categorical_accuracy: 0.5579\n",
            "Epoch 120/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 0.9908 - categorical_accuracy: 0.5637 - val_loss: 1.0120 - val_categorical_accuracy: 0.5579\n",
            "Epoch 121/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 0.9874 - categorical_accuracy: 0.5529 - val_loss: 1.0661 - val_categorical_accuracy: 0.5275\n",
            "Epoch 122/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 0.9893 - categorical_accuracy: 0.5517 - val_loss: 1.1040 - val_categorical_accuracy: 0.4896\n",
            "Epoch 123/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 0.9912 - categorical_accuracy: 0.5620 - val_loss: 0.9990 - val_categorical_accuracy: 0.5522\n",
            "Epoch 124/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 0.9721 - categorical_accuracy: 0.5672 - val_loss: 1.0462 - val_categorical_accuracy: 0.5275\n",
            "Epoch 125/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 0.9801 - categorical_accuracy: 0.5593 - val_loss: 1.0529 - val_categorical_accuracy: 0.4687\n",
            "Epoch 126/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 0.9870 - categorical_accuracy: 0.5603 - val_loss: 1.0946 - val_categorical_accuracy: 0.5047\n",
            "Epoch 127/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 0.9867 - categorical_accuracy: 0.5562 - val_loss: 1.0028 - val_categorical_accuracy: 0.5655\n",
            "Epoch 128/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 0.9982 - categorical_accuracy: 0.5647 - val_loss: 1.0479 - val_categorical_accuracy: 0.4972\n",
            "Epoch 129/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 1.0032 - categorical_accuracy: 0.5599 - val_loss: 1.0686 - val_categorical_accuracy: 0.5047\n",
            "Epoch 130/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 0.9731 - categorical_accuracy: 0.5725 - val_loss: 1.0380 - val_categorical_accuracy: 0.5503\n",
            "Epoch 131/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 0.9744 - categorical_accuracy: 0.5770 - val_loss: 1.0537 - val_categorical_accuracy: 0.5465\n",
            "Epoch 132/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 0.9784 - categorical_accuracy: 0.5641 - val_loss: 1.1161 - val_categorical_accuracy: 0.4668\n",
            "Epoch 133/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 1.0161 - categorical_accuracy: 0.5308 - val_loss: 0.9994 - val_categorical_accuracy: 0.5541\n",
            "Epoch 134/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 0.9753 - categorical_accuracy: 0.5612 - val_loss: 1.0171 - val_categorical_accuracy: 0.5750\n",
            "Epoch 135/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 0.9739 - categorical_accuracy: 0.5706 - val_loss: 1.0047 - val_categorical_accuracy: 0.5427\n",
            "Epoch 136/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 0.9738 - categorical_accuracy: 0.5643 - val_loss: 0.9711 - val_categorical_accuracy: 0.5598\n",
            "Epoch 137/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 0.9506 - categorical_accuracy: 0.5845 - val_loss: 1.0125 - val_categorical_accuracy: 0.5522\n",
            "Epoch 138/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 0.9788 - categorical_accuracy: 0.5733 - val_loss: 0.9657 - val_categorical_accuracy: 0.5806\n",
            "Epoch 139/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 0.9654 - categorical_accuracy: 0.5696 - val_loss: 0.9623 - val_categorical_accuracy: 0.5712\n",
            "Epoch 140/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 0.9581 - categorical_accuracy: 0.5844 - val_loss: 1.0417 - val_categorical_accuracy: 0.5465\n",
            "Epoch 141/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 0.9734 - categorical_accuracy: 0.5836 - val_loss: 1.0164 - val_categorical_accuracy: 0.5636\n",
            "Epoch 142/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 0.9892 - categorical_accuracy: 0.5433 - val_loss: 0.9870 - val_categorical_accuracy: 0.5655\n",
            "Epoch 143/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 0.9719 - categorical_accuracy: 0.5751 - val_loss: 1.0841 - val_categorical_accuracy: 0.4972\n",
            "Epoch 144/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 0.9933 - categorical_accuracy: 0.5499 - val_loss: 0.9971 - val_categorical_accuracy: 0.5465\n",
            "Epoch 145/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 0.9699 - categorical_accuracy: 0.5695 - val_loss: 0.9890 - val_categorical_accuracy: 0.5693\n",
            "Epoch 146/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 0.9699 - categorical_accuracy: 0.5717 - val_loss: 0.9905 - val_categorical_accuracy: 0.5560\n",
            "Epoch 147/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 0.9886 - categorical_accuracy: 0.5584 - val_loss: 0.9903 - val_categorical_accuracy: 0.5598\n",
            "Epoch 148/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 0.9803 - categorical_accuracy: 0.5687 - val_loss: 0.9956 - val_categorical_accuracy: 0.5655\n",
            "Epoch 149/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 0.9641 - categorical_accuracy: 0.5739 - val_loss: 1.0592 - val_categorical_accuracy: 0.4535\n",
            "Epoch 150/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 0.9899 - categorical_accuracy: 0.5580 - val_loss: 1.2232 - val_categorical_accuracy: 0.4953\n",
            "Epoch 151/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 0.9653 - categorical_accuracy: 0.5754 - val_loss: 1.0433 - val_categorical_accuracy: 0.5104\n",
            "Epoch 152/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 0.9742 - categorical_accuracy: 0.5634 - val_loss: 1.0347 - val_categorical_accuracy: 0.5161\n",
            "Epoch 153/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 0.9773 - categorical_accuracy: 0.5557 - val_loss: 1.0189 - val_categorical_accuracy: 0.5370\n",
            "Epoch 154/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 0.9614 - categorical_accuracy: 0.5759 - val_loss: 1.0628 - val_categorical_accuracy: 0.5142\n",
            "Epoch 155/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 0.9558 - categorical_accuracy: 0.5801 - val_loss: 1.0765 - val_categorical_accuracy: 0.5199\n",
            "Epoch 156/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 0.9626 - categorical_accuracy: 0.5798 - val_loss: 1.0736 - val_categorical_accuracy: 0.5275\n",
            "Epoch 157/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 0.9825 - categorical_accuracy: 0.5738 - val_loss: 1.0250 - val_categorical_accuracy: 0.5332\n",
            "Epoch 158/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 0.9394 - categorical_accuracy: 0.5875 - val_loss: 0.9995 - val_categorical_accuracy: 0.5427\n",
            "Epoch 159/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 0.9440 - categorical_accuracy: 0.5820 - val_loss: 1.1101 - val_categorical_accuracy: 0.5028\n",
            "Epoch 160/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 0.9436 - categorical_accuracy: 0.5915 - val_loss: 1.0757 - val_categorical_accuracy: 0.4877\n",
            "Epoch 161/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 0.9590 - categorical_accuracy: 0.5801 - val_loss: 1.0258 - val_categorical_accuracy: 0.5085\n",
            "Epoch 162/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 0.9726 - categorical_accuracy: 0.5792 - val_loss: 0.9894 - val_categorical_accuracy: 0.5769\n",
            "Epoch 163/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 0.9628 - categorical_accuracy: 0.5781 - val_loss: 0.9775 - val_categorical_accuracy: 0.5465\n",
            "Epoch 164/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 0.9567 - categorical_accuracy: 0.5780 - val_loss: 0.9830 - val_categorical_accuracy: 0.5522\n",
            "Epoch 165/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 0.9642 - categorical_accuracy: 0.5613 - val_loss: 0.9884 - val_categorical_accuracy: 0.5655\n",
            "Epoch 166/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 0.9827 - categorical_accuracy: 0.5614 - val_loss: 1.0635 - val_categorical_accuracy: 0.4953\n",
            "Epoch 167/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 0.9589 - categorical_accuracy: 0.5718 - val_loss: 1.0022 - val_categorical_accuracy: 0.5750\n",
            "Epoch 168/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 0.9825 - categorical_accuracy: 0.5713 - val_loss: 1.0035 - val_categorical_accuracy: 0.5294\n",
            "Epoch 169/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 0.9892 - categorical_accuracy: 0.5526 - val_loss: 1.0284 - val_categorical_accuracy: 0.5237\n",
            "Epoch 170/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 0.9663 - categorical_accuracy: 0.5872 - val_loss: 1.1360 - val_categorical_accuracy: 0.4820\n",
            "Epoch 171/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 0.9348 - categorical_accuracy: 0.5898 - val_loss: 0.9811 - val_categorical_accuracy: 0.5579\n",
            "Epoch 172/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 0.9721 - categorical_accuracy: 0.5828 - val_loss: 0.9499 - val_categorical_accuracy: 0.5769\n",
            "Epoch 173/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 0.9272 - categorical_accuracy: 0.5884 - val_loss: 1.0778 - val_categorical_accuracy: 0.4915\n",
            "Epoch 174/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 0.9506 - categorical_accuracy: 0.5630 - val_loss: 1.0297 - val_categorical_accuracy: 0.5484\n",
            "Epoch 175/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 0.9542 - categorical_accuracy: 0.5798 - val_loss: 1.0063 - val_categorical_accuracy: 0.5256\n",
            "Epoch 176/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 0.9316 - categorical_accuracy: 0.5937 - val_loss: 1.0631 - val_categorical_accuracy: 0.5218\n",
            "Epoch 177/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 0.9616 - categorical_accuracy: 0.5792 - val_loss: 0.9623 - val_categorical_accuracy: 0.5598\n",
            "Epoch 178/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 0.9560 - categorical_accuracy: 0.5794 - val_loss: 0.9801 - val_categorical_accuracy: 0.5503\n",
            "Epoch 179/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 0.9388 - categorical_accuracy: 0.5964 - val_loss: 1.0380 - val_categorical_accuracy: 0.5237\n",
            "Epoch 180/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 0.9290 - categorical_accuracy: 0.6072 - val_loss: 1.1656 - val_categorical_accuracy: 0.5009\n",
            "Epoch 181/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 0.9307 - categorical_accuracy: 0.5956 - val_loss: 0.9873 - val_categorical_accuracy: 0.5693\n",
            "Epoch 182/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 0.9457 - categorical_accuracy: 0.5959 - val_loss: 0.9715 - val_categorical_accuracy: 0.5750\n",
            "Epoch 183/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 0.9317 - categorical_accuracy: 0.5900 - val_loss: 0.9426 - val_categorical_accuracy: 0.5920\n",
            "Epoch 184/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 0.9508 - categorical_accuracy: 0.5790 - val_loss: 0.9481 - val_categorical_accuracy: 0.5787\n",
            "Epoch 185/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 0.9400 - categorical_accuracy: 0.5899 - val_loss: 0.9723 - val_categorical_accuracy: 0.5674\n",
            "Epoch 186/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 0.9398 - categorical_accuracy: 0.5919 - val_loss: 1.0888 - val_categorical_accuracy: 0.4858\n",
            "Epoch 187/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 0.9439 - categorical_accuracy: 0.5872 - val_loss: 0.9566 - val_categorical_accuracy: 0.5522\n",
            "Epoch 188/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 0.9668 - categorical_accuracy: 0.5864 - val_loss: 1.0573 - val_categorical_accuracy: 0.5370\n",
            "Epoch 189/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 0.9636 - categorical_accuracy: 0.5698 - val_loss: 1.0584 - val_categorical_accuracy: 0.5389\n",
            "Epoch 190/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 0.9606 - categorical_accuracy: 0.5773 - val_loss: 1.0064 - val_categorical_accuracy: 0.5408\n",
            "Epoch 191/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 0.9480 - categorical_accuracy: 0.5743 - val_loss: 0.9813 - val_categorical_accuracy: 0.5465\n",
            "Epoch 192/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 0.9428 - categorical_accuracy: 0.5825 - val_loss: 0.9804 - val_categorical_accuracy: 0.5503\n",
            "Epoch 193/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 0.9300 - categorical_accuracy: 0.6015 - val_loss: 0.9840 - val_categorical_accuracy: 0.5674\n",
            "Epoch 194/200\n",
            "297/297 [==============================] - 4s 13ms/step - loss: 0.9545 - categorical_accuracy: 0.5896 - val_loss: 1.0481 - val_categorical_accuracy: 0.5237\n",
            "Epoch 195/200\n",
            "297/297 [==============================] - 4s 13ms/step - loss: 0.9577 - categorical_accuracy: 0.5839 - val_loss: 0.9700 - val_categorical_accuracy: 0.5731\n",
            "Epoch 196/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 0.9424 - categorical_accuracy: 0.5842 - val_loss: 1.1217 - val_categorical_accuracy: 0.4725\n",
            "Epoch 197/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 0.9125 - categorical_accuracy: 0.5962 - val_loss: 1.0514 - val_categorical_accuracy: 0.5256\n",
            "Epoch 198/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 0.9532 - categorical_accuracy: 0.5856 - val_loss: 1.0443 - val_categorical_accuracy: 0.5237\n",
            "Epoch 199/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 0.9662 - categorical_accuracy: 0.5742 - val_loss: 1.0944 - val_categorical_accuracy: 0.5161\n",
            "Epoch 200/200\n",
            "297/297 [==============================] - 4s 12ms/step - loss: 0.9436 - categorical_accuracy: 0.5906 - val_loss: 1.0947 - val_categorical_accuracy: 0.4991\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FSQMRrtt8LyK"
      },
      "source": [
        "model.save('/content/drive/MyDrive/Colab Notebooks/SPEECH_EMOTION_Recognition/Nộp bài(chốt hạ)/model_saver/conv1D_mfcc26_merged.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "soL_83cb8LyL"
      },
      "source": [
        "###test_result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HeaUupku8LyM",
        "outputId": "794f8757-87ed-4a24-a36c-7323425b303e"
      },
      "source": [
        "d = {0: 'happy',\n",
        "     1: 'sad',\n",
        "     2: 'angry',\n",
        "     3: 'fear'}\n",
        "Y_test_pred = np.argmax(model.predict(X_test), axis=-1)\n",
        "Y_test_pred = list(map(lambda x: d[x], Y_test_pred))\n",
        "y_test = np.argmax(y_test, axis=-1)\n",
        "y_test = list(map(lambda x: d[x], y_test))\n",
        "print(classification_report(y_test, Y_test_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.92      0.35      0.51       129\n",
            "        fear       0.46      0.58      0.51       174\n",
            "       happy       0.44      0.41      0.42       127\n",
            "         sad       0.60      0.76      0.67       156\n",
            "\n",
            "    accuracy                           0.54       586\n",
            "   macro avg       0.60      0.53      0.53       586\n",
            "weighted avg       0.59      0.54      0.53       586\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "id": "0I7Pgkx58LyN",
        "outputId": "40622643-1aed-49b7-ee3c-ffe75dc6e489"
      },
      "source": [
        "import scikitplot as skplt\n",
        "\n",
        "skplt.metrics.plot_confusion_matrix(\n",
        "    y_test, \n",
        "    Y_test_pred,\n",
        "    figsize=(8,8))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f44e4e65c50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xHBdsNOD8LyO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZpIh-TaKsLc8"
      },
      "source": [
        "# mfcc_39 + conv1D:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h7vPPBRPsLdj"
      },
      "source": [
        "audio_duration = 3\n",
        "sampling_rate = 22050\n",
        "input_length = sampling_rate * audio_duration"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGoqD5OksLdj"
      },
      "source": [
        "features = []\n",
        "labels = []\n",
        "for i in range(len(Ravdess_DF['Paths'])):\n",
        "  if ((Ravdess_DF['Emotion'][i] == '03') | (Ravdess_DF['Emotion'][i] == '04') | \n",
        "      (Ravdess_DF['Emotion'][i] == '05') | (Ravdess_DF['Emotion'][i] == '06')):\n",
        "    signal, sr = librosa.load(Ravdess_DF['Paths'][i])\n",
        "\n",
        "    if len(signal) > input_length:\n",
        "      signal = signal[0:input_length]\n",
        "    elif  input_length > len(signal):\n",
        "      max_offset = input_length - len(signal)  \n",
        "      signal = np.pad(signal, (0, max_offset), \"constant\")\n",
        "\n",
        "    mfcc = librosa.feature.mfcc(y=signal, sr=sr, n_mfcc=39).T\n",
        "    mfcc = mfcc.reshape(-1,1)\n",
        "    features.append(mfcc)\n",
        "\n",
        "    if Ravdess_DF['Emotion'][i] == '03':\n",
        "      labels.append(0)\n",
        "    elif Ravdess_DF['Emotion'][i] == '04':\n",
        "      labels.append(1)\n",
        "    elif Ravdess_DF['Emotion'][i] == '05':\n",
        "      labels.append(2)\n",
        "    elif Ravdess_DF['Emotion'][i] == '06':\n",
        "      labels.append(3)\n",
        "\n",
        "\n",
        "for i in range(len(CREMA_D_df)):\n",
        "  if ((CREMA_D_df['Emotion'][i] == 'HAP') | (CREMA_D_df['Emotion'][i] == 'SAD') | \n",
        "      (CREMA_D_df['Emotion'][i] == 'ANG') | (CREMA_D_df['Emotion'][i] == 'FEA')):\n",
        "    \n",
        "    if CREMA_D_df['Emotion'][i] == 'HAP':\n",
        "      labels.append(0)\n",
        "    elif CREMA_D_df['Emotion'][i] == 'SAD':\n",
        "      labels.append(1)\n",
        "    elif CREMA_D_df['Emotion'][i] == 'ANG':\n",
        "      labels.append(2)\n",
        "    elif CREMA_D_df['Emotion'][i] == 'FEA':\n",
        "      labels.append(3)\n",
        "\n",
        "\n",
        "    signal, sr =  librosa.load(CREMA_D_df['Paths'][i])\n",
        "\n",
        "    if len(signal) > input_length:\n",
        "        signal = signal[0:input_length]\n",
        "    elif  input_length > len(signal):\n",
        "        max_offset = input_length - len(signal)  \n",
        "        signal = np.pad(signal, (0, max_offset), \"constant\")\n",
        "\n",
        "    mfcc = librosa.feature.mfcc(y=signal, sr=sr, n_mfcc=39).T\n",
        "    mfcc = mfcc.reshape(-1,1)\n",
        "    features.append(mfcc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sarMg9qVsLdk"
      },
      "source": [
        "X = features\n",
        "y = labels\n",
        "\n",
        "y = np.array(y)\n",
        "y = to_categorical(y)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=0)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=0)\n",
        "\n",
        "X_train = np.array(X_train)\n",
        "X_test = np.array(X_test)\n",
        "X_val = np.array(X_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7z7p-ZOlsLdk",
        "outputId": "b5b0c5f4-73ac-4b78-c575-c2898c55b956"
      },
      "source": [
        "X_train.shape,X_test.shape,y_train.shape,y_test.shape\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((4739, 5070, 1), (586, 5070, 1), (4739, 4), (586, 4))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1Ubsz7tsLdm"
      },
      "source": [
        "\n",
        "# CNN I/P Config\n",
        "num_classes = 4\n",
        "input_shape = X_train.shape[1:]\n",
        "learning_rate = 0.0001\n",
        "decay = 1e-6\n",
        "momentum = 0.9\n",
        "\n",
        "#LSTM Configuration\n",
        "num_lstm = 256"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5iow3KTsLdm",
        "outputId": "50ce6fd4-9335-4613-878c-4e387ab84d0b"
      },
      "source": [
        "model = Sequential(name='Audio_CNN_1D')\n",
        "\n",
        "# LFLB1\n",
        "model.add(Conv1D(filters=64, kernel_size=(3), strides=1, padding='same', data_format='channels_last',input_shape=input_shape))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('elu'))\n",
        "model.add(MaxPooling1D(pool_size=4, strides=4))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "# LFLB2\n",
        "model.add(Conv1D(filters=64, kernel_size=3, strides=1, padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('elu'))\n",
        "model.add(MaxPooling1D(pool_size=4, strides=4))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# LFLB3\n",
        "model.add(Conv1D(filters=128, kernel_size=3, strides=1, padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('elu'))\n",
        "model.add(MaxPooling1D(pool_size=4, strides=4))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# LFLB4\n",
        "model.add(Conv1D(filters=128, kernel_size=3, strides=1, padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('elu'))\n",
        "model.add(MaxPooling1D(pool_size=4, strides=4))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# LSTM\n",
        "model.add(LSTM(units=num_lstm))\n",
        "\n",
        "# FC\n",
        "model.add(Dense(units=num_classes, activation='softmax'))\n",
        "\n",
        "# Model compilation\n",
        "opt= keras.optimizers.Adam(lr=0.01, beta_1=0.9,  beta_2=0.999, amsgrad=False)\n",
        "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
        "\n",
        "model.summary()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"Audio_CNN_1D\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_4 (Conv1D)            (None, 5070, 64)          256       \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 5070, 64)          256       \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 5070, 64)          0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_4 (MaxPooling1 (None, 1267, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 1267, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv1d_5 (Conv1D)            (None, 1267, 64)          12352     \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 1267, 64)          256       \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 1267, 64)          0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_5 (MaxPooling1 (None, 316, 64)           0         \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 316, 64)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_6 (Conv1D)            (None, 316, 128)          24704     \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 316, 128)          512       \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 316, 128)          0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_6 (MaxPooling1 (None, 79, 128)           0         \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 79, 128)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_7 (Conv1D)            (None, 79, 128)           49280     \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 79, 128)           512       \n",
            "_________________________________________________________________\n",
            "activation_7 (Activation)    (None, 79, 128)           0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_7 (MaxPooling1 (None, 19, 128)           0         \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 19, 128)           0         \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 256)               394240    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 4)                 1028      \n",
            "=================================================================\n",
            "Total params: 483,396\n",
            "Trainable params: 482,628\n",
            "Non-trainable params: 768\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CxCPGD8vsLdm",
        "outputId": "94c1c95c-a9cb-4d9a-99c0-48734e5dac99"
      },
      "source": [
        "#Train Config\n",
        "\n",
        "batch_size = 16\n",
        "num_epochs = 200\n",
        "\n",
        "# Model Training\n",
        "lr_reduce = ReduceLROnPlateau(monitor='val_loss', factor=0.9, patience=20, min_lr=0.000001)\n",
        "# Please change the model name accordingly.\n",
        "mcp_save = ModelCheckpoint('/content/Audio_1DCNN.h5', save_best_only=True, monitor='val_categorical_accuracy', mode='max')\n",
        "cnnhistory=model.fit(X_train, y_train, batch_size=batch_size, epochs=num_epochs,validation_data=(X_val, y_val), callbacks=[mcp_save, lr_reduce])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "297/297 [==============================] - 10s 20ms/step - loss: 1.3470 - categorical_accuracy: 0.4169 - val_loss: 1.6187 - val_categorical_accuracy: 0.2827\n",
            "Epoch 2/200\n",
            "297/297 [==============================] - 5s 15ms/step - loss: 1.1580 - categorical_accuracy: 0.4783 - val_loss: 1.7136 - val_categorical_accuracy: 0.2922\n",
            "Epoch 3/200\n",
            "297/297 [==============================] - 5s 15ms/step - loss: 1.0928 - categorical_accuracy: 0.5095 - val_loss: 1.2473 - val_categorical_accuracy: 0.4440\n",
            "Epoch 4/200\n",
            "297/297 [==============================] - 5s 15ms/step - loss: 1.0966 - categorical_accuracy: 0.4950 - val_loss: 1.2458 - val_categorical_accuracy: 0.4478\n",
            "Epoch 5/200\n",
            "297/297 [==============================] - 5s 15ms/step - loss: 1.1063 - categorical_accuracy: 0.5051 - val_loss: 1.1254 - val_categorical_accuracy: 0.4858\n",
            "Epoch 6/200\n",
            "297/297 [==============================] - 5s 16ms/step - loss: 1.1105 - categorical_accuracy: 0.4994 - val_loss: 1.2475 - val_categorical_accuracy: 0.4782\n",
            "Epoch 7/200\n",
            "297/297 [==============================] - 5s 15ms/step - loss: 1.1129 - categorical_accuracy: 0.4945 - val_loss: 1.1553 - val_categorical_accuracy: 0.4744\n",
            "Epoch 8/200\n",
            "297/297 [==============================] - 5s 15ms/step - loss: 1.1373 - categorical_accuracy: 0.4831 - val_loss: 1.1930 - val_categorical_accuracy: 0.4421\n",
            "Epoch 9/200\n",
            "297/297 [==============================] - 5s 15ms/step - loss: 1.1184 - categorical_accuracy: 0.4761 - val_loss: 1.1469 - val_categorical_accuracy: 0.4991\n",
            "Epoch 10/200\n",
            "297/297 [==============================] - 5s 15ms/step - loss: 1.1201 - categorical_accuracy: 0.4907 - val_loss: 1.1328 - val_categorical_accuracy: 0.4991\n",
            "Epoch 11/200\n",
            "297/297 [==============================] - 5s 15ms/step - loss: 1.0983 - categorical_accuracy: 0.5093 - val_loss: 1.2093 - val_categorical_accuracy: 0.4611\n",
            "Epoch 12/200\n",
            "297/297 [==============================] - 5s 15ms/step - loss: 1.0851 - categorical_accuracy: 0.5126 - val_loss: 1.1316 - val_categorical_accuracy: 0.4440\n",
            "Epoch 13/200\n",
            "297/297 [==============================] - 5s 16ms/step - loss: 1.0936 - categorical_accuracy: 0.5114 - val_loss: 1.1355 - val_categorical_accuracy: 0.4554\n",
            "Epoch 14/200\n",
            "297/297 [==============================] - 5s 15ms/step - loss: 1.0964 - categorical_accuracy: 0.4910 - val_loss: 1.1225 - val_categorical_accuracy: 0.4915\n",
            "Epoch 15/200\n",
            "297/297 [==============================] - 5s 15ms/step - loss: 1.0953 - categorical_accuracy: 0.5073 - val_loss: 1.1694 - val_categorical_accuracy: 0.4763\n",
            "Epoch 16/200\n",
            "297/297 [==============================] - 5s 15ms/step - loss: 1.0884 - categorical_accuracy: 0.5061 - val_loss: 1.1678 - val_categorical_accuracy: 0.4630\n",
            "Epoch 17/200\n",
            "297/297 [==============================] - 5s 16ms/step - loss: 1.0944 - categorical_accuracy: 0.5132 - val_loss: 1.1876 - val_categorical_accuracy: 0.5028\n",
            "Epoch 18/200\n",
            "297/297 [==============================] - 5s 15ms/step - loss: 1.0895 - categorical_accuracy: 0.4944 - val_loss: 1.1251 - val_categorical_accuracy: 0.4896\n",
            "Epoch 19/200\n",
            "297/297 [==============================] - 5s 15ms/step - loss: 1.0925 - categorical_accuracy: 0.4981 - val_loss: 1.1669 - val_categorical_accuracy: 0.4839\n",
            "Epoch 20/200\n",
            "297/297 [==============================] - 5s 15ms/step - loss: 1.1045 - categorical_accuracy: 0.4913 - val_loss: 1.2411 - val_categorical_accuracy: 0.4668\n",
            "Epoch 21/200\n",
            "297/297 [==============================] - 5s 15ms/step - loss: 1.1375 - categorical_accuracy: 0.4910 - val_loss: 1.1086 - val_categorical_accuracy: 0.5104\n",
            "Epoch 22/200\n",
            "297/297 [==============================] - 5s 15ms/step - loss: 1.0991 - categorical_accuracy: 0.4961 - val_loss: 1.1002 - val_categorical_accuracy: 0.4953\n",
            "Epoch 23/200\n",
            "297/297 [==============================] - 5s 15ms/step - loss: 1.0964 - categorical_accuracy: 0.5049 - val_loss: 1.1900 - val_categorical_accuracy: 0.4668\n",
            "Epoch 24/200\n",
            "297/297 [==============================] - 5s 15ms/step - loss: 1.1010 - categorical_accuracy: 0.4882 - val_loss: 1.1212 - val_categorical_accuracy: 0.4915\n",
            "Epoch 25/200\n",
            "297/297 [==============================] - 5s 16ms/step - loss: 1.1080 - categorical_accuracy: 0.4966 - val_loss: 1.1135 - val_categorical_accuracy: 0.4801\n",
            "Epoch 26/200\n",
            "297/297 [==============================] - 5s 15ms/step - loss: 1.1114 - categorical_accuracy: 0.5008 - val_loss: 1.1379 - val_categorical_accuracy: 0.4820\n",
            "Epoch 27/200\n",
            "297/297 [==============================] - 5s 15ms/step - loss: 1.1315 - categorical_accuracy: 0.4822 - val_loss: 1.1811 - val_categorical_accuracy: 0.4592\n",
            "Epoch 28/200\n",
            "297/297 [==============================] - 5s 15ms/step - loss: 1.0857 - categorical_accuracy: 0.5026 - val_loss: 1.1563 - val_categorical_accuracy: 0.4801\n",
            "Epoch 29/200\n",
            "297/297 [==============================] - 5s 15ms/step - loss: 1.1025 - categorical_accuracy: 0.4933 - val_loss: 1.1414 - val_categorical_accuracy: 0.4934\n",
            "Epoch 30/200\n",
            "297/297 [==============================] - 5s 16ms/step - loss: 1.0982 - categorical_accuracy: 0.4922 - val_loss: 1.1652 - val_categorical_accuracy: 0.4668\n",
            "Epoch 31/200\n",
            "297/297 [==============================] - 5s 15ms/step - loss: 1.0925 - categorical_accuracy: 0.5033 - val_loss: 1.1313 - val_categorical_accuracy: 0.4934\n",
            "Epoch 32/200\n",
            "297/297 [==============================] - 5s 15ms/step - loss: 1.1285 - categorical_accuracy: 0.4702 - val_loss: 1.2357 - val_categorical_accuracy: 0.4231\n",
            "Epoch 33/200\n",
            "297/297 [==============================] - 5s 15ms/step - loss: 1.0832 - categorical_accuracy: 0.5108 - val_loss: 1.1902 - val_categorical_accuracy: 0.4744\n",
            "Epoch 34/200\n",
            "297/297 [==============================] - 5s 16ms/step - loss: 1.0915 - categorical_accuracy: 0.5046 - val_loss: 1.1921 - val_categorical_accuracy: 0.4858\n",
            "Epoch 35/200\n",
            "297/297 [==============================] - 5s 15ms/step - loss: 1.1083 - categorical_accuracy: 0.5044 - val_loss: 1.1078 - val_categorical_accuracy: 0.5237\n",
            "Epoch 36/200\n",
            "297/297 [==============================] - 5s 15ms/step - loss: 1.0990 - categorical_accuracy: 0.4971 - val_loss: 1.1260 - val_categorical_accuracy: 0.4953\n",
            "Epoch 37/200\n",
            "297/297 [==============================] - 5s 15ms/step - loss: 1.1115 - categorical_accuracy: 0.5038 - val_loss: 1.1929 - val_categorical_accuracy: 0.4649\n",
            "Epoch 38/200\n",
            "297/297 [==============================] - 5s 15ms/step - loss: 1.0940 - categorical_accuracy: 0.5125 - val_loss: 1.1452 - val_categorical_accuracy: 0.5085\n",
            "Epoch 39/200\n",
            "297/297 [==============================] - 5s 15ms/step - loss: 1.1021 - categorical_accuracy: 0.4888 - val_loss: 1.1384 - val_categorical_accuracy: 0.4858\n",
            "Epoch 40/200\n",
            "297/297 [==============================] - 5s 15ms/step - loss: 1.1068 - categorical_accuracy: 0.4967 - val_loss: 1.1314 - val_categorical_accuracy: 0.4991\n",
            "Epoch 41/200\n",
            "297/297 [==============================] - 5s 16ms/step - loss: 1.0951 - categorical_accuracy: 0.5034 - val_loss: 1.2575 - val_categorical_accuracy: 0.4497\n",
            "Epoch 42/200\n",
            "297/297 [==============================] - 5s 15ms/step - loss: 1.0868 - categorical_accuracy: 0.5101 - val_loss: 1.2839 - val_categorical_accuracy: 0.4383\n",
            "Epoch 43/200\n",
            "297/297 [==============================] - 5s 15ms/step - loss: 1.1041 - categorical_accuracy: 0.5104 - val_loss: 1.1010 - val_categorical_accuracy: 0.4991\n",
            "Epoch 44/200\n",
            "297/297 [==============================] - 5s 15ms/step - loss: 1.0908 - categorical_accuracy: 0.4937 - val_loss: 1.1842 - val_categorical_accuracy: 0.4535\n",
            "Epoch 45/200\n",
            "297/297 [==============================] - 5s 15ms/step - loss: 1.1002 - categorical_accuracy: 0.4902 - val_loss: 1.1911 - val_categorical_accuracy: 0.4535\n",
            "Epoch 46/200\n",
            "297/297 [==============================] - 5s 15ms/step - loss: 1.0777 - categorical_accuracy: 0.5126 - val_loss: 1.1325 - val_categorical_accuracy: 0.4858\n",
            "Epoch 47/200\n",
            "297/297 [==============================] - 5s 15ms/step - loss: 1.0710 - categorical_accuracy: 0.5196 - val_loss: 1.1203 - val_categorical_accuracy: 0.4630\n",
            "Epoch 48/200\n",
            "297/297 [==============================] - 5s 15ms/step - loss: 1.0730 - categorical_accuracy: 0.5117 - val_loss: 1.1582 - val_categorical_accuracy: 0.4782\n",
            "Epoch 49/200\n",
            "297/297 [==============================] - 5s 15ms/step - loss: 1.0677 - categorical_accuracy: 0.5294 - val_loss: 1.2914 - val_categorical_accuracy: 0.4345\n",
            "Epoch 50/200\n",
            "297/297 [==============================] - 5s 16ms/step - loss: 1.0998 - categorical_accuracy: 0.4892 - val_loss: 1.1939 - val_categorical_accuracy: 0.4649\n",
            "Epoch 51/200\n",
            "297/297 [==============================] - 5s 15ms/step - loss: 1.0735 - categorical_accuracy: 0.5153 - val_loss: 1.1304 - val_categorical_accuracy: 0.4953\n",
            "Epoch 52/200\n",
            "297/297 [==============================] - 5s 15ms/step - loss: 1.0739 - categorical_accuracy: 0.5165 - val_loss: 1.2325 - val_categorical_accuracy: 0.4250\n",
            "Epoch 53/200\n",
            "297/297 [==============================] - 5s 16ms/step - loss: 1.0950 - categorical_accuracy: 0.5053 - val_loss: 1.1042 - val_categorical_accuracy: 0.5237\n",
            "Epoch 54/200\n",
            "297/297 [==============================] - 5s 16ms/step - loss: 1.1112 - categorical_accuracy: 0.4863 - val_loss: 1.0916 - val_categorical_accuracy: 0.5047\n",
            "Epoch 55/200\n",
            "297/297 [==============================] - 5s 16ms/step - loss: 1.0607 - categorical_accuracy: 0.5196 - val_loss: 1.1222 - val_categorical_accuracy: 0.5028\n",
            "Epoch 56/200\n",
            "297/297 [==============================] - 5s 16ms/step - loss: 1.0812 - categorical_accuracy: 0.5174 - val_loss: 1.1413 - val_categorical_accuracy: 0.4744\n",
            "Epoch 57/200\n",
            "297/297 [==============================] - 5s 15ms/step - loss: 1.0870 - categorical_accuracy: 0.5109 - val_loss: 1.1042 - val_categorical_accuracy: 0.4953\n",
            "Epoch 58/200\n",
            "297/297 [==============================] - 5s 16ms/step - loss: 1.0549 - categorical_accuracy: 0.5346 - val_loss: 1.0921 - val_categorical_accuracy: 0.5104\n",
            "Epoch 59/200\n",
            "297/297 [==============================] - 5s 16ms/step - loss: 1.0739 - categorical_accuracy: 0.5159 - val_loss: 1.1146 - val_categorical_accuracy: 0.5180\n",
            "Epoch 60/200\n",
            "297/297 [==============================] - 5s 15ms/step - loss: 1.0705 - categorical_accuracy: 0.5084 - val_loss: 1.1538 - val_categorical_accuracy: 0.4877\n",
            "Epoch 61/200\n",
            "297/297 [==============================] - 5s 15ms/step - loss: 1.0974 - categorical_accuracy: 0.5070 - val_loss: 1.1198 - val_categorical_accuracy: 0.4858\n",
            "Epoch 62/200\n",
            "297/297 [==============================] - 5s 16ms/step - loss: 1.0795 - categorical_accuracy: 0.5128 - val_loss: 1.1855 - val_categorical_accuracy: 0.4782\n",
            "Epoch 63/200\n",
            "297/297 [==============================] - 5s 16ms/step - loss: 1.0914 - categorical_accuracy: 0.5088 - val_loss: 1.1733 - val_categorical_accuracy: 0.4782\n",
            "Epoch 64/200\n",
            "297/297 [==============================] - 5s 16ms/step - loss: 1.0939 - categorical_accuracy: 0.5038 - val_loss: 1.1421 - val_categorical_accuracy: 0.5009\n",
            "Epoch 65/200\n",
            "297/297 [==============================] - 5s 16ms/step - loss: 1.0609 - categorical_accuracy: 0.5233 - val_loss: 1.1314 - val_categorical_accuracy: 0.5123\n",
            "Epoch 66/200\n",
            "297/297 [==============================] - 5s 16ms/step - loss: 1.0655 - categorical_accuracy: 0.5297 - val_loss: 1.1526 - val_categorical_accuracy: 0.4915\n",
            "Epoch 67/200\n",
            "297/297 [==============================] - 5s 15ms/step - loss: 1.0892 - categorical_accuracy: 0.5104 - val_loss: 1.1492 - val_categorical_accuracy: 0.4801\n",
            "Epoch 68/200\n",
            "297/297 [==============================] - 5s 15ms/step - loss: 1.0674 - categorical_accuracy: 0.4956 - val_loss: 1.1392 - val_categorical_accuracy: 0.4934\n",
            "Epoch 69/200\n",
            "297/297 [==============================] - 5s 15ms/step - loss: 1.1041 - categorical_accuracy: 0.5026 - val_loss: 1.1503 - val_categorical_accuracy: 0.4839\n",
            "Epoch 70/200\n",
            "297/297 [==============================] - 5s 16ms/step - loss: 1.0769 - categorical_accuracy: 0.5093 - val_loss: 1.1179 - val_categorical_accuracy: 0.4858\n",
            "Epoch 71/200\n",
            "297/297 [==============================] - 5s 16ms/step - loss: 1.0820 - categorical_accuracy: 0.5056 - val_loss: 1.2674 - val_categorical_accuracy: 0.4497\n",
            "Epoch 72/200\n",
            "297/297 [==============================] - 5s 15ms/step - loss: 1.0585 - categorical_accuracy: 0.5196 - val_loss: 1.1832 - val_categorical_accuracy: 0.4763\n",
            "Epoch 73/200\n",
            "297/297 [==============================] - 5s 15ms/step - loss: 1.0878 - categorical_accuracy: 0.4951 - val_loss: 1.1037 - val_categorical_accuracy: 0.4972\n",
            "Epoch 74/200\n",
            "297/297 [==============================] - 5s 15ms/step - loss: 1.1288 - categorical_accuracy: 0.4903 - val_loss: 1.1517 - val_categorical_accuracy: 0.4744\n",
            "Epoch 75/200\n",
            "297/297 [==============================] - 5s 16ms/step - loss: 1.0661 - categorical_accuracy: 0.5166 - val_loss: 1.2427 - val_categorical_accuracy: 0.4478\n",
            "Epoch 76/200\n",
            "297/297 [==============================] - 5s 16ms/step - loss: 1.0549 - categorical_accuracy: 0.5391 - val_loss: 1.1873 - val_categorical_accuracy: 0.4744\n",
            "Epoch 77/200\n",
            "297/297 [==============================] - 5s 16ms/step - loss: 1.0840 - categorical_accuracy: 0.5034 - val_loss: 1.0994 - val_categorical_accuracy: 0.4744\n",
            "Epoch 78/200\n",
            "297/297 [==============================] - 5s 15ms/step - loss: 1.1007 - categorical_accuracy: 0.5052 - val_loss: 1.2276 - val_categorical_accuracy: 0.4383\n",
            "Epoch 79/200\n",
            "297/297 [==============================] - 5s 16ms/step - loss: 1.0818 - categorical_accuracy: 0.5071 - val_loss: 1.1193 - val_categorical_accuracy: 0.4915\n",
            "Epoch 80/200\n",
            "297/297 [==============================] - 5s 16ms/step - loss: 1.0607 - categorical_accuracy: 0.5263 - val_loss: 1.1211 - val_categorical_accuracy: 0.4782\n",
            "Epoch 81/200\n",
            "297/297 [==============================] - 5s 16ms/step - loss: 1.0625 - categorical_accuracy: 0.5028 - val_loss: 1.1206 - val_categorical_accuracy: 0.4953\n",
            "Epoch 82/200\n",
            "297/297 [==============================] - 5s 15ms/step - loss: 1.0417 - categorical_accuracy: 0.5370 - val_loss: 1.0854 - val_categorical_accuracy: 0.5009\n",
            "Epoch 83/200\n",
            "297/297 [==============================] - 5s 15ms/step - loss: 1.0739 - categorical_accuracy: 0.5119 - val_loss: 1.1147 - val_categorical_accuracy: 0.4972\n",
            "Epoch 84/200\n",
            "297/297 [==============================] - 5s 16ms/step - loss: 1.0588 - categorical_accuracy: 0.5247 - val_loss: 1.1054 - val_categorical_accuracy: 0.5009\n",
            "Epoch 85/200\n",
            "297/297 [==============================] - 5s 16ms/step - loss: 1.0305 - categorical_accuracy: 0.5404 - val_loss: 1.1020 - val_categorical_accuracy: 0.4953\n",
            "Epoch 86/200\n",
            "297/297 [==============================] - 5s 16ms/step - loss: 1.0770 - categorical_accuracy: 0.5072 - val_loss: 1.1389 - val_categorical_accuracy: 0.4896\n",
            "Epoch 87/200\n",
            "297/297 [==============================] - 5s 16ms/step - loss: 1.0674 - categorical_accuracy: 0.5205 - val_loss: 1.1829 - val_categorical_accuracy: 0.4801\n",
            "Epoch 88/200\n",
            "297/297 [==============================] - 5s 15ms/step - loss: 1.0688 - categorical_accuracy: 0.5133 - val_loss: 1.1854 - val_categorical_accuracy: 0.4649\n",
            "Epoch 89/200\n",
            "297/297 [==============================] - 5s 15ms/step - loss: 1.0647 - categorical_accuracy: 0.5186 - val_loss: 1.0961 - val_categorical_accuracy: 0.4972\n",
            "Epoch 90/200\n",
            "297/297 [==============================] - 5s 15ms/step - loss: 1.0817 - categorical_accuracy: 0.5023 - val_loss: 1.0857 - val_categorical_accuracy: 0.5199\n",
            "Epoch 91/200\n",
            "297/297 [==============================] - 5s 15ms/step - loss: 1.0728 - categorical_accuracy: 0.5080 - val_loss: 1.1735 - val_categorical_accuracy: 0.4725\n",
            "Epoch 92/200\n",
            "297/297 [==============================] - 5s 16ms/step - loss: 1.0722 - categorical_accuracy: 0.5015 - val_loss: 1.1547 - val_categorical_accuracy: 0.4516\n",
            "Epoch 93/200\n",
            "297/297 [==============================] - 5s 15ms/step - loss: 1.0773 - categorical_accuracy: 0.5184 - val_loss: 1.1094 - val_categorical_accuracy: 0.4820\n",
            "Epoch 94/200\n",
            "297/297 [==============================] - 5s 16ms/step - loss: 1.0595 - categorical_accuracy: 0.5110 - val_loss: 1.1760 - val_categorical_accuracy: 0.4896\n",
            "Epoch 95/200\n",
            "297/297 [==============================] - 5s 15ms/step - loss: 1.0893 - categorical_accuracy: 0.4947 - val_loss: 1.0910 - val_categorical_accuracy: 0.4820\n",
            "Epoch 96/200\n",
            "297/297 [==============================] - 5s 16ms/step - loss: 1.0635 - categorical_accuracy: 0.5114 - val_loss: 1.0952 - val_categorical_accuracy: 0.4991\n",
            "Epoch 97/200\n",
            "297/297 [==============================] - 5s 15ms/step - loss: 1.0647 - categorical_accuracy: 0.5117 - val_loss: 1.1651 - val_categorical_accuracy: 0.4858\n",
            "Epoch 98/200\n",
            "297/297 [==============================] - 5s 15ms/step - loss: 1.0838 - categorical_accuracy: 0.5043 - val_loss: 1.1090 - val_categorical_accuracy: 0.5066\n",
            "Epoch 99/200\n",
            "297/297 [==============================] - 5s 16ms/step - loss: 1.0838 - categorical_accuracy: 0.5033 - val_loss: 1.0872 - val_categorical_accuracy: 0.5085\n",
            "Epoch 100/200\n",
            "297/297 [==============================] - 5s 15ms/step - loss: 1.0668 - categorical_accuracy: 0.5148 - val_loss: 1.0784 - val_categorical_accuracy: 0.5009\n",
            "Epoch 101/200\n",
            "297/297 [==============================] - 5s 16ms/step - loss: 1.0516 - categorical_accuracy: 0.5154 - val_loss: 1.1347 - val_categorical_accuracy: 0.4801\n",
            "Epoch 102/200\n",
            "297/297 [==============================] - 5s 15ms/step - loss: 1.0666 - categorical_accuracy: 0.5030 - val_loss: 1.0909 - val_categorical_accuracy: 0.5047\n",
            "Epoch 103/200\n",
            "297/297 [==============================] - 5s 16ms/step - loss: 1.0693 - categorical_accuracy: 0.5160 - val_loss: 1.1333 - val_categorical_accuracy: 0.4896\n",
            "Epoch 104/200\n",
            "297/297 [==============================] - 5s 15ms/step - loss: 1.0540 - categorical_accuracy: 0.5317 - val_loss: 1.2151 - val_categorical_accuracy: 0.4516\n",
            "Epoch 105/200\n",
            "297/297 [==============================] - 5s 15ms/step - loss: 1.0848 - categorical_accuracy: 0.4987 - val_loss: 1.1164 - val_categorical_accuracy: 0.4801\n",
            "Epoch 106/200\n",
            "297/297 [==============================] - 5s 16ms/step - loss: 1.0666 - categorical_accuracy: 0.5245 - val_loss: 1.1754 - val_categorical_accuracy: 0.4668\n",
            "Epoch 107/200\n",
            "297/297 [==============================] - 5s 16ms/step - loss: 1.0756 - categorical_accuracy: 0.5210 - val_loss: 1.1825 - val_categorical_accuracy: 0.4478\n",
            "Epoch 108/200\n",
            "297/297 [==============================] - 5s 15ms/step - loss: 1.0893 - categorical_accuracy: 0.5111 - val_loss: 1.1040 - val_categorical_accuracy: 0.4991\n",
            "Epoch 109/200\n",
            "297/297 [==============================] - 5s 15ms/step - loss: 1.0640 - categorical_accuracy: 0.5211 - val_loss: 1.0887 - val_categorical_accuracy: 0.5028\n",
            "Epoch 110/200\n",
            "297/297 [==============================] - 5s 16ms/step - loss: 1.0722 - categorical_accuracy: 0.5129 - val_loss: 1.0868 - val_categorical_accuracy: 0.5104\n",
            "Epoch 111/200\n",
            "297/297 [==============================] - 5s 15ms/step - loss: 1.0668 - categorical_accuracy: 0.5276 - val_loss: 1.0810 - val_categorical_accuracy: 0.4953\n",
            "Epoch 112/200\n",
            "297/297 [==============================] - 5s 16ms/step - loss: 1.0771 - categorical_accuracy: 0.5086 - val_loss: 1.0615 - val_categorical_accuracy: 0.5275\n",
            "Epoch 113/200\n",
            "297/297 [==============================] - 5s 16ms/step - loss: 1.0664 - categorical_accuracy: 0.5267 - val_loss: 1.0933 - val_categorical_accuracy: 0.4877\n",
            "Epoch 114/200\n",
            "297/297 [==============================] - 5s 15ms/step - loss: 1.0290 - categorical_accuracy: 0.5210 - val_loss: 1.1286 - val_categorical_accuracy: 0.4573\n",
            "Epoch 115/200\n",
            "297/297 [==============================] - 5s 16ms/step - loss: 1.0735 - categorical_accuracy: 0.5169 - val_loss: 1.0963 - val_categorical_accuracy: 0.5047\n",
            "Epoch 116/200\n",
            "297/297 [==============================] - 5s 16ms/step - loss: 1.0598 - categorical_accuracy: 0.5168 - val_loss: 1.1432 - val_categorical_accuracy: 0.4877\n",
            "Epoch 117/200\n",
            "297/297 [==============================] - 5s 15ms/step - loss: 1.0592 - categorical_accuracy: 0.5339 - val_loss: 1.0995 - val_categorical_accuracy: 0.5066\n",
            "Epoch 118/200\n",
            "297/297 [==============================] - 5s 16ms/step - loss: 1.0670 - categorical_accuracy: 0.5167 - val_loss: 1.1196 - val_categorical_accuracy: 0.4953\n",
            "Epoch 119/200\n",
            "297/297 [==============================] - 5s 15ms/step - loss: 1.0655 - categorical_accuracy: 0.5337 - val_loss: 1.0895 - val_categorical_accuracy: 0.4991\n",
            "Epoch 120/200\n",
            "297/297 [==============================] - 5s 15ms/step - loss: 1.0596 - categorical_accuracy: 0.5184 - val_loss: 1.0660 - val_categorical_accuracy: 0.5180\n",
            "Epoch 121/200\n",
            "297/297 [==============================] - 5s 15ms/step - loss: 1.0416 - categorical_accuracy: 0.5230 - val_loss: 1.0879 - val_categorical_accuracy: 0.4896\n",
            "Epoch 122/200\n",
            "297/297 [==============================] - 5s 16ms/step - loss: 1.0559 - categorical_accuracy: 0.5144 - val_loss: 1.1328 - val_categorical_accuracy: 0.4763\n",
            "Epoch 123/200\n",
            "297/297 [==============================] - 5s 16ms/step - loss: 1.0716 - categorical_accuracy: 0.5153 - val_loss: 1.1338 - val_categorical_accuracy: 0.4744\n",
            "Epoch 124/200\n",
            "297/297 [==============================] - 5s 16ms/step - loss: 1.0704 - categorical_accuracy: 0.5151 - val_loss: 1.1218 - val_categorical_accuracy: 0.4459\n",
            "Epoch 125/200\n",
            "297/297 [==============================] - 5s 16ms/step - loss: 1.0503 - categorical_accuracy: 0.5181 - val_loss: 1.1119 - val_categorical_accuracy: 0.4592\n",
            "Epoch 126/200\n",
            "297/297 [==============================] - 5s 15ms/step - loss: 1.0616 - categorical_accuracy: 0.5273 - val_loss: 1.1535 - val_categorical_accuracy: 0.4877\n",
            "Epoch 127/200\n",
            "297/297 [==============================] - 5s 16ms/step - loss: 1.0632 - categorical_accuracy: 0.5167 - val_loss: 1.0853 - val_categorical_accuracy: 0.5009\n",
            "Epoch 128/200\n",
            "297/297 [==============================] - 5s 15ms/step - loss: 1.0666 - categorical_accuracy: 0.5185 - val_loss: 1.1387 - val_categorical_accuracy: 0.4991\n",
            "Epoch 129/200\n",
            "297/297 [==============================] - 5s 16ms/step - loss: 1.0937 - categorical_accuracy: 0.5099 - val_loss: 1.1301 - val_categorical_accuracy: 0.4782\n",
            "Epoch 130/200\n",
            "297/297 [==============================] - 5s 15ms/step - loss: 1.0474 - categorical_accuracy: 0.5174 - val_loss: 1.1763 - val_categorical_accuracy: 0.4858\n",
            "Epoch 131/200\n",
            "297/297 [==============================] - 5s 15ms/step - loss: 1.0522 - categorical_accuracy: 0.5208 - val_loss: 1.0908 - val_categorical_accuracy: 0.5104\n",
            "Epoch 132/200\n",
            "297/297 [==============================] - 5s 15ms/step - loss: 1.0429 - categorical_accuracy: 0.5426 - val_loss: 1.0735 - val_categorical_accuracy: 0.5199\n",
            "Epoch 133/200\n",
            "297/297 [==============================] - 5s 16ms/step - loss: 1.0400 - categorical_accuracy: 0.5271 - val_loss: 1.0802 - val_categorical_accuracy: 0.5218\n",
            "Epoch 134/200\n",
            "297/297 [==============================] - 5s 15ms/step - loss: 1.0615 - categorical_accuracy: 0.5167 - val_loss: 1.1096 - val_categorical_accuracy: 0.4934\n",
            "Epoch 135/200\n",
            "297/297 [==============================] - 5s 15ms/step - loss: 1.0644 - categorical_accuracy: 0.5138 - val_loss: 1.1455 - val_categorical_accuracy: 0.4915\n",
            "Epoch 136/200\n",
            "297/297 [==============================] - 5s 15ms/step - loss: 1.0496 - categorical_accuracy: 0.5345 - val_loss: 1.1236 - val_categorical_accuracy: 0.4725\n",
            "Epoch 137/200\n",
            "297/297 [==============================] - 5s 15ms/step - loss: 1.0605 - categorical_accuracy: 0.5345 - val_loss: 1.0880 - val_categorical_accuracy: 0.5161\n",
            "Epoch 138/200\n",
            "297/297 [==============================] - 5s 15ms/step - loss: 1.0656 - categorical_accuracy: 0.5290 - val_loss: 1.0950 - val_categorical_accuracy: 0.5123\n",
            "Epoch 139/200\n",
            "297/297 [==============================] - 5s 15ms/step - loss: 1.0555 - categorical_accuracy: 0.5267 - val_loss: 1.1278 - val_categorical_accuracy: 0.4706\n",
            "Epoch 140/200\n",
            "297/297 [==============================] - 5s 15ms/step - loss: 1.0503 - categorical_accuracy: 0.5261 - val_loss: 1.1292 - val_categorical_accuracy: 0.4915\n",
            "Epoch 141/200\n",
            "297/297 [==============================] - 5s 16ms/step - loss: 1.0470 - categorical_accuracy: 0.5275 - val_loss: 1.0831 - val_categorical_accuracy: 0.5028\n",
            "Epoch 142/200\n",
            "297/297 [==============================] - 5s 16ms/step - loss: 1.0333 - categorical_accuracy: 0.5280 - val_loss: 1.1091 - val_categorical_accuracy: 0.4820\n",
            "Epoch 143/200\n",
            "297/297 [==============================] - 5s 15ms/step - loss: 1.0478 - categorical_accuracy: 0.5301 - val_loss: 1.1425 - val_categorical_accuracy: 0.4820\n",
            "Epoch 144/200\n",
            "297/297 [==============================] - 5s 16ms/step - loss: 1.0604 - categorical_accuracy: 0.5265 - val_loss: 1.0926 - val_categorical_accuracy: 0.4858\n",
            "Epoch 145/200\n",
            "297/297 [==============================] - 5s 16ms/step - loss: 1.0332 - categorical_accuracy: 0.5433 - val_loss: 1.0903 - val_categorical_accuracy: 0.5047\n",
            "Epoch 146/200\n",
            "297/297 [==============================] - 5s 16ms/step - loss: 1.0467 - categorical_accuracy: 0.5193 - val_loss: 1.1384 - val_categorical_accuracy: 0.5085\n",
            "Epoch 147/200\n",
            "297/297 [==============================] - 5s 16ms/step - loss: 1.0740 - categorical_accuracy: 0.5240 - val_loss: 1.1071 - val_categorical_accuracy: 0.4763\n",
            "Epoch 148/200\n",
            "297/297 [==============================] - 5s 16ms/step - loss: 1.0791 - categorical_accuracy: 0.5207 - val_loss: 1.0801 - val_categorical_accuracy: 0.5199\n",
            "Epoch 149/200\n",
            "297/297 [==============================] - 5s 16ms/step - loss: 1.0666 - categorical_accuracy: 0.5125 - val_loss: 1.0862 - val_categorical_accuracy: 0.5104\n",
            "Epoch 150/200\n",
            "297/297 [==============================] - 5s 15ms/step - loss: 1.0459 - categorical_accuracy: 0.5253 - val_loss: 1.0823 - val_categorical_accuracy: 0.5123\n",
            "Epoch 151/200\n",
            "297/297 [==============================] - 5s 16ms/step - loss: 1.0191 - categorical_accuracy: 0.5364 - val_loss: 1.0628 - val_categorical_accuracy: 0.5313\n",
            "Epoch 152/200\n",
            "297/297 [==============================] - 5s 16ms/step - loss: 1.0499 - categorical_accuracy: 0.5371 - val_loss: 1.0788 - val_categorical_accuracy: 0.4915\n",
            "Epoch 153/200\n",
            "297/297 [==============================] - 5s 15ms/step - loss: 1.0382 - categorical_accuracy: 0.5404 - val_loss: 1.1116 - val_categorical_accuracy: 0.5218\n",
            "Epoch 154/200\n",
            "297/297 [==============================] - 5s 16ms/step - loss: 1.0680 - categorical_accuracy: 0.5196 - val_loss: 1.0692 - val_categorical_accuracy: 0.5370\n",
            "Epoch 155/200\n",
            "297/297 [==============================] - 5s 16ms/step - loss: 1.0556 - categorical_accuracy: 0.5217 - val_loss: 1.1233 - val_categorical_accuracy: 0.5047\n",
            "Epoch 156/200\n",
            "297/297 [==============================] - 5s 16ms/step - loss: 1.0251 - categorical_accuracy: 0.5408 - val_loss: 1.1431 - val_categorical_accuracy: 0.4820\n",
            "Epoch 157/200\n",
            "297/297 [==============================] - 5s 15ms/step - loss: 1.0362 - categorical_accuracy: 0.5272 - val_loss: 1.0927 - val_categorical_accuracy: 0.4991\n",
            "Epoch 158/200\n",
            "297/297 [==============================] - 5s 15ms/step - loss: 1.0566 - categorical_accuracy: 0.5339 - val_loss: 1.0886 - val_categorical_accuracy: 0.5047\n",
            "Epoch 159/200\n",
            "297/297 [==============================] - 5s 15ms/step - loss: 1.0381 - categorical_accuracy: 0.5268 - val_loss: 1.0793 - val_categorical_accuracy: 0.4991\n",
            "Epoch 160/200\n",
            "297/297 [==============================] - 5s 15ms/step - loss: 1.0520 - categorical_accuracy: 0.5143 - val_loss: 1.0756 - val_categorical_accuracy: 0.4934\n",
            "Epoch 161/200\n",
            "297/297 [==============================] - 5s 16ms/step - loss: 1.0359 - categorical_accuracy: 0.5462 - val_loss: 1.0873 - val_categorical_accuracy: 0.4991\n",
            "Epoch 162/200\n",
            "297/297 [==============================] - 5s 16ms/step - loss: 1.0504 - categorical_accuracy: 0.5387 - val_loss: 1.1089 - val_categorical_accuracy: 0.5028\n",
            "Epoch 163/200\n",
            "297/297 [==============================] - 5s 16ms/step - loss: 1.0162 - categorical_accuracy: 0.5487 - val_loss: 1.1483 - val_categorical_accuracy: 0.4896\n",
            "Epoch 164/200\n",
            "297/297 [==============================] - 5s 16ms/step - loss: 1.0576 - categorical_accuracy: 0.5134 - val_loss: 1.0506 - val_categorical_accuracy: 0.5123\n",
            "Epoch 165/200\n",
            "297/297 [==============================] - 5s 16ms/step - loss: 1.0516 - categorical_accuracy: 0.5200 - val_loss: 1.1416 - val_categorical_accuracy: 0.4649\n",
            "Epoch 166/200\n",
            "297/297 [==============================] - 5s 16ms/step - loss: 1.0537 - categorical_accuracy: 0.5219 - val_loss: 1.0879 - val_categorical_accuracy: 0.5047\n",
            "Epoch 167/200\n",
            "297/297 [==============================] - 5s 16ms/step - loss: 1.0589 - categorical_accuracy: 0.5184 - val_loss: 1.0962 - val_categorical_accuracy: 0.5066\n",
            "Epoch 168/200\n",
            "297/297 [==============================] - 5s 16ms/step - loss: 1.0298 - categorical_accuracy: 0.5352 - val_loss: 1.0879 - val_categorical_accuracy: 0.4934\n",
            "Epoch 169/200\n",
            "297/297 [==============================] - 5s 16ms/step - loss: 1.0560 - categorical_accuracy: 0.5066 - val_loss: 1.1064 - val_categorical_accuracy: 0.4725\n",
            "Epoch 170/200\n",
            "297/297 [==============================] - 5s 16ms/step - loss: 1.0460 - categorical_accuracy: 0.5251 - val_loss: 1.0767 - val_categorical_accuracy: 0.5161\n",
            "Epoch 171/200\n",
            "297/297 [==============================] - 5s 16ms/step - loss: 1.0621 - categorical_accuracy: 0.5140 - val_loss: 1.0733 - val_categorical_accuracy: 0.5066\n",
            "Epoch 172/200\n",
            "297/297 [==============================] - 5s 16ms/step - loss: 1.0307 - categorical_accuracy: 0.5256 - val_loss: 1.1145 - val_categorical_accuracy: 0.4972\n",
            "Epoch 173/200\n",
            "297/297 [==============================] - 5s 15ms/step - loss: 1.0336 - categorical_accuracy: 0.5235 - val_loss: 1.0847 - val_categorical_accuracy: 0.5028\n",
            "Epoch 174/200\n",
            "297/297 [==============================] - 5s 16ms/step - loss: 1.0490 - categorical_accuracy: 0.5176 - val_loss: 1.1396 - val_categorical_accuracy: 0.4763\n",
            "Epoch 175/200\n",
            "297/297 [==============================] - 5s 16ms/step - loss: 1.0581 - categorical_accuracy: 0.5139 - val_loss: 1.1678 - val_categorical_accuracy: 0.4611\n",
            "Epoch 176/200\n",
            "297/297 [==============================] - 5s 16ms/step - loss: 1.0554 - categorical_accuracy: 0.5056 - val_loss: 1.1387 - val_categorical_accuracy: 0.4934\n",
            "Epoch 177/200\n",
            "297/297 [==============================] - 5s 16ms/step - loss: 1.0373 - categorical_accuracy: 0.5257 - val_loss: 1.1222 - val_categorical_accuracy: 0.4896\n",
            "Epoch 178/200\n",
            "297/297 [==============================] - 5s 15ms/step - loss: 1.0395 - categorical_accuracy: 0.5203 - val_loss: 1.1241 - val_categorical_accuracy: 0.4858\n",
            "Epoch 179/200\n",
            "297/297 [==============================] - 5s 16ms/step - loss: 1.0563 - categorical_accuracy: 0.5163 - val_loss: 1.1354 - val_categorical_accuracy: 0.4782\n",
            "Epoch 180/200\n",
            "297/297 [==============================] - 5s 16ms/step - loss: 1.0393 - categorical_accuracy: 0.5290 - val_loss: 1.1128 - val_categorical_accuracy: 0.4497\n",
            "Epoch 181/200\n",
            "297/297 [==============================] - 5s 16ms/step - loss: 1.0713 - categorical_accuracy: 0.5036 - val_loss: 1.0928 - val_categorical_accuracy: 0.4972\n",
            "Epoch 182/200\n",
            "297/297 [==============================] - 5s 16ms/step - loss: 1.0485 - categorical_accuracy: 0.5290 - val_loss: 1.1357 - val_categorical_accuracy: 0.4915\n",
            "Epoch 183/200\n",
            "297/297 [==============================] - 5s 16ms/step - loss: 1.0136 - categorical_accuracy: 0.5435 - val_loss: 1.1391 - val_categorical_accuracy: 0.4991\n",
            "Epoch 184/200\n",
            "297/297 [==============================] - 5s 16ms/step - loss: 1.0260 - categorical_accuracy: 0.5299 - val_loss: 1.1143 - val_categorical_accuracy: 0.4991\n",
            "Epoch 185/200\n",
            "297/297 [==============================] - 5s 16ms/step - loss: 1.0362 - categorical_accuracy: 0.5330 - val_loss: 1.0762 - val_categorical_accuracy: 0.5123\n",
            "Epoch 186/200\n",
            "297/297 [==============================] - 5s 16ms/step - loss: 1.0426 - categorical_accuracy: 0.5309 - val_loss: 1.0921 - val_categorical_accuracy: 0.5085\n",
            "Epoch 187/200\n",
            "297/297 [==============================] - 5s 16ms/step - loss: 1.0322 - categorical_accuracy: 0.5260 - val_loss: 1.1147 - val_categorical_accuracy: 0.4934\n",
            "Epoch 188/200\n",
            "297/297 [==============================] - 5s 16ms/step - loss: 1.0472 - categorical_accuracy: 0.5314 - val_loss: 1.0717 - val_categorical_accuracy: 0.5256\n",
            "Epoch 189/200\n",
            "297/297 [==============================] - 5s 16ms/step - loss: 1.0561 - categorical_accuracy: 0.5194 - val_loss: 1.1316 - val_categorical_accuracy: 0.4972\n",
            "Epoch 190/200\n",
            "297/297 [==============================] - 5s 16ms/step - loss: 1.0211 - categorical_accuracy: 0.5430 - val_loss: 1.0856 - val_categorical_accuracy: 0.4953\n",
            "Epoch 191/200\n",
            "297/297 [==============================] - 5s 16ms/step - loss: 1.0477 - categorical_accuracy: 0.5243 - val_loss: 1.0801 - val_categorical_accuracy: 0.5047\n",
            "Epoch 192/200\n",
            "297/297 [==============================] - 5s 16ms/step - loss: 1.0335 - categorical_accuracy: 0.5395 - val_loss: 1.1223 - val_categorical_accuracy: 0.4668\n",
            "Epoch 193/200\n",
            "297/297 [==============================] - 5s 16ms/step - loss: 1.0286 - categorical_accuracy: 0.5428 - val_loss: 1.0772 - val_categorical_accuracy: 0.5237\n",
            "Epoch 194/200\n",
            "297/297 [==============================] - 5s 16ms/step - loss: 1.0404 - categorical_accuracy: 0.5301 - val_loss: 1.0673 - val_categorical_accuracy: 0.5066\n",
            "Epoch 195/200\n",
            "297/297 [==============================] - 5s 16ms/step - loss: 1.0408 - categorical_accuracy: 0.5237 - val_loss: 1.0617 - val_categorical_accuracy: 0.5009\n",
            "Epoch 196/200\n",
            "297/297 [==============================] - 5s 16ms/step - loss: 1.0398 - categorical_accuracy: 0.5225 - val_loss: 1.0795 - val_categorical_accuracy: 0.5161\n",
            "Epoch 197/200\n",
            "297/297 [==============================] - 5s 16ms/step - loss: 1.0290 - categorical_accuracy: 0.5410 - val_loss: 1.0889 - val_categorical_accuracy: 0.5199\n",
            "Epoch 198/200\n",
            "297/297 [==============================] - 5s 16ms/step - loss: 1.0297 - categorical_accuracy: 0.5259 - val_loss: 1.0837 - val_categorical_accuracy: 0.4991\n",
            "Epoch 199/200\n",
            "297/297 [==============================] - 5s 16ms/step - loss: 1.0539 - categorical_accuracy: 0.5314 - val_loss: 1.1167 - val_categorical_accuracy: 0.4896\n",
            "Epoch 200/200\n",
            "297/297 [==============================] - 5s 16ms/step - loss: 1.0132 - categorical_accuracy: 0.5498 - val_loss: 1.1379 - val_categorical_accuracy: 0.4877\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RkwgTbiLsLdn"
      },
      "source": [
        "model.save('/content/drive/MyDrive/Colab Notebooks/SPEECH_EMOTION_Recognition/Nộp bài(chốt hạ)/model_saver/conv1D_mfcc39_merged.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1pmv3fqMsLdn"
      },
      "source": [
        "###test_result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yYhzc-Y3sLdo",
        "outputId": "9f5f86e1-7b4f-496f-881a-0aac6bfe3026"
      },
      "source": [
        "d = {0: 'happy',\n",
        "     1: 'sad',\n",
        "     2: 'angry',\n",
        "     3: 'fear'}\n",
        "Y_test_pred = np.argmax(model.predict(X_test), axis=-1)\n",
        "Y_test_pred = list(map(lambda x: d[x], Y_test_pred))\n",
        "y_test = np.argmax(y_test, axis=-1)\n",
        "y_test = list(map(lambda x: d[x], y_test))\n",
        "print(classification_report(y_test, Y_test_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.54      0.80      0.64       129\n",
            "        fear       0.50      0.01      0.02       174\n",
            "       happy       0.36      0.64      0.46       127\n",
            "         sad       0.67      0.72      0.69       156\n",
            "\n",
            "    accuracy                           0.51       586\n",
            "   macro avg       0.52      0.54      0.45       586\n",
            "weighted avg       0.52      0.51      0.43       586\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qZM-CKDNsLdo",
        "outputId": "1c2dc99b-020c-4d02-b74c-262f5f8ad4ab"
      },
      "source": [
        "import scikitplot as skplt\n",
        "\n",
        "skplt.metrics.plot_confusion_matrix(\n",
        "    y_test, \n",
        "    Y_test_pred,\n",
        "    figsize=(8,8))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f4539efbad0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8YJKkKMsLdp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8JPwepBQ2ndF"
      },
      "source": [
        "# mfcc_13 + conv2D:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wmPx3AB62ndc"
      },
      "source": [
        "audio_duration = 3\n",
        "sampling_rate = 22050\n",
        "input_length = sampling_rate * audio_duration"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hwf1Uquo2ndd"
      },
      "source": [
        "features = []\n",
        "labels = []\n",
        "for i in range(len(Ravdess_DF['Paths'])):\n",
        "  if ((Ravdess_DF['Emotion'][i] == '03') | (Ravdess_DF['Emotion'][i] == '04') | \n",
        "      (Ravdess_DF['Emotion'][i] == '05') | (Ravdess_DF['Emotion'][i] == '06')):\n",
        "    signal, sr = librosa.load(Ravdess_DF['Paths'][i])\n",
        "\n",
        "    if len(signal) > input_length:\n",
        "      signal = signal[0:input_length]\n",
        "    elif  input_length > len(signal):\n",
        "      max_offset = input_length - len(signal)  \n",
        "      signal = np.pad(signal, (0, max_offset), \"constant\")\n",
        "\n",
        "    mfcc = librosa.feature.mfcc(y=signal, sr=sr, n_mfcc=13).T\n",
        "    mfcc = np.expand_dims(mfcc, axis=-1)\n",
        "    features.append(mfcc)\n",
        "\n",
        "    if Ravdess_DF['Emotion'][i] == '03':\n",
        "      labels.append(0)\n",
        "    elif Ravdess_DF['Emotion'][i] == '04':\n",
        "      labels.append(1)\n",
        "    elif Ravdess_DF['Emotion'][i] == '05':\n",
        "      labels.append(2)\n",
        "    elif Ravdess_DF['Emotion'][i] == '06':\n",
        "      labels.append(3)\n",
        "\n",
        "\n",
        "for i in range(len(CREMA_D_df)):\n",
        "  if ((CREMA_D_df['Emotion'][i] == 'HAP') | (CREMA_D_df['Emotion'][i] == 'SAD') | \n",
        "      (CREMA_D_df['Emotion'][i] == 'ANG') | (CREMA_D_df['Emotion'][i] == 'FEA')):\n",
        "    \n",
        "    if CREMA_D_df['Emotion'][i] == 'HAP':\n",
        "      labels.append(0)\n",
        "    elif CREMA_D_df['Emotion'][i] == 'SAD':\n",
        "      labels.append(1)\n",
        "    elif CREMA_D_df['Emotion'][i] == 'ANG':\n",
        "      labels.append(2)\n",
        "    elif CREMA_D_df['Emotion'][i] == 'FEA':\n",
        "      labels.append(3)\n",
        "\n",
        "\n",
        "    signal, sr =  librosa.load(CREMA_D_df['Paths'][i])\n",
        "\n",
        "    if len(signal) > input_length:\n",
        "        signal = signal[0:input_length]\n",
        "    elif  input_length > len(signal):\n",
        "        max_offset = input_length - len(signal)  \n",
        "        signal = np.pad(signal, (0, max_offset), \"constant\")\n",
        "\n",
        "    mfcc = librosa.feature.mfcc(y=signal, sr=sr, n_mfcc=13).T\n",
        "    mfcc = np.expand_dims(mfcc, axis=-1)\n",
        "    features.append(mfcc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahakomyG2nde"
      },
      "source": [
        "X = features\n",
        "y = labels\n",
        "\n",
        "y = np.array(y)\n",
        "y = to_categorical(y)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=0)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=0)\n",
        "\n",
        "X_train = np.array(X_train)\n",
        "X_test = np.array(X_test)\n",
        "X_val = np.array(X_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xaP08C9C2nde",
        "outputId": "b07a2370-4fb0-40cd-abd4-c417a50fa530"
      },
      "source": [
        "X_train.shape,X_test.shape,y_train.shape,y_test.shape\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((4739, 130, 13, 1), (586, 130, 13, 1), (4739, 4), (586, 4))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UsHxeSsK2ndf"
      },
      "source": [
        "# CNN I/P Config\n",
        "num_classes = 4\n",
        "input_shape = X_train.shape[1:]\n",
        "learning_rate = 0.0001\n",
        "decay = 1e-6\n",
        "momentum = 0.9"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0RqouXuA2ndg",
        "outputId": "59d0e4cc-62d1-4599-df2e-590bc2729610"
      },
      "source": [
        "model = Sequential(name='Audio_CNN_2D')\n",
        "\n",
        "# LFLB1\n",
        "model.add(Conv2D(filters=64, kernel_size=(3,3), strides=(1,1), padding='same',input_shape=input_shape))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Conv2D(filters=64, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(4,4), strides=(4,4)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(units=num_classes, activation='softmax'))\n",
        "\n",
        "# Model compilation\n",
        "opt = optimizers.SGD(lr=learning_rate, decay=decay, momentum=momentum, nesterov=True)\n",
        "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"Audio_CNN_2D\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 130, 13, 64)       640       \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 130, 13, 64)       256       \n",
            "_________________________________________________________________\n",
            "activation_8 (Activation)    (None, 130, 13, 64)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 65, 6, 64)         0         \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 65, 6, 64)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 65, 6, 64)         36928     \n",
            "_________________________________________________________________\n",
            "batch_normalization_9 (Batch (None, 65, 6, 64)         256       \n",
            "_________________________________________________________________\n",
            "activation_9 (Activation)    (None, 65, 6, 64)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 16, 1, 64)         0         \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 16, 1, 64)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 4)                 4100      \n",
            "=================================================================\n",
            "Total params: 42,180\n",
            "Trainable params: 41,924\n",
            "Non-trainable params: 256\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2_85mCVM2ndg",
        "outputId": "32905a89-f981-4a1c-8e9f-dcccca7946fc"
      },
      "source": [
        "#Train Config\n",
        "\n",
        "batch_size = 16\n",
        "num_epochs = 200\n",
        "\n",
        "# Model Training\n",
        "lr_reduce = ReduceLROnPlateau(monitor='val_loss', factor=0.9, patience=20, min_lr=0.000001)\n",
        "# Please change the model name accordingly.\n",
        "mcp_save = ModelCheckpoint('/content/Modelfull_2_1.h5', save_best_only=True, monitor='val_categorical_accuracy', mode='max')\n",
        "cnnhistory=model.fit(X_train, y_train, batch_size=batch_size, epochs=num_epochs,validation_data=(X_val, y_val), callbacks=[mcp_save, lr_reduce])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "297/297 [==============================] - 4s 6ms/step - loss: 2.5731 - categorical_accuracy: 0.2671 - val_loss: 1.3296 - val_categorical_accuracy: 0.3491\n",
            "Epoch 2/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 1.7609 - categorical_accuracy: 0.3568 - val_loss: 1.1788 - val_categorical_accuracy: 0.4706\n",
            "Epoch 3/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 1.5340 - categorical_accuracy: 0.4030 - val_loss: 1.1359 - val_categorical_accuracy: 0.5180\n",
            "Epoch 4/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 1.4233 - categorical_accuracy: 0.4169 - val_loss: 1.1234 - val_categorical_accuracy: 0.5199\n",
            "Epoch 5/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 1.3621 - categorical_accuracy: 0.4269 - val_loss: 1.1532 - val_categorical_accuracy: 0.4915\n",
            "Epoch 6/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 1.2934 - categorical_accuracy: 0.4392 - val_loss: 1.1702 - val_categorical_accuracy: 0.4573\n",
            "Epoch 7/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 1.2581 - categorical_accuracy: 0.4543 - val_loss: 1.1231 - val_categorical_accuracy: 0.5066\n",
            "Epoch 8/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 1.2145 - categorical_accuracy: 0.4645 - val_loss: 1.1275 - val_categorical_accuracy: 0.5104\n",
            "Epoch 9/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 1.2136 - categorical_accuracy: 0.4623 - val_loss: 1.1287 - val_categorical_accuracy: 0.5066\n",
            "Epoch 10/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 1.1866 - categorical_accuracy: 0.4649 - val_loss: 1.2449 - val_categorical_accuracy: 0.4137\n",
            "Epoch 11/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 1.1797 - categorical_accuracy: 0.4876 - val_loss: 1.1423 - val_categorical_accuracy: 0.4972\n",
            "Epoch 12/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 1.1556 - categorical_accuracy: 0.4695 - val_loss: 1.1357 - val_categorical_accuracy: 0.4953\n",
            "Epoch 13/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 1.1427 - categorical_accuracy: 0.4958 - val_loss: 1.1388 - val_categorical_accuracy: 0.4896\n",
            "Epoch 14/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 1.1543 - categorical_accuracy: 0.4935 - val_loss: 1.1386 - val_categorical_accuracy: 0.4896\n",
            "Epoch 15/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 1.1364 - categorical_accuracy: 0.4901 - val_loss: 1.1924 - val_categorical_accuracy: 0.4649\n",
            "Epoch 16/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 1.1594 - categorical_accuracy: 0.4827 - val_loss: 1.1667 - val_categorical_accuracy: 0.4706\n",
            "Epoch 17/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 1.1113 - categorical_accuracy: 0.5030 - val_loss: 1.1145 - val_categorical_accuracy: 0.5218\n",
            "Epoch 18/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 1.1059 - categorical_accuracy: 0.4999 - val_loss: 1.1208 - val_categorical_accuracy: 0.5066\n",
            "Epoch 19/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 1.1147 - categorical_accuracy: 0.4823 - val_loss: 1.1296 - val_categorical_accuracy: 0.4782\n",
            "Epoch 20/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 1.1342 - categorical_accuracy: 0.4860 - val_loss: 1.1183 - val_categorical_accuracy: 0.4915\n",
            "Epoch 21/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 1.1008 - categorical_accuracy: 0.5006 - val_loss: 1.1435 - val_categorical_accuracy: 0.4725\n",
            "Epoch 22/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 1.0861 - categorical_accuracy: 0.5154 - val_loss: 1.1648 - val_categorical_accuracy: 0.4839\n",
            "Epoch 23/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 1.0847 - categorical_accuracy: 0.5118 - val_loss: 1.1173 - val_categorical_accuracy: 0.5047\n",
            "Epoch 24/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 1.0733 - categorical_accuracy: 0.5200 - val_loss: 1.1098 - val_categorical_accuracy: 0.5066\n",
            "Epoch 25/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 1.0811 - categorical_accuracy: 0.5056 - val_loss: 1.0843 - val_categorical_accuracy: 0.5256\n",
            "Epoch 26/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 1.0762 - categorical_accuracy: 0.5203 - val_loss: 1.0816 - val_categorical_accuracy: 0.4820\n",
            "Epoch 27/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 1.0846 - categorical_accuracy: 0.5155 - val_loss: 1.1383 - val_categorical_accuracy: 0.5104\n",
            "Epoch 28/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 1.0822 - categorical_accuracy: 0.5116 - val_loss: 1.0593 - val_categorical_accuracy: 0.5408\n",
            "Epoch 29/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 1.0890 - categorical_accuracy: 0.5060 - val_loss: 1.1266 - val_categorical_accuracy: 0.4972\n",
            "Epoch 30/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 1.0413 - categorical_accuracy: 0.5364 - val_loss: 1.1655 - val_categorical_accuracy: 0.4858\n",
            "Epoch 31/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 1.0419 - categorical_accuracy: 0.5428 - val_loss: 1.1280 - val_categorical_accuracy: 0.4858\n",
            "Epoch 32/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 1.0768 - categorical_accuracy: 0.5040 - val_loss: 1.0825 - val_categorical_accuracy: 0.5294\n",
            "Epoch 33/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 1.0627 - categorical_accuracy: 0.5289 - val_loss: 1.0810 - val_categorical_accuracy: 0.5123\n",
            "Epoch 34/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 1.0740 - categorical_accuracy: 0.5254 - val_loss: 1.1030 - val_categorical_accuracy: 0.5123\n",
            "Epoch 35/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 1.0554 - categorical_accuracy: 0.5249 - val_loss: 1.0921 - val_categorical_accuracy: 0.5047\n",
            "Epoch 36/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 1.0443 - categorical_accuracy: 0.5289 - val_loss: 1.0780 - val_categorical_accuracy: 0.5256\n",
            "Epoch 37/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 1.0316 - categorical_accuracy: 0.5414 - val_loss: 1.0814 - val_categorical_accuracy: 0.5104\n",
            "Epoch 38/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 1.0669 - categorical_accuracy: 0.5245 - val_loss: 1.1269 - val_categorical_accuracy: 0.4934\n",
            "Epoch 39/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 1.0415 - categorical_accuracy: 0.5270 - val_loss: 1.1266 - val_categorical_accuracy: 0.4915\n",
            "Epoch 40/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 1.0599 - categorical_accuracy: 0.5187 - val_loss: 1.0538 - val_categorical_accuracy: 0.5066\n",
            "Epoch 41/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 1.0497 - categorical_accuracy: 0.5234 - val_loss: 1.0865 - val_categorical_accuracy: 0.5180\n",
            "Epoch 42/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 1.0561 - categorical_accuracy: 0.5130 - val_loss: 1.0594 - val_categorical_accuracy: 0.5427\n",
            "Epoch 43/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 1.0208 - categorical_accuracy: 0.5427 - val_loss: 1.0689 - val_categorical_accuracy: 0.5256\n",
            "Epoch 44/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 1.0179 - categorical_accuracy: 0.5370 - val_loss: 1.0566 - val_categorical_accuracy: 0.4953\n",
            "Epoch 45/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 1.0189 - categorical_accuracy: 0.5373 - val_loss: 1.0923 - val_categorical_accuracy: 0.5085\n",
            "Epoch 46/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 1.0258 - categorical_accuracy: 0.5346 - val_loss: 1.1126 - val_categorical_accuracy: 0.4801\n",
            "Epoch 47/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 1.0242 - categorical_accuracy: 0.5332 - val_loss: 1.0383 - val_categorical_accuracy: 0.5408\n",
            "Epoch 48/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 1.0262 - categorical_accuracy: 0.5510 - val_loss: 1.0673 - val_categorical_accuracy: 0.4934\n",
            "Epoch 49/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 1.0358 - categorical_accuracy: 0.5418 - val_loss: 1.1048 - val_categorical_accuracy: 0.4915\n",
            "Epoch 50/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 1.0186 - categorical_accuracy: 0.5448 - val_loss: 1.0633 - val_categorical_accuracy: 0.5256\n",
            "Epoch 51/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 1.0169 - categorical_accuracy: 0.5475 - val_loss: 1.1123 - val_categorical_accuracy: 0.4953\n",
            "Epoch 52/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 1.0053 - categorical_accuracy: 0.5489 - val_loss: 1.0366 - val_categorical_accuracy: 0.5522\n",
            "Epoch 53/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 1.0275 - categorical_accuracy: 0.5357 - val_loss: 1.0444 - val_categorical_accuracy: 0.5389\n",
            "Epoch 54/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 1.0219 - categorical_accuracy: 0.5360 - val_loss: 1.0139 - val_categorical_accuracy: 0.5598\n",
            "Epoch 55/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 1.0081 - categorical_accuracy: 0.5439 - val_loss: 1.0632 - val_categorical_accuracy: 0.5218\n",
            "Epoch 56/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 1.0089 - categorical_accuracy: 0.5417 - val_loss: 1.0223 - val_categorical_accuracy: 0.5617\n",
            "Epoch 57/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 1.0057 - categorical_accuracy: 0.5359 - val_loss: 1.1014 - val_categorical_accuracy: 0.4991\n",
            "Epoch 58/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 1.0132 - categorical_accuracy: 0.5466 - val_loss: 1.0484 - val_categorical_accuracy: 0.5408\n",
            "Epoch 59/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 1.0105 - categorical_accuracy: 0.5530 - val_loss: 1.0728 - val_categorical_accuracy: 0.5294\n",
            "Epoch 60/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 1.0052 - categorical_accuracy: 0.5487 - val_loss: 1.0840 - val_categorical_accuracy: 0.5066\n",
            "Epoch 61/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 0.9939 - categorical_accuracy: 0.5503 - val_loss: 1.0599 - val_categorical_accuracy: 0.4934\n",
            "Epoch 62/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 1.0093 - categorical_accuracy: 0.5520 - val_loss: 1.0445 - val_categorical_accuracy: 0.5294\n",
            "Epoch 63/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 1.0188 - categorical_accuracy: 0.5423 - val_loss: 1.0355 - val_categorical_accuracy: 0.5446\n",
            "Epoch 64/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 0.9898 - categorical_accuracy: 0.5595 - val_loss: 1.0922 - val_categorical_accuracy: 0.4953\n",
            "Epoch 65/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 1.0101 - categorical_accuracy: 0.5400 - val_loss: 1.0520 - val_categorical_accuracy: 0.5313\n",
            "Epoch 66/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 1.0078 - categorical_accuracy: 0.5482 - val_loss: 1.0324 - val_categorical_accuracy: 0.5370\n",
            "Epoch 67/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 1.0071 - categorical_accuracy: 0.5421 - val_loss: 1.0491 - val_categorical_accuracy: 0.5351\n",
            "Epoch 68/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 1.0149 - categorical_accuracy: 0.5419 - val_loss: 1.0763 - val_categorical_accuracy: 0.5066\n",
            "Epoch 69/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 1.0116 - categorical_accuracy: 0.5514 - val_loss: 1.0523 - val_categorical_accuracy: 0.5313\n",
            "Epoch 70/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 0.9779 - categorical_accuracy: 0.5536 - val_loss: 1.0494 - val_categorical_accuracy: 0.5237\n",
            "Epoch 71/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 1.0202 - categorical_accuracy: 0.5464 - val_loss: 1.0666 - val_categorical_accuracy: 0.5123\n",
            "Epoch 72/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 1.0057 - categorical_accuracy: 0.5447 - val_loss: 1.0624 - val_categorical_accuracy: 0.5237\n",
            "Epoch 73/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 0.9971 - categorical_accuracy: 0.5563 - val_loss: 0.9991 - val_categorical_accuracy: 0.5750\n",
            "Epoch 74/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 1.0144 - categorical_accuracy: 0.5403 - val_loss: 1.0202 - val_categorical_accuracy: 0.5370\n",
            "Epoch 75/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 0.9893 - categorical_accuracy: 0.5511 - val_loss: 0.9980 - val_categorical_accuracy: 0.5693\n",
            "Epoch 76/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 0.9832 - categorical_accuracy: 0.5680 - val_loss: 1.0156 - val_categorical_accuracy: 0.5579\n",
            "Epoch 77/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 1.0015 - categorical_accuracy: 0.5429 - val_loss: 1.0719 - val_categorical_accuracy: 0.5256\n",
            "Epoch 78/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 1.0125 - categorical_accuracy: 0.5435 - val_loss: 1.0842 - val_categorical_accuracy: 0.5104\n",
            "Epoch 79/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 1.0081 - categorical_accuracy: 0.5458 - val_loss: 1.0317 - val_categorical_accuracy: 0.5389\n",
            "Epoch 80/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 1.0021 - categorical_accuracy: 0.5603 - val_loss: 0.9909 - val_categorical_accuracy: 0.5731\n",
            "Epoch 81/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 1.0103 - categorical_accuracy: 0.5433 - val_loss: 1.0001 - val_categorical_accuracy: 0.5674\n",
            "Epoch 82/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 0.9943 - categorical_accuracy: 0.5569 - val_loss: 0.9946 - val_categorical_accuracy: 0.5674\n",
            "Epoch 83/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 0.9818 - categorical_accuracy: 0.5629 - val_loss: 1.0378 - val_categorical_accuracy: 0.5332\n",
            "Epoch 84/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 1.0025 - categorical_accuracy: 0.5451 - val_loss: 1.0662 - val_categorical_accuracy: 0.5237\n",
            "Epoch 85/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 0.9804 - categorical_accuracy: 0.5617 - val_loss: 1.1193 - val_categorical_accuracy: 0.5009\n",
            "Epoch 86/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 0.9974 - categorical_accuracy: 0.5634 - val_loss: 1.0123 - val_categorical_accuracy: 0.5522\n",
            "Epoch 87/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 0.9964 - categorical_accuracy: 0.5460 - val_loss: 1.0454 - val_categorical_accuracy: 0.5408\n",
            "Epoch 88/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 0.9915 - categorical_accuracy: 0.5574 - val_loss: 0.9982 - val_categorical_accuracy: 0.5446\n",
            "Epoch 89/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 1.0086 - categorical_accuracy: 0.5537 - val_loss: 1.0036 - val_categorical_accuracy: 0.5579\n",
            "Epoch 90/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 0.9855 - categorical_accuracy: 0.5510 - val_loss: 1.0346 - val_categorical_accuracy: 0.5484\n",
            "Epoch 91/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 0.9595 - categorical_accuracy: 0.5802 - val_loss: 0.9911 - val_categorical_accuracy: 0.5712\n",
            "Epoch 92/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 0.9849 - categorical_accuracy: 0.5628 - val_loss: 1.0036 - val_categorical_accuracy: 0.5560\n",
            "Epoch 93/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 0.9899 - categorical_accuracy: 0.5636 - val_loss: 1.0242 - val_categorical_accuracy: 0.5351\n",
            "Epoch 94/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 0.9754 - categorical_accuracy: 0.5594 - val_loss: 0.9962 - val_categorical_accuracy: 0.5579\n",
            "Epoch 95/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 0.9932 - categorical_accuracy: 0.5623 - val_loss: 1.0284 - val_categorical_accuracy: 0.5465\n",
            "Epoch 96/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 0.9946 - categorical_accuracy: 0.5503 - val_loss: 0.9999 - val_categorical_accuracy: 0.5655\n",
            "Epoch 97/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 0.9745 - categorical_accuracy: 0.5639 - val_loss: 0.9780 - val_categorical_accuracy: 0.5693\n",
            "Epoch 98/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 0.9593 - categorical_accuracy: 0.5747 - val_loss: 0.9983 - val_categorical_accuracy: 0.5693\n",
            "Epoch 99/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 0.9812 - categorical_accuracy: 0.5584 - val_loss: 1.0102 - val_categorical_accuracy: 0.5617\n",
            "Epoch 100/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 0.9771 - categorical_accuracy: 0.5557 - val_loss: 1.0320 - val_categorical_accuracy: 0.5332\n",
            "Epoch 101/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 0.9806 - categorical_accuracy: 0.5567 - val_loss: 1.0451 - val_categorical_accuracy: 0.5389\n",
            "Epoch 102/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 0.9904 - categorical_accuracy: 0.5588 - val_loss: 0.9976 - val_categorical_accuracy: 0.5560\n",
            "Epoch 103/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 0.9544 - categorical_accuracy: 0.5802 - val_loss: 0.9929 - val_categorical_accuracy: 0.5712\n",
            "Epoch 104/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 0.9582 - categorical_accuracy: 0.5645 - val_loss: 0.9764 - val_categorical_accuracy: 0.5844\n",
            "Epoch 105/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 0.9974 - categorical_accuracy: 0.5490 - val_loss: 0.9935 - val_categorical_accuracy: 0.5408\n",
            "Epoch 106/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 0.9907 - categorical_accuracy: 0.5536 - val_loss: 0.9879 - val_categorical_accuracy: 0.5787\n",
            "Epoch 107/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 0.9764 - categorical_accuracy: 0.5656 - val_loss: 0.9768 - val_categorical_accuracy: 0.5579\n",
            "Epoch 108/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 0.9823 - categorical_accuracy: 0.5563 - val_loss: 0.9793 - val_categorical_accuracy: 0.5674\n",
            "Epoch 109/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 0.9615 - categorical_accuracy: 0.5742 - val_loss: 0.9857 - val_categorical_accuracy: 0.5598\n",
            "Epoch 110/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 0.9810 - categorical_accuracy: 0.5717 - val_loss: 0.9830 - val_categorical_accuracy: 0.5598\n",
            "Epoch 111/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 0.9841 - categorical_accuracy: 0.5658 - val_loss: 0.9817 - val_categorical_accuracy: 0.5825\n",
            "Epoch 112/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 0.9665 - categorical_accuracy: 0.5730 - val_loss: 1.0133 - val_categorical_accuracy: 0.5446\n",
            "Epoch 113/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 0.9830 - categorical_accuracy: 0.5493 - val_loss: 0.9748 - val_categorical_accuracy: 0.5693\n",
            "Epoch 114/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 0.9725 - categorical_accuracy: 0.5686 - val_loss: 1.0021 - val_categorical_accuracy: 0.5541\n",
            "Epoch 115/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 0.9634 - categorical_accuracy: 0.5648 - val_loss: 0.9800 - val_categorical_accuracy: 0.5731\n",
            "Epoch 116/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 0.9504 - categorical_accuracy: 0.5784 - val_loss: 1.0197 - val_categorical_accuracy: 0.5427\n",
            "Epoch 117/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 0.9665 - categorical_accuracy: 0.5717 - val_loss: 1.0050 - val_categorical_accuracy: 0.5693\n",
            "Epoch 118/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 0.9406 - categorical_accuracy: 0.5879 - val_loss: 0.9763 - val_categorical_accuracy: 0.5769\n",
            "Epoch 119/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 0.9705 - categorical_accuracy: 0.5746 - val_loss: 0.9766 - val_categorical_accuracy: 0.5863\n",
            "Epoch 120/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 0.9855 - categorical_accuracy: 0.5574 - val_loss: 0.9950 - val_categorical_accuracy: 0.5579\n",
            "Epoch 121/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 0.9636 - categorical_accuracy: 0.5705 - val_loss: 1.0308 - val_categorical_accuracy: 0.5408\n",
            "Epoch 122/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 0.9666 - categorical_accuracy: 0.5577 - val_loss: 0.9946 - val_categorical_accuracy: 0.5598\n",
            "Epoch 123/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 0.9562 - categorical_accuracy: 0.5753 - val_loss: 0.9704 - val_categorical_accuracy: 0.5882\n",
            "Epoch 124/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 0.9932 - categorical_accuracy: 0.5699 - val_loss: 0.9640 - val_categorical_accuracy: 0.5731\n",
            "Epoch 125/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 0.9653 - categorical_accuracy: 0.5653 - val_loss: 0.9870 - val_categorical_accuracy: 0.5674\n",
            "Epoch 126/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 0.9543 - categorical_accuracy: 0.5856 - val_loss: 0.9893 - val_categorical_accuracy: 0.5693\n",
            "Epoch 127/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 0.9478 - categorical_accuracy: 0.5818 - val_loss: 0.9793 - val_categorical_accuracy: 0.5636\n",
            "Epoch 128/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 0.9712 - categorical_accuracy: 0.5753 - val_loss: 0.9697 - val_categorical_accuracy: 0.5693\n",
            "Epoch 129/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 0.9581 - categorical_accuracy: 0.5785 - val_loss: 1.0036 - val_categorical_accuracy: 0.5825\n",
            "Epoch 130/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 0.9513 - categorical_accuracy: 0.5974 - val_loss: 0.9723 - val_categorical_accuracy: 0.5939\n",
            "Epoch 131/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 0.9538 - categorical_accuracy: 0.5756 - val_loss: 0.9588 - val_categorical_accuracy: 0.5958\n",
            "Epoch 132/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 0.9578 - categorical_accuracy: 0.5793 - val_loss: 0.9658 - val_categorical_accuracy: 0.5977\n",
            "Epoch 133/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 0.9687 - categorical_accuracy: 0.5735 - val_loss: 0.9704 - val_categorical_accuracy: 0.5901\n",
            "Epoch 134/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 0.9501 - categorical_accuracy: 0.5744 - val_loss: 0.9961 - val_categorical_accuracy: 0.5674\n",
            "Epoch 135/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 0.9687 - categorical_accuracy: 0.5632 - val_loss: 0.9603 - val_categorical_accuracy: 0.5977\n",
            "Epoch 136/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 0.9521 - categorical_accuracy: 0.5803 - val_loss: 0.9937 - val_categorical_accuracy: 0.5427\n",
            "Epoch 137/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 0.9588 - categorical_accuracy: 0.5643 - val_loss: 1.0169 - val_categorical_accuracy: 0.5351\n",
            "Epoch 138/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 0.9534 - categorical_accuracy: 0.5684 - val_loss: 1.0366 - val_categorical_accuracy: 0.5446\n",
            "Epoch 139/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 0.9429 - categorical_accuracy: 0.5823 - val_loss: 0.9554 - val_categorical_accuracy: 0.5882\n",
            "Epoch 140/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 0.9374 - categorical_accuracy: 0.5754 - val_loss: 0.9536 - val_categorical_accuracy: 0.5996\n",
            "Epoch 141/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 0.9664 - categorical_accuracy: 0.5793 - val_loss: 0.9651 - val_categorical_accuracy: 0.6034\n",
            "Epoch 142/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 0.9691 - categorical_accuracy: 0.5730 - val_loss: 1.0024 - val_categorical_accuracy: 0.5693\n",
            "Epoch 143/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 0.9416 - categorical_accuracy: 0.5916 - val_loss: 0.9616 - val_categorical_accuracy: 0.5901\n",
            "Epoch 144/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 0.9376 - categorical_accuracy: 0.5902 - val_loss: 1.0202 - val_categorical_accuracy: 0.5541\n",
            "Epoch 145/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 0.9511 - categorical_accuracy: 0.5792 - val_loss: 0.9914 - val_categorical_accuracy: 0.5731\n",
            "Epoch 146/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 0.9581 - categorical_accuracy: 0.5817 - val_loss: 0.9831 - val_categorical_accuracy: 0.5750\n",
            "Epoch 147/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 0.9437 - categorical_accuracy: 0.5896 - val_loss: 0.9705 - val_categorical_accuracy: 0.5769\n",
            "Epoch 148/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 0.9573 - categorical_accuracy: 0.5805 - val_loss: 0.9599 - val_categorical_accuracy: 0.5920\n",
            "Epoch 149/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 0.9483 - categorical_accuracy: 0.5828 - val_loss: 0.9757 - val_categorical_accuracy: 0.5806\n",
            "Epoch 150/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 0.9604 - categorical_accuracy: 0.5851 - val_loss: 0.9581 - val_categorical_accuracy: 0.5920\n",
            "Epoch 151/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 0.9557 - categorical_accuracy: 0.5838 - val_loss: 0.9704 - val_categorical_accuracy: 0.5674\n",
            "Epoch 152/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 0.9446 - categorical_accuracy: 0.5678 - val_loss: 0.9814 - val_categorical_accuracy: 0.5750\n",
            "Epoch 153/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 0.9493 - categorical_accuracy: 0.5718 - val_loss: 0.9660 - val_categorical_accuracy: 0.5939\n",
            "Epoch 154/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 0.9301 - categorical_accuracy: 0.5911 - val_loss: 1.0113 - val_categorical_accuracy: 0.5389\n",
            "Epoch 155/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 0.9486 - categorical_accuracy: 0.5734 - val_loss: 0.9646 - val_categorical_accuracy: 0.5920\n",
            "Epoch 156/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 0.9667 - categorical_accuracy: 0.5739 - val_loss: 0.9823 - val_categorical_accuracy: 0.5712\n",
            "Epoch 157/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 0.9296 - categorical_accuracy: 0.5836 - val_loss: 0.9730 - val_categorical_accuracy: 0.5617\n",
            "Epoch 158/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 0.9501 - categorical_accuracy: 0.5866 - val_loss: 0.9712 - val_categorical_accuracy: 0.5787\n",
            "Epoch 159/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 0.9371 - categorical_accuracy: 0.5888 - val_loss: 0.9474 - val_categorical_accuracy: 0.5996\n",
            "Epoch 160/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 0.9303 - categorical_accuracy: 0.6007 - val_loss: 0.9635 - val_categorical_accuracy: 0.5977\n",
            "Epoch 161/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 0.9301 - categorical_accuracy: 0.5963 - val_loss: 0.9724 - val_categorical_accuracy: 0.5731\n",
            "Epoch 162/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 0.9547 - categorical_accuracy: 0.5717 - val_loss: 0.9592 - val_categorical_accuracy: 0.5882\n",
            "Epoch 163/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 0.9368 - categorical_accuracy: 0.5921 - val_loss: 0.9776 - val_categorical_accuracy: 0.5825\n",
            "Epoch 164/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 0.9344 - categorical_accuracy: 0.5864 - val_loss: 0.9700 - val_categorical_accuracy: 0.5901\n",
            "Epoch 165/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 0.9536 - categorical_accuracy: 0.5613 - val_loss: 0.9425 - val_categorical_accuracy: 0.5901\n",
            "Epoch 166/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 0.9630 - categorical_accuracy: 0.5718 - val_loss: 0.9430 - val_categorical_accuracy: 0.6034\n",
            "Epoch 167/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 0.9507 - categorical_accuracy: 0.5857 - val_loss: 0.9477 - val_categorical_accuracy: 0.6053\n",
            "Epoch 168/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 0.9388 - categorical_accuracy: 0.5851 - val_loss: 0.9652 - val_categorical_accuracy: 0.5977\n",
            "Epoch 169/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 0.9215 - categorical_accuracy: 0.5908 - val_loss: 0.9407 - val_categorical_accuracy: 0.6053\n",
            "Epoch 170/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 0.9416 - categorical_accuracy: 0.5814 - val_loss: 0.9477 - val_categorical_accuracy: 0.6091\n",
            "Epoch 171/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 0.9407 - categorical_accuracy: 0.5897 - val_loss: 0.9435 - val_categorical_accuracy: 0.5958\n",
            "Epoch 172/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 0.9348 - categorical_accuracy: 0.5771 - val_loss: 0.9572 - val_categorical_accuracy: 0.5920\n",
            "Epoch 173/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 0.9470 - categorical_accuracy: 0.5786 - val_loss: 0.9574 - val_categorical_accuracy: 0.5977\n",
            "Epoch 174/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 0.9446 - categorical_accuracy: 0.5868 - val_loss: 0.9489 - val_categorical_accuracy: 0.5901\n",
            "Epoch 175/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 0.9496 - categorical_accuracy: 0.5874 - val_loss: 0.9562 - val_categorical_accuracy: 0.5920\n",
            "Epoch 176/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 0.9383 - categorical_accuracy: 0.5815 - val_loss: 0.9635 - val_categorical_accuracy: 0.5863\n",
            "Epoch 177/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 0.9228 - categorical_accuracy: 0.5842 - val_loss: 0.9533 - val_categorical_accuracy: 0.5958\n",
            "Epoch 178/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 0.9359 - categorical_accuracy: 0.5809 - val_loss: 0.9559 - val_categorical_accuracy: 0.5825\n",
            "Epoch 179/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 0.9448 - categorical_accuracy: 0.5779 - val_loss: 0.9420 - val_categorical_accuracy: 0.5996\n",
            "Epoch 180/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 0.9245 - categorical_accuracy: 0.5864 - val_loss: 0.9592 - val_categorical_accuracy: 0.5806\n",
            "Epoch 181/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 0.9388 - categorical_accuracy: 0.5877 - val_loss: 0.9416 - val_categorical_accuracy: 0.5882\n",
            "Epoch 182/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 0.9292 - categorical_accuracy: 0.5993 - val_loss: 0.9574 - val_categorical_accuracy: 0.5844\n",
            "Epoch 183/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 0.9267 - categorical_accuracy: 0.5759 - val_loss: 0.9870 - val_categorical_accuracy: 0.5939\n",
            "Epoch 184/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 0.9459 - categorical_accuracy: 0.5700 - val_loss: 0.9730 - val_categorical_accuracy: 0.5863\n",
            "Epoch 185/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 0.9527 - categorical_accuracy: 0.5816 - val_loss: 0.9529 - val_categorical_accuracy: 0.5996\n",
            "Epoch 186/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 0.9381 - categorical_accuracy: 0.5865 - val_loss: 0.9473 - val_categorical_accuracy: 0.5958\n",
            "Epoch 187/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 0.9319 - categorical_accuracy: 0.5896 - val_loss: 0.9423 - val_categorical_accuracy: 0.6053\n",
            "Epoch 188/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 0.9399 - categorical_accuracy: 0.5847 - val_loss: 0.9409 - val_categorical_accuracy: 0.5958\n",
            "Epoch 189/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 0.9253 - categorical_accuracy: 0.6024 - val_loss: 0.9407 - val_categorical_accuracy: 0.6034\n",
            "Epoch 190/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 0.9178 - categorical_accuracy: 0.5958 - val_loss: 0.9622 - val_categorical_accuracy: 0.5977\n",
            "Epoch 191/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 0.9267 - categorical_accuracy: 0.5897 - val_loss: 0.9594 - val_categorical_accuracy: 0.6034\n",
            "Epoch 192/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 0.9441 - categorical_accuracy: 0.5796 - val_loss: 0.9605 - val_categorical_accuracy: 0.5977\n",
            "Epoch 193/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 0.8957 - categorical_accuracy: 0.6066 - val_loss: 0.9348 - val_categorical_accuracy: 0.6034\n",
            "Epoch 194/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 0.9326 - categorical_accuracy: 0.5911 - val_loss: 0.9587 - val_categorical_accuracy: 0.5844\n",
            "Epoch 195/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 0.9330 - categorical_accuracy: 0.5917 - val_loss: 0.9738 - val_categorical_accuracy: 0.5598\n",
            "Epoch 196/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 0.9417 - categorical_accuracy: 0.5943 - val_loss: 0.9474 - val_categorical_accuracy: 0.5977\n",
            "Epoch 197/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 0.9258 - categorical_accuracy: 0.5902 - val_loss: 0.9445 - val_categorical_accuracy: 0.6034\n",
            "Epoch 198/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 0.9268 - categorical_accuracy: 0.5946 - val_loss: 0.9461 - val_categorical_accuracy: 0.5806\n",
            "Epoch 199/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 0.9396 - categorical_accuracy: 0.5775 - val_loss: 0.9617 - val_categorical_accuracy: 0.5844\n",
            "Epoch 200/200\n",
            "297/297 [==============================] - 1s 4ms/step - loss: 0.9504 - categorical_accuracy: 0.5741 - val_loss: 0.9355 - val_categorical_accuracy: 0.6148\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "phONxCpg2ndh"
      },
      "source": [
        "model.save('/content/drive/MyDrive/Colab Notebooks/SPEECH_EMOTION_Recognition/Nộp bài(chốt hạ)/model_saver/conv2D_mfcc13_merged.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HjbGkNOG2ndi"
      },
      "source": [
        "###test_result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a80Gcu9H2ndi",
        "outputId": "a8f57267-ce3c-400b-a513-100916e3d175"
      },
      "source": [
        "d = {0: 'happy',\n",
        "     1: 'sad',\n",
        "     2: 'angry',\n",
        "     3: 'fear'}\n",
        "Y_test_pred = np.argmax(model.predict(X_test), axis=-1)\n",
        "Y_test_pred = list(map(lambda x: d[x], Y_test_pred))\n",
        "y_test = np.argmax(y_test, axis=-1)\n",
        "y_test = list(map(lambda x: d[x], y_test))\n",
        "print(classification_report(y_test, Y_test_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.78      0.73      0.75       129\n",
            "        fear       0.59      0.27      0.37       174\n",
            "       happy       0.50      0.75      0.60       127\n",
            "         sad       0.63      0.79      0.70       156\n",
            "\n",
            "    accuracy                           0.61       586\n",
            "   macro avg       0.62      0.63      0.61       586\n",
            "weighted avg       0.62      0.61      0.59       586\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Y0mQ9rM2ndj",
        "outputId": "2490f6bd-6998-414d-f081-ab4aac75a803"
      },
      "source": [
        "import scikitplot as skplt\n",
        "\n",
        "skplt.metrics.plot_confusion_matrix(\n",
        "    y_test, \n",
        "    Y_test_pred,\n",
        "    figsize=(8,8))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f44e4207890>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNZony_t2ndk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EmYkQLiis54l"
      },
      "source": [
        "# mfcc_26 + conv2D:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tj_EpRThs549"
      },
      "source": [
        "audio_duration = 3\n",
        "sampling_rate = 22050\n",
        "input_length = sampling_rate * audio_duration"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFjtAig0s54-"
      },
      "source": [
        "features = []\n",
        "labels = []\n",
        "for i in range(len(Ravdess_DF['Paths'])):\n",
        "  if ((Ravdess_DF['Emotion'][i] == '03') | (Ravdess_DF['Emotion'][i] == '04') | \n",
        "      (Ravdess_DF['Emotion'][i] == '05') | (Ravdess_DF['Emotion'][i] == '06')):\n",
        "    signal, sr = librosa.load(Ravdess_DF['Paths'][i])\n",
        "\n",
        "    if len(signal) > input_length:\n",
        "      signal = signal[0:input_length]\n",
        "    elif  input_length > len(signal):\n",
        "      max_offset = input_length - len(signal)  \n",
        "      signal = np.pad(signal, (0, max_offset), \"constant\")\n",
        "\n",
        "    mfcc = librosa.feature.mfcc(y=signal, sr=sr, n_mfcc=26).T\n",
        "    mfcc = np.expand_dims(mfcc, axis=-1)\n",
        "    features.append(mfcc)\n",
        "\n",
        "    if Ravdess_DF['Emotion'][i] == '03':\n",
        "      labels.append(0)\n",
        "    elif Ravdess_DF['Emotion'][i] == '04':\n",
        "      labels.append(1)\n",
        "    elif Ravdess_DF['Emotion'][i] == '05':\n",
        "      labels.append(2)\n",
        "    elif Ravdess_DF['Emotion'][i] == '06':\n",
        "      labels.append(3)\n",
        "\n",
        "\n",
        "for i in range(len(CREMA_D_df)):\n",
        "  if ((CREMA_D_df['Emotion'][i] == 'HAP') | (CREMA_D_df['Emotion'][i] == 'SAD') | \n",
        "      (CREMA_D_df['Emotion'][i] == 'ANG') | (CREMA_D_df['Emotion'][i] == 'FEA')):\n",
        "    \n",
        "    if CREMA_D_df['Emotion'][i] == 'HAP':\n",
        "      labels.append(0)\n",
        "    elif CREMA_D_df['Emotion'][i] == 'SAD':\n",
        "      labels.append(1)\n",
        "    elif CREMA_D_df['Emotion'][i] == 'ANG':\n",
        "      labels.append(2)\n",
        "    elif CREMA_D_df['Emotion'][i] == 'FEA':\n",
        "      labels.append(3)\n",
        "\n",
        "\n",
        "    signal, sr =  librosa.load(CREMA_D_df['Paths'][i])\n",
        "\n",
        "    if len(signal) > input_length:\n",
        "        signal = signal[0:input_length]\n",
        "    elif  input_length > len(signal):\n",
        "        max_offset = input_length - len(signal)  \n",
        "        signal = np.pad(signal, (0, max_offset), \"constant\")\n",
        "\n",
        "    mfcc = librosa.feature.mfcc(y=signal, sr=sr, n_mfcc=26).T\n",
        "    mfcc = np.expand_dims(mfcc, axis=-1)\n",
        "    features.append(mfcc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6ERzYaQs54-"
      },
      "source": [
        "X = features\n",
        "y = labels\n",
        "\n",
        "y = np.array(y)\n",
        "y = to_categorical(y)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=0)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=0)\n",
        "\n",
        "X_train = np.array(X_train)\n",
        "X_test = np.array(X_test)\n",
        "X_val = np.array(X_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qs61kkZWs54_",
        "outputId": "3b38d478-7127-48a3-e020-2014756f6ead"
      },
      "source": [
        "X_train.shape,X_test.shape,y_train.shape,y_test.shape\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((4739, 130, 26, 1), (586, 130, 26, 1), (4739, 4), (586, 4))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cbeA_Qots55A"
      },
      "source": [
        "# CNN I/P Config\n",
        "num_classes = 4\n",
        "input_shape = X_train.shape[1:]\n",
        "learning_rate = 0.0001\n",
        "decay = 1e-6\n",
        "momentum = 0.9"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UVRpmzk7s55A",
        "outputId": "2d85fad4-d3ca-49d0-8524-2675ed7fbb45"
      },
      "source": [
        "model = Sequential(name='Audio_CNN_2D')\n",
        "\n",
        "# LFLB1\n",
        "model.add(Conv2D(filters=64, kernel_size=(3,3), strides=(1,1), padding='same',input_shape=input_shape))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Conv2D(filters=64, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(4,4), strides=(4,4)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(units=num_classes, activation='softmax'))\n",
        "\n",
        "# Model compilation\n",
        "opt = optimizers.SGD(lr=learning_rate, decay=decay, momentum=momentum, nesterov=True)\n",
        "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"Audio_CNN_2D\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_2 (Conv2D)            (None, 130, 26, 64)       640       \n",
            "_________________________________________________________________\n",
            "batch_normalization_10 (Batc (None, 130, 26, 64)       256       \n",
            "_________________________________________________________________\n",
            "activation_10 (Activation)   (None, 130, 26, 64)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 65, 13, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 65, 13, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 65, 13, 64)        36928     \n",
            "_________________________________________________________________\n",
            "batch_normalization_11 (Batc (None, 65, 13, 64)        256       \n",
            "_________________________________________________________________\n",
            "activation_11 (Activation)   (None, 65, 13, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 16, 3, 64)         0         \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 16, 3, 64)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 3072)              0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 4)                 12292     \n",
            "=================================================================\n",
            "Total params: 50,372\n",
            "Trainable params: 50,116\n",
            "Non-trainable params: 256\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XjnBFr-4s55B",
        "outputId": "2c6f17c0-66a0-44bc-842c-9f6b07d3eac2"
      },
      "source": [
        "#Train Config\n",
        "\n",
        "batch_size = 16\n",
        "num_epochs = 200\n",
        "\n",
        "# Model Training\n",
        "lr_reduce = ReduceLROnPlateau(monitor='val_loss', factor=0.9, patience=20, min_lr=0.000001)\n",
        "# Please change the model name accordingly.\n",
        "mcp_save = ModelCheckpoint('/content/Modelfull_2_1.h5', save_best_only=True, monitor='val_categorical_accuracy', mode='max')\n",
        "cnnhistory=model.fit(X_train, y_train, batch_size=batch_size, epochs=num_epochs,validation_data=(X_val, y_val), callbacks=[mcp_save, lr_reduce])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "297/297 [==============================] - 4s 8ms/step - loss: 2.2866 - categorical_accuracy: 0.2982 - val_loss: 1.5806 - val_categorical_accuracy: 0.3510\n",
            "Epoch 2/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 1.6023 - categorical_accuracy: 0.3720 - val_loss: 1.2002 - val_categorical_accuracy: 0.4497\n",
            "Epoch 3/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 1.3635 - categorical_accuracy: 0.4243 - val_loss: 1.1283 - val_categorical_accuracy: 0.5180\n",
            "Epoch 4/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 1.2896 - categorical_accuracy: 0.4403 - val_loss: 1.1099 - val_categorical_accuracy: 0.5332\n",
            "Epoch 5/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 1.2403 - categorical_accuracy: 0.4477 - val_loss: 1.1166 - val_categorical_accuracy: 0.4934\n",
            "Epoch 6/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 1.2079 - categorical_accuracy: 0.4691 - val_loss: 1.0900 - val_categorical_accuracy: 0.5313\n",
            "Epoch 7/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 1.1677 - categorical_accuracy: 0.4917 - val_loss: 1.1238 - val_categorical_accuracy: 0.4383\n",
            "Epoch 8/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 1.1791 - categorical_accuracy: 0.4768 - val_loss: 1.1387 - val_categorical_accuracy: 0.4858\n",
            "Epoch 9/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 1.1520 - categorical_accuracy: 0.4911 - val_loss: 1.0721 - val_categorical_accuracy: 0.5332\n",
            "Epoch 10/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 1.1315 - categorical_accuracy: 0.4918 - val_loss: 1.0922 - val_categorical_accuracy: 0.4991\n",
            "Epoch 11/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 1.1179 - categorical_accuracy: 0.5123 - val_loss: 1.1318 - val_categorical_accuracy: 0.4099\n",
            "Epoch 12/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 1.1243 - categorical_accuracy: 0.4960 - val_loss: 1.1278 - val_categorical_accuracy: 0.3985\n",
            "Epoch 13/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 1.0892 - categorical_accuracy: 0.5211 - val_loss: 1.2124 - val_categorical_accuracy: 0.4440\n",
            "Epoch 14/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 1.0943 - categorical_accuracy: 0.5179 - val_loss: 1.1171 - val_categorical_accuracy: 0.4497\n",
            "Epoch 15/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 1.0730 - categorical_accuracy: 0.5194 - val_loss: 1.1428 - val_categorical_accuracy: 0.4137\n",
            "Epoch 16/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 1.0889 - categorical_accuracy: 0.5169 - val_loss: 1.1051 - val_categorical_accuracy: 0.4383\n",
            "Epoch 17/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 1.0913 - categorical_accuracy: 0.5208 - val_loss: 1.1186 - val_categorical_accuracy: 0.4288\n",
            "Epoch 18/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 1.0695 - categorical_accuracy: 0.5236 - val_loss: 1.0864 - val_categorical_accuracy: 0.4763\n",
            "Epoch 19/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 1.0815 - categorical_accuracy: 0.5213 - val_loss: 1.1699 - val_categorical_accuracy: 0.3985\n",
            "Epoch 20/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 1.0813 - categorical_accuracy: 0.5179 - val_loss: 1.1523 - val_categorical_accuracy: 0.3890\n",
            "Epoch 21/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 1.0648 - categorical_accuracy: 0.5298 - val_loss: 1.1243 - val_categorical_accuracy: 0.4250\n",
            "Epoch 22/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 1.0494 - categorical_accuracy: 0.5175 - val_loss: 1.1778 - val_categorical_accuracy: 0.4156\n",
            "Epoch 23/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 1.0378 - categorical_accuracy: 0.5278 - val_loss: 1.0995 - val_categorical_accuracy: 0.4611\n",
            "Epoch 24/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 1.0611 - categorical_accuracy: 0.5259 - val_loss: 1.1030 - val_categorical_accuracy: 0.4459\n",
            "Epoch 25/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 1.0305 - categorical_accuracy: 0.5445 - val_loss: 1.0879 - val_categorical_accuracy: 0.4269\n",
            "Epoch 26/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 1.0661 - categorical_accuracy: 0.5247 - val_loss: 1.1998 - val_categorical_accuracy: 0.4213\n",
            "Epoch 27/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 1.0633 - categorical_accuracy: 0.5214 - val_loss: 1.0921 - val_categorical_accuracy: 0.4326\n",
            "Epoch 28/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 1.0791 - categorical_accuracy: 0.5023 - val_loss: 1.0881 - val_categorical_accuracy: 0.4156\n",
            "Epoch 29/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 1.0098 - categorical_accuracy: 0.5308 - val_loss: 1.1718 - val_categorical_accuracy: 0.4061\n",
            "Epoch 30/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 1.0300 - categorical_accuracy: 0.5376 - val_loss: 1.1180 - val_categorical_accuracy: 0.4516\n",
            "Epoch 31/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 1.0645 - categorical_accuracy: 0.5147 - val_loss: 1.1247 - val_categorical_accuracy: 0.4175\n",
            "Epoch 32/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 1.0198 - categorical_accuracy: 0.5499 - val_loss: 1.1162 - val_categorical_accuracy: 0.4250\n",
            "Epoch 33/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 1.0287 - categorical_accuracy: 0.5334 - val_loss: 1.1014 - val_categorical_accuracy: 0.4763\n",
            "Epoch 34/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 1.0241 - categorical_accuracy: 0.5488 - val_loss: 1.0878 - val_categorical_accuracy: 0.4535\n",
            "Epoch 35/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 1.0193 - categorical_accuracy: 0.5417 - val_loss: 1.0773 - val_categorical_accuracy: 0.4725\n",
            "Epoch 36/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 1.0072 - categorical_accuracy: 0.5503 - val_loss: 1.0489 - val_categorical_accuracy: 0.5408\n",
            "Epoch 37/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 1.0341 - categorical_accuracy: 0.5388 - val_loss: 1.0760 - val_categorical_accuracy: 0.4668\n",
            "Epoch 38/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 1.0476 - categorical_accuracy: 0.5486 - val_loss: 1.1036 - val_categorical_accuracy: 0.4269\n",
            "Epoch 39/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.9785 - categorical_accuracy: 0.5652 - val_loss: 1.0641 - val_categorical_accuracy: 0.4630\n",
            "Epoch 40/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 1.0086 - categorical_accuracy: 0.5657 - val_loss: 1.0787 - val_categorical_accuracy: 0.4611\n",
            "Epoch 41/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 1.0039 - categorical_accuracy: 0.5534 - val_loss: 1.1429 - val_categorical_accuracy: 0.3871\n",
            "Epoch 42/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 1.0045 - categorical_accuracy: 0.5552 - val_loss: 1.1547 - val_categorical_accuracy: 0.4573\n",
            "Epoch 43/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 1.0112 - categorical_accuracy: 0.5474 - val_loss: 1.0880 - val_categorical_accuracy: 0.4250\n",
            "Epoch 44/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.9874 - categorical_accuracy: 0.5633 - val_loss: 1.0294 - val_categorical_accuracy: 0.4953\n",
            "Epoch 45/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.9845 - categorical_accuracy: 0.5589 - val_loss: 1.0954 - val_categorical_accuracy: 0.4535\n",
            "Epoch 46/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.9852 - categorical_accuracy: 0.5567 - val_loss: 1.1407 - val_categorical_accuracy: 0.4345\n",
            "Epoch 47/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 1.0248 - categorical_accuracy: 0.5501 - val_loss: 1.0558 - val_categorical_accuracy: 0.4991\n",
            "Epoch 48/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.9847 - categorical_accuracy: 0.5612 - val_loss: 1.0923 - val_categorical_accuracy: 0.4554\n",
            "Epoch 49/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.9710 - categorical_accuracy: 0.5792 - val_loss: 1.0871 - val_categorical_accuracy: 0.4630\n",
            "Epoch 50/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.9877 - categorical_accuracy: 0.5628 - val_loss: 1.0438 - val_categorical_accuracy: 0.4592\n",
            "Epoch 51/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 1.0028 - categorical_accuracy: 0.5559 - val_loss: 1.1490 - val_categorical_accuracy: 0.4156\n",
            "Epoch 52/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 1.0089 - categorical_accuracy: 0.5590 - val_loss: 1.0899 - val_categorical_accuracy: 0.4307\n",
            "Epoch 53/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.9887 - categorical_accuracy: 0.5658 - val_loss: 1.0902 - val_categorical_accuracy: 0.4231\n",
            "Epoch 54/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.9927 - categorical_accuracy: 0.5512 - val_loss: 1.1021 - val_categorical_accuracy: 0.4269\n",
            "Epoch 55/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.9635 - categorical_accuracy: 0.5628 - val_loss: 1.0590 - val_categorical_accuracy: 0.4535\n",
            "Epoch 56/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.9709 - categorical_accuracy: 0.5774 - val_loss: 1.0826 - val_categorical_accuracy: 0.4326\n",
            "Epoch 57/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.9736 - categorical_accuracy: 0.5741 - val_loss: 1.1377 - val_categorical_accuracy: 0.3966\n",
            "Epoch 58/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.9782 - categorical_accuracy: 0.5672 - val_loss: 1.0282 - val_categorical_accuracy: 0.4725\n",
            "Epoch 59/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.9746 - categorical_accuracy: 0.5689 - val_loss: 1.0235 - val_categorical_accuracy: 0.4820\n",
            "Epoch 60/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.9609 - categorical_accuracy: 0.5793 - val_loss: 1.0186 - val_categorical_accuracy: 0.5256\n",
            "Epoch 61/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.9531 - categorical_accuracy: 0.5814 - val_loss: 1.0589 - val_categorical_accuracy: 0.4402\n",
            "Epoch 62/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.9660 - categorical_accuracy: 0.5680 - val_loss: 1.0378 - val_categorical_accuracy: 0.5009\n",
            "Epoch 63/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.9833 - categorical_accuracy: 0.5772 - val_loss: 1.0328 - val_categorical_accuracy: 0.5104\n",
            "Epoch 64/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.9654 - categorical_accuracy: 0.5766 - val_loss: 1.0139 - val_categorical_accuracy: 0.4839\n",
            "Epoch 65/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.9417 - categorical_accuracy: 0.5800 - val_loss: 0.9940 - val_categorical_accuracy: 0.5351\n",
            "Epoch 66/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.9517 - categorical_accuracy: 0.5772 - val_loss: 1.0480 - val_categorical_accuracy: 0.4953\n",
            "Epoch 67/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.9882 - categorical_accuracy: 0.5448 - val_loss: 1.1509 - val_categorical_accuracy: 0.4288\n",
            "Epoch 68/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.9677 - categorical_accuracy: 0.5815 - val_loss: 1.0776 - val_categorical_accuracy: 0.4554\n",
            "Epoch 69/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.9532 - categorical_accuracy: 0.5782 - val_loss: 1.0178 - val_categorical_accuracy: 0.5028\n",
            "Epoch 70/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.9639 - categorical_accuracy: 0.5832 - val_loss: 1.0100 - val_categorical_accuracy: 0.5161\n",
            "Epoch 71/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.9673 - categorical_accuracy: 0.5661 - val_loss: 1.0386 - val_categorical_accuracy: 0.4782\n",
            "Epoch 72/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.9480 - categorical_accuracy: 0.5806 - val_loss: 0.9967 - val_categorical_accuracy: 0.5066\n",
            "Epoch 73/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.9750 - categorical_accuracy: 0.5756 - val_loss: 1.0782 - val_categorical_accuracy: 0.4345\n",
            "Epoch 74/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.9661 - categorical_accuracy: 0.5702 - val_loss: 1.1469 - val_categorical_accuracy: 0.4592\n",
            "Epoch 75/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.9644 - categorical_accuracy: 0.5785 - val_loss: 1.0421 - val_categorical_accuracy: 0.5123\n",
            "Epoch 76/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.9454 - categorical_accuracy: 0.5889 - val_loss: 0.9924 - val_categorical_accuracy: 0.5465\n",
            "Epoch 77/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.9412 - categorical_accuracy: 0.5777 - val_loss: 1.0571 - val_categorical_accuracy: 0.4820\n",
            "Epoch 78/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.9573 - categorical_accuracy: 0.5850 - val_loss: 1.0148 - val_categorical_accuracy: 0.4953\n",
            "Epoch 79/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.9295 - categorical_accuracy: 0.5937 - val_loss: 1.0291 - val_categorical_accuracy: 0.4611\n",
            "Epoch 80/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.9457 - categorical_accuracy: 0.5678 - val_loss: 1.0362 - val_categorical_accuracy: 0.4782\n",
            "Epoch 81/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.9408 - categorical_accuracy: 0.5917 - val_loss: 0.9966 - val_categorical_accuracy: 0.5332\n",
            "Epoch 82/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.9228 - categorical_accuracy: 0.5999 - val_loss: 1.0416 - val_categorical_accuracy: 0.4611\n",
            "Epoch 83/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.9326 - categorical_accuracy: 0.5854 - val_loss: 1.0354 - val_categorical_accuracy: 0.4611\n",
            "Epoch 84/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.9412 - categorical_accuracy: 0.5807 - val_loss: 1.0177 - val_categorical_accuracy: 0.4953\n",
            "Epoch 85/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.9457 - categorical_accuracy: 0.5919 - val_loss: 0.9968 - val_categorical_accuracy: 0.5256\n",
            "Epoch 86/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.9485 - categorical_accuracy: 0.5762 - val_loss: 0.9980 - val_categorical_accuracy: 0.5465\n",
            "Epoch 87/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.9387 - categorical_accuracy: 0.5859 - val_loss: 0.9815 - val_categorical_accuracy: 0.5484\n",
            "Epoch 88/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.9382 - categorical_accuracy: 0.5831 - val_loss: 1.0280 - val_categorical_accuracy: 0.5047\n",
            "Epoch 89/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.9220 - categorical_accuracy: 0.5953 - val_loss: 1.0398 - val_categorical_accuracy: 0.4630\n",
            "Epoch 90/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.9399 - categorical_accuracy: 0.5831 - val_loss: 1.0131 - val_categorical_accuracy: 0.5142\n",
            "Epoch 91/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.9346 - categorical_accuracy: 0.5982 - val_loss: 1.0423 - val_categorical_accuracy: 0.4554\n",
            "Epoch 92/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.9249 - categorical_accuracy: 0.6042 - val_loss: 1.1046 - val_categorical_accuracy: 0.4383\n",
            "Epoch 93/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.9361 - categorical_accuracy: 0.5889 - val_loss: 0.9977 - val_categorical_accuracy: 0.5047\n",
            "Epoch 94/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.9275 - categorical_accuracy: 0.6034 - val_loss: 1.0885 - val_categorical_accuracy: 0.4231\n",
            "Epoch 95/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.9315 - categorical_accuracy: 0.5953 - val_loss: 0.9769 - val_categorical_accuracy: 0.5332\n",
            "Epoch 96/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.9396 - categorical_accuracy: 0.5851 - val_loss: 0.9955 - val_categorical_accuracy: 0.4972\n",
            "Epoch 97/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.9132 - categorical_accuracy: 0.5951 - val_loss: 0.9628 - val_categorical_accuracy: 0.5636\n",
            "Epoch 98/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.9216 - categorical_accuracy: 0.6018 - val_loss: 0.9788 - val_categorical_accuracy: 0.5199\n",
            "Epoch 99/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.9130 - categorical_accuracy: 0.6052 - val_loss: 1.0119 - val_categorical_accuracy: 0.4972\n",
            "Epoch 100/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.9234 - categorical_accuracy: 0.5950 - val_loss: 0.9679 - val_categorical_accuracy: 0.5503\n",
            "Epoch 101/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.9042 - categorical_accuracy: 0.6020 - val_loss: 0.9939 - val_categorical_accuracy: 0.5104\n",
            "Epoch 102/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.9143 - categorical_accuracy: 0.6003 - val_loss: 0.9898 - val_categorical_accuracy: 0.5237\n",
            "Epoch 103/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.9173 - categorical_accuracy: 0.6032 - val_loss: 0.9690 - val_categorical_accuracy: 0.5503\n",
            "Epoch 104/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.9252 - categorical_accuracy: 0.5903 - val_loss: 0.9849 - val_categorical_accuracy: 0.5541\n",
            "Epoch 105/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.9318 - categorical_accuracy: 0.5958 - val_loss: 1.0160 - val_categorical_accuracy: 0.4820\n",
            "Epoch 106/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.9347 - categorical_accuracy: 0.6054 - val_loss: 0.9780 - val_categorical_accuracy: 0.5598\n",
            "Epoch 107/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.9227 - categorical_accuracy: 0.5929 - val_loss: 1.0106 - val_categorical_accuracy: 0.5104\n",
            "Epoch 108/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.9332 - categorical_accuracy: 0.5874 - val_loss: 0.9568 - val_categorical_accuracy: 0.5806\n",
            "Epoch 109/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.9072 - categorical_accuracy: 0.6072 - val_loss: 0.9742 - val_categorical_accuracy: 0.5332\n",
            "Epoch 110/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.9102 - categorical_accuracy: 0.5955 - val_loss: 0.9826 - val_categorical_accuracy: 0.5199\n",
            "Epoch 111/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.9343 - categorical_accuracy: 0.5956 - val_loss: 1.0187 - val_categorical_accuracy: 0.4953\n",
            "Epoch 112/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.9277 - categorical_accuracy: 0.5989 - val_loss: 0.9708 - val_categorical_accuracy: 0.5408\n",
            "Epoch 113/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.8994 - categorical_accuracy: 0.6047 - val_loss: 0.9639 - val_categorical_accuracy: 0.5484\n",
            "Epoch 114/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.9021 - categorical_accuracy: 0.5982 - val_loss: 1.0166 - val_categorical_accuracy: 0.5161\n",
            "Epoch 115/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.9002 - categorical_accuracy: 0.6094 - val_loss: 0.9855 - val_categorical_accuracy: 0.5522\n",
            "Epoch 116/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.9226 - categorical_accuracy: 0.5930 - val_loss: 0.9643 - val_categorical_accuracy: 0.5446\n",
            "Epoch 117/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.8945 - categorical_accuracy: 0.6066 - val_loss: 0.9494 - val_categorical_accuracy: 0.5882\n",
            "Epoch 118/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.9193 - categorical_accuracy: 0.5911 - val_loss: 1.0151 - val_categorical_accuracy: 0.5028\n",
            "Epoch 119/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.8908 - categorical_accuracy: 0.6130 - val_loss: 0.9381 - val_categorical_accuracy: 0.6072\n",
            "Epoch 120/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.9146 - categorical_accuracy: 0.6075 - val_loss: 0.9520 - val_categorical_accuracy: 0.5863\n",
            "Epoch 121/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.8952 - categorical_accuracy: 0.6269 - val_loss: 0.9713 - val_categorical_accuracy: 0.5446\n",
            "Epoch 122/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.9220 - categorical_accuracy: 0.5992 - val_loss: 0.9559 - val_categorical_accuracy: 0.5825\n",
            "Epoch 123/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.8850 - categorical_accuracy: 0.6242 - val_loss: 0.9653 - val_categorical_accuracy: 0.5522\n",
            "Epoch 124/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.8934 - categorical_accuracy: 0.6108 - val_loss: 0.9959 - val_categorical_accuracy: 0.5313\n",
            "Epoch 125/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.8894 - categorical_accuracy: 0.6093 - val_loss: 0.9505 - val_categorical_accuracy: 0.5787\n",
            "Epoch 126/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.8959 - categorical_accuracy: 0.6169 - val_loss: 0.9597 - val_categorical_accuracy: 0.5636\n",
            "Epoch 127/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.9192 - categorical_accuracy: 0.5970 - val_loss: 0.9509 - val_categorical_accuracy: 0.5806\n",
            "Epoch 128/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.9030 - categorical_accuracy: 0.6110 - val_loss: 0.9956 - val_categorical_accuracy: 0.5313\n",
            "Epoch 129/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.9079 - categorical_accuracy: 0.6018 - val_loss: 0.9821 - val_categorical_accuracy: 0.5218\n",
            "Epoch 130/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.9000 - categorical_accuracy: 0.6136 - val_loss: 0.9257 - val_categorical_accuracy: 0.6110\n",
            "Epoch 131/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.9097 - categorical_accuracy: 0.6008 - val_loss: 0.9712 - val_categorical_accuracy: 0.5541\n",
            "Epoch 132/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.9114 - categorical_accuracy: 0.5904 - val_loss: 0.9566 - val_categorical_accuracy: 0.5541\n",
            "Epoch 133/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.8741 - categorical_accuracy: 0.6182 - val_loss: 0.9546 - val_categorical_accuracy: 0.5636\n",
            "Epoch 134/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.8916 - categorical_accuracy: 0.6044 - val_loss: 0.9408 - val_categorical_accuracy: 0.5787\n",
            "Epoch 135/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.8760 - categorical_accuracy: 0.6276 - val_loss: 0.9841 - val_categorical_accuracy: 0.5161\n",
            "Epoch 136/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.8974 - categorical_accuracy: 0.6139 - val_loss: 0.9730 - val_categorical_accuracy: 0.5484\n",
            "Epoch 137/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.8791 - categorical_accuracy: 0.6138 - val_loss: 0.9355 - val_categorical_accuracy: 0.5977\n",
            "Epoch 138/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.8808 - categorical_accuracy: 0.6198 - val_loss: 0.9458 - val_categorical_accuracy: 0.5750\n",
            "Epoch 139/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.8799 - categorical_accuracy: 0.6137 - val_loss: 0.9875 - val_categorical_accuracy: 0.5028\n",
            "Epoch 140/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.8751 - categorical_accuracy: 0.6191 - val_loss: 0.9752 - val_categorical_accuracy: 0.5332\n",
            "Epoch 141/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.8804 - categorical_accuracy: 0.6136 - val_loss: 0.9251 - val_categorical_accuracy: 0.5996\n",
            "Epoch 142/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.9061 - categorical_accuracy: 0.6123 - val_loss: 0.9417 - val_categorical_accuracy: 0.5901\n",
            "Epoch 143/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.8785 - categorical_accuracy: 0.6126 - val_loss: 0.9246 - val_categorical_accuracy: 0.5977\n",
            "Epoch 144/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.8794 - categorical_accuracy: 0.6197 - val_loss: 0.9612 - val_categorical_accuracy: 0.5617\n",
            "Epoch 145/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.8957 - categorical_accuracy: 0.6067 - val_loss: 0.9515 - val_categorical_accuracy: 0.5674\n",
            "Epoch 146/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.8699 - categorical_accuracy: 0.6275 - val_loss: 0.9296 - val_categorical_accuracy: 0.6053\n",
            "Epoch 147/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.8772 - categorical_accuracy: 0.6193 - val_loss: 0.9785 - val_categorical_accuracy: 0.5313\n",
            "Epoch 148/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.8873 - categorical_accuracy: 0.6205 - val_loss: 0.9339 - val_categorical_accuracy: 0.5977\n",
            "Epoch 149/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.9088 - categorical_accuracy: 0.5995 - val_loss: 0.9491 - val_categorical_accuracy: 0.5674\n",
            "Epoch 150/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.8678 - categorical_accuracy: 0.6265 - val_loss: 0.9385 - val_categorical_accuracy: 0.5769\n",
            "Epoch 151/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.8945 - categorical_accuracy: 0.6049 - val_loss: 0.9772 - val_categorical_accuracy: 0.5161\n",
            "Epoch 152/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.8579 - categorical_accuracy: 0.6441 - val_loss: 0.9849 - val_categorical_accuracy: 0.5332\n",
            "Epoch 153/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.8800 - categorical_accuracy: 0.6267 - val_loss: 0.9646 - val_categorical_accuracy: 0.5465\n",
            "Epoch 154/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.8685 - categorical_accuracy: 0.6251 - val_loss: 0.9291 - val_categorical_accuracy: 0.6110\n",
            "Epoch 155/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.8765 - categorical_accuracy: 0.6225 - val_loss: 0.9453 - val_categorical_accuracy: 0.5787\n",
            "Epoch 156/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.8850 - categorical_accuracy: 0.6191 - val_loss: 0.9431 - val_categorical_accuracy: 0.5787\n",
            "Epoch 157/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.8866 - categorical_accuracy: 0.6215 - val_loss: 1.0122 - val_categorical_accuracy: 0.4839\n",
            "Epoch 158/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.8688 - categorical_accuracy: 0.6315 - val_loss: 0.9166 - val_categorical_accuracy: 0.6129\n",
            "Epoch 159/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.8786 - categorical_accuracy: 0.6239 - val_loss: 0.9574 - val_categorical_accuracy: 0.5882\n",
            "Epoch 160/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.8769 - categorical_accuracy: 0.6239 - val_loss: 0.9693 - val_categorical_accuracy: 0.5446\n",
            "Epoch 161/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.8926 - categorical_accuracy: 0.6227 - val_loss: 0.9388 - val_categorical_accuracy: 0.5958\n",
            "Epoch 162/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.8630 - categorical_accuracy: 0.6236 - val_loss: 0.9596 - val_categorical_accuracy: 0.5712\n",
            "Epoch 163/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.8527 - categorical_accuracy: 0.6379 - val_loss: 0.9363 - val_categorical_accuracy: 0.5787\n",
            "Epoch 164/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.8809 - categorical_accuracy: 0.6203 - val_loss: 0.9546 - val_categorical_accuracy: 0.5484\n",
            "Epoch 165/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.8548 - categorical_accuracy: 0.6282 - val_loss: 0.9528 - val_categorical_accuracy: 0.5693\n",
            "Epoch 166/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.8836 - categorical_accuracy: 0.6205 - val_loss: 0.9225 - val_categorical_accuracy: 0.5920\n",
            "Epoch 167/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.8926 - categorical_accuracy: 0.6190 - val_loss: 0.9216 - val_categorical_accuracy: 0.5996\n",
            "Epoch 168/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.8640 - categorical_accuracy: 0.6215 - val_loss: 0.9610 - val_categorical_accuracy: 0.5427\n",
            "Epoch 169/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.8465 - categorical_accuracy: 0.6331 - val_loss: 0.9131 - val_categorical_accuracy: 0.5996\n",
            "Epoch 170/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.8501 - categorical_accuracy: 0.6322 - val_loss: 0.9749 - val_categorical_accuracy: 0.5389\n",
            "Epoch 171/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.8614 - categorical_accuracy: 0.6416 - val_loss: 0.9543 - val_categorical_accuracy: 0.5579\n",
            "Epoch 172/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.8544 - categorical_accuracy: 0.6258 - val_loss: 0.9433 - val_categorical_accuracy: 0.5693\n",
            "Epoch 173/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.8585 - categorical_accuracy: 0.6258 - val_loss: 0.9462 - val_categorical_accuracy: 0.5579\n",
            "Epoch 174/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.8592 - categorical_accuracy: 0.6270 - val_loss: 0.9694 - val_categorical_accuracy: 0.5332\n",
            "Epoch 175/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.8548 - categorical_accuracy: 0.6338 - val_loss: 0.9338 - val_categorical_accuracy: 0.5863\n",
            "Epoch 176/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.8781 - categorical_accuracy: 0.6159 - val_loss: 0.9343 - val_categorical_accuracy: 0.5825\n",
            "Epoch 177/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.8399 - categorical_accuracy: 0.6367 - val_loss: 0.9393 - val_categorical_accuracy: 0.5750\n",
            "Epoch 178/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.8869 - categorical_accuracy: 0.6149 - val_loss: 0.9862 - val_categorical_accuracy: 0.5313\n",
            "Epoch 179/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.8528 - categorical_accuracy: 0.6355 - val_loss: 0.9734 - val_categorical_accuracy: 0.5332\n",
            "Epoch 180/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.8408 - categorical_accuracy: 0.6478 - val_loss: 0.9224 - val_categorical_accuracy: 0.5863\n",
            "Epoch 181/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.8679 - categorical_accuracy: 0.6250 - val_loss: 0.9638 - val_categorical_accuracy: 0.5408\n",
            "Epoch 182/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.8486 - categorical_accuracy: 0.6275 - val_loss: 0.9337 - val_categorical_accuracy: 0.5825\n",
            "Epoch 183/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.8812 - categorical_accuracy: 0.6239 - val_loss: 0.9196 - val_categorical_accuracy: 0.6091\n",
            "Epoch 184/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.8531 - categorical_accuracy: 0.6345 - val_loss: 0.9089 - val_categorical_accuracy: 0.6091\n",
            "Epoch 185/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.8881 - categorical_accuracy: 0.6152 - val_loss: 0.9096 - val_categorical_accuracy: 0.6034\n",
            "Epoch 186/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.8572 - categorical_accuracy: 0.6306 - val_loss: 0.9351 - val_categorical_accuracy: 0.5787\n",
            "Epoch 187/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.8579 - categorical_accuracy: 0.6365 - val_loss: 0.9556 - val_categorical_accuracy: 0.5370\n",
            "Epoch 188/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.8687 - categorical_accuracy: 0.6212 - val_loss: 0.9044 - val_categorical_accuracy: 0.6072\n",
            "Epoch 189/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.8653 - categorical_accuracy: 0.6261 - val_loss: 0.9319 - val_categorical_accuracy: 0.5693\n",
            "Epoch 190/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.8625 - categorical_accuracy: 0.6257 - val_loss: 0.9137 - val_categorical_accuracy: 0.6072\n",
            "Epoch 191/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.8466 - categorical_accuracy: 0.6348 - val_loss: 0.9260 - val_categorical_accuracy: 0.6034\n",
            "Epoch 192/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.8630 - categorical_accuracy: 0.6337 - val_loss: 0.9453 - val_categorical_accuracy: 0.5806\n",
            "Epoch 193/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.8759 - categorical_accuracy: 0.6131 - val_loss: 0.9283 - val_categorical_accuracy: 0.5787\n",
            "Epoch 194/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.8543 - categorical_accuracy: 0.6387 - val_loss: 0.9389 - val_categorical_accuracy: 0.5674\n",
            "Epoch 195/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.8429 - categorical_accuracy: 0.6415 - val_loss: 0.9254 - val_categorical_accuracy: 0.5825\n",
            "Epoch 196/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.8608 - categorical_accuracy: 0.6251 - val_loss: 0.9451 - val_categorical_accuracy: 0.5598\n",
            "Epoch 197/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.8291 - categorical_accuracy: 0.6512 - val_loss: 0.9006 - val_categorical_accuracy: 0.6148\n",
            "Epoch 198/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.8425 - categorical_accuracy: 0.6325 - val_loss: 0.9272 - val_categorical_accuracy: 0.5863\n",
            "Epoch 199/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.8484 - categorical_accuracy: 0.6379 - val_loss: 0.9221 - val_categorical_accuracy: 0.5787\n",
            "Epoch 200/200\n",
            "297/297 [==============================] - 2s 6ms/step - loss: 0.8380 - categorical_accuracy: 0.6411 - val_loss: 0.9263 - val_categorical_accuracy: 0.5844\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvbMzy-zs55B"
      },
      "source": [
        "model.save('/content/drive/MyDrive/Colab Notebooks/SPEECH_EMOTION_Recognition/Nộp bài(chốt hạ)/model_saver/conv2D_mfcc26_merged.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DrAqFd4bs55B"
      },
      "source": [
        "###test_result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UOyhNlK3s55C",
        "outputId": "5e6124d2-cfe1-4bd6-e789-a22027dac934"
      },
      "source": [
        "d = {0: 'happy',\n",
        "     1: 'sad',\n",
        "     2: 'angry',\n",
        "     3: 'fear'}\n",
        "Y_test_pred = np.argmax(model.predict(X_test), axis=-1)\n",
        "Y_test_pred = list(map(lambda x: d[x], Y_test_pred))\n",
        "y_test = np.argmax(y_test, axis=-1)\n",
        "y_test = list(map(lambda x: d[x], y_test))\n",
        "print(classification_report(y_test, Y_test_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.80      0.76      0.78       129\n",
            "        fear       0.52      0.75      0.62       174\n",
            "       happy       0.64      0.42      0.50       127\n",
            "         sad       0.72      0.60      0.65       156\n",
            "\n",
            "    accuracy                           0.64       586\n",
            "   macro avg       0.67      0.63      0.64       586\n",
            "weighted avg       0.66      0.64      0.64       586\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fK7IuMJcs55C",
        "outputId": "a29bb309-3599-434d-e4c2-ff94005110ba"
      },
      "source": [
        "import scikitplot as skplt\n",
        "\n",
        "skplt.metrics.plot_confusion_matrix(\n",
        "    y_test, \n",
        "    Y_test_pred,\n",
        "    figsize=(8,8))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f44dc676250>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z3_dhduYs55D"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1pr4LcUbtDhd"
      },
      "source": [
        "# mfcc_39 + conv2D:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4rxcn92OtDhf"
      },
      "source": [
        "audio_duration = 3\n",
        "sampling_rate = 22050\n",
        "input_length = sampling_rate * audio_duration"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jk2fJkjLtDhg"
      },
      "source": [
        "features = []\n",
        "labels = []\n",
        "for i in range(len(Ravdess_DF['Paths'])):\n",
        "  if ((Ravdess_DF['Emotion'][i] == '03') | (Ravdess_DF['Emotion'][i] == '04') | \n",
        "      (Ravdess_DF['Emotion'][i] == '05') | (Ravdess_DF['Emotion'][i] == '06')):\n",
        "    signal, sr = librosa.load(Ravdess_DF['Paths'][i])\n",
        "\n",
        "    if len(signal) > input_length:\n",
        "      signal = signal[0:input_length]\n",
        "    elif  input_length > len(signal):\n",
        "      max_offset = input_length - len(signal)  \n",
        "      signal = np.pad(signal, (0, max_offset), \"constant\")\n",
        "\n",
        "    mfcc = librosa.feature.mfcc(y=signal, sr=sr, n_mfcc=39).T\n",
        "    mfcc = np.expand_dims(mfcc, axis=-1)\n",
        "    features.append(mfcc)\n",
        "\n",
        "    if Ravdess_DF['Emotion'][i] == '03':\n",
        "      labels.append(0)\n",
        "    elif Ravdess_DF['Emotion'][i] == '04':\n",
        "      labels.append(1)\n",
        "    elif Ravdess_DF['Emotion'][i] == '05':\n",
        "      labels.append(2)\n",
        "    elif Ravdess_DF['Emotion'][i] == '06':\n",
        "      labels.append(3)\n",
        "\n",
        "\n",
        "for i in range(len(CREMA_D_df)):\n",
        "  if ((CREMA_D_df['Emotion'][i] == 'HAP') | (CREMA_D_df['Emotion'][i] == 'SAD') | \n",
        "      (CREMA_D_df['Emotion'][i] == 'ANG') | (CREMA_D_df['Emotion'][i] == 'FEA')):\n",
        "    \n",
        "    if CREMA_D_df['Emotion'][i] == 'HAP':\n",
        "      labels.append(0)\n",
        "    elif CREMA_D_df['Emotion'][i] == 'SAD':\n",
        "      labels.append(1)\n",
        "    elif CREMA_D_df['Emotion'][i] == 'ANG':\n",
        "      labels.append(2)\n",
        "    elif CREMA_D_df['Emotion'][i] == 'FEA':\n",
        "      labels.append(3)\n",
        "\n",
        "\n",
        "    signal, sr =  librosa.load(CREMA_D_df['Paths'][i])\n",
        "\n",
        "    if len(signal) > input_length:\n",
        "        signal = signal[0:input_length]\n",
        "    elif  input_length > len(signal):\n",
        "        max_offset = input_length - len(signal)  \n",
        "        signal = np.pad(signal, (0, max_offset), \"constant\")\n",
        "\n",
        "    mfcc = librosa.feature.mfcc(y=signal, sr=sr, n_mfcc=39).T\n",
        "    mfcc = np.expand_dims(mfcc, axis=-1)\n",
        "    features.append(mfcc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8TGX2O51tDhh"
      },
      "source": [
        "X = features\n",
        "y = labels\n",
        "\n",
        "y = np.array(y)\n",
        "y = to_categorical(y)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=0)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=0)\n",
        "\n",
        "X_train = np.array(X_train)\n",
        "X_test = np.array(X_test)\n",
        "X_val = np.array(X_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uo9FMh7BtDhi",
        "outputId": "105258de-7a79-4427-e132-3e8d0c2f9bb8"
      },
      "source": [
        "X_train.shape,X_test.shape,y_train.shape,y_test.shape\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((4739, 130, 39, 1), (586, 130, 39, 1), (4739, 4), (586, 4))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1F-a3GatDhj"
      },
      "source": [
        "# CNN I/P Config\n",
        "num_classes = 4\n",
        "input_shape = X_train.shape[1:]\n",
        "learning_rate = 0.0001\n",
        "decay = 1e-6\n",
        "momentum = 0.9"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D1d2jv7MtDhk",
        "outputId": "9c9163eb-9dcf-4d49-d469-26405cc8d282"
      },
      "source": [
        "model = Sequential(name='Audio_CNN_2D')\n",
        "\n",
        "# LFLB1\n",
        "model.add(Conv2D(filters=64, kernel_size=(3,3), strides=(1,1), padding='same',input_shape=input_shape))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Conv2D(filters=64, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(4,4), strides=(4,4)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(units=num_classes, activation='softmax'))\n",
        "\n",
        "# Model compilation\n",
        "opt = optimizers.SGD(lr=learning_rate, decay=decay, momentum=momentum, nesterov=True)\n",
        "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"Audio_CNN_2D\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_4 (Conv2D)            (None, 130, 39, 64)       640       \n",
            "_________________________________________________________________\n",
            "batch_normalization_12 (Batc (None, 130, 39, 64)       256       \n",
            "_________________________________________________________________\n",
            "activation_12 (Activation)   (None, 130, 39, 64)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 65, 19, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_12 (Dropout)         (None, 65, 19, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 65, 19, 64)        36928     \n",
            "_________________________________________________________________\n",
            "batch_normalization_13 (Batc (None, 65, 19, 64)        256       \n",
            "_________________________________________________________________\n",
            "activation_13 (Activation)   (None, 65, 19, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 16, 4, 64)         0         \n",
            "_________________________________________________________________\n",
            "dropout_13 (Dropout)         (None, 16, 4, 64)         0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 4)                 16388     \n",
            "=================================================================\n",
            "Total params: 54,468\n",
            "Trainable params: 54,212\n",
            "Non-trainable params: 256\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aP_H0tuItDhm",
        "outputId": "911d0117-0c32-46b1-df8e-63e6bc4f2312"
      },
      "source": [
        "#Train Config\n",
        "\n",
        "batch_size = 16\n",
        "num_epochs = 200\n",
        "\n",
        "# Model Training\n",
        "lr_reduce = ReduceLROnPlateau(monitor='val_loss', factor=0.9, patience=20, min_lr=0.000001)\n",
        "# Please change the model name accordingly.\n",
        "mcp_save = ModelCheckpoint('/content/Modelfull_2_1.h5', save_best_only=True, monitor='val_categorical_accuracy', mode='max')\n",
        "cnnhistory=model.fit(X_train, y_train, batch_size=batch_size, epochs=num_epochs,validation_data=(X_val, y_val), callbacks=[mcp_save, lr_reduce])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "297/297 [==============================] - 4s 10ms/step - loss: 2.2805 - categorical_accuracy: 0.2980 - val_loss: 1.2041 - val_categorical_accuracy: 0.4023\n",
            "Epoch 2/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 1.5291 - categorical_accuracy: 0.3956 - val_loss: 1.1879 - val_categorical_accuracy: 0.4744\n",
            "Epoch 3/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 1.3010 - categorical_accuracy: 0.4484 - val_loss: 1.1519 - val_categorical_accuracy: 0.4801\n",
            "Epoch 4/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 1.2570 - categorical_accuracy: 0.4411 - val_loss: 1.1424 - val_categorical_accuracy: 0.5028\n",
            "Epoch 5/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 1.1922 - categorical_accuracy: 0.4747 - val_loss: 1.1277 - val_categorical_accuracy: 0.5009\n",
            "Epoch 6/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 1.1923 - categorical_accuracy: 0.4718 - val_loss: 1.1780 - val_categorical_accuracy: 0.3928\n",
            "Epoch 7/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 1.1824 - categorical_accuracy: 0.4737 - val_loss: 1.1969 - val_categorical_accuracy: 0.3738\n",
            "Epoch 8/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 1.1522 - categorical_accuracy: 0.4890 - val_loss: 1.1716 - val_categorical_accuracy: 0.4194\n",
            "Epoch 9/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 1.1424 - categorical_accuracy: 0.4939 - val_loss: 1.1303 - val_categorical_accuracy: 0.4326\n",
            "Epoch 10/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 1.1406 - categorical_accuracy: 0.4873 - val_loss: 1.1362 - val_categorical_accuracy: 0.4763\n",
            "Epoch 11/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 1.1224 - categorical_accuracy: 0.4941 - val_loss: 1.1638 - val_categorical_accuracy: 0.3852\n",
            "Epoch 12/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 1.1034 - categorical_accuracy: 0.5023 - val_loss: 1.1337 - val_categorical_accuracy: 0.4250\n",
            "Epoch 13/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 1.1048 - categorical_accuracy: 0.5121 - val_loss: 1.0823 - val_categorical_accuracy: 0.5313\n",
            "Epoch 14/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 1.1324 - categorical_accuracy: 0.4939 - val_loss: 1.1375 - val_categorical_accuracy: 0.4137\n",
            "Epoch 15/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 1.0963 - categorical_accuracy: 0.5103 - val_loss: 1.1472 - val_categorical_accuracy: 0.4023\n",
            "Epoch 16/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 1.0845 - categorical_accuracy: 0.5096 - val_loss: 1.2452 - val_categorical_accuracy: 0.3529\n",
            "Epoch 17/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 1.0703 - categorical_accuracy: 0.5101 - val_loss: 1.2195 - val_categorical_accuracy: 0.3567\n",
            "Epoch 18/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 1.0776 - categorical_accuracy: 0.5100 - val_loss: 1.1232 - val_categorical_accuracy: 0.4004\n",
            "Epoch 19/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 1.0859 - categorical_accuracy: 0.5199 - val_loss: 1.0741 - val_categorical_accuracy: 0.5047\n",
            "Epoch 20/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 1.0707 - categorical_accuracy: 0.5305 - val_loss: 1.1304 - val_categorical_accuracy: 0.4175\n",
            "Epoch 21/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 1.0785 - categorical_accuracy: 0.5204 - val_loss: 1.0848 - val_categorical_accuracy: 0.4592\n",
            "Epoch 22/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 1.0428 - categorical_accuracy: 0.5350 - val_loss: 1.1693 - val_categorical_accuracy: 0.3852\n",
            "Epoch 23/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 1.0595 - categorical_accuracy: 0.5217 - val_loss: 1.0762 - val_categorical_accuracy: 0.4573\n",
            "Epoch 24/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 1.0578 - categorical_accuracy: 0.5249 - val_loss: 1.2187 - val_categorical_accuracy: 0.3605\n",
            "Epoch 25/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 1.0662 - categorical_accuracy: 0.5218 - val_loss: 1.1291 - val_categorical_accuracy: 0.4004\n",
            "Epoch 26/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 1.0463 - categorical_accuracy: 0.5369 - val_loss: 1.0767 - val_categorical_accuracy: 0.4611\n",
            "Epoch 27/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 1.0485 - categorical_accuracy: 0.5279 - val_loss: 1.0949 - val_categorical_accuracy: 0.4250\n",
            "Epoch 28/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 1.0276 - categorical_accuracy: 0.5576 - val_loss: 1.1076 - val_categorical_accuracy: 0.4250\n",
            "Epoch 29/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 1.0416 - categorical_accuracy: 0.5346 - val_loss: 1.0305 - val_categorical_accuracy: 0.5237\n",
            "Epoch 30/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 1.0198 - categorical_accuracy: 0.5503 - val_loss: 1.0894 - val_categorical_accuracy: 0.4630\n",
            "Epoch 31/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 1.0257 - categorical_accuracy: 0.5453 - val_loss: 1.1527 - val_categorical_accuracy: 0.3928\n",
            "Epoch 32/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 1.0319 - categorical_accuracy: 0.5455 - val_loss: 1.1278 - val_categorical_accuracy: 0.4307\n",
            "Epoch 33/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 1.0106 - categorical_accuracy: 0.5483 - val_loss: 1.1229 - val_categorical_accuracy: 0.4231\n",
            "Epoch 34/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 1.0340 - categorical_accuracy: 0.5447 - val_loss: 1.0438 - val_categorical_accuracy: 0.4782\n",
            "Epoch 35/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 1.0255 - categorical_accuracy: 0.5620 - val_loss: 1.0576 - val_categorical_accuracy: 0.4535\n",
            "Epoch 36/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.9984 - categorical_accuracy: 0.5496 - val_loss: 1.0948 - val_categorical_accuracy: 0.4630\n",
            "Epoch 37/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 1.0156 - categorical_accuracy: 0.5433 - val_loss: 1.1068 - val_categorical_accuracy: 0.4497\n",
            "Epoch 38/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.9929 - categorical_accuracy: 0.5631 - val_loss: 1.0708 - val_categorical_accuracy: 0.4478\n",
            "Epoch 39/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 1.0047 - categorical_accuracy: 0.5526 - val_loss: 1.1702 - val_categorical_accuracy: 0.3985\n",
            "Epoch 40/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.9895 - categorical_accuracy: 0.5544 - val_loss: 1.0518 - val_categorical_accuracy: 0.5047\n",
            "Epoch 41/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.9850 - categorical_accuracy: 0.5637 - val_loss: 1.1324 - val_categorical_accuracy: 0.4611\n",
            "Epoch 42/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 1.0078 - categorical_accuracy: 0.5625 - val_loss: 1.0167 - val_categorical_accuracy: 0.5085\n",
            "Epoch 43/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.9624 - categorical_accuracy: 0.5797 - val_loss: 1.0819 - val_categorical_accuracy: 0.4345\n",
            "Epoch 44/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.9839 - categorical_accuracy: 0.5619 - val_loss: 1.1097 - val_categorical_accuracy: 0.4175\n",
            "Epoch 45/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.9881 - categorical_accuracy: 0.5674 - val_loss: 1.0716 - val_categorical_accuracy: 0.4801\n",
            "Epoch 46/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.9931 - categorical_accuracy: 0.5648 - val_loss: 1.0884 - val_categorical_accuracy: 0.4288\n",
            "Epoch 47/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.9731 - categorical_accuracy: 0.5669 - val_loss: 1.0805 - val_categorical_accuracy: 0.4953\n",
            "Epoch 48/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.9947 - categorical_accuracy: 0.5556 - val_loss: 1.0555 - val_categorical_accuracy: 0.4649\n",
            "Epoch 49/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.9783 - categorical_accuracy: 0.5737 - val_loss: 1.0410 - val_categorical_accuracy: 0.5028\n",
            "Epoch 50/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.9618 - categorical_accuracy: 0.5757 - val_loss: 1.0423 - val_categorical_accuracy: 0.4858\n",
            "Epoch 51/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.9679 - categorical_accuracy: 0.5777 - val_loss: 1.0328 - val_categorical_accuracy: 0.4991\n",
            "Epoch 52/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.9675 - categorical_accuracy: 0.5811 - val_loss: 1.0617 - val_categorical_accuracy: 0.4668\n",
            "Epoch 53/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.9512 - categorical_accuracy: 0.5815 - val_loss: 1.0296 - val_categorical_accuracy: 0.4706\n",
            "Epoch 54/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.9890 - categorical_accuracy: 0.5605 - val_loss: 1.0325 - val_categorical_accuracy: 0.4649\n",
            "Epoch 55/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.9650 - categorical_accuracy: 0.5685 - val_loss: 1.0276 - val_categorical_accuracy: 0.4763\n",
            "Epoch 56/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.9548 - categorical_accuracy: 0.5788 - val_loss: 1.1060 - val_categorical_accuracy: 0.4402\n",
            "Epoch 57/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.9718 - categorical_accuracy: 0.5819 - val_loss: 1.0034 - val_categorical_accuracy: 0.5294\n",
            "Epoch 58/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.9532 - categorical_accuracy: 0.5858 - val_loss: 1.0652 - val_categorical_accuracy: 0.4402\n",
            "Epoch 59/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.9505 - categorical_accuracy: 0.5820 - val_loss: 1.0346 - val_categorical_accuracy: 0.4668\n",
            "Epoch 60/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.9593 - categorical_accuracy: 0.5761 - val_loss: 1.0334 - val_categorical_accuracy: 0.4649\n",
            "Epoch 61/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.9457 - categorical_accuracy: 0.5893 - val_loss: 1.0705 - val_categorical_accuracy: 0.4383\n",
            "Epoch 62/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.9643 - categorical_accuracy: 0.5733 - val_loss: 0.9895 - val_categorical_accuracy: 0.5275\n",
            "Epoch 63/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.9509 - categorical_accuracy: 0.5822 - val_loss: 1.0263 - val_categorical_accuracy: 0.4763\n",
            "Epoch 64/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.9733 - categorical_accuracy: 0.5884 - val_loss: 1.0585 - val_categorical_accuracy: 0.4896\n",
            "Epoch 65/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.9435 - categorical_accuracy: 0.5940 - val_loss: 1.0145 - val_categorical_accuracy: 0.4820\n",
            "Epoch 66/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.9496 - categorical_accuracy: 0.5846 - val_loss: 1.0471 - val_categorical_accuracy: 0.4478\n",
            "Epoch 67/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.9560 - categorical_accuracy: 0.5847 - val_loss: 1.0304 - val_categorical_accuracy: 0.4687\n",
            "Epoch 68/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.9452 - categorical_accuracy: 0.5822 - val_loss: 1.0159 - val_categorical_accuracy: 0.4668\n",
            "Epoch 69/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.9509 - categorical_accuracy: 0.5863 - val_loss: 1.0145 - val_categorical_accuracy: 0.4953\n",
            "Epoch 70/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.9428 - categorical_accuracy: 0.5775 - val_loss: 1.0235 - val_categorical_accuracy: 0.4820\n",
            "Epoch 71/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.9632 - categorical_accuracy: 0.5792 - val_loss: 0.9913 - val_categorical_accuracy: 0.5693\n",
            "Epoch 72/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.9338 - categorical_accuracy: 0.5833 - val_loss: 1.0240 - val_categorical_accuracy: 0.4839\n",
            "Epoch 73/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.9370 - categorical_accuracy: 0.5977 - val_loss: 1.0098 - val_categorical_accuracy: 0.4953\n",
            "Epoch 74/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.9397 - categorical_accuracy: 0.5866 - val_loss: 0.9708 - val_categorical_accuracy: 0.5769\n",
            "Epoch 75/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.9263 - categorical_accuracy: 0.6102 - val_loss: 1.0249 - val_categorical_accuracy: 0.5161\n",
            "Epoch 76/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.9370 - categorical_accuracy: 0.5964 - val_loss: 0.9844 - val_categorical_accuracy: 0.5484\n",
            "Epoch 77/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.9424 - categorical_accuracy: 0.5825 - val_loss: 1.0239 - val_categorical_accuracy: 0.4820\n",
            "Epoch 78/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.9405 - categorical_accuracy: 0.5845 - val_loss: 1.0171 - val_categorical_accuracy: 0.5085\n",
            "Epoch 79/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.9497 - categorical_accuracy: 0.5768 - val_loss: 0.9989 - val_categorical_accuracy: 0.5465\n",
            "Epoch 80/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.9178 - categorical_accuracy: 0.5908 - val_loss: 1.0357 - val_categorical_accuracy: 0.4744\n",
            "Epoch 81/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.9435 - categorical_accuracy: 0.5864 - val_loss: 1.0493 - val_categorical_accuracy: 0.4972\n",
            "Epoch 82/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.9316 - categorical_accuracy: 0.5966 - val_loss: 1.0427 - val_categorical_accuracy: 0.4934\n",
            "Epoch 83/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.9264 - categorical_accuracy: 0.5893 - val_loss: 0.9805 - val_categorical_accuracy: 0.5560\n",
            "Epoch 84/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.9456 - categorical_accuracy: 0.5910 - val_loss: 0.9599 - val_categorical_accuracy: 0.6072\n",
            "Epoch 85/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.9134 - categorical_accuracy: 0.6107 - val_loss: 1.0964 - val_categorical_accuracy: 0.4118\n",
            "Epoch 86/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.9130 - categorical_accuracy: 0.6044 - val_loss: 0.9999 - val_categorical_accuracy: 0.5313\n",
            "Epoch 87/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.9160 - categorical_accuracy: 0.6026 - val_loss: 0.9600 - val_categorical_accuracy: 0.5920\n",
            "Epoch 88/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.9251 - categorical_accuracy: 0.5964 - val_loss: 1.0126 - val_categorical_accuracy: 0.4915\n",
            "Epoch 89/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.9193 - categorical_accuracy: 0.6052 - val_loss: 1.0017 - val_categorical_accuracy: 0.5047\n",
            "Epoch 90/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.9353 - categorical_accuracy: 0.5851 - val_loss: 0.9933 - val_categorical_accuracy: 0.5123\n",
            "Epoch 91/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.9143 - categorical_accuracy: 0.6070 - val_loss: 0.9672 - val_categorical_accuracy: 0.5825\n",
            "Epoch 92/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.9117 - categorical_accuracy: 0.6118 - val_loss: 0.9963 - val_categorical_accuracy: 0.5237\n",
            "Epoch 93/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.9084 - categorical_accuracy: 0.6130 - val_loss: 1.0249 - val_categorical_accuracy: 0.4611\n",
            "Epoch 94/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.9240 - categorical_accuracy: 0.5893 - val_loss: 0.9909 - val_categorical_accuracy: 0.5199\n",
            "Epoch 95/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.9164 - categorical_accuracy: 0.6023 - val_loss: 1.0172 - val_categorical_accuracy: 0.4801\n",
            "Epoch 96/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.9129 - categorical_accuracy: 0.5913 - val_loss: 1.0081 - val_categorical_accuracy: 0.4877\n",
            "Epoch 97/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.9176 - categorical_accuracy: 0.6084 - val_loss: 0.9889 - val_categorical_accuracy: 0.5427\n",
            "Epoch 98/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.9090 - categorical_accuracy: 0.5966 - val_loss: 0.9841 - val_categorical_accuracy: 0.5560\n",
            "Epoch 99/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.9070 - categorical_accuracy: 0.6148 - val_loss: 0.9912 - val_categorical_accuracy: 0.5655\n",
            "Epoch 100/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.8944 - categorical_accuracy: 0.6154 - val_loss: 0.9573 - val_categorical_accuracy: 0.5598\n",
            "Epoch 101/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.8907 - categorical_accuracy: 0.6071 - val_loss: 0.9660 - val_categorical_accuracy: 0.5541\n",
            "Epoch 102/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.9183 - categorical_accuracy: 0.6009 - val_loss: 1.0283 - val_categorical_accuracy: 0.4668\n",
            "Epoch 103/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.9062 - categorical_accuracy: 0.6153 - val_loss: 0.9928 - val_categorical_accuracy: 0.5104\n",
            "Epoch 104/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.8990 - categorical_accuracy: 0.6178 - val_loss: 0.9607 - val_categorical_accuracy: 0.5787\n",
            "Epoch 105/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.9040 - categorical_accuracy: 0.6063 - val_loss: 0.9531 - val_categorical_accuracy: 0.5674\n",
            "Epoch 106/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.9016 - categorical_accuracy: 0.6224 - val_loss: 0.9592 - val_categorical_accuracy: 0.5579\n",
            "Epoch 107/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.9163 - categorical_accuracy: 0.6115 - val_loss: 1.0459 - val_categorical_accuracy: 0.4668\n",
            "Epoch 108/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.8839 - categorical_accuracy: 0.6081 - val_loss: 0.9705 - val_categorical_accuracy: 0.5370\n",
            "Epoch 109/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.8762 - categorical_accuracy: 0.6105 - val_loss: 1.0023 - val_categorical_accuracy: 0.4877\n",
            "Epoch 110/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.9024 - categorical_accuracy: 0.6095 - val_loss: 0.9938 - val_categorical_accuracy: 0.5028\n",
            "Epoch 111/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.8686 - categorical_accuracy: 0.6257 - val_loss: 0.9645 - val_categorical_accuracy: 0.5598\n",
            "Epoch 112/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.8990 - categorical_accuracy: 0.6106 - val_loss: 0.9958 - val_categorical_accuracy: 0.5104\n",
            "Epoch 113/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.8999 - categorical_accuracy: 0.6130 - val_loss: 0.9976 - val_categorical_accuracy: 0.4915\n",
            "Epoch 114/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.8878 - categorical_accuracy: 0.6188 - val_loss: 0.9588 - val_categorical_accuracy: 0.5769\n",
            "Epoch 115/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.8757 - categorical_accuracy: 0.6172 - val_loss: 0.9901 - val_categorical_accuracy: 0.5522\n",
            "Epoch 116/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.9121 - categorical_accuracy: 0.6099 - val_loss: 1.0298 - val_categorical_accuracy: 0.4839\n",
            "Epoch 117/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.8695 - categorical_accuracy: 0.6241 - val_loss: 0.9682 - val_categorical_accuracy: 0.5636\n",
            "Epoch 118/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.8921 - categorical_accuracy: 0.6044 - val_loss: 0.9504 - val_categorical_accuracy: 0.5787\n",
            "Epoch 119/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.8764 - categorical_accuracy: 0.6254 - val_loss: 0.9545 - val_categorical_accuracy: 0.5731\n",
            "Epoch 120/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.8651 - categorical_accuracy: 0.6356 - val_loss: 0.9581 - val_categorical_accuracy: 0.5825\n",
            "Epoch 121/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.8767 - categorical_accuracy: 0.6306 - val_loss: 0.9790 - val_categorical_accuracy: 0.5427\n",
            "Epoch 122/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.8788 - categorical_accuracy: 0.6259 - val_loss: 1.0940 - val_categorical_accuracy: 0.4782\n",
            "Epoch 123/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.8922 - categorical_accuracy: 0.6142 - val_loss: 0.9562 - val_categorical_accuracy: 0.5560\n",
            "Epoch 124/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.8828 - categorical_accuracy: 0.6112 - val_loss: 0.9937 - val_categorical_accuracy: 0.4934\n",
            "Epoch 125/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.8730 - categorical_accuracy: 0.6334 - val_loss: 0.9722 - val_categorical_accuracy: 0.5389\n",
            "Epoch 126/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.8668 - categorical_accuracy: 0.6176 - val_loss: 0.9755 - val_categorical_accuracy: 0.5389\n",
            "Epoch 127/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.8565 - categorical_accuracy: 0.6312 - val_loss: 0.9766 - val_categorical_accuracy: 0.5825\n",
            "Epoch 128/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.8703 - categorical_accuracy: 0.6462 - val_loss: 0.9820 - val_categorical_accuracy: 0.5123\n",
            "Epoch 129/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.8692 - categorical_accuracy: 0.6257 - val_loss: 0.9433 - val_categorical_accuracy: 0.6129\n",
            "Epoch 130/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.8809 - categorical_accuracy: 0.6215 - val_loss: 0.9846 - val_categorical_accuracy: 0.5104\n",
            "Epoch 131/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.8728 - categorical_accuracy: 0.6156 - val_loss: 0.9824 - val_categorical_accuracy: 0.5332\n",
            "Epoch 132/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.8654 - categorical_accuracy: 0.6362 - val_loss: 1.0001 - val_categorical_accuracy: 0.5237\n",
            "Epoch 133/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.8712 - categorical_accuracy: 0.6328 - val_loss: 0.9549 - val_categorical_accuracy: 0.5541\n",
            "Epoch 134/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.8694 - categorical_accuracy: 0.6168 - val_loss: 0.9387 - val_categorical_accuracy: 0.6091\n",
            "Epoch 135/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.8689 - categorical_accuracy: 0.6232 - val_loss: 0.9724 - val_categorical_accuracy: 0.5408\n",
            "Epoch 136/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.8504 - categorical_accuracy: 0.6321 - val_loss: 0.9536 - val_categorical_accuracy: 0.5560\n",
            "Epoch 137/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.8722 - categorical_accuracy: 0.6350 - val_loss: 0.9369 - val_categorical_accuracy: 0.5674\n",
            "Epoch 138/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.8825 - categorical_accuracy: 0.6178 - val_loss: 0.9494 - val_categorical_accuracy: 0.5693\n",
            "Epoch 139/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.8650 - categorical_accuracy: 0.6179 - val_loss: 0.9478 - val_categorical_accuracy: 0.6072\n",
            "Epoch 140/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.8682 - categorical_accuracy: 0.6323 - val_loss: 0.9286 - val_categorical_accuracy: 0.5977\n",
            "Epoch 141/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.8479 - categorical_accuracy: 0.6417 - val_loss: 0.9997 - val_categorical_accuracy: 0.4839\n",
            "Epoch 142/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.8409 - categorical_accuracy: 0.6462 - val_loss: 0.9526 - val_categorical_accuracy: 0.5977\n",
            "Epoch 143/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.8533 - categorical_accuracy: 0.6337 - val_loss: 0.9298 - val_categorical_accuracy: 0.5901\n",
            "Epoch 144/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.8791 - categorical_accuracy: 0.6258 - val_loss: 0.9230 - val_categorical_accuracy: 0.5958\n",
            "Epoch 145/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.8588 - categorical_accuracy: 0.6407 - val_loss: 0.9498 - val_categorical_accuracy: 0.5882\n",
            "Epoch 146/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.8683 - categorical_accuracy: 0.6289 - val_loss: 0.9394 - val_categorical_accuracy: 0.5825\n",
            "Epoch 147/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.8672 - categorical_accuracy: 0.6271 - val_loss: 0.9868 - val_categorical_accuracy: 0.5066\n",
            "Epoch 148/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.8663 - categorical_accuracy: 0.6212 - val_loss: 0.9549 - val_categorical_accuracy: 0.5996\n",
            "Epoch 149/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.8638 - categorical_accuracy: 0.6357 - val_loss: 1.0031 - val_categorical_accuracy: 0.5332\n",
            "Epoch 150/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.8691 - categorical_accuracy: 0.6268 - val_loss: 0.9817 - val_categorical_accuracy: 0.5256\n",
            "Epoch 151/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.8490 - categorical_accuracy: 0.6357 - val_loss: 1.0105 - val_categorical_accuracy: 0.4953\n",
            "Epoch 152/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.8695 - categorical_accuracy: 0.6173 - val_loss: 0.9082 - val_categorical_accuracy: 0.6110\n",
            "Epoch 153/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.8675 - categorical_accuracy: 0.6269 - val_loss: 0.9387 - val_categorical_accuracy: 0.5844\n",
            "Epoch 154/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.8468 - categorical_accuracy: 0.6423 - val_loss: 0.9495 - val_categorical_accuracy: 0.5674\n",
            "Epoch 155/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.8392 - categorical_accuracy: 0.6410 - val_loss: 0.9547 - val_categorical_accuracy: 0.5712\n",
            "Epoch 156/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.8500 - categorical_accuracy: 0.6307 - val_loss: 0.9885 - val_categorical_accuracy: 0.5180\n",
            "Epoch 157/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.8443 - categorical_accuracy: 0.6437 - val_loss: 0.9578 - val_categorical_accuracy: 0.5541\n",
            "Epoch 158/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.8343 - categorical_accuracy: 0.6472 - val_loss: 0.9237 - val_categorical_accuracy: 0.6015\n",
            "Epoch 159/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.8270 - categorical_accuracy: 0.6379 - val_loss: 0.9589 - val_categorical_accuracy: 0.5636\n",
            "Epoch 160/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.8448 - categorical_accuracy: 0.6328 - val_loss: 0.9724 - val_categorical_accuracy: 0.5370\n",
            "Epoch 161/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.8409 - categorical_accuracy: 0.6425 - val_loss: 0.9400 - val_categorical_accuracy: 0.5769\n",
            "Epoch 162/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.8420 - categorical_accuracy: 0.6390 - val_loss: 0.9202 - val_categorical_accuracy: 0.6129\n",
            "Epoch 163/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.8408 - categorical_accuracy: 0.6537 - val_loss: 0.9134 - val_categorical_accuracy: 0.6148\n",
            "Epoch 164/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.8447 - categorical_accuracy: 0.6408 - val_loss: 0.9613 - val_categorical_accuracy: 0.5541\n",
            "Epoch 165/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.8436 - categorical_accuracy: 0.6327 - val_loss: 0.9433 - val_categorical_accuracy: 0.5731\n",
            "Epoch 166/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.8487 - categorical_accuracy: 0.6372 - val_loss: 0.9373 - val_categorical_accuracy: 0.5882\n",
            "Epoch 167/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.8460 - categorical_accuracy: 0.6361 - val_loss: 0.9292 - val_categorical_accuracy: 0.6129\n",
            "Epoch 168/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.8501 - categorical_accuracy: 0.6432 - val_loss: 0.9574 - val_categorical_accuracy: 0.5408\n",
            "Epoch 169/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.8165 - categorical_accuracy: 0.6478 - val_loss: 0.9598 - val_categorical_accuracy: 0.5332\n",
            "Epoch 170/200\n",
            "297/297 [==============================] - 2s 8ms/step - loss: 0.8600 - categorical_accuracy: 0.6214 - val_loss: 0.9035 - val_categorical_accuracy: 0.6205\n",
            "Epoch 171/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.8436 - categorical_accuracy: 0.6341 - val_loss: 0.9480 - val_categorical_accuracy: 0.5693\n",
            "Epoch 172/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.8353 - categorical_accuracy: 0.6499 - val_loss: 0.9253 - val_categorical_accuracy: 0.5977\n",
            "Epoch 173/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.8309 - categorical_accuracy: 0.6415 - val_loss: 0.9318 - val_categorical_accuracy: 0.5787\n",
            "Epoch 174/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.8512 - categorical_accuracy: 0.6356 - val_loss: 0.9264 - val_categorical_accuracy: 0.5977\n",
            "Epoch 175/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.8475 - categorical_accuracy: 0.6328 - val_loss: 0.9324 - val_categorical_accuracy: 0.6072\n",
            "Epoch 176/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.8179 - categorical_accuracy: 0.6521 - val_loss: 0.9802 - val_categorical_accuracy: 0.5256\n",
            "Epoch 177/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.8280 - categorical_accuracy: 0.6513 - val_loss: 0.9772 - val_categorical_accuracy: 0.5332\n",
            "Epoch 178/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.8277 - categorical_accuracy: 0.6523 - val_loss: 0.9259 - val_categorical_accuracy: 0.6091\n",
            "Epoch 179/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.8317 - categorical_accuracy: 0.6472 - val_loss: 0.9957 - val_categorical_accuracy: 0.5218\n",
            "Epoch 180/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.8468 - categorical_accuracy: 0.6429 - val_loss: 0.9285 - val_categorical_accuracy: 0.6053\n",
            "Epoch 181/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.8528 - categorical_accuracy: 0.6302 - val_loss: 0.9347 - val_categorical_accuracy: 0.5787\n",
            "Epoch 182/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.8131 - categorical_accuracy: 0.6454 - val_loss: 0.9255 - val_categorical_accuracy: 0.5958\n",
            "Epoch 183/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.8378 - categorical_accuracy: 0.6480 - val_loss: 0.9443 - val_categorical_accuracy: 0.5636\n",
            "Epoch 184/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.8007 - categorical_accuracy: 0.6589 - val_loss: 0.9449 - val_categorical_accuracy: 0.5693\n",
            "Epoch 185/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.8180 - categorical_accuracy: 0.6554 - val_loss: 0.9354 - val_categorical_accuracy: 0.5939\n",
            "Epoch 186/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.8279 - categorical_accuracy: 0.6454 - val_loss: 0.9312 - val_categorical_accuracy: 0.6053\n",
            "Epoch 187/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.8251 - categorical_accuracy: 0.6375 - val_loss: 0.9351 - val_categorical_accuracy: 0.5750\n",
            "Epoch 188/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.8038 - categorical_accuracy: 0.6687 - val_loss: 0.9286 - val_categorical_accuracy: 0.6129\n",
            "Epoch 189/200\n",
            "297/297 [==============================] - 2s 8ms/step - loss: 0.8125 - categorical_accuracy: 0.6610 - val_loss: 0.9324 - val_categorical_accuracy: 0.5806\n",
            "Epoch 190/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.8031 - categorical_accuracy: 0.6654 - val_loss: 0.9570 - val_categorical_accuracy: 0.5351\n",
            "Epoch 191/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.8406 - categorical_accuracy: 0.6323 - val_loss: 0.9400 - val_categorical_accuracy: 0.5731\n",
            "Epoch 192/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.8280 - categorical_accuracy: 0.6472 - val_loss: 0.9607 - val_categorical_accuracy: 0.5484\n",
            "Epoch 193/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.8240 - categorical_accuracy: 0.6377 - val_loss: 0.9082 - val_categorical_accuracy: 0.6091\n",
            "Epoch 194/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.8198 - categorical_accuracy: 0.6535 - val_loss: 0.9223 - val_categorical_accuracy: 0.5958\n",
            "Epoch 195/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.8157 - categorical_accuracy: 0.6555 - val_loss: 0.9109 - val_categorical_accuracy: 0.6205\n",
            "Epoch 196/200\n",
            "297/297 [==============================] - 2s 8ms/step - loss: 0.8264 - categorical_accuracy: 0.6536 - val_loss: 0.9006 - val_categorical_accuracy: 0.6053\n",
            "Epoch 197/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.8262 - categorical_accuracy: 0.6586 - val_loss: 0.9251 - val_categorical_accuracy: 0.5920\n",
            "Epoch 198/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.8200 - categorical_accuracy: 0.6629 - val_loss: 0.9271 - val_categorical_accuracy: 0.5769\n",
            "Epoch 199/200\n",
            "297/297 [==============================] - 2s 7ms/step - loss: 0.8259 - categorical_accuracy: 0.6387 - val_loss: 0.8966 - val_categorical_accuracy: 0.6205\n",
            "Epoch 200/200\n",
            "297/297 [==============================] - 2s 8ms/step - loss: 0.8009 - categorical_accuracy: 0.6530 - val_loss: 0.9254 - val_categorical_accuracy: 0.5939\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1gtXisiatDhm"
      },
      "source": [
        "model.save('/content/drive/MyDrive/Colab Notebooks/SPEECH_EMOTION_Recognition/Nộp bài(chốt hạ)/model_saver/conv2D_mfcc39_merged.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1u19O41utDhn"
      },
      "source": [
        "###test_result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KTdGtV9LtDho",
        "outputId": "e1556d45-bae8-4a85-e223-54653cb84b5f"
      },
      "source": [
        "d = {0: 'happy',\n",
        "     1: 'sad',\n",
        "     2: 'angry',\n",
        "     3: 'fear'}\n",
        "Y_test_pred = np.argmax(model.predict(X_test), axis=-1)\n",
        "Y_test_pred = list(map(lambda x: d[x], Y_test_pred))\n",
        "y_test = np.argmax(y_test, axis=-1)\n",
        "y_test = list(map(lambda x: d[x], y_test))\n",
        "print(classification_report(y_test, Y_test_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.78      0.75      0.76       129\n",
            "        fear       0.49      0.55      0.52       174\n",
            "       happy       0.43      0.57      0.49       127\n",
            "         sad       0.76      0.47      0.58       156\n",
            "\n",
            "    accuracy                           0.58       586\n",
            "   macro avg       0.61      0.59      0.59       586\n",
            "weighted avg       0.61      0.58      0.58       586\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 483
        },
        "id": "UL9tJ1wltDho",
        "outputId": "862e7840-2bec-4f08-a530-8605ba2c1887"
      },
      "source": [
        "import scikitplot as skplt\n",
        "\n",
        "skplt.metrics.plot_confusion_matrix(\n",
        "    y_test, \n",
        "    Y_test_pred,\n",
        "    figsize=(8,8))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f44dc2bdbd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LzkQi7D0tDhp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_7YOAt2TIKPI"
      },
      "source": [
        "# Mel Spectrogram + basic model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xr3mQSInIQ84"
      },
      "source": [
        "audio_duration = 3\n",
        "sampling_rate = 44100\n",
        "input_length = sampling_rate * audio_duration\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_mWyb8nIYyb",
        "outputId": "3e9db5bf-8c1b-4eab-9dac-8641ff307945"
      },
      "source": [
        "features = []\n",
        "labels = []\n",
        "for i in range(len(Ravdess_DF['Paths'])):\n",
        "  if ((Ravdess_DF['Emotion'][i] == '03') | (Ravdess_DF['Emotion'][i] == '04') | \n",
        "      (Ravdess_DF['Emotion'][i] == '05') | (Ravdess_DF['Emotion'][i] == '06')):\n",
        "    signal, sample_rate = librosa.load(Ravdess_DF['Paths'][i], res_type='kaiser_fast',sr=22050*2)\n",
        "    signal,index = librosa.effects.trim(signal,top_db = 25)\n",
        "    signal = scipy.signal.wiener(signal)\n",
        "\n",
        "    if len(signal) > input_length:\n",
        "      signal = signal[0:input_length]\n",
        "    elif  input_length > len(signal):\n",
        "      max_offset = input_length - len(signal)  \n",
        "      signal = np.pad(signal, (0, max_offset), \"constant\")\n",
        "\n",
        "    melspec = librosa.feature.melspectrogram(signal, sr=sample_rate, n_mels=128,n_fft=2048,hop_length=512)   \n",
        "    melspec = np.mean(melspec, axis=0)\n",
        "    features.append(melspec)\n",
        "\n",
        "    if Ravdess_DF['Emotion'][i] == '03':\n",
        "      labels.append(0)\n",
        "    elif Ravdess_DF['Emotion'][i] == '04':\n",
        "      labels.append(1)\n",
        "    elif Ravdess_DF['Emotion'][i] == '05':\n",
        "      labels.append(2)\n",
        "    elif Ravdess_DF['Emotion'][i] == '06':\n",
        "      labels.append(3)\n",
        "\n",
        "\n",
        "for i in range(len(CREMA_D_df)):\n",
        "  if ((CREMA_D_df['Emotion'][i] == 'HAP') | (CREMA_D_df['Emotion'][i] == 'SAD') | \n",
        "      (CREMA_D_df['Emotion'][i] == 'ANG') | (CREMA_D_df['Emotion'][i] == 'FEA')):\n",
        "    \n",
        "    if CREMA_D_df['Emotion'][i] == 'HAP':\n",
        "      labels.append(0)\n",
        "    elif CREMA_D_df['Emotion'][i] == 'SAD':\n",
        "      labels.append(1)\n",
        "    elif CREMA_D_df['Emotion'][i] == 'ANG':\n",
        "      labels.append(2)\n",
        "    elif CREMA_D_df['Emotion'][i] == 'FEA':\n",
        "      labels.append(3)\n",
        "\n",
        "\n",
        "    signal, sr =  librosa.load(CREMA_D_df['Paths'][i])\n",
        "\n",
        "\n",
        "    if len(signal) > input_length:\n",
        "      signal = signal[0:input_length]\n",
        "    elif  input_length > len(signal):\n",
        "      max_offset = input_length - len(signal)  \n",
        "      signal = np.pad(signal, (0, max_offset), \"constant\")\n",
        "\n",
        "    melspec = librosa.feature.melspectrogram(signal, sr=sampling_rate, n_mels=128,n_fft=2048,hop_length=512)   \n",
        "    melspec = np.mean(melspec, axis=0)\n",
        "    features.append(melspec)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/scipy/signal/signaltools.py:1456: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  res *= (1 - noise / lVar)\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/signal/signaltools.py:1456: RuntimeWarning: invalid value encountered in multiply\n",
            "  res *= (1 - noise / lVar)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6yk6fzByIY1W"
      },
      "source": [
        "X = features\n",
        "y = labels\n",
        "\n",
        "y = np.array(y)\n",
        "y = to_categorical(y)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=0)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=0)\n",
        "\n",
        "X_train = np.array(X_train)\n",
        "X_test = np.array(X_test)\n",
        "X_val = np.array(X_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aowUl_16N8b3",
        "outputId": "a5012d0d-6cd2-41c4-8327-2b6ca1f0a495"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4739, 259)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TgEIFTMtNvym"
      },
      "source": [
        "## basic models:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-i-abjOsNvzH",
        "outputId": "040995df-32d1-4d5f-cae4-15926c3a2ee3"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(259, input_shape=(259, ), activation = 'relu'))\n",
        "#model.add(Dropout(0.1))\n",
        "model.add(Dense(128, activation = 'relu'))\n",
        "#model.add(Dropout(0.25))\n",
        "model.add(Dense(128, activation = 'relu'))\n",
        "#model.add(Dropout(0.2))\n",
        "model.add(Dense(4, activation = 'softmax'))\n",
        "\n",
        "optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
        "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer=optimizer)\n",
        "early_stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=100, verbose=1, mode='auto')\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_5 (Dense)              (None, 259)               67340     \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 128)               33280     \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 4)                 516       \n",
            "=================================================================\n",
            "Total params: 117,648\n",
            "Trainable params: 117,648\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Q3G-i0jNvzI",
        "outputId": "3192858d-c4f2-41b6-aa98-c4243502cc58"
      },
      "source": [
        "history = model.fit(X_train, y_train, batch_size=64, epochs=200, \n",
        "                    validation_data=(X_val, y_val))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "75/75 [==============================] - 1s 6ms/step - loss: 1.3408 - accuracy: 0.3890 - val_loss: 1.2058 - val_accuracy: 0.4896\n",
            "Epoch 2/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.1191 - accuracy: 0.4973 - val_loss: 1.1691 - val_accuracy: 0.4991\n",
            "Epoch 3/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0412 - accuracy: 0.5388 - val_loss: 1.1411 - val_accuracy: 0.5123\n",
            "Epoch 4/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0091 - accuracy: 0.5478 - val_loss: 1.1507 - val_accuracy: 0.4896\n",
            "Epoch 5/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.9919 - accuracy: 0.5488 - val_loss: 1.1528 - val_accuracy: 0.5180\n",
            "Epoch 6/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.9664 - accuracy: 0.5873 - val_loss: 1.2313 - val_accuracy: 0.4877\n",
            "Epoch 7/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.9672 - accuracy: 0.5773 - val_loss: 1.1462 - val_accuracy: 0.5066\n",
            "Epoch 8/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.9088 - accuracy: 0.6060 - val_loss: 1.2065 - val_accuracy: 0.5123\n",
            "Epoch 9/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.8950 - accuracy: 0.6137 - val_loss: 1.2431 - val_accuracy: 0.5104\n",
            "Epoch 10/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.8808 - accuracy: 0.6298 - val_loss: 1.1690 - val_accuracy: 0.5256\n",
            "Epoch 11/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.8795 - accuracy: 0.6247 - val_loss: 1.2139 - val_accuracy: 0.5142\n",
            "Epoch 12/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.8541 - accuracy: 0.6283 - val_loss: 1.3012 - val_accuracy: 0.5275\n",
            "Epoch 13/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.8208 - accuracy: 0.6526 - val_loss: 1.3110 - val_accuracy: 0.5218\n",
            "Epoch 14/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.8323 - accuracy: 0.6515 - val_loss: 1.3056 - val_accuracy: 0.5085\n",
            "Epoch 15/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.7706 - accuracy: 0.6741 - val_loss: 1.4306 - val_accuracy: 0.4972\n",
            "Epoch 16/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.7912 - accuracy: 0.6634 - val_loss: 1.3732 - val_accuracy: 0.4896\n",
            "Epoch 17/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.7836 - accuracy: 0.6681 - val_loss: 1.4656 - val_accuracy: 0.5142\n",
            "Epoch 18/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.7484 - accuracy: 0.6866 - val_loss: 1.5202 - val_accuracy: 0.5028\n",
            "Epoch 19/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.7432 - accuracy: 0.6913 - val_loss: 1.5231 - val_accuracy: 0.5161\n",
            "Epoch 20/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.6842 - accuracy: 0.7257 - val_loss: 1.6463 - val_accuracy: 0.5294\n",
            "Epoch 21/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.7071 - accuracy: 0.7124 - val_loss: 1.6940 - val_accuracy: 0.5104\n",
            "Epoch 22/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.6754 - accuracy: 0.7259 - val_loss: 1.7232 - val_accuracy: 0.5199\n",
            "Epoch 23/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.6369 - accuracy: 0.7393 - val_loss: 1.8508 - val_accuracy: 0.5332\n",
            "Epoch 24/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.6154 - accuracy: 0.7449 - val_loss: 1.8588 - val_accuracy: 0.5351\n",
            "Epoch 25/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.6998 - accuracy: 0.7254 - val_loss: 1.9177 - val_accuracy: 0.5047\n",
            "Epoch 26/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.6182 - accuracy: 0.7521 - val_loss: 1.9067 - val_accuracy: 0.5389\n",
            "Epoch 27/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.5572 - accuracy: 0.7813 - val_loss: 2.0413 - val_accuracy: 0.5332\n",
            "Epoch 28/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.5292 - accuracy: 0.7883 - val_loss: 2.2180 - val_accuracy: 0.5047\n",
            "Epoch 29/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.5099 - accuracy: 0.7955 - val_loss: 2.3312 - val_accuracy: 0.5218\n",
            "Epoch 30/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.6004 - accuracy: 0.7783 - val_loss: 2.0781 - val_accuracy: 0.4953\n",
            "Epoch 31/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.6277 - accuracy: 0.7468 - val_loss: 2.1306 - val_accuracy: 0.4934\n",
            "Epoch 32/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.5442 - accuracy: 0.7933 - val_loss: 2.3095 - val_accuracy: 0.4934\n",
            "Epoch 33/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.5925 - accuracy: 0.7810 - val_loss: 2.2374 - val_accuracy: 0.4839\n",
            "Epoch 34/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.4916 - accuracy: 0.8099 - val_loss: 2.3334 - val_accuracy: 0.4991\n",
            "Epoch 35/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.4881 - accuracy: 0.8145 - val_loss: 2.3471 - val_accuracy: 0.4915\n",
            "Epoch 36/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.4557 - accuracy: 0.8247 - val_loss: 2.5825 - val_accuracy: 0.4839\n",
            "Epoch 37/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.4466 - accuracy: 0.8261 - val_loss: 2.4863 - val_accuracy: 0.4820\n",
            "Epoch 38/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.4498 - accuracy: 0.8193 - val_loss: 2.8302 - val_accuracy: 0.4782\n",
            "Epoch 39/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.4748 - accuracy: 0.8334 - val_loss: 2.8543 - val_accuracy: 0.4896\n",
            "Epoch 40/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.4539 - accuracy: 0.8250 - val_loss: 2.7543 - val_accuracy: 0.4706\n",
            "Epoch 41/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.3700 - accuracy: 0.8658 - val_loss: 2.9735 - val_accuracy: 0.4858\n",
            "Epoch 42/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.3545 - accuracy: 0.8666 - val_loss: 3.1212 - val_accuracy: 0.4364\n",
            "Epoch 43/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.3702 - accuracy: 0.8619 - val_loss: 3.3422 - val_accuracy: 0.4972\n",
            "Epoch 44/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.2913 - accuracy: 0.8983 - val_loss: 3.4870 - val_accuracy: 0.4763\n",
            "Epoch 45/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.3181 - accuracy: 0.8840 - val_loss: 3.6823 - val_accuracy: 0.4858\n",
            "Epoch 46/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.2870 - accuracy: 0.8886 - val_loss: 3.7330 - val_accuracy: 0.4991\n",
            "Epoch 47/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.2835 - accuracy: 0.8940 - val_loss: 3.8070 - val_accuracy: 0.4725\n",
            "Epoch 48/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.3909 - accuracy: 0.8649 - val_loss: 3.1086 - val_accuracy: 0.4801\n",
            "Epoch 49/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.4365 - accuracy: 0.8456 - val_loss: 2.9711 - val_accuracy: 0.4877\n",
            "Epoch 50/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.4094 - accuracy: 0.8488 - val_loss: 2.9602 - val_accuracy: 0.4877\n",
            "Epoch 51/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.2793 - accuracy: 0.9032 - val_loss: 3.3628 - val_accuracy: 0.4953\n",
            "Epoch 52/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.2781 - accuracy: 0.8951 - val_loss: 3.5960 - val_accuracy: 0.4649\n",
            "Epoch 53/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.2764 - accuracy: 0.8944 - val_loss: 3.8484 - val_accuracy: 0.4725\n",
            "Epoch 54/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.2683 - accuracy: 0.8966 - val_loss: 3.9421 - val_accuracy: 0.4858\n",
            "Epoch 55/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.2394 - accuracy: 0.9188 - val_loss: 4.1263 - val_accuracy: 0.4364\n",
            "Epoch 56/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.2524 - accuracy: 0.9013 - val_loss: 4.2413 - val_accuracy: 0.4820\n",
            "Epoch 57/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.2463 - accuracy: 0.9061 - val_loss: 4.3778 - val_accuracy: 0.4858\n",
            "Epoch 58/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.2325 - accuracy: 0.9159 - val_loss: 4.1740 - val_accuracy: 0.4668\n",
            "Epoch 59/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.3114 - accuracy: 0.8986 - val_loss: 3.5388 - val_accuracy: 0.4573\n",
            "Epoch 60/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.3244 - accuracy: 0.8917 - val_loss: 3.5937 - val_accuracy: 0.4744\n",
            "Epoch 61/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.2699 - accuracy: 0.8961 - val_loss: 3.4237 - val_accuracy: 0.4516\n",
            "Epoch 62/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.2928 - accuracy: 0.8891 - val_loss: 3.5299 - val_accuracy: 0.4668\n",
            "Epoch 63/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.1924 - accuracy: 0.9323 - val_loss: 3.8745 - val_accuracy: 0.4649\n",
            "Epoch 64/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.2092 - accuracy: 0.9264 - val_loss: 4.1934 - val_accuracy: 0.4782\n",
            "Epoch 65/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.1865 - accuracy: 0.9370 - val_loss: 4.1624 - val_accuracy: 0.4706\n",
            "Epoch 66/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.1735 - accuracy: 0.9391 - val_loss: 4.4616 - val_accuracy: 0.4801\n",
            "Epoch 67/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.1585 - accuracy: 0.9420 - val_loss: 4.8004 - val_accuracy: 0.4668\n",
            "Epoch 68/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.1557 - accuracy: 0.9463 - val_loss: 4.9529 - val_accuracy: 0.4649\n",
            "Epoch 69/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.1658 - accuracy: 0.9412 - val_loss: 5.0974 - val_accuracy: 0.4763\n",
            "Epoch 70/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.1623 - accuracy: 0.9348 - val_loss: 5.3736 - val_accuracy: 0.4877\n",
            "Epoch 71/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.1336 - accuracy: 0.9548 - val_loss: 5.5490 - val_accuracy: 0.4573\n",
            "Epoch 72/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.1304 - accuracy: 0.9580 - val_loss: 5.5703 - val_accuracy: 0.4611\n",
            "Epoch 73/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.2377 - accuracy: 0.9266 - val_loss: 4.3506 - val_accuracy: 0.4497\n",
            "Epoch 74/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.4294 - accuracy: 0.8604 - val_loss: 3.9178 - val_accuracy: 0.4611\n",
            "Epoch 75/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.2140 - accuracy: 0.9269 - val_loss: 4.3031 - val_accuracy: 0.4478\n",
            "Epoch 76/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.2097 - accuracy: 0.9524 - val_loss: 4.4055 - val_accuracy: 0.4744\n",
            "Epoch 77/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.1512 - accuracy: 0.9494 - val_loss: 4.6586 - val_accuracy: 0.4649\n",
            "Epoch 78/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.1161 - accuracy: 0.9646 - val_loss: 4.8598 - val_accuracy: 0.4250\n",
            "Epoch 79/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.1337 - accuracy: 0.9510 - val_loss: 5.1844 - val_accuracy: 0.4592\n",
            "Epoch 80/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.1158 - accuracy: 0.9531 - val_loss: 5.3614 - val_accuracy: 0.4706\n",
            "Epoch 81/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0967 - accuracy: 0.9656 - val_loss: 5.6835 - val_accuracy: 0.4782\n",
            "Epoch 82/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.1020 - accuracy: 0.9659 - val_loss: 5.7016 - val_accuracy: 0.4706\n",
            "Epoch 83/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0974 - accuracy: 0.9703 - val_loss: 6.1486 - val_accuracy: 0.4554\n",
            "Epoch 84/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.1100 - accuracy: 0.9650 - val_loss: 5.7143 - val_accuracy: 0.4649\n",
            "Epoch 85/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0982 - accuracy: 0.9650 - val_loss: 5.7148 - val_accuracy: 0.4440\n",
            "Epoch 86/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.1187 - accuracy: 0.9560 - val_loss: 5.9328 - val_accuracy: 0.4782\n",
            "Epoch 87/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.1434 - accuracy: 0.9524 - val_loss: 5.5894 - val_accuracy: 0.4687\n",
            "Epoch 88/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.1937 - accuracy: 0.9422 - val_loss: 4.5605 - val_accuracy: 0.4364\n",
            "Epoch 89/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.2715 - accuracy: 0.9257 - val_loss: 4.7786 - val_accuracy: 0.4516\n",
            "Epoch 90/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.1582 - accuracy: 0.9505 - val_loss: 4.3536 - val_accuracy: 0.4668\n",
            "Epoch 91/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.2004 - accuracy: 0.9359 - val_loss: 4.3482 - val_accuracy: 0.4744\n",
            "Epoch 92/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.1456 - accuracy: 0.9497 - val_loss: 4.7344 - val_accuracy: 0.4763\n",
            "Epoch 93/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0947 - accuracy: 0.9652 - val_loss: 4.9626 - val_accuracy: 0.4801\n",
            "Epoch 94/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0912 - accuracy: 0.9717 - val_loss: 5.1069 - val_accuracy: 0.4687\n",
            "Epoch 95/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0789 - accuracy: 0.9722 - val_loss: 5.2088 - val_accuracy: 0.4440\n",
            "Epoch 96/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0677 - accuracy: 0.9757 - val_loss: 5.3527 - val_accuracy: 0.4744\n",
            "Epoch 97/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0595 - accuracy: 0.9832 - val_loss: 5.5740 - val_accuracy: 0.4630\n",
            "Epoch 98/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0605 - accuracy: 0.9813 - val_loss: 5.7452 - val_accuracy: 0.4156\n",
            "Epoch 99/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0739 - accuracy: 0.9721 - val_loss: 5.9294 - val_accuracy: 0.4269\n",
            "Epoch 100/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0634 - accuracy: 0.9787 - val_loss: 5.9560 - val_accuracy: 0.4668\n",
            "Epoch 101/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0739 - accuracy: 0.9761 - val_loss: 6.0242 - val_accuracy: 0.4668\n",
            "Epoch 102/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0585 - accuracy: 0.9792 - val_loss: 6.1693 - val_accuracy: 0.4478\n",
            "Epoch 103/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0518 - accuracy: 0.9827 - val_loss: 6.3051 - val_accuracy: 0.4706\n",
            "Epoch 104/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0598 - accuracy: 0.9809 - val_loss: 6.3808 - val_accuracy: 0.4725\n",
            "Epoch 105/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0567 - accuracy: 0.9799 - val_loss: 6.5980 - val_accuracy: 0.4421\n",
            "Epoch 106/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.1771 - accuracy: 0.9430 - val_loss: 4.6319 - val_accuracy: 0.4478\n",
            "Epoch 107/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.1819 - accuracy: 0.9400 - val_loss: 4.4890 - val_accuracy: 0.4383\n",
            "Epoch 108/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.1917 - accuracy: 0.9322 - val_loss: 4.9499 - val_accuracy: 0.4288\n",
            "Epoch 109/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.1006 - accuracy: 0.9695 - val_loss: 4.9770 - val_accuracy: 0.4592\n",
            "Epoch 110/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0914 - accuracy: 0.9740 - val_loss: 4.8920 - val_accuracy: 0.4402\n",
            "Epoch 111/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.1061 - accuracy: 0.9662 - val_loss: 5.3024 - val_accuracy: 0.4516\n",
            "Epoch 112/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0589 - accuracy: 0.9826 - val_loss: 5.6420 - val_accuracy: 0.4820\n",
            "Epoch 113/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0563 - accuracy: 0.9804 - val_loss: 5.8178 - val_accuracy: 0.4516\n",
            "Epoch 114/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0468 - accuracy: 0.9858 - val_loss: 5.9517 - val_accuracy: 0.4592\n",
            "Epoch 115/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0438 - accuracy: 0.9873 - val_loss: 6.0687 - val_accuracy: 0.4877\n",
            "Epoch 116/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0673 - accuracy: 0.9752 - val_loss: 6.1103 - val_accuracy: 0.4763\n",
            "Epoch 117/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0396 - accuracy: 0.9897 - val_loss: 6.2772 - val_accuracy: 0.4725\n",
            "Epoch 118/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0561 - accuracy: 0.9835 - val_loss: 5.8633 - val_accuracy: 0.4592\n",
            "Epoch 119/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0524 - accuracy: 0.9842 - val_loss: 6.0146 - val_accuracy: 0.4592\n",
            "Epoch 120/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0447 - accuracy: 0.9863 - val_loss: 6.0583 - val_accuracy: 0.4573\n",
            "Epoch 121/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0413 - accuracy: 0.9868 - val_loss: 6.2902 - val_accuracy: 0.4611\n",
            "Epoch 122/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0428 - accuracy: 0.9852 - val_loss: 6.5764 - val_accuracy: 0.4668\n",
            "Epoch 123/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0340 - accuracy: 0.9887 - val_loss: 6.7255 - val_accuracy: 0.4535\n",
            "Epoch 124/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0360 - accuracy: 0.9874 - val_loss: 6.9690 - val_accuracy: 0.4156\n",
            "Epoch 125/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.1233 - accuracy: 0.9592 - val_loss: 7.0328 - val_accuracy: 0.4023\n",
            "Epoch 126/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.1602 - accuracy: 0.9443 - val_loss: 5.6187 - val_accuracy: 0.4421\n",
            "Epoch 127/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.1720 - accuracy: 0.9370 - val_loss: 4.6607 - val_accuracy: 0.4744\n",
            "Epoch 128/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.2243 - accuracy: 0.9202 - val_loss: 4.5653 - val_accuracy: 0.4668\n",
            "Epoch 129/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0967 - accuracy: 0.9702 - val_loss: 5.0895 - val_accuracy: 0.4630\n",
            "Epoch 130/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0655 - accuracy: 0.9798 - val_loss: 5.5596 - val_accuracy: 0.4630\n",
            "Epoch 131/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0405 - accuracy: 0.9868 - val_loss: 6.0604 - val_accuracy: 0.4592\n",
            "Epoch 132/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0331 - accuracy: 0.9904 - val_loss: 6.1634 - val_accuracy: 0.4592\n",
            "Epoch 133/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0299 - accuracy: 0.9905 - val_loss: 6.3588 - val_accuracy: 0.4611\n",
            "Epoch 134/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0416 - accuracy: 0.9853 - val_loss: 6.4119 - val_accuracy: 0.4573\n",
            "Epoch 135/200\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0269 - accuracy: 0.9919 - val_loss: 6.6582 - val_accuracy: 0.4611\n",
            "Epoch 136/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0243 - accuracy: 0.9935 - val_loss: 6.7739 - val_accuracy: 0.4535\n",
            "Epoch 137/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0211 - accuracy: 0.9940 - val_loss: 6.9029 - val_accuracy: 0.4573\n",
            "Epoch 138/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0257 - accuracy: 0.9919 - val_loss: 7.0245 - val_accuracy: 0.4573\n",
            "Epoch 139/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0200 - accuracy: 0.9953 - val_loss: 7.2742 - val_accuracy: 0.4213\n",
            "Epoch 140/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.1905 - accuracy: 0.9397 - val_loss: 6.6241 - val_accuracy: 0.4801\n",
            "Epoch 141/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0777 - accuracy: 0.9641 - val_loss: 6.7913 - val_accuracy: 0.4250\n",
            "Epoch 142/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0380 - accuracy: 0.9911 - val_loss: 7.1750 - val_accuracy: 0.4592\n",
            "Epoch 143/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0462 - accuracy: 0.9880 - val_loss: 6.7167 - val_accuracy: 0.4611\n",
            "Epoch 144/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0529 - accuracy: 0.9883 - val_loss: 5.9622 - val_accuracy: 0.4326\n",
            "Epoch 145/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.1920 - accuracy: 0.9447 - val_loss: 5.3117 - val_accuracy: 0.4288\n",
            "Epoch 146/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0989 - accuracy: 0.9678 - val_loss: 5.5566 - val_accuracy: 0.4231\n",
            "Epoch 147/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0759 - accuracy: 0.9795 - val_loss: 6.1179 - val_accuracy: 0.4023\n",
            "Epoch 148/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.1381 - accuracy: 0.9560 - val_loss: 5.9461 - val_accuracy: 0.4345\n",
            "Epoch 149/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0293 - accuracy: 0.9907 - val_loss: 6.2955 - val_accuracy: 0.4402\n",
            "Epoch 150/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0275 - accuracy: 0.9923 - val_loss: 6.4602 - val_accuracy: 0.4554\n",
            "Epoch 151/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0223 - accuracy: 0.9934 - val_loss: 6.6590 - val_accuracy: 0.4535\n",
            "Epoch 152/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0216 - accuracy: 0.9944 - val_loss: 6.8512 - val_accuracy: 0.4421\n",
            "Epoch 153/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0167 - accuracy: 0.9945 - val_loss: 6.9396 - val_accuracy: 0.4440\n",
            "Epoch 154/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0268 - accuracy: 0.9897 - val_loss: 7.1778 - val_accuracy: 0.4231\n",
            "Epoch 155/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0226 - accuracy: 0.9924 - val_loss: 7.1758 - val_accuracy: 0.4668\n",
            "Epoch 156/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.1676 - accuracy: 0.9559 - val_loss: 6.9218 - val_accuracy: 0.4611\n",
            "Epoch 157/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0963 - accuracy: 0.9783 - val_loss: 6.1976 - val_accuracy: 0.4326\n",
            "Epoch 158/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.1175 - accuracy: 0.9613 - val_loss: 5.8800 - val_accuracy: 0.4307\n",
            "Epoch 159/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0760 - accuracy: 0.9779 - val_loss: 6.4924 - val_accuracy: 0.4440\n",
            "Epoch 160/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0296 - accuracy: 0.9912 - val_loss: 6.4585 - val_accuracy: 0.4459\n",
            "Epoch 161/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0206 - accuracy: 0.9946 - val_loss: 7.0839 - val_accuracy: 0.4269\n",
            "Epoch 162/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0380 - accuracy: 0.9859 - val_loss: 6.9140 - val_accuracy: 0.4402\n",
            "Epoch 163/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0334 - accuracy: 0.9903 - val_loss: 7.1455 - val_accuracy: 0.4440\n",
            "Epoch 164/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0488 - accuracy: 0.9879 - val_loss: 6.7002 - val_accuracy: 0.4440\n",
            "Epoch 165/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0284 - accuracy: 0.9913 - val_loss: 6.9725 - val_accuracy: 0.4421\n",
            "Epoch 166/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0171 - accuracy: 0.9951 - val_loss: 7.2550 - val_accuracy: 0.4516\n",
            "Epoch 167/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0181 - accuracy: 0.9940 - val_loss: 7.4785 - val_accuracy: 0.4345\n",
            "Epoch 168/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0138 - accuracy: 0.9958 - val_loss: 7.5606 - val_accuracy: 0.4459\n",
            "Epoch 169/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0190 - accuracy: 0.9943 - val_loss: 7.7215 - val_accuracy: 0.4118\n",
            "Epoch 170/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0224 - accuracy: 0.9922 - val_loss: 7.7850 - val_accuracy: 0.4326\n",
            "Epoch 171/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0158 - accuracy: 0.9937 - val_loss: 7.8813 - val_accuracy: 0.4269\n",
            "Epoch 172/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0146 - accuracy: 0.9955 - val_loss: 7.9498 - val_accuracy: 0.4459\n",
            "Epoch 173/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0228 - accuracy: 0.9922 - val_loss: 8.2158 - val_accuracy: 0.4194\n",
            "Epoch 174/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0784 - accuracy: 0.9723 - val_loss: 7.4964 - val_accuracy: 0.4383\n",
            "Epoch 175/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.1919 - accuracy: 0.9476 - val_loss: 6.7732 - val_accuracy: 0.4706\n",
            "Epoch 176/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.1299 - accuracy: 0.9591 - val_loss: 6.1559 - val_accuracy: 0.4383\n",
            "Epoch 177/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.1180 - accuracy: 0.9673 - val_loss: 6.2618 - val_accuracy: 0.4516\n",
            "Epoch 178/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0583 - accuracy: 0.9880 - val_loss: 6.0628 - val_accuracy: 0.4592\n",
            "Epoch 179/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.1013 - accuracy: 0.9819 - val_loss: 6.0499 - val_accuracy: 0.4535\n",
            "Epoch 180/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0334 - accuracy: 0.9898 - val_loss: 7.2059 - val_accuracy: 0.4440\n",
            "Epoch 181/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0930 - accuracy: 0.9818 - val_loss: 6.4432 - val_accuracy: 0.4554\n",
            "Epoch 182/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0324 - accuracy: 0.9905 - val_loss: 6.7115 - val_accuracy: 0.4535\n",
            "Epoch 183/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0129 - accuracy: 0.9973 - val_loss: 7.0266 - val_accuracy: 0.4573\n",
            "Epoch 184/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0136 - accuracy: 0.9953 - val_loss: 7.1203 - val_accuracy: 0.4592\n",
            "Epoch 185/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0136 - accuracy: 0.9950 - val_loss: 7.2853 - val_accuracy: 0.4592\n",
            "Epoch 186/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0177 - accuracy: 0.9936 - val_loss: 7.2720 - val_accuracy: 0.4706\n",
            "Epoch 187/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0244 - accuracy: 0.9912 - val_loss: 7.4173 - val_accuracy: 0.4782\n",
            "Epoch 188/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0203 - accuracy: 0.9933 - val_loss: 7.5269 - val_accuracy: 0.4630\n",
            "Epoch 189/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0263 - accuracy: 0.9897 - val_loss: 7.4070 - val_accuracy: 0.4725\n",
            "Epoch 190/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0462 - accuracy: 0.9835 - val_loss: 7.6393 - val_accuracy: 0.4592\n",
            "Epoch 191/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0162 - accuracy: 0.9947 - val_loss: 7.7533 - val_accuracy: 0.4611\n",
            "Epoch 192/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0111 - accuracy: 0.9971 - val_loss: 7.8941 - val_accuracy: 0.4421\n",
            "Epoch 193/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0095 - accuracy: 0.9972 - val_loss: 7.9192 - val_accuracy: 0.4478\n",
            "Epoch 194/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0089 - accuracy: 0.9979 - val_loss: 8.0487 - val_accuracy: 0.4611\n",
            "Epoch 195/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0119 - accuracy: 0.9958 - val_loss: 8.1216 - val_accuracy: 0.4687\n",
            "Epoch 196/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0102 - accuracy: 0.9968 - val_loss: 8.2663 - val_accuracy: 0.4611\n",
            "Epoch 197/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0091 - accuracy: 0.9976 - val_loss: 8.4171 - val_accuracy: 0.4345\n",
            "Epoch 198/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0188 - accuracy: 0.9931 - val_loss: 8.4170 - val_accuracy: 0.4535\n",
            "Epoch 199/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0300 - accuracy: 0.9884 - val_loss: 8.3098 - val_accuracy: 0.4573\n",
            "Epoch 200/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0280 - accuracy: 0.9904 - val_loss: 8.2212 - val_accuracy: 0.4459\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jma0YnoltSx1"
      },
      "source": [
        "model.save('/content/drive/MyDrive/Colab Notebooks/SPEECH_EMOTION_Recognition/Nộp bài(chốt hạ)/model_saver/basic_melspec_merged.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JY0Ki_DJNvzK"
      },
      "source": [
        "###test_result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_syQ5_c5NvzL",
        "outputId": "ca1a3e4d-1615-45e3-bc19-9519063d396e"
      },
      "source": [
        "d = {0: 'happy',\n",
        "     1: 'sad',\n",
        "     2: 'angry',\n",
        "     3: 'fear'}\n",
        "Y_test_pred = np.argmax(model.predict(X_test), axis=-1)\n",
        "Y_test_pred = list(map(lambda x: d[x], Y_test_pred))\n",
        "y_test = np.argmax(y_test, axis=-1)\n",
        "y_test = list(map(lambda x: d[x], y_test))\n",
        "print(classification_report(y_test, Y_test_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.55      0.62      0.58       129\n",
            "        fear       0.38      0.40      0.39       174\n",
            "       happy       0.33      0.36      0.35       127\n",
            "         sad       0.58      0.43      0.49       156\n",
            "\n",
            "    accuracy                           0.45       586\n",
            "   macro avg       0.46      0.45      0.45       586\n",
            "weighted avg       0.46      0.45      0.45       586\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "cFY-fvMRNvzL",
        "outputId": "e3c80148-0338-40d3-c565-e416bb985fca"
      },
      "source": [
        "import scikitplot as skplt\n",
        "\n",
        "skplt.metrics.plot_confusion_matrix(\n",
        "    y_test, \n",
        "    Y_test_pred,\n",
        "    figsize=(8,8))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f44ec082610>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jNEbmeonPxXR"
      },
      "source": [
        "# Mel Spectrogram + conv1D"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j8K-0mOcPxXm"
      },
      "source": [
        "audio_duration = 3\n",
        "sampling_rate = 44100\n",
        "input_length = sampling_rate * audio_duration\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "eKTGQBGrPxXo",
        "outputId": "94c35a01-6f41-4dbf-8349-2b0d854963d8"
      },
      "source": [
        "features = []\n",
        "labels = []\n",
        "for i in range(len(Ravdess_DF['Paths'])):\n",
        "  if ((Ravdess_DF['Emotion'][i] == '03') | (Ravdess_DF['Emotion'][i] == '04') | \n",
        "      (Ravdess_DF['Emotion'][i] == '05') | (Ravdess_DF['Emotion'][i] == '06')):\n",
        "    signal, sample_rate = librosa.load(Ravdess_DF['Paths'][i], res_type='kaiser_fast',sr=22050*2)\n",
        "    signal,index = librosa.effects.trim(signal,top_db = 25)\n",
        "    signal = scipy.signal.wiener(signal)\n",
        "\n",
        "    if len(signal) > input_length:\n",
        "      signal = signal[0:input_length]\n",
        "    elif  input_length > len(signal):\n",
        "      max_offset = input_length - len(signal)  \n",
        "      signal = np.pad(signal, (0, max_offset), \"constant\")\n",
        "\n",
        "    melspec = librosa.feature.melspectrogram(signal, sr=sample_rate, n_mels=128,n_fft=2048,hop_length=512)   \n",
        "    melspec = melspec.reshape(-1,1)\n",
        "    features.append(melspec)\n",
        "\n",
        "    if Ravdess_DF['Emotion'][i] == '03':\n",
        "      labels.append(0)\n",
        "    elif Ravdess_DF['Emotion'][i] == '04':\n",
        "      labels.append(1)\n",
        "    elif Ravdess_DF['Emotion'][i] == '05':\n",
        "      labels.append(2)\n",
        "    elif Ravdess_DF['Emotion'][i] == '06':\n",
        "      labels.append(3)\n",
        "\n",
        "for i in range(len(CREMA_D_df)):\n",
        "  if ((CREMA_D_df['Emotion'][i] == 'HAP') | (CREMA_D_df['Emotion'][i] == 'SAD') | \n",
        "      (CREMA_D_df['Emotion'][i] == 'ANG') | (CREMA_D_df['Emotion'][i] == 'FEA')):\n",
        "    \n",
        "    if CREMA_D_df['Emotion'][i] == 'HAP':\n",
        "      labels.append(0)\n",
        "    elif CREMA_D_df['Emotion'][i] == 'SAD':\n",
        "      labels.append(1)\n",
        "    elif CREMA_D_df['Emotion'][i] == 'ANG':\n",
        "      labels.append(2)\n",
        "    elif CREMA_D_df['Emotion'][i] == 'FEA':\n",
        "      labels.append(3)\n",
        "\n",
        "\n",
        "    signal, sr =  librosa.load(CREMA_D_df['Paths'][i])\n",
        "\n",
        "    if len(signal) > input_length:\n",
        "      signal = signal[0:input_length]\n",
        "    elif  input_length > len(signal):\n",
        "      max_offset = input_length - len(signal)  \n",
        "      signal = np.pad(signal, (0, max_offset), \"constant\")\n",
        "\n",
        "    melspec = librosa.feature.melspectrogram(signal, sr=sampling_rate, n_mels=128,n_fft=2048,hop_length=512)   \n",
        "    melspec = melspec.reshape(-1,1)\n",
        "    features.append(melspec)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/scipy/signal/signaltools.py:1456: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  res *= (1 - noise / lVar)\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/signal/signaltools.py:1456: RuntimeWarning: invalid value encountered in multiply\n",
            "  res *= (1 - noise / lVar)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1inUhrfPxXp"
      },
      "source": [
        "X = features\n",
        "y = labels\n",
        "\n",
        "y = np.array(y)\n",
        "y = to_categorical(y)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=0)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=0)\n",
        "\n",
        "X_train = np.array(X_train)\n",
        "X_test = np.array(X_test)\n",
        "X_val = np.array(X_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75dgiNuHPxXq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2859a217-ce14-4394-9d58-662dc23d7b5b"
      },
      "source": [
        "X_train.shape,X_test.shape,y_train.shape,y_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((4739, 33152, 1), (586, 33152, 1), (4739, 4), (586, 4))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oh_OiXY_Yg4_"
      },
      "source": [
        "### conv1D"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0YU2uUSwQXSk"
      },
      "source": [
        "\n",
        "# CNN I/P Config\n",
        "num_classes = 4\n",
        "input_shape = X_train.shape[1:]\n",
        "learning_rate = 0.0001\n",
        "decay = 1e-6\n",
        "momentum = 0.9\n",
        "\n",
        "#LSTM Configuration\n",
        "num_lstm = 256"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SqfS1FIXQYZc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbcdecb9-7217-43c1-87f3-fc65d1c85e60"
      },
      "source": [
        "model = Sequential(name='Audio_CNN_1D')\n",
        "\n",
        "# LFLB1\n",
        "model.add(Conv1D(filters=64, kernel_size=(3), strides=1, padding='same', data_format='channels_last',input_shape=input_shape))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('elu'))\n",
        "model.add(MaxPooling1D(pool_size=4, strides=4))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "# LFLB2\n",
        "model.add(Conv1D(filters=64, kernel_size=3, strides=1, padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('elu'))\n",
        "model.add(MaxPooling1D(pool_size=4, strides=4))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# LFLB3\n",
        "model.add(Conv1D(filters=128, kernel_size=3, strides=1, padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('elu'))\n",
        "model.add(MaxPooling1D(pool_size=4, strides=4))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# LFLB4\n",
        "model.add(Conv1D(filters=128, kernel_size=3, strides=1, padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('elu'))\n",
        "model.add(MaxPooling1D(pool_size=4, strides=4))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# LSTM\n",
        "model.add(LSTM(units=num_lstm))\n",
        "\n",
        "# FC\n",
        "model.add(Dense(units=num_classes, activation='softmax'))\n",
        "\n",
        "# Model compilation\n",
        "opt= keras.optimizers.Adam(lr=0.01, beta_1=0.9,  beta_2=0.999, amsgrad=False)\n",
        "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
        "\n",
        "model.summary()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"Audio_CNN_1D\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 33152, 64)         256       \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 33152, 64)         256       \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 33152, 64)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D) (None, 8288, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 8288, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 8288, 64)          12352     \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 8288, 64)          256       \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 8288, 64)          0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1 (None, 2072, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 2072, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 2072, 128)         24704     \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 2072, 128)         512       \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 2072, 128)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_2 (MaxPooling1 (None, 518, 128)          0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 518, 128)          0         \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 518, 128)          49280     \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 518, 128)          512       \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 518, 128)          0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_3 (MaxPooling1 (None, 129, 128)          0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 129, 128)          0         \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 256)               394240    \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 4)                 1028      \n",
            "=================================================================\n",
            "Total params: 483,396\n",
            "Trainable params: 482,628\n",
            "Non-trainable params: 768\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "StwxbTydQegU",
        "outputId": "cd68bc97-2d07-45f2-a77b-7ce658e9008e"
      },
      "source": [
        "#Train Config\n",
        "\n",
        "batch_size = 16\n",
        "num_epochs = 200\n",
        "\n",
        "# Model Training\n",
        "lr_reduce = ReduceLROnPlateau(monitor='val_loss', factor=0.9, patience=20, min_lr=0.000001)\n",
        "# Please change the model name accordingly.\n",
        "mcp_save = ModelCheckpoint('/content/Audio_1DCNN.h5', save_best_only=True, monitor='val_categorical_accuracy', mode='max')\n",
        "cnnhistory=model.fit(X_train, y_train, batch_size=batch_size, epochs=num_epochs,validation_data=(X_val, y_val), callbacks=[mcp_save, lr_reduce])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "297/297 [==============================] - 73s 78ms/step - loss: 1.5096 - categorical_accuracy: 0.2840 - val_loss: 1.6764 - val_categorical_accuracy: 0.2106\n",
            "Epoch 2/200\n",
            "297/297 [==============================] - 22s 74ms/step - loss: 1.4265 - categorical_accuracy: 0.3144 - val_loss: 1.2966 - val_categorical_accuracy: 0.3966\n",
            "Epoch 3/200\n",
            "297/297 [==============================] - 23s 78ms/step - loss: 1.2529 - categorical_accuracy: 0.4179 - val_loss: 1.2510 - val_categorical_accuracy: 0.3909\n",
            "Epoch 4/200\n",
            "297/297 [==============================] - 23s 76ms/step - loss: 1.2056 - categorical_accuracy: 0.4394 - val_loss: 1.1627 - val_categorical_accuracy: 0.4858\n",
            "Epoch 5/200\n",
            "297/297 [==============================] - 23s 76ms/step - loss: 1.2520 - categorical_accuracy: 0.4094 - val_loss: 1.2156 - val_categorical_accuracy: 0.3510\n",
            "Epoch 6/200\n",
            "297/297 [==============================] - 22s 75ms/step - loss: 1.2317 - categorical_accuracy: 0.3951 - val_loss: 1.2309 - val_categorical_accuracy: 0.3491\n",
            "Epoch 7/200\n",
            "297/297 [==============================] - 22s 75ms/step - loss: 1.2095 - categorical_accuracy: 0.4291 - val_loss: 1.1744 - val_categorical_accuracy: 0.4630\n",
            "Epoch 8/200\n",
            "297/297 [==============================] - 22s 75ms/step - loss: 1.2456 - categorical_accuracy: 0.4394 - val_loss: 1.1854 - val_categorical_accuracy: 0.5066\n",
            "Epoch 9/200\n",
            "297/297 [==============================] - 22s 76ms/step - loss: 1.2165 - categorical_accuracy: 0.4124 - val_loss: 1.1714 - val_categorical_accuracy: 0.5104\n",
            "Epoch 10/200\n",
            "297/297 [==============================] - 22s 75ms/step - loss: 1.2001 - categorical_accuracy: 0.4477 - val_loss: 1.1499 - val_categorical_accuracy: 0.5047\n",
            "Epoch 11/200\n",
            "297/297 [==============================] - 22s 75ms/step - loss: 1.1728 - categorical_accuracy: 0.4518 - val_loss: 1.1507 - val_categorical_accuracy: 0.4934\n",
            "Epoch 12/200\n",
            "297/297 [==============================] - 22s 75ms/step - loss: 1.2160 - categorical_accuracy: 0.4244 - val_loss: 1.2109 - val_categorical_accuracy: 0.4991\n",
            "Epoch 13/200\n",
            "297/297 [==============================] - 22s 75ms/step - loss: 1.2093 - categorical_accuracy: 0.4415 - val_loss: 1.2274 - val_categorical_accuracy: 0.4782\n",
            "Epoch 14/200\n",
            "297/297 [==============================] - 22s 75ms/step - loss: 1.1889 - categorical_accuracy: 0.4560 - val_loss: 1.1491 - val_categorical_accuracy: 0.5218\n",
            "Epoch 15/200\n",
            "297/297 [==============================] - 22s 75ms/step - loss: 1.1528 - categorical_accuracy: 0.4675 - val_loss: 1.3098 - val_categorical_accuracy: 0.4061\n",
            "Epoch 16/200\n",
            "297/297 [==============================] - 22s 75ms/step - loss: 1.1791 - categorical_accuracy: 0.4489 - val_loss: 1.3184 - val_categorical_accuracy: 0.3662\n",
            "Epoch 17/200\n",
            "297/297 [==============================] - 22s 75ms/step - loss: 1.1623 - categorical_accuracy: 0.4711 - val_loss: 1.2092 - val_categorical_accuracy: 0.4194\n",
            "Epoch 18/200\n",
            "297/297 [==============================] - 22s 75ms/step - loss: 1.1500 - categorical_accuracy: 0.4711 - val_loss: 1.1460 - val_categorical_accuracy: 0.4991\n",
            "Epoch 19/200\n",
            "297/297 [==============================] - 22s 75ms/step - loss: 1.1515 - categorical_accuracy: 0.4760 - val_loss: 1.0930 - val_categorical_accuracy: 0.5123\n",
            "Epoch 20/200\n",
            "297/297 [==============================] - 22s 75ms/step - loss: 1.1548 - categorical_accuracy: 0.4766 - val_loss: 1.1490 - val_categorical_accuracy: 0.4687\n",
            "Epoch 21/200\n",
            "297/297 [==============================] - 22s 75ms/step - loss: 1.1616 - categorical_accuracy: 0.4539 - val_loss: 1.1633 - val_categorical_accuracy: 0.4535\n",
            "Epoch 22/200\n",
            "297/297 [==============================] - 22s 75ms/step - loss: 1.1335 - categorical_accuracy: 0.4819 - val_loss: 1.0814 - val_categorical_accuracy: 0.5389\n",
            "Epoch 23/200\n",
            "297/297 [==============================] - 22s 75ms/step - loss: 1.1363 - categorical_accuracy: 0.4773 - val_loss: 1.1235 - val_categorical_accuracy: 0.5009\n",
            "Epoch 24/200\n",
            "297/297 [==============================] - 22s 75ms/step - loss: 1.1463 - categorical_accuracy: 0.4631 - val_loss: 1.0753 - val_categorical_accuracy: 0.5446\n",
            "Epoch 25/200\n",
            "297/297 [==============================] - 22s 75ms/step - loss: 1.1448 - categorical_accuracy: 0.4780 - val_loss: 1.1771 - val_categorical_accuracy: 0.4307\n",
            "Epoch 26/200\n",
            "297/297 [==============================] - 22s 75ms/step - loss: 1.1161 - categorical_accuracy: 0.5003 - val_loss: 1.0986 - val_categorical_accuracy: 0.4953\n",
            "Epoch 27/200\n",
            "297/297 [==============================] - 22s 75ms/step - loss: 1.1305 - categorical_accuracy: 0.4655 - val_loss: 1.1676 - val_categorical_accuracy: 0.4649\n",
            "Epoch 28/200\n",
            "297/297 [==============================] - 22s 75ms/step - loss: 1.1117 - categorical_accuracy: 0.4772 - val_loss: 1.1093 - val_categorical_accuracy: 0.4782\n",
            "Epoch 29/200\n",
            "297/297 [==============================] - 22s 75ms/step - loss: 1.1196 - categorical_accuracy: 0.4889 - val_loss: 1.0582 - val_categorical_accuracy: 0.5522\n",
            "Epoch 30/200\n",
            "297/297 [==============================] - 22s 75ms/step - loss: 1.1311 - categorical_accuracy: 0.4955 - val_loss: 1.0593 - val_categorical_accuracy: 0.5503\n",
            "Epoch 31/200\n",
            "297/297 [==============================] - 22s 75ms/step - loss: 1.1469 - categorical_accuracy: 0.4849 - val_loss: 1.2235 - val_categorical_accuracy: 0.3928\n",
            "Epoch 32/200\n",
            "297/297 [==============================] - 22s 75ms/step - loss: 1.1462 - categorical_accuracy: 0.4794 - val_loss: 1.1090 - val_categorical_accuracy: 0.5199\n",
            "Epoch 33/200\n",
            "297/297 [==============================] - 22s 75ms/step - loss: 1.1157 - categorical_accuracy: 0.4920 - val_loss: 1.1176 - val_categorical_accuracy: 0.5085\n",
            "Epoch 34/200\n",
            "297/297 [==============================] - 22s 75ms/step - loss: 1.1315 - categorical_accuracy: 0.4916 - val_loss: 1.0795 - val_categorical_accuracy: 0.5180\n",
            "Epoch 35/200\n",
            "297/297 [==============================] - 22s 75ms/step - loss: 1.1391 - categorical_accuracy: 0.4792 - val_loss: 1.0853 - val_categorical_accuracy: 0.5294\n",
            "Epoch 36/200\n",
            "297/297 [==============================] - 22s 75ms/step - loss: 1.1248 - categorical_accuracy: 0.4855 - val_loss: 1.0774 - val_categorical_accuracy: 0.5370\n",
            "Epoch 37/200\n",
            "297/297 [==============================] - 22s 75ms/step - loss: 1.1133 - categorical_accuracy: 0.5063 - val_loss: 1.0579 - val_categorical_accuracy: 0.5256\n",
            "Epoch 38/200\n",
            "297/297 [==============================] - 23s 76ms/step - loss: 1.1169 - categorical_accuracy: 0.4847 - val_loss: 1.1060 - val_categorical_accuracy: 0.5009\n",
            "Epoch 39/200\n",
            "297/297 [==============================] - 23s 76ms/step - loss: 1.2362 - categorical_accuracy: 0.4403 - val_loss: 1.3601 - val_categorical_accuracy: 0.3548\n",
            "Epoch 40/200\n",
            "297/297 [==============================] - 22s 75ms/step - loss: 1.2876 - categorical_accuracy: 0.3776 - val_loss: 1.3095 - val_categorical_accuracy: 0.4440\n",
            "Epoch 41/200\n",
            "297/297 [==============================] - 22s 75ms/step - loss: 1.2364 - categorical_accuracy: 0.4279 - val_loss: 1.1947 - val_categorical_accuracy: 0.4763\n",
            "Epoch 42/200\n",
            "297/297 [==============================] - 22s 76ms/step - loss: 1.2350 - categorical_accuracy: 0.4417 - val_loss: 1.2400 - val_categorical_accuracy: 0.3928\n",
            "Epoch 43/200\n",
            "297/297 [==============================] - 23s 76ms/step - loss: 1.2487 - categorical_accuracy: 0.4012 - val_loss: 1.1738 - val_categorical_accuracy: 0.4972\n",
            "Epoch 44/200\n",
            "297/297 [==============================] - 22s 75ms/step - loss: 1.2724 - categorical_accuracy: 0.4126 - val_loss: 1.1658 - val_categorical_accuracy: 0.4991\n",
            "Epoch 45/200\n",
            "297/297 [==============================] - 22s 75ms/step - loss: 1.2382 - categorical_accuracy: 0.4255 - val_loss: 1.4029 - val_categorical_accuracy: 0.4061\n",
            "Epoch 46/200\n",
            "297/297 [==============================] - 22s 75ms/step - loss: 1.2924 - categorical_accuracy: 0.4098 - val_loss: 1.2011 - val_categorical_accuracy: 0.4706\n",
            "Epoch 47/200\n",
            "297/297 [==============================] - 22s 75ms/step - loss: 1.1881 - categorical_accuracy: 0.4651 - val_loss: 1.2080 - val_categorical_accuracy: 0.4801\n",
            "Epoch 48/200\n",
            "297/297 [==============================] - 22s 75ms/step - loss: 1.2045 - categorical_accuracy: 0.4490 - val_loss: 1.1192 - val_categorical_accuracy: 0.5085\n",
            "Epoch 49/200\n",
            "297/297 [==============================] - 22s 75ms/step - loss: 1.1815 - categorical_accuracy: 0.4638 - val_loss: 1.2047 - val_categorical_accuracy: 0.4668\n",
            "Epoch 50/200\n",
            "297/297 [==============================] - 22s 75ms/step - loss: 1.1968 - categorical_accuracy: 0.4506 - val_loss: 1.1582 - val_categorical_accuracy: 0.4934\n",
            "Epoch 51/200\n",
            "297/297 [==============================] - 22s 75ms/step - loss: 1.2279 - categorical_accuracy: 0.4271 - val_loss: 1.1179 - val_categorical_accuracy: 0.5142\n",
            "Epoch 52/200\n",
            "297/297 [==============================] - 22s 75ms/step - loss: 1.1890 - categorical_accuracy: 0.4724 - val_loss: 1.1800 - val_categorical_accuracy: 0.4858\n",
            "Epoch 53/200\n",
            "297/297 [==============================] - 22s 75ms/step - loss: 1.2051 - categorical_accuracy: 0.4561 - val_loss: 1.1824 - val_categorical_accuracy: 0.4706\n",
            "Epoch 54/200\n",
            "297/297 [==============================] - 22s 75ms/step - loss: 1.1753 - categorical_accuracy: 0.4698 - val_loss: 1.2285 - val_categorical_accuracy: 0.4478\n",
            "Epoch 55/200\n",
            "297/297 [==============================] - 22s 75ms/step - loss: 1.2203 - categorical_accuracy: 0.4372 - val_loss: 1.1804 - val_categorical_accuracy: 0.4440\n",
            "Epoch 56/200\n",
            "297/297 [==============================] - 22s 75ms/step - loss: 1.1832 - categorical_accuracy: 0.4575 - val_loss: 1.1911 - val_categorical_accuracy: 0.4839\n",
            "Epoch 57/200\n",
            "297/297 [==============================] - 22s 75ms/step - loss: 1.2089 - categorical_accuracy: 0.4414 - val_loss: 1.1274 - val_categorical_accuracy: 0.4915\n",
            "Epoch 58/200\n",
            "297/297 [==============================] - 22s 75ms/step - loss: 1.2209 - categorical_accuracy: 0.4446 - val_loss: 1.1943 - val_categorical_accuracy: 0.4497\n",
            "Epoch 59/200\n",
            "297/297 [==============================] - 22s 75ms/step - loss: 1.1855 - categorical_accuracy: 0.4431 - val_loss: 1.2152 - val_categorical_accuracy: 0.4175\n",
            "Epoch 60/200\n",
            "297/297 [==============================] - 22s 75ms/step - loss: 1.2127 - categorical_accuracy: 0.4265 - val_loss: 1.1371 - val_categorical_accuracy: 0.5047\n",
            "Epoch 61/200\n",
            "297/297 [==============================] - 22s 75ms/step - loss: 1.1887 - categorical_accuracy: 0.4478 - val_loss: 1.1746 - val_categorical_accuracy: 0.4839\n",
            "Epoch 62/200\n",
            "297/297 [==============================] - 22s 75ms/step - loss: 1.1793 - categorical_accuracy: 0.4654 - val_loss: 1.1951 - val_categorical_accuracy: 0.4801\n",
            "Epoch 63/200\n",
            "297/297 [==============================] - 22s 75ms/step - loss: 1.2029 - categorical_accuracy: 0.4602 - val_loss: 1.1568 - val_categorical_accuracy: 0.5085\n",
            "Epoch 64/200\n",
            "297/297 [==============================] - 22s 75ms/step - loss: 1.1853 - categorical_accuracy: 0.4649 - val_loss: 1.1032 - val_categorical_accuracy: 0.5028\n",
            "Epoch 65/200\n",
            "297/297 [==============================] - 22s 75ms/step - loss: 1.1927 - categorical_accuracy: 0.4425 - val_loss: 1.1536 - val_categorical_accuracy: 0.4801\n",
            "Epoch 66/200\n",
            "297/297 [==============================] - 22s 75ms/step - loss: 1.1968 - categorical_accuracy: 0.4467 - val_loss: 1.2351 - val_categorical_accuracy: 0.4706\n",
            "Epoch 67/200\n",
            "297/297 [==============================] - 22s 75ms/step - loss: 1.1980 - categorical_accuracy: 0.4596 - val_loss: 1.1402 - val_categorical_accuracy: 0.4839\n",
            "Epoch 68/200\n",
            "297/297 [==============================] - 22s 75ms/step - loss: 1.1949 - categorical_accuracy: 0.4399 - val_loss: 1.1739 - val_categorical_accuracy: 0.4687\n",
            "Epoch 69/200\n",
            "297/297 [==============================] - 22s 75ms/step - loss: 1.1835 - categorical_accuracy: 0.4602 - val_loss: 1.1312 - val_categorical_accuracy: 0.5085\n",
            "Epoch 70/200\n",
            "297/297 [==============================] - 22s 75ms/step - loss: 1.1876 - categorical_accuracy: 0.4584 - val_loss: 1.1607 - val_categorical_accuracy: 0.4953\n",
            "Epoch 71/200\n",
            "297/297 [==============================] - 22s 75ms/step - loss: 1.1979 - categorical_accuracy: 0.4461 - val_loss: 1.1141 - val_categorical_accuracy: 0.4915\n",
            "Epoch 72/200\n",
            "297/297 [==============================] - 22s 75ms/step - loss: 1.1693 - categorical_accuracy: 0.4674 - val_loss: 1.1172 - val_categorical_accuracy: 0.4839\n",
            "Epoch 73/200\n",
            "297/297 [==============================] - 22s 75ms/step - loss: 1.1731 - categorical_accuracy: 0.4628 - val_loss: 1.1488 - val_categorical_accuracy: 0.4706\n",
            "Epoch 74/200\n",
            "297/297 [==============================] - 22s 75ms/step - loss: 1.2217 - categorical_accuracy: 0.4347 - val_loss: 1.1286 - val_categorical_accuracy: 0.4915\n",
            "Epoch 75/200\n",
            "297/297 [==============================] - 22s 75ms/step - loss: 1.1695 - categorical_accuracy: 0.4725 - val_loss: 1.1381 - val_categorical_accuracy: 0.4896\n",
            "Epoch 76/200\n",
            "297/297 [==============================] - 22s 75ms/step - loss: 1.1751 - categorical_accuracy: 0.4674 - val_loss: 1.1181 - val_categorical_accuracy: 0.5104\n",
            "Epoch 77/200\n",
            "297/297 [==============================] - 22s 75ms/step - loss: 1.1818 - categorical_accuracy: 0.4629 - val_loss: 1.1304 - val_categorical_accuracy: 0.4801\n",
            "Epoch 78/200\n",
            "297/297 [==============================] - 22s 75ms/step - loss: 1.1619 - categorical_accuracy: 0.4697 - val_loss: 1.1357 - val_categorical_accuracy: 0.4896\n",
            "Epoch 79/200\n",
            "297/297 [==============================] - 22s 75ms/step - loss: 1.1738 - categorical_accuracy: 0.4605 - val_loss: 1.1684 - val_categorical_accuracy: 0.4440\n",
            "Epoch 80/200\n",
            "297/297 [==============================] - 22s 75ms/step - loss: 1.1775 - categorical_accuracy: 0.4508 - val_loss: 1.1566 - val_categorical_accuracy: 0.4877\n",
            "Epoch 81/200\n",
            "297/297 [==============================] - 22s 75ms/step - loss: 1.1830 - categorical_accuracy: 0.4600 - val_loss: 1.1149 - val_categorical_accuracy: 0.5275\n",
            "Epoch 82/200\n",
            "297/297 [==============================] - 22s 75ms/step - loss: 1.1815 - categorical_accuracy: 0.4494 - val_loss: 1.0862 - val_categorical_accuracy: 0.5218\n",
            "Epoch 83/200\n",
            "297/297 [==============================] - 22s 75ms/step - loss: 1.1706 - categorical_accuracy: 0.4661 - val_loss: 1.1215 - val_categorical_accuracy: 0.4915\n",
            "Epoch 84/200\n",
            "297/297 [==============================] - 22s 75ms/step - loss: 1.1863 - categorical_accuracy: 0.4561 - val_loss: 1.1112 - val_categorical_accuracy: 0.5047\n",
            "Epoch 85/200\n",
            "297/297 [==============================] - 22s 75ms/step - loss: 1.1860 - categorical_accuracy: 0.4557 - val_loss: 1.1408 - val_categorical_accuracy: 0.4934\n",
            "Epoch 86/200\n",
            "297/297 [==============================] - 22s 75ms/step - loss: 1.1928 - categorical_accuracy: 0.4616 - val_loss: 1.1862 - val_categorical_accuracy: 0.4478\n",
            "Epoch 87/200\n",
            "297/297 [==============================] - 22s 75ms/step - loss: 1.1783 - categorical_accuracy: 0.4414 - val_loss: 1.2522 - val_categorical_accuracy: 0.4383\n",
            "Epoch 88/200\n",
            "297/297 [==============================] - 22s 75ms/step - loss: 1.1774 - categorical_accuracy: 0.4698 - val_loss: 1.1261 - val_categorical_accuracy: 0.5180\n",
            "Epoch 89/200\n",
            "297/297 [==============================] - 22s 75ms/step - loss: 1.1700 - categorical_accuracy: 0.4629 - val_loss: 1.1073 - val_categorical_accuracy: 0.4915\n",
            "Epoch 90/200\n",
            "297/297 [==============================] - 22s 75ms/step - loss: 1.1803 - categorical_accuracy: 0.4789 - val_loss: 1.1057 - val_categorical_accuracy: 0.4991\n",
            "Epoch 91/200\n",
            "297/297 [==============================] - 22s 75ms/step - loss: 1.1603 - categorical_accuracy: 0.4790 - val_loss: 1.0961 - val_categorical_accuracy: 0.5066\n",
            "Epoch 92/200\n",
            "297/297 [==============================] - 22s 75ms/step - loss: 1.1656 - categorical_accuracy: 0.4728 - val_loss: 1.1102 - val_categorical_accuracy: 0.5294\n",
            "Epoch 93/200\n",
            "297/297 [==============================] - 22s 75ms/step - loss: 1.1841 - categorical_accuracy: 0.4561 - val_loss: 1.1083 - val_categorical_accuracy: 0.5275\n",
            "Epoch 94/200\n",
            "297/297 [==============================] - 22s 75ms/step - loss: 1.1701 - categorical_accuracy: 0.4504 - val_loss: 1.0981 - val_categorical_accuracy: 0.5294\n",
            "Epoch 95/200\n",
            "297/297 [==============================] - 22s 75ms/step - loss: 1.1466 - categorical_accuracy: 0.4713 - val_loss: 1.1611 - val_categorical_accuracy: 0.4991\n",
            "Epoch 96/200\n",
            "297/297 [==============================] - 22s 75ms/step - loss: 1.1821 - categorical_accuracy: 0.4668 - val_loss: 1.2337 - val_categorical_accuracy: 0.4649\n",
            "Epoch 97/200\n",
            "297/297 [==============================] - 22s 76ms/step - loss: 1.1832 - categorical_accuracy: 0.4503 - val_loss: 1.1261 - val_categorical_accuracy: 0.5066\n",
            "Epoch 98/200\n",
            "297/297 [==============================] - 22s 75ms/step - loss: 1.1655 - categorical_accuracy: 0.4699 - val_loss: 1.2600 - val_categorical_accuracy: 0.4118\n",
            "Epoch 99/200\n",
            "297/297 [==============================] - 22s 75ms/step - loss: 1.1856 - categorical_accuracy: 0.4470 - val_loss: 1.1584 - val_categorical_accuracy: 0.4801\n",
            "Epoch 100/200\n",
            "297/297 [==============================] - 22s 75ms/step - loss: 1.1623 - categorical_accuracy: 0.4530 - val_loss: 1.1091 - val_categorical_accuracy: 0.5009\n",
            "Epoch 101/200\n",
            "297/297 [==============================] - 22s 75ms/step - loss: 1.1574 - categorical_accuracy: 0.4687 - val_loss: 1.1025 - val_categorical_accuracy: 0.5028\n",
            "Epoch 102/200\n",
            "297/297 [==============================] - 22s 75ms/step - loss: 1.1620 - categorical_accuracy: 0.4748 - val_loss: 1.0898 - val_categorical_accuracy: 0.5180\n",
            "Epoch 103/200\n",
            "297/297 [==============================] - 22s 75ms/step - loss: 1.1531 - categorical_accuracy: 0.4826 - val_loss: 1.0826 - val_categorical_accuracy: 0.5161\n",
            "Epoch 104/200\n",
            "297/297 [==============================] - 22s 75ms/step - loss: 1.1525 - categorical_accuracy: 0.4797 - val_loss: 1.1054 - val_categorical_accuracy: 0.4858\n",
            "Epoch 105/200\n",
            "297/297 [==============================] - 22s 75ms/step - loss: 1.1562 - categorical_accuracy: 0.4745 - val_loss: 1.1369 - val_categorical_accuracy: 0.5009\n",
            "Epoch 106/200\n",
            "297/297 [==============================] - 22s 75ms/step - loss: 1.1597 - categorical_accuracy: 0.4613 - val_loss: 1.1293 - val_categorical_accuracy: 0.4934\n",
            "Epoch 107/200\n",
            "297/297 [==============================] - 22s 75ms/step - loss: 1.1749 - categorical_accuracy: 0.4648 - val_loss: 1.0740 - val_categorical_accuracy: 0.5180\n",
            "Epoch 108/200\n",
            "297/297 [==============================] - 22s 75ms/step - loss: 1.1489 - categorical_accuracy: 0.4874 - val_loss: 1.0964 - val_categorical_accuracy: 0.5066\n",
            "Epoch 109/200\n",
            "297/297 [==============================] - 22s 75ms/step - loss: 1.1412 - categorical_accuracy: 0.4816 - val_loss: 1.1786 - val_categorical_accuracy: 0.4706\n",
            "Epoch 110/200\n",
            "297/297 [==============================] - 22s 75ms/step - loss: 1.1527 - categorical_accuracy: 0.4724 - val_loss: 1.1472 - val_categorical_accuracy: 0.5009\n",
            "Epoch 111/200\n",
            "297/297 [==============================] - 22s 75ms/step - loss: 1.1454 - categorical_accuracy: 0.4826 - val_loss: 1.0876 - val_categorical_accuracy: 0.5199\n",
            "Epoch 112/200\n",
            "297/297 [==============================] - 22s 75ms/step - loss: 1.1840 - categorical_accuracy: 0.4687 - val_loss: 1.2005 - val_categorical_accuracy: 0.4630\n",
            "Epoch 113/200\n",
            "297/297 [==============================] - 22s 75ms/step - loss: 1.1611 - categorical_accuracy: 0.4795 - val_loss: 1.1743 - val_categorical_accuracy: 0.4630\n",
            "Epoch 114/200\n",
            "297/297 [==============================] - 22s 75ms/step - loss: 1.1525 - categorical_accuracy: 0.4702 - val_loss: 1.2203 - val_categorical_accuracy: 0.4649\n",
            "Epoch 115/200\n",
            "297/297 [==============================] - 22s 75ms/step - loss: 1.1761 - categorical_accuracy: 0.4608 - val_loss: 1.1211 - val_categorical_accuracy: 0.5066\n",
            "Epoch 116/200\n",
            "297/297 [==============================] - 22s 75ms/step - loss: 1.1529 - categorical_accuracy: 0.4669 - val_loss: 1.1447 - val_categorical_accuracy: 0.4782\n",
            "Epoch 117/200\n",
            "297/297 [==============================] - 22s 75ms/step - loss: 1.1544 - categorical_accuracy: 0.4944 - val_loss: 1.1314 - val_categorical_accuracy: 0.5028\n",
            "Epoch 118/200\n",
            "297/297 [==============================] - 22s 75ms/step - loss: 1.1650 - categorical_accuracy: 0.4808 - val_loss: 1.1642 - val_categorical_accuracy: 0.4763\n",
            "Epoch 119/200\n",
            "297/297 [==============================] - 22s 75ms/step - loss: 1.1433 - categorical_accuracy: 0.4714 - val_loss: 1.1096 - val_categorical_accuracy: 0.5066\n",
            "Epoch 120/200\n",
            "297/297 [==============================] - 22s 76ms/step - loss: 1.1636 - categorical_accuracy: 0.4662 - val_loss: 1.1384 - val_categorical_accuracy: 0.4877\n",
            "Epoch 121/200\n",
            "297/297 [==============================] - 22s 76ms/step - loss: 1.1578 - categorical_accuracy: 0.4704 - val_loss: 1.1169 - val_categorical_accuracy: 0.5009\n",
            "Epoch 122/200\n",
            "297/297 [==============================] - 23s 76ms/step - loss: 1.1339 - categorical_accuracy: 0.4857 - val_loss: 1.1214 - val_categorical_accuracy: 0.4953\n",
            "Epoch 123/200\n",
            "297/297 [==============================] - 23s 76ms/step - loss: 1.1603 - categorical_accuracy: 0.4764 - val_loss: 1.1366 - val_categorical_accuracy: 0.4839\n",
            "Epoch 124/200\n",
            "297/297 [==============================] - 22s 76ms/step - loss: 1.1727 - categorical_accuracy: 0.4611 - val_loss: 1.1569 - val_categorical_accuracy: 0.4820\n",
            "Epoch 125/200\n",
            "297/297 [==============================] - 22s 76ms/step - loss: 1.1589 - categorical_accuracy: 0.4781 - val_loss: 1.0956 - val_categorical_accuracy: 0.5180\n",
            "Epoch 126/200\n",
            "297/297 [==============================] - 22s 76ms/step - loss: 1.1335 - categorical_accuracy: 0.4845 - val_loss: 1.1912 - val_categorical_accuracy: 0.4763\n",
            "Epoch 127/200\n",
            "297/297 [==============================] - 22s 76ms/step - loss: 1.1647 - categorical_accuracy: 0.4638 - val_loss: 1.1104 - val_categorical_accuracy: 0.5180\n",
            "Epoch 128/200\n",
            "297/297 [==============================] - 22s 75ms/step - loss: 1.1614 - categorical_accuracy: 0.4722 - val_loss: 1.1961 - val_categorical_accuracy: 0.4421\n",
            "Epoch 129/200\n",
            "297/297 [==============================] - 22s 75ms/step - loss: 1.1758 - categorical_accuracy: 0.4604 - val_loss: 1.1176 - val_categorical_accuracy: 0.5332\n",
            "Epoch 130/200\n",
            "297/297 [==============================] - 22s 76ms/step - loss: 1.1652 - categorical_accuracy: 0.4659 - val_loss: 1.1361 - val_categorical_accuracy: 0.5123\n",
            "Epoch 131/200\n",
            "297/297 [==============================] - 22s 76ms/step - loss: 1.1643 - categorical_accuracy: 0.4621 - val_loss: 1.1395 - val_categorical_accuracy: 0.4801\n",
            "Epoch 132/200\n",
            "297/297 [==============================] - 23s 76ms/step - loss: 1.1393 - categorical_accuracy: 0.4765 - val_loss: 1.1580 - val_categorical_accuracy: 0.4858\n",
            "Epoch 133/200\n",
            "297/297 [==============================] - 22s 76ms/step - loss: 1.1487 - categorical_accuracy: 0.4668 - val_loss: 1.1471 - val_categorical_accuracy: 0.4896\n",
            "Epoch 134/200\n",
            "297/297 [==============================] - 22s 76ms/step - loss: 1.1525 - categorical_accuracy: 0.4659 - val_loss: 1.1376 - val_categorical_accuracy: 0.5028\n",
            "Epoch 135/200\n",
            "297/297 [==============================] - 22s 75ms/step - loss: 1.1603 - categorical_accuracy: 0.4688 - val_loss: 1.1292 - val_categorical_accuracy: 0.4801\n",
            "Epoch 136/200\n",
            "297/297 [==============================] - 22s 75ms/step - loss: 1.1621 - categorical_accuracy: 0.4701 - val_loss: 1.2180 - val_categorical_accuracy: 0.4687\n",
            "Epoch 137/200\n",
            "297/297 [==============================] - 22s 76ms/step - loss: 1.1748 - categorical_accuracy: 0.4512 - val_loss: 1.1307 - val_categorical_accuracy: 0.4953\n",
            "Epoch 138/200\n",
            "297/297 [==============================] - 22s 76ms/step - loss: 1.1625 - categorical_accuracy: 0.4721 - val_loss: 1.1515 - val_categorical_accuracy: 0.4649\n",
            "Epoch 139/200\n",
            "297/297 [==============================] - 23s 76ms/step - loss: 1.1626 - categorical_accuracy: 0.4692 - val_loss: 1.1731 - val_categorical_accuracy: 0.4554\n",
            "Epoch 140/200\n",
            "297/297 [==============================] - 22s 75ms/step - loss: 1.1565 - categorical_accuracy: 0.4732 - val_loss: 1.1206 - val_categorical_accuracy: 0.4934\n",
            "Epoch 141/200\n",
            "297/297 [==============================] - 22s 76ms/step - loss: 1.1394 - categorical_accuracy: 0.4869 - val_loss: 1.1331 - val_categorical_accuracy: 0.5123\n",
            "Epoch 142/200\n",
            "297/297 [==============================] - 22s 76ms/step - loss: 1.1610 - categorical_accuracy: 0.4613 - val_loss: 1.1029 - val_categorical_accuracy: 0.5066\n",
            "Epoch 143/200\n",
            "297/297 [==============================] - 23s 76ms/step - loss: 1.1734 - categorical_accuracy: 0.4625 - val_loss: 1.1165 - val_categorical_accuracy: 0.5123\n",
            "Epoch 144/200\n",
            "297/297 [==============================] - 23s 76ms/step - loss: 1.1562 - categorical_accuracy: 0.4724 - val_loss: 1.2174 - val_categorical_accuracy: 0.4744\n",
            "Epoch 145/200\n",
            "297/297 [==============================] - 23s 76ms/step - loss: 1.1620 - categorical_accuracy: 0.4606 - val_loss: 1.1755 - val_categorical_accuracy: 0.4611\n",
            "Epoch 146/200\n",
            "297/297 [==============================] - 23s 76ms/step - loss: 1.1576 - categorical_accuracy: 0.4775 - val_loss: 1.1858 - val_categorical_accuracy: 0.4687\n",
            "Epoch 147/200\n",
            "297/297 [==============================] - 22s 76ms/step - loss: 1.1505 - categorical_accuracy: 0.4577 - val_loss: 1.2575 - val_categorical_accuracy: 0.4554\n",
            "Epoch 148/200\n",
            "297/297 [==============================] - 23s 76ms/step - loss: 1.1479 - categorical_accuracy: 0.4702 - val_loss: 1.1358 - val_categorical_accuracy: 0.4915\n",
            "Epoch 149/200\n",
            "297/297 [==============================] - 23s 76ms/step - loss: 1.1461 - categorical_accuracy: 0.4781 - val_loss: 1.1464 - val_categorical_accuracy: 0.4858\n",
            "Epoch 150/200\n",
            "297/297 [==============================] - 22s 76ms/step - loss: 1.1404 - categorical_accuracy: 0.4679 - val_loss: 1.1094 - val_categorical_accuracy: 0.5009\n",
            "Epoch 151/200\n",
            "297/297 [==============================] - 22s 76ms/step - loss: 1.1420 - categorical_accuracy: 0.4783 - val_loss: 1.1181 - val_categorical_accuracy: 0.4915\n",
            "Epoch 152/200\n",
            "297/297 [==============================] - 23s 76ms/step - loss: 1.1119 - categorical_accuracy: 0.4803 - val_loss: 1.1221 - val_categorical_accuracy: 0.4972\n",
            "Epoch 153/200\n",
            "297/297 [==============================] - 23s 76ms/step - loss: 1.1459 - categorical_accuracy: 0.4665 - val_loss: 1.1804 - val_categorical_accuracy: 0.4478\n",
            "Epoch 154/200\n",
            "297/297 [==============================] - 23s 76ms/step - loss: 1.1446 - categorical_accuracy: 0.4815 - val_loss: 1.1815 - val_categorical_accuracy: 0.4307\n",
            "Epoch 155/200\n",
            "297/297 [==============================] - 23s 76ms/step - loss: 1.1511 - categorical_accuracy: 0.4703 - val_loss: 1.1511 - val_categorical_accuracy: 0.4915\n",
            "Epoch 156/200\n",
            "297/297 [==============================] - 23s 76ms/step - loss: 1.1649 - categorical_accuracy: 0.4649 - val_loss: 1.0993 - val_categorical_accuracy: 0.4972\n",
            "Epoch 157/200\n",
            "297/297 [==============================] - 22s 76ms/step - loss: 1.1223 - categorical_accuracy: 0.4813 - val_loss: 1.1859 - val_categorical_accuracy: 0.4649\n",
            "Epoch 158/200\n",
            "297/297 [==============================] - 23s 76ms/step - loss: 1.1369 - categorical_accuracy: 0.4587 - val_loss: 1.1522 - val_categorical_accuracy: 0.4402\n",
            "Epoch 159/200\n",
            "297/297 [==============================] - 23s 76ms/step - loss: 1.1401 - categorical_accuracy: 0.4675 - val_loss: 1.1123 - val_categorical_accuracy: 0.4421\n",
            "Epoch 160/200\n",
            "297/297 [==============================] - 23s 76ms/step - loss: 1.1469 - categorical_accuracy: 0.4618 - val_loss: 1.0996 - val_categorical_accuracy: 0.5085\n",
            "Epoch 161/200\n",
            "297/297 [==============================] - 23s 76ms/step - loss: 1.1107 - categorical_accuracy: 0.4854 - val_loss: 1.0921 - val_categorical_accuracy: 0.5142\n",
            "Epoch 162/200\n",
            "297/297 [==============================] - 23s 76ms/step - loss: 1.1308 - categorical_accuracy: 0.4680 - val_loss: 1.1046 - val_categorical_accuracy: 0.4858\n",
            "Epoch 163/200\n",
            "297/297 [==============================] - 23s 76ms/step - loss: 1.1394 - categorical_accuracy: 0.4761 - val_loss: 1.0989 - val_categorical_accuracy: 0.5123\n",
            "Epoch 164/200\n",
            "297/297 [==============================] - 23s 76ms/step - loss: 1.1062 - categorical_accuracy: 0.4945 - val_loss: 1.0780 - val_categorical_accuracy: 0.5066\n",
            "Epoch 165/200\n",
            "297/297 [==============================] - 23s 76ms/step - loss: 1.1082 - categorical_accuracy: 0.4818 - val_loss: 1.0826 - val_categorical_accuracy: 0.5066\n",
            "Epoch 166/200\n",
            "297/297 [==============================] - 23s 76ms/step - loss: 1.1479 - categorical_accuracy: 0.4675 - val_loss: 1.1809 - val_categorical_accuracy: 0.4364\n",
            "Epoch 167/200\n",
            "297/297 [==============================] - 23s 76ms/step - loss: 1.1533 - categorical_accuracy: 0.4654 - val_loss: 1.2100 - val_categorical_accuracy: 0.4269\n",
            "Epoch 168/200\n",
            "297/297 [==============================] - 23s 76ms/step - loss: 1.1498 - categorical_accuracy: 0.4627 - val_loss: 1.1506 - val_categorical_accuracy: 0.4839\n",
            "Epoch 169/200\n",
            "297/297 [==============================] - 23s 76ms/step - loss: 1.1035 - categorical_accuracy: 0.4891 - val_loss: 1.1137 - val_categorical_accuracy: 0.4706\n",
            "Epoch 170/200\n",
            "297/297 [==============================] - 23s 76ms/step - loss: 1.1339 - categorical_accuracy: 0.4870 - val_loss: 1.0982 - val_categorical_accuracy: 0.5123\n",
            "Epoch 171/200\n",
            "297/297 [==============================] - 23s 76ms/step - loss: 1.1401 - categorical_accuracy: 0.4600 - val_loss: 1.1057 - val_categorical_accuracy: 0.4991\n",
            "Epoch 172/200\n",
            "297/297 [==============================] - 23s 76ms/step - loss: 1.1123 - categorical_accuracy: 0.4732 - val_loss: 1.0814 - val_categorical_accuracy: 0.4934\n",
            "Epoch 173/200\n",
            "297/297 [==============================] - 23s 76ms/step - loss: 1.1377 - categorical_accuracy: 0.4708 - val_loss: 1.1403 - val_categorical_accuracy: 0.4725\n",
            "Epoch 174/200\n",
            "297/297 [==============================] - 23s 77ms/step - loss: 1.1435 - categorical_accuracy: 0.4739 - val_loss: 1.1897 - val_categorical_accuracy: 0.4725\n",
            "Epoch 175/200\n",
            "297/297 [==============================] - 23s 76ms/step - loss: 1.1212 - categorical_accuracy: 0.4741 - val_loss: 1.1158 - val_categorical_accuracy: 0.4763\n",
            "Epoch 176/200\n",
            "297/297 [==============================] - 23s 76ms/step - loss: 1.1528 - categorical_accuracy: 0.4809 - val_loss: 1.2747 - val_categorical_accuracy: 0.4535\n",
            "Epoch 177/200\n",
            "297/297 [==============================] - 23s 78ms/step - loss: 1.1371 - categorical_accuracy: 0.4583 - val_loss: 1.3201 - val_categorical_accuracy: 0.4061\n",
            "Epoch 178/200\n",
            "297/297 [==============================] - 23s 76ms/step - loss: 1.1231 - categorical_accuracy: 0.4854 - val_loss: 1.2506 - val_categorical_accuracy: 0.4535\n",
            "Epoch 179/200\n",
            "297/297 [==============================] - 23s 76ms/step - loss: 1.1391 - categorical_accuracy: 0.4630 - val_loss: 1.1368 - val_categorical_accuracy: 0.4687\n",
            "Epoch 180/200\n",
            "297/297 [==============================] - 23s 76ms/step - loss: 1.1073 - categorical_accuracy: 0.4859 - val_loss: 1.1286 - val_categorical_accuracy: 0.4858\n",
            "Epoch 181/200\n",
            "297/297 [==============================] - 23s 76ms/step - loss: 1.1214 - categorical_accuracy: 0.4766 - val_loss: 1.2081 - val_categorical_accuracy: 0.4288\n",
            "Epoch 182/200\n",
            "297/297 [==============================] - 23s 76ms/step - loss: 1.1337 - categorical_accuracy: 0.4799 - val_loss: 1.1291 - val_categorical_accuracy: 0.4972\n",
            "Epoch 183/200\n",
            "297/297 [==============================] - 23s 76ms/step - loss: 1.1293 - categorical_accuracy: 0.4687 - val_loss: 1.1089 - val_categorical_accuracy: 0.4877\n",
            "Epoch 184/200\n",
            "297/297 [==============================] - 23s 76ms/step - loss: 1.1321 - categorical_accuracy: 0.4811 - val_loss: 1.1046 - val_categorical_accuracy: 0.4611\n",
            "Epoch 185/200\n",
            "297/297 [==============================] - 23s 76ms/step - loss: 1.1090 - categorical_accuracy: 0.4984 - val_loss: 1.1665 - val_categorical_accuracy: 0.4630\n",
            "Epoch 186/200\n",
            "297/297 [==============================] - 23s 76ms/step - loss: 1.1184 - categorical_accuracy: 0.4823 - val_loss: 1.1830 - val_categorical_accuracy: 0.4535\n",
            "Epoch 187/200\n",
            "297/297 [==============================] - 23s 76ms/step - loss: 1.1224 - categorical_accuracy: 0.4803 - val_loss: 1.1374 - val_categorical_accuracy: 0.4782\n",
            "Epoch 188/200\n",
            "297/297 [==============================] - 23s 76ms/step - loss: 1.1159 - categorical_accuracy: 0.4954 - val_loss: 1.2362 - val_categorical_accuracy: 0.4820\n",
            "Epoch 189/200\n",
            "297/297 [==============================] - 23s 76ms/step - loss: 1.1450 - categorical_accuracy: 0.4756 - val_loss: 1.2154 - val_categorical_accuracy: 0.4554\n",
            "Epoch 190/200\n",
            "297/297 [==============================] - 23s 76ms/step - loss: 1.1395 - categorical_accuracy: 0.4768 - val_loss: 1.1838 - val_categorical_accuracy: 0.4649\n",
            "Epoch 191/200\n",
            "297/297 [==============================] - 23s 76ms/step - loss: 1.1112 - categorical_accuracy: 0.5022 - val_loss: 1.3268 - val_categorical_accuracy: 0.4839\n",
            "Epoch 192/200\n",
            "297/297 [==============================] - 23s 76ms/step - loss: 1.1490 - categorical_accuracy: 0.4666 - val_loss: 1.3409 - val_categorical_accuracy: 0.4877\n",
            "Epoch 193/200\n",
            "297/297 [==============================] - 23s 76ms/step - loss: 1.1513 - categorical_accuracy: 0.4827 - val_loss: 1.3234 - val_categorical_accuracy: 0.4782\n",
            "Epoch 194/200\n",
            "297/297 [==============================] - 23s 76ms/step - loss: 1.1442 - categorical_accuracy: 0.4795 - val_loss: 1.1621 - val_categorical_accuracy: 0.4839\n",
            "Epoch 195/200\n",
            "297/297 [==============================] - 23s 76ms/step - loss: 1.1150 - categorical_accuracy: 0.4876 - val_loss: 1.1073 - val_categorical_accuracy: 0.5085\n",
            "Epoch 196/200\n",
            "297/297 [==============================] - 23s 76ms/step - loss: 1.0976 - categorical_accuracy: 0.4769 - val_loss: 1.0998 - val_categorical_accuracy: 0.4991\n",
            "Epoch 197/200\n",
            "297/297 [==============================] - 23s 76ms/step - loss: 1.1441 - categorical_accuracy: 0.4594 - val_loss: 1.1388 - val_categorical_accuracy: 0.4763\n",
            "Epoch 198/200\n",
            "297/297 [==============================] - 23s 76ms/step - loss: 1.1145 - categorical_accuracy: 0.4813 - val_loss: 1.1402 - val_categorical_accuracy: 0.4763\n",
            "Epoch 199/200\n",
            "297/297 [==============================] - 23s 76ms/step - loss: 1.1036 - categorical_accuracy: 0.4808 - val_loss: 1.1727 - val_categorical_accuracy: 0.4801\n",
            "Epoch 200/200\n",
            "297/297 [==============================] - 23s 76ms/step - loss: 1.1128 - categorical_accuracy: 0.4918 - val_loss: 1.1669 - val_categorical_accuracy: 0.4782\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBXg3gsrQei2"
      },
      "source": [
        "model.save('/content/drive/MyDrive/Colab Notebooks/speech/dataset/conv1D_melspec_merged.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SyfTyHY2mRsz"
      },
      "source": [
        "###test_result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aC1K1ol-mRs1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d3706bc-97ab-42f9-8afd-0a1c0351aff3"
      },
      "source": [
        "d = {0: 'happy',\n",
        "     1: 'sad',\n",
        "     2: 'angry',\n",
        "     3: 'fear'}\n",
        "Y_test_pred = np.argmax(model.predict(X_test), axis=-1)\n",
        "Y_test_pred = list(map(lambda x: d[x], Y_test_pred))\n",
        "y_test = np.argmax(y_test, axis=-1)\n",
        "y_test = list(map(lambda x: d[x], y_test))\n",
        "print(classification_report(y_test, Y_test_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.89      0.37      0.52       155\n",
            "        fear       0.31      0.22      0.25       144\n",
            "       happy       0.35      0.36      0.35       151\n",
            "         sad       0.47      0.90      0.62       136\n",
            "\n",
            "    accuracy                           0.45       586\n",
            "   macro avg       0.50      0.46      0.44       586\n",
            "weighted avg       0.51      0.45      0.43       586\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "svW2gQfTmRs2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 483
        },
        "outputId": "5b84d93a-2a29-4551-fd9e-71b50bbc651b"
      },
      "source": [
        "import scikitplot as skplt\n",
        "\n",
        "skplt.metrics.plot_confusion_matrix(\n",
        "    y_test, \n",
        "    Y_test_pred,\n",
        "    figsize=(8,8))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fb6a6a32310>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vOFxBO2mRs3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vQHiqzXuW3ay"
      },
      "source": [
        "# Mel Spectrogram + conv2D:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AbvUHwMIW3bV"
      },
      "source": [
        "audio_duration = 3\n",
        "sampling_rate = 44100\n",
        "input_length = sampling_rate * audio_duration\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTz4bJz0XfIR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f420fba-9710-4e61-c522-71f83b7d24cd"
      },
      "source": [
        "features = []\n",
        "labels = []\n",
        "for i in range(len(Ravdess_DF['Paths'])):\n",
        "  if ((Ravdess_DF['Emotion'][i] == '03') | (Ravdess_DF['Emotion'][i] == '04') | \n",
        "      (Ravdess_DF['Emotion'][i] == '05') | (Ravdess_DF['Emotion'][i] == '06')):\n",
        "    signal, sample_rate = librosa.load(Ravdess_DF['Paths'][i], res_type='kaiser_fast',sr=22050*2)\n",
        "    signal,index = librosa.effects.trim(signal,top_db = 25)\n",
        "    signal = scipy.signal.wiener(signal)\n",
        "\n",
        "    if len(signal) > input_length:\n",
        "      signal = signal[0:input_length]\n",
        "    elif  input_length > len(signal):\n",
        "      max_offset = input_length - len(signal)  \n",
        "      signal = np.pad(signal, (0, max_offset), \"constant\")\n",
        "\n",
        "    melspec = librosa.feature.melspectrogram(signal, sr=sample_rate, n_mels=128,n_fft=2048,hop_length=512)   \n",
        "    melspec = np.expand_dims(melspec, axis=-1)\n",
        "\n",
        "    features.append(melspec)\n",
        "\n",
        "    if Ravdess_DF['Emotion'][i] == '03':\n",
        "      labels.append(0)\n",
        "    elif Ravdess_DF['Emotion'][i] == '04':\n",
        "      labels.append(1)\n",
        "    elif Ravdess_DF['Emotion'][i] == '05':\n",
        "      labels.append(2)\n",
        "    elif Ravdess_DF['Emotion'][i] == '06':\n",
        "      labels.append(3)\n",
        "\n",
        "for i in range(len(CREMA_D_df)):\n",
        "  if ((CREMA_D_df['Emotion'][i] == 'HAP') | (CREMA_D_df['Emotion'][i] == 'SAD') | \n",
        "      (CREMA_D_df['Emotion'][i] == 'ANG') | (CREMA_D_df['Emotion'][i] == 'FEA')):\n",
        "    \n",
        "    if CREMA_D_df['Emotion'][i] == 'HAP':\n",
        "      labels.append(0)\n",
        "    elif CREMA_D_df['Emotion'][i] == 'SAD':\n",
        "      labels.append(1)\n",
        "    elif CREMA_D_df['Emotion'][i] == 'ANG':\n",
        "      labels.append(2)\n",
        "    elif CREMA_D_df['Emotion'][i] == 'FEA':\n",
        "      labels.append(3)\n",
        "\n",
        "\n",
        "    signal, sr =  librosa.load(CREMA_D_df['Paths'][i])\n",
        "\n",
        "    if len(signal) > input_length:\n",
        "      signal = signal[0:input_length]\n",
        "    elif  input_length > len(signal):\n",
        "      max_offset = input_length - len(signal)  \n",
        "      signal = np.pad(signal, (0, max_offset), \"constant\")\n",
        "\n",
        "    melspec = librosa.feature.melspectrogram(signal, sr=sampling_rate, n_mels=128,n_fft=2048,hop_length=512)   \n",
        "    melspec = np.expand_dims(melspec, axis=-1)\n",
        "\n",
        "    features.append(melspec)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/scipy/signal/signaltools.py:1456: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  res *= (1 - noise / lVar)\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/signal/signaltools.py:1456: RuntimeWarning: invalid value encountered in multiply\n",
            "  res *= (1 - noise / lVar)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fzmHePCaZiM"
      },
      "source": [
        "X = features\n",
        "y = labels\n",
        "\n",
        "y = np.array(y)\n",
        "y = to_categorical(y)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=0)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=0)\n",
        "\n",
        "X_train = np.array(X_train)\n",
        "X_test = np.array(X_test)\n",
        "X_val = np.array(X_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lsI1T1_wW3bX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c03bbb4-6d12-4b4e-a29e-c296e5bda5e1"
      },
      "source": [
        "X_train.shape,X_test.shape,y_train.shape,y_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((4739, 128, 259, 1), (586, 128, 259, 1), (4739, 4), (586, 4))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LzVUl83kaRQt"
      },
      "source": [
        "### conv2D"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KvxTuJHKW3bY"
      },
      "source": [
        "# CNN I/P Config\n",
        "num_classes = 4\n",
        "input_shape = X_train.shape[1:]\n",
        "learning_rate = 0.0001\n",
        "decay = 1e-6\n",
        "momentum = 0.9"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LAcvZf5UW3bY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e24056fb-2063-4e6e-e04b-9d4faea6f421"
      },
      "source": [
        "model = Sequential(name='Audio_CNN_2D')\n",
        "\n",
        "# LFLB1\n",
        "model.add(Conv2D(filters=64, kernel_size=(3,3), strides=(1,1), padding='same',input_shape=input_shape))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Conv2D(filters=64, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(4,4), strides=(4,4)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(units=num_classes, activation='softmax'))\n",
        "\n",
        "# Model compilation\n",
        "opt = optimizers.SGD(lr=learning_rate, decay=decay, momentum=momentum, nesterov=True)\n",
        "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"Audio_CNN_2D\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 128, 259, 64)      640       \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 128, 259, 64)      256       \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 128, 259, 64)      0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 64, 129, 64)       0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 64, 129, 64)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 64, 129, 64)       36928     \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 64, 129, 64)       256       \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 64, 129, 64)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 16, 32, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 16, 32, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 32768)             0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 4)                 131076    \n",
            "=================================================================\n",
            "Total params: 169,156\n",
            "Trainable params: 168,900\n",
            "Non-trainable params: 256\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wpkX6KUYW3bb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb657566-25aa-4496-b2f0-f0954d86c9e7"
      },
      "source": [
        "#Train Config\n",
        "\n",
        "batch_size = 16\n",
        "num_epochs = 200\n",
        "\n",
        "# Model Training\n",
        "lr_reduce = ReduceLROnPlateau(monitor='val_loss', factor=0.9, patience=20, min_lr=0.000001)\n",
        "# Please change the model name accordingly.\n",
        "mcp_save = ModelCheckpoint('/content/Modelfull_2_1.h5', save_best_only=True, monitor='val_categorical_accuracy', mode='max')\n",
        "cnnhistory=model.fit(X_train, y_train, batch_size=batch_size, epochs=num_epochs,validation_data=(X_val, y_val), callbacks=[mcp_save, lr_reduce])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "297/297 [==============================] - 13s 34ms/step - loss: 2.9656 - categorical_accuracy: 0.3467 - val_loss: 1.3048 - val_categorical_accuracy: 0.4516\n",
            "Epoch 2/200\n",
            "297/297 [==============================] - 9s 31ms/step - loss: 1.8039 - categorical_accuracy: 0.4321 - val_loss: 1.2648 - val_categorical_accuracy: 0.4725\n",
            "Epoch 3/200\n",
            "297/297 [==============================] - 9s 31ms/step - loss: 1.4471 - categorical_accuracy: 0.4557 - val_loss: 1.2379 - val_categorical_accuracy: 0.4516\n",
            "Epoch 4/200\n",
            "297/297 [==============================] - 9s 31ms/step - loss: 1.3927 - categorical_accuracy: 0.4504 - val_loss: 1.2342 - val_categorical_accuracy: 0.4383\n",
            "Epoch 5/200\n",
            "297/297 [==============================] - 9s 31ms/step - loss: 1.3831 - categorical_accuracy: 0.4378 - val_loss: 1.2635 - val_categorical_accuracy: 0.4175\n",
            "Epoch 6/200\n",
            "297/297 [==============================] - 9s 31ms/step - loss: 1.3166 - categorical_accuracy: 0.4630 - val_loss: 1.2553 - val_categorical_accuracy: 0.4383\n",
            "Epoch 7/200\n",
            "297/297 [==============================] - 9s 31ms/step - loss: 1.2765 - categorical_accuracy: 0.4542 - val_loss: 1.2187 - val_categorical_accuracy: 0.4459\n",
            "Epoch 8/200\n",
            "297/297 [==============================] - 9s 31ms/step - loss: 1.2671 - categorical_accuracy: 0.4539 - val_loss: 1.2125 - val_categorical_accuracy: 0.4782\n",
            "Epoch 9/200\n",
            "297/297 [==============================] - 9s 31ms/step - loss: 1.2470 - categorical_accuracy: 0.4637 - val_loss: 1.2326 - val_categorical_accuracy: 0.4725\n",
            "Epoch 10/200\n",
            "297/297 [==============================] - 9s 31ms/step - loss: 1.2682 - categorical_accuracy: 0.4576 - val_loss: 1.2740 - val_categorical_accuracy: 0.4668\n",
            "Epoch 11/200\n",
            "297/297 [==============================] - 9s 32ms/step - loss: 1.2487 - categorical_accuracy: 0.4618 - val_loss: 1.2188 - val_categorical_accuracy: 0.4687\n",
            "Epoch 12/200\n",
            "297/297 [==============================] - 9s 31ms/step - loss: 1.2394 - categorical_accuracy: 0.4659 - val_loss: 1.2126 - val_categorical_accuracy: 0.4288\n",
            "Epoch 13/200\n",
            "297/297 [==============================] - 9s 31ms/step - loss: 1.2549 - categorical_accuracy: 0.4567 - val_loss: 1.2298 - val_categorical_accuracy: 0.4478\n",
            "Epoch 14/200\n",
            "297/297 [==============================] - 9s 31ms/step - loss: 1.2163 - categorical_accuracy: 0.4645 - val_loss: 1.2372 - val_categorical_accuracy: 0.4478\n",
            "Epoch 15/200\n",
            "297/297 [==============================] - 9s 31ms/step - loss: 1.2414 - categorical_accuracy: 0.4584 - val_loss: 1.2286 - val_categorical_accuracy: 0.4687\n",
            "Epoch 16/200\n",
            "297/297 [==============================] - 9s 31ms/step - loss: 1.1846 - categorical_accuracy: 0.4708 - val_loss: 1.2430 - val_categorical_accuracy: 0.4402\n",
            "Epoch 17/200\n",
            "297/297 [==============================] - 9s 31ms/step - loss: 1.1909 - categorical_accuracy: 0.4819 - val_loss: 1.2479 - val_categorical_accuracy: 0.4497\n",
            "Epoch 18/200\n",
            "297/297 [==============================] - 9s 32ms/step - loss: 1.1609 - categorical_accuracy: 0.4932 - val_loss: 1.2673 - val_categorical_accuracy: 0.4326\n",
            "Epoch 19/200\n",
            "297/297 [==============================] - 9s 31ms/step - loss: 1.1638 - categorical_accuracy: 0.4705 - val_loss: 1.2007 - val_categorical_accuracy: 0.4516\n",
            "Epoch 20/200\n",
            "297/297 [==============================] - 9s 31ms/step - loss: 1.1883 - categorical_accuracy: 0.4856 - val_loss: 1.2762 - val_categorical_accuracy: 0.4364\n",
            "Epoch 21/200\n",
            "297/297 [==============================] - 9s 31ms/step - loss: 1.1929 - categorical_accuracy: 0.4684 - val_loss: 1.3073 - val_categorical_accuracy: 0.4288\n",
            "Epoch 22/200\n",
            "297/297 [==============================] - 9s 31ms/step - loss: 1.1630 - categorical_accuracy: 0.4919 - val_loss: 1.2203 - val_categorical_accuracy: 0.4592\n",
            "Epoch 23/200\n",
            "297/297 [==============================] - 9s 31ms/step - loss: 1.1453 - categorical_accuracy: 0.4942 - val_loss: 1.2244 - val_categorical_accuracy: 0.4478\n",
            "Epoch 24/200\n",
            "297/297 [==============================] - 9s 31ms/step - loss: 1.1888 - categorical_accuracy: 0.4686 - val_loss: 1.2170 - val_categorical_accuracy: 0.4649\n",
            "Epoch 25/200\n",
            "297/297 [==============================] - 9s 31ms/step - loss: 1.1690 - categorical_accuracy: 0.4676 - val_loss: 1.1979 - val_categorical_accuracy: 0.4706\n",
            "Epoch 26/200\n",
            "297/297 [==============================] - 9s 31ms/step - loss: 1.1646 - categorical_accuracy: 0.4759 - val_loss: 1.2070 - val_categorical_accuracy: 0.4744\n",
            "Epoch 27/200\n",
            "297/297 [==============================] - 9s 31ms/step - loss: 1.1495 - categorical_accuracy: 0.4966 - val_loss: 1.1868 - val_categorical_accuracy: 0.4630\n",
            "Epoch 28/200\n",
            "297/297 [==============================] - 9s 32ms/step - loss: 1.1449 - categorical_accuracy: 0.4957 - val_loss: 1.2331 - val_categorical_accuracy: 0.4497\n",
            "Epoch 29/200\n",
            "297/297 [==============================] - 9s 31ms/step - loss: 1.1616 - categorical_accuracy: 0.4900 - val_loss: 1.2240 - val_categorical_accuracy: 0.4611\n",
            "Epoch 30/200\n",
            "297/297 [==============================] - 9s 31ms/step - loss: 1.1597 - categorical_accuracy: 0.4929 - val_loss: 1.2754 - val_categorical_accuracy: 0.4383\n",
            "Epoch 31/200\n",
            "297/297 [==============================] - 9s 32ms/step - loss: 1.1480 - categorical_accuracy: 0.5033 - val_loss: 1.2426 - val_categorical_accuracy: 0.4440\n",
            "Epoch 32/200\n",
            "297/297 [==============================] - 9s 31ms/step - loss: 1.1460 - categorical_accuracy: 0.4946 - val_loss: 1.2373 - val_categorical_accuracy: 0.4592\n",
            "Epoch 33/200\n",
            "297/297 [==============================] - 9s 31ms/step - loss: 1.1434 - categorical_accuracy: 0.4891 - val_loss: 1.2394 - val_categorical_accuracy: 0.4383\n",
            "Epoch 34/200\n",
            "297/297 [==============================] - 9s 31ms/step - loss: 1.1353 - categorical_accuracy: 0.5045 - val_loss: 1.2478 - val_categorical_accuracy: 0.4497\n",
            "Epoch 35/200\n",
            "297/297 [==============================] - 9s 31ms/step - loss: 1.1355 - categorical_accuracy: 0.4859 - val_loss: 1.1968 - val_categorical_accuracy: 0.4839\n",
            "Epoch 36/200\n",
            "297/297 [==============================] - 9s 31ms/step - loss: 1.1381 - categorical_accuracy: 0.4976 - val_loss: 1.2257 - val_categorical_accuracy: 0.4516\n",
            "Epoch 37/200\n",
            "297/297 [==============================] - 9s 31ms/step - loss: 1.1562 - categorical_accuracy: 0.4852 - val_loss: 1.2028 - val_categorical_accuracy: 0.4497\n",
            "Epoch 38/200\n",
            "297/297 [==============================] - 9s 31ms/step - loss: 1.1163 - categorical_accuracy: 0.5087 - val_loss: 1.2229 - val_categorical_accuracy: 0.4535\n",
            "Epoch 39/200\n",
            "297/297 [==============================] - 9s 31ms/step - loss: 1.1303 - categorical_accuracy: 0.4917 - val_loss: 1.2032 - val_categorical_accuracy: 0.4611\n",
            "Epoch 40/200\n",
            "297/297 [==============================] - 10s 32ms/step - loss: 1.1246 - categorical_accuracy: 0.5033 - val_loss: 1.1857 - val_categorical_accuracy: 0.4877\n",
            "Epoch 41/200\n",
            "297/297 [==============================] - 9s 31ms/step - loss: 1.1376 - categorical_accuracy: 0.4858 - val_loss: 1.2020 - val_categorical_accuracy: 0.4668\n",
            "Epoch 42/200\n",
            "297/297 [==============================] - 9s 31ms/step - loss: 1.1424 - categorical_accuracy: 0.4951 - val_loss: 1.2231 - val_categorical_accuracy: 0.4573\n",
            "Epoch 43/200\n",
            "297/297 [==============================] - 9s 31ms/step - loss: 1.1263 - categorical_accuracy: 0.5049 - val_loss: 1.2221 - val_categorical_accuracy: 0.4630\n",
            "Epoch 44/200\n",
            "297/297 [==============================] - 10s 32ms/step - loss: 1.1191 - categorical_accuracy: 0.5129 - val_loss: 1.2646 - val_categorical_accuracy: 0.4402\n",
            "Epoch 45/200\n",
            "297/297 [==============================] - 10s 32ms/step - loss: 1.1181 - categorical_accuracy: 0.5016 - val_loss: 1.2360 - val_categorical_accuracy: 0.4364\n",
            "Epoch 46/200\n",
            "297/297 [==============================] - 9s 31ms/step - loss: 1.1418 - categorical_accuracy: 0.5093 - val_loss: 1.2155 - val_categorical_accuracy: 0.4592\n",
            "Epoch 47/200\n",
            "297/297 [==============================] - 9s 31ms/step - loss: 1.1022 - categorical_accuracy: 0.5262 - val_loss: 1.2498 - val_categorical_accuracy: 0.4307\n",
            "Epoch 48/200\n",
            "297/297 [==============================] - 9s 31ms/step - loss: 1.1476 - categorical_accuracy: 0.5034 - val_loss: 1.2081 - val_categorical_accuracy: 0.4782\n",
            "Epoch 49/200\n",
            "297/297 [==============================] - 9s 31ms/step - loss: 1.1160 - categorical_accuracy: 0.5018 - val_loss: 1.2153 - val_categorical_accuracy: 0.4573\n",
            "Epoch 50/200\n",
            "297/297 [==============================] - 9s 31ms/step - loss: 1.0942 - categorical_accuracy: 0.5124 - val_loss: 1.2099 - val_categorical_accuracy: 0.4763\n",
            "Epoch 51/200\n",
            "297/297 [==============================] - 9s 31ms/step - loss: 1.0946 - categorical_accuracy: 0.5177 - val_loss: 1.2281 - val_categorical_accuracy: 0.4554\n",
            "Epoch 52/200\n",
            "297/297 [==============================] - 9s 31ms/step - loss: 1.1047 - categorical_accuracy: 0.5198 - val_loss: 1.2014 - val_categorical_accuracy: 0.4953\n",
            "Epoch 53/200\n",
            "297/297 [==============================] - 9s 31ms/step - loss: 1.0980 - categorical_accuracy: 0.5090 - val_loss: 1.1986 - val_categorical_accuracy: 0.4934\n",
            "Epoch 54/200\n",
            "297/297 [==============================] - 10s 32ms/step - loss: 1.1090 - categorical_accuracy: 0.5123 - val_loss: 1.2332 - val_categorical_accuracy: 0.4649\n",
            "Epoch 55/200\n",
            "297/297 [==============================] - 10s 32ms/step - loss: 1.0887 - categorical_accuracy: 0.5156 - val_loss: 1.1975 - val_categorical_accuracy: 0.4934\n",
            "Epoch 56/200\n",
            "297/297 [==============================] - 9s 31ms/step - loss: 1.1043 - categorical_accuracy: 0.5098 - val_loss: 1.1970 - val_categorical_accuracy: 0.4915\n",
            "Epoch 57/200\n",
            "297/297 [==============================] - 9s 31ms/step - loss: 1.0766 - categorical_accuracy: 0.5193 - val_loss: 1.2110 - val_categorical_accuracy: 0.4668\n",
            "Epoch 58/200\n",
            "297/297 [==============================] - 9s 31ms/step - loss: 1.0810 - categorical_accuracy: 0.5222 - val_loss: 1.1862 - val_categorical_accuracy: 0.4763\n",
            "Epoch 59/200\n",
            "297/297 [==============================] - 9s 31ms/step - loss: 1.1085 - categorical_accuracy: 0.5404 - val_loss: 1.2115 - val_categorical_accuracy: 0.4706\n",
            "Epoch 60/200\n",
            "297/297 [==============================] - 9s 31ms/step - loss: 1.1005 - categorical_accuracy: 0.5260 - val_loss: 1.2111 - val_categorical_accuracy: 0.4725\n",
            "Epoch 61/200\n",
            "297/297 [==============================] - 9s 31ms/step - loss: 1.0775 - categorical_accuracy: 0.5228 - val_loss: 1.1837 - val_categorical_accuracy: 0.4858\n",
            "Epoch 62/200\n",
            "297/297 [==============================] - 9s 31ms/step - loss: 1.0902 - categorical_accuracy: 0.5215 - val_loss: 1.2049 - val_categorical_accuracy: 0.4706\n",
            "Epoch 63/200\n",
            "297/297 [==============================] - 9s 31ms/step - loss: 1.0757 - categorical_accuracy: 0.5346 - val_loss: 1.1953 - val_categorical_accuracy: 0.4763\n",
            "Epoch 64/200\n",
            "297/297 [==============================] - 9s 31ms/step - loss: 1.0733 - categorical_accuracy: 0.5251 - val_loss: 1.2082 - val_categorical_accuracy: 0.4782\n",
            "Epoch 65/200\n",
            "297/297 [==============================] - 9s 31ms/step - loss: 1.1090 - categorical_accuracy: 0.5144 - val_loss: 1.2036 - val_categorical_accuracy: 0.4858\n",
            "Epoch 66/200\n",
            "297/297 [==============================] - 9s 31ms/step - loss: 1.0667 - categorical_accuracy: 0.5342 - val_loss: 1.1919 - val_categorical_accuracy: 0.4972\n",
            "Epoch 67/200\n",
            "297/297 [==============================] - 9s 31ms/step - loss: 1.0817 - categorical_accuracy: 0.5111 - val_loss: 1.2080 - val_categorical_accuracy: 0.4763\n",
            "Epoch 68/200\n",
            "297/297 [==============================] - 9s 31ms/step - loss: 1.1026 - categorical_accuracy: 0.5137 - val_loss: 1.2362 - val_categorical_accuracy: 0.4554\n",
            "Epoch 69/200\n",
            "297/297 [==============================] - 9s 31ms/step - loss: 1.0910 - categorical_accuracy: 0.5323 - val_loss: 1.1897 - val_categorical_accuracy: 0.4934\n",
            "Epoch 70/200\n",
            "297/297 [==============================] - 9s 31ms/step - loss: 1.0776 - categorical_accuracy: 0.5335 - val_loss: 1.1823 - val_categorical_accuracy: 0.4915\n",
            "Epoch 71/200\n",
            "297/297 [==============================] - 10s 32ms/step - loss: 1.0673 - categorical_accuracy: 0.5448 - val_loss: 1.2182 - val_categorical_accuracy: 0.4744\n",
            "Epoch 72/200\n",
            "297/297 [==============================] - 9s 31ms/step - loss: 1.1055 - categorical_accuracy: 0.5225 - val_loss: 1.1729 - val_categorical_accuracy: 0.4915\n",
            "Epoch 73/200\n",
            "297/297 [==============================] - 9s 31ms/step - loss: 1.0686 - categorical_accuracy: 0.5410 - val_loss: 1.1939 - val_categorical_accuracy: 0.4858\n",
            "Epoch 74/200\n",
            "297/297 [==============================] - 9s 31ms/step - loss: 1.0687 - categorical_accuracy: 0.5311 - val_loss: 1.1786 - val_categorical_accuracy: 0.5047\n",
            "Epoch 75/200\n",
            "297/297 [==============================] - 9s 31ms/step - loss: 1.0744 - categorical_accuracy: 0.5291 - val_loss: 1.1769 - val_categorical_accuracy: 0.4934\n",
            "Epoch 76/200\n",
            "297/297 [==============================] - 9s 31ms/step - loss: 1.1133 - categorical_accuracy: 0.5201 - val_loss: 1.1944 - val_categorical_accuracy: 0.4896\n",
            "Epoch 77/200\n",
            "297/297 [==============================] - 9s 31ms/step - loss: 1.0427 - categorical_accuracy: 0.5384 - val_loss: 1.1951 - val_categorical_accuracy: 0.4991\n",
            "Epoch 78/200\n",
            "297/297 [==============================] - 9s 31ms/step - loss: 1.0681 - categorical_accuracy: 0.5282 - val_loss: 1.2188 - val_categorical_accuracy: 0.4801\n",
            "Epoch 79/200\n",
            "297/297 [==============================] - 9s 31ms/step - loss: 1.0807 - categorical_accuracy: 0.5180 - val_loss: 1.2109 - val_categorical_accuracy: 0.4725\n",
            "Epoch 80/200\n",
            "297/297 [==============================] - 10s 32ms/step - loss: 1.0703 - categorical_accuracy: 0.5237 - val_loss: 1.1787 - val_categorical_accuracy: 0.4991\n",
            "Epoch 81/200\n",
            "297/297 [==============================] - 9s 31ms/step - loss: 1.0676 - categorical_accuracy: 0.5526 - val_loss: 1.1967 - val_categorical_accuracy: 0.5066\n",
            "Epoch 82/200\n",
            "297/297 [==============================] - 9s 31ms/step - loss: 1.0788 - categorical_accuracy: 0.5151 - val_loss: 1.1929 - val_categorical_accuracy: 0.4953\n",
            "Epoch 83/200\n",
            "297/297 [==============================] - 9s 31ms/step - loss: 1.0508 - categorical_accuracy: 0.5414 - val_loss: 1.2107 - val_categorical_accuracy: 0.4820\n",
            "Epoch 84/200\n",
            "297/297 [==============================] - 9s 31ms/step - loss: 1.0600 - categorical_accuracy: 0.5402 - val_loss: 1.2147 - val_categorical_accuracy: 0.4782\n",
            "Epoch 85/200\n",
            "297/297 [==============================] - 9s 31ms/step - loss: 1.0782 - categorical_accuracy: 0.5371 - val_loss: 1.1934 - val_categorical_accuracy: 0.4896\n",
            "Epoch 86/200\n",
            "297/297 [==============================] - 9s 31ms/step - loss: 1.0424 - categorical_accuracy: 0.5430 - val_loss: 1.1820 - val_categorical_accuracy: 0.5047\n",
            "Epoch 87/200\n",
            "297/297 [==============================] - 9s 31ms/step - loss: 1.0534 - categorical_accuracy: 0.5561 - val_loss: 1.1980 - val_categorical_accuracy: 0.4934\n",
            "Epoch 88/200\n",
            "297/297 [==============================] - 9s 31ms/step - loss: 1.0707 - categorical_accuracy: 0.5503 - val_loss: 1.2038 - val_categorical_accuracy: 0.4820\n",
            "Epoch 89/200\n",
            "297/297 [==============================] - 9s 31ms/step - loss: 1.0480 - categorical_accuracy: 0.5485 - val_loss: 1.2047 - val_categorical_accuracy: 0.4991\n",
            "Epoch 90/200\n",
            "297/297 [==============================] - 9s 31ms/step - loss: 1.0838 - categorical_accuracy: 0.5296 - val_loss: 1.1760 - val_categorical_accuracy: 0.5028\n",
            "Epoch 91/200\n",
            "297/297 [==============================] - 9s 31ms/step - loss: 1.0526 - categorical_accuracy: 0.5450 - val_loss: 1.1725 - val_categorical_accuracy: 0.5123\n",
            "Epoch 92/200\n",
            "297/297 [==============================] - 9s 31ms/step - loss: 1.0298 - categorical_accuracy: 0.5509 - val_loss: 1.1888 - val_categorical_accuracy: 0.5275\n",
            "Epoch 93/200\n",
            "297/297 [==============================] - 10s 32ms/step - loss: 1.0472 - categorical_accuracy: 0.5313 - val_loss: 1.2101 - val_categorical_accuracy: 0.4782\n",
            "Epoch 94/200\n",
            "297/297 [==============================] - 10s 32ms/step - loss: 1.0610 - categorical_accuracy: 0.5205 - val_loss: 1.1891 - val_categorical_accuracy: 0.4972\n",
            "Epoch 95/200\n",
            "297/297 [==============================] - 9s 31ms/step - loss: 1.0406 - categorical_accuracy: 0.5465 - val_loss: 1.2033 - val_categorical_accuracy: 0.4991\n",
            "Epoch 96/200\n",
            "297/297 [==============================] - 10s 32ms/step - loss: 1.0802 - categorical_accuracy: 0.5423 - val_loss: 1.1894 - val_categorical_accuracy: 0.4972\n",
            "Epoch 97/200\n",
            "297/297 [==============================] - 9s 31ms/step - loss: 1.0604 - categorical_accuracy: 0.5423 - val_loss: 1.1923 - val_categorical_accuracy: 0.4991\n",
            "Epoch 98/200\n",
            "297/297 [==============================] - 9s 31ms/step - loss: 1.0377 - categorical_accuracy: 0.5527 - val_loss: 1.1974 - val_categorical_accuracy: 0.5123\n",
            "Epoch 99/200\n",
            "297/297 [==============================] - 9s 31ms/step - loss: 1.0609 - categorical_accuracy: 0.5404 - val_loss: 1.1938 - val_categorical_accuracy: 0.4858\n",
            "Epoch 100/200\n",
            "297/297 [==============================] - 9s 31ms/step - loss: 1.0477 - categorical_accuracy: 0.5422 - val_loss: 1.2612 - val_categorical_accuracy: 0.4725\n",
            "Epoch 101/200\n",
            "297/297 [==============================] - 9s 31ms/step - loss: 1.0592 - categorical_accuracy: 0.5497 - val_loss: 1.2094 - val_categorical_accuracy: 0.4877\n",
            "Epoch 102/200\n",
            "297/297 [==============================] - 10s 32ms/step - loss: 1.0706 - categorical_accuracy: 0.5432 - val_loss: 1.1950 - val_categorical_accuracy: 0.4972\n",
            "Epoch 103/200\n",
            "297/297 [==============================] - 9s 31ms/step - loss: 1.0463 - categorical_accuracy: 0.5382 - val_loss: 1.1941 - val_categorical_accuracy: 0.5085\n",
            "Epoch 104/200\n",
            "297/297 [==============================] - 9s 31ms/step - loss: 1.0262 - categorical_accuracy: 0.5660 - val_loss: 1.1866 - val_categorical_accuracy: 0.5066\n",
            "Epoch 105/200\n",
            "297/297 [==============================] - 9s 31ms/step - loss: 1.0505 - categorical_accuracy: 0.5345 - val_loss: 1.2085 - val_categorical_accuracy: 0.5104\n",
            "Epoch 106/200\n",
            "297/297 [==============================] - 10s 32ms/step - loss: 1.0422 - categorical_accuracy: 0.5432 - val_loss: 1.2109 - val_categorical_accuracy: 0.5142\n",
            "Epoch 107/200\n",
            "297/297 [==============================] - 9s 31ms/step - loss: 1.0613 - categorical_accuracy: 0.5449 - val_loss: 1.2284 - val_categorical_accuracy: 0.4991\n",
            "Epoch 108/200\n",
            "297/297 [==============================] - 9s 31ms/step - loss: 1.0345 - categorical_accuracy: 0.5548 - val_loss: 1.1865 - val_categorical_accuracy: 0.5009\n",
            "Epoch 109/200\n",
            "297/297 [==============================] - 9s 31ms/step - loss: 1.0529 - categorical_accuracy: 0.5541 - val_loss: 1.1973 - val_categorical_accuracy: 0.5047\n",
            "Epoch 110/200\n",
            "297/297 [==============================] - 9s 31ms/step - loss: 1.0383 - categorical_accuracy: 0.5405 - val_loss: 1.2072 - val_categorical_accuracy: 0.4858\n",
            "Epoch 111/200\n",
            "297/297 [==============================] - 9s 31ms/step - loss: 1.0354 - categorical_accuracy: 0.5386 - val_loss: 1.2312 - val_categorical_accuracy: 0.4877\n",
            "Epoch 112/200\n",
            "297/297 [==============================] - 10s 32ms/step - loss: 1.0279 - categorical_accuracy: 0.5482 - val_loss: 1.1913 - val_categorical_accuracy: 0.5028\n",
            "Epoch 113/200\n",
            "297/297 [==============================] - 9s 31ms/step - loss: 1.0180 - categorical_accuracy: 0.5677 - val_loss: 1.2120 - val_categorical_accuracy: 0.5237\n",
            "Epoch 114/200\n",
            "297/297 [==============================] - 9s 31ms/step - loss: 1.0367 - categorical_accuracy: 0.5532 - val_loss: 1.2044 - val_categorical_accuracy: 0.5066\n",
            "Epoch 115/200\n",
            "297/297 [==============================] - 9s 31ms/step - loss: 1.0344 - categorical_accuracy: 0.5485 - val_loss: 1.2094 - val_categorical_accuracy: 0.5047\n",
            "Epoch 116/200\n",
            "297/297 [==============================] - 9s 31ms/step - loss: 1.0253 - categorical_accuracy: 0.5622 - val_loss: 1.2037 - val_categorical_accuracy: 0.4953\n",
            "Epoch 117/200\n",
            "297/297 [==============================] - 9s 31ms/step - loss: 1.0357 - categorical_accuracy: 0.5496 - val_loss: 1.1988 - val_categorical_accuracy: 0.5066\n",
            "Epoch 118/200\n",
            "297/297 [==============================] - 9s 31ms/step - loss: 1.0209 - categorical_accuracy: 0.5526 - val_loss: 1.2001 - val_categorical_accuracy: 0.5028\n",
            "Epoch 119/200\n",
            "297/297 [==============================] - 9s 31ms/step - loss: 1.0249 - categorical_accuracy: 0.5558 - val_loss: 1.1938 - val_categorical_accuracy: 0.4991\n",
            "Epoch 120/200\n",
            "297/297 [==============================] - 9s 31ms/step - loss: 1.0383 - categorical_accuracy: 0.5560 - val_loss: 1.1941 - val_categorical_accuracy: 0.5180\n",
            "Epoch 121/200\n",
            "297/297 [==============================] - 9s 31ms/step - loss: 1.0271 - categorical_accuracy: 0.5602 - val_loss: 1.2186 - val_categorical_accuracy: 0.4991\n",
            "Epoch 122/200\n",
            "297/297 [==============================] - 9s 31ms/step - loss: 1.0170 - categorical_accuracy: 0.5591 - val_loss: 1.2082 - val_categorical_accuracy: 0.5047\n",
            "Epoch 123/200\n",
            "297/297 [==============================] - 9s 31ms/step - loss: 1.0270 - categorical_accuracy: 0.5618 - val_loss: 1.1989 - val_categorical_accuracy: 0.5028\n",
            "Epoch 124/200\n",
            "297/297 [==============================] - 9s 31ms/step - loss: 1.0278 - categorical_accuracy: 0.5486 - val_loss: 1.1924 - val_categorical_accuracy: 0.5180\n",
            "Epoch 125/200\n",
            "297/297 [==============================] - 9s 31ms/step - loss: 1.0248 - categorical_accuracy: 0.5586 - val_loss: 1.2017 - val_categorical_accuracy: 0.5142\n",
            "Epoch 126/200\n",
            "297/297 [==============================] - 10s 32ms/step - loss: 1.0379 - categorical_accuracy: 0.5443 - val_loss: 1.1912 - val_categorical_accuracy: 0.5085\n",
            "Epoch 127/200\n",
            "297/297 [==============================] - 9s 31ms/step - loss: 1.0376 - categorical_accuracy: 0.5600 - val_loss: 1.2110 - val_categorical_accuracy: 0.5066\n",
            "Epoch 128/200\n",
            "297/297 [==============================] - 9s 31ms/step - loss: 1.0247 - categorical_accuracy: 0.5600 - val_loss: 1.2123 - val_categorical_accuracy: 0.4934\n",
            "Epoch 129/200\n",
            "297/297 [==============================] - 9s 31ms/step - loss: 1.0126 - categorical_accuracy: 0.5658 - val_loss: 1.2064 - val_categorical_accuracy: 0.5066\n",
            "Epoch 130/200\n",
            "297/297 [==============================] - 9s 31ms/step - loss: 1.0280 - categorical_accuracy: 0.5497 - val_loss: 1.2029 - val_categorical_accuracy: 0.5199\n",
            "Epoch 131/200\n",
            "297/297 [==============================] - 10s 33ms/step - loss: 1.0038 - categorical_accuracy: 0.5730 - val_loss: 1.1730 - val_categorical_accuracy: 0.5104\n",
            "Epoch 132/200\n",
            "297/297 [==============================] - 9s 31ms/step - loss: 1.0059 - categorical_accuracy: 0.5638 - val_loss: 1.1889 - val_categorical_accuracy: 0.5104\n",
            "Epoch 133/200\n",
            "297/297 [==============================] - 9s 32ms/step - loss: 1.0253 - categorical_accuracy: 0.5679 - val_loss: 1.1982 - val_categorical_accuracy: 0.5009\n",
            "Epoch 134/200\n",
            "297/297 [==============================] - 9s 31ms/step - loss: 1.0237 - categorical_accuracy: 0.5568 - val_loss: 1.2071 - val_categorical_accuracy: 0.5123\n",
            "Epoch 135/200\n",
            "297/297 [==============================] - 9s 31ms/step - loss: 1.0282 - categorical_accuracy: 0.5626 - val_loss: 1.2229 - val_categorical_accuracy: 0.4934\n",
            "Epoch 136/200\n",
            "297/297 [==============================] - 9s 31ms/step - loss: 1.0120 - categorical_accuracy: 0.5623 - val_loss: 1.2151 - val_categorical_accuracy: 0.5104\n",
            "Epoch 137/200\n",
            "297/297 [==============================] - 9s 31ms/step - loss: 1.0154 - categorical_accuracy: 0.5582 - val_loss: 1.2071 - val_categorical_accuracy: 0.5161\n",
            "Epoch 138/200\n",
            "297/297 [==============================] - 9s 31ms/step - loss: 1.0207 - categorical_accuracy: 0.5710 - val_loss: 1.2135 - val_categorical_accuracy: 0.5237\n",
            "Epoch 139/200\n",
            "297/297 [==============================] - 10s 32ms/step - loss: 1.0088 - categorical_accuracy: 0.5644 - val_loss: 1.1900 - val_categorical_accuracy: 0.5275\n",
            "Epoch 140/200\n",
            "297/297 [==============================] - 9s 31ms/step - loss: 1.0322 - categorical_accuracy: 0.5779 - val_loss: 1.2226 - val_categorical_accuracy: 0.4953\n",
            "Epoch 141/200\n",
            "297/297 [==============================] - 10s 33ms/step - loss: 1.0198 - categorical_accuracy: 0.5593 - val_loss: 1.2103 - val_categorical_accuracy: 0.5199\n",
            "Epoch 142/200\n",
            "297/297 [==============================] - 9s 31ms/step - loss: 1.0079 - categorical_accuracy: 0.5577 - val_loss: 1.1958 - val_categorical_accuracy: 0.5237\n",
            "Epoch 143/200\n",
            "297/297 [==============================] - 9s 31ms/step - loss: 1.0059 - categorical_accuracy: 0.5640 - val_loss: 1.2040 - val_categorical_accuracy: 0.5370\n",
            "Epoch 144/200\n",
            "297/297 [==============================] - 9s 31ms/step - loss: 1.0096 - categorical_accuracy: 0.5666 - val_loss: 1.1997 - val_categorical_accuracy: 0.5313\n",
            "Epoch 145/200\n",
            "297/297 [==============================] - 9s 31ms/step - loss: 1.0394 - categorical_accuracy: 0.5631 - val_loss: 1.2018 - val_categorical_accuracy: 0.5142\n",
            "Epoch 146/200\n",
            "297/297 [==============================] - 9s 31ms/step - loss: 1.0219 - categorical_accuracy: 0.5488 - val_loss: 1.2155 - val_categorical_accuracy: 0.4972\n",
            "Epoch 147/200\n",
            "297/297 [==============================] - 9s 31ms/step - loss: 0.9844 - categorical_accuracy: 0.5787 - val_loss: 1.2515 - val_categorical_accuracy: 0.4991\n",
            "Epoch 148/200\n",
            "297/297 [==============================] - 9s 31ms/step - loss: 1.0139 - categorical_accuracy: 0.5768 - val_loss: 1.1919 - val_categorical_accuracy: 0.5275\n",
            "Epoch 149/200\n",
            "297/297 [==============================] - 9s 31ms/step - loss: 1.0223 - categorical_accuracy: 0.5444 - val_loss: 1.2051 - val_categorical_accuracy: 0.5237\n",
            "Epoch 150/200\n",
            "297/297 [==============================] - 9s 31ms/step - loss: 1.0008 - categorical_accuracy: 0.5703 - val_loss: 1.2032 - val_categorical_accuracy: 0.5066\n",
            "Epoch 151/200\n",
            "297/297 [==============================] - 9s 31ms/step - loss: 1.0140 - categorical_accuracy: 0.5596 - val_loss: 1.2172 - val_categorical_accuracy: 0.5123\n",
            "Epoch 152/200\n",
            "297/297 [==============================] - 9s 32ms/step - loss: 0.9953 - categorical_accuracy: 0.5685 - val_loss: 1.1928 - val_categorical_accuracy: 0.5180\n",
            "Epoch 153/200\n",
            "297/297 [==============================] - 9s 31ms/step - loss: 1.0030 - categorical_accuracy: 0.5585 - val_loss: 1.1927 - val_categorical_accuracy: 0.5294\n",
            "Epoch 154/200\n",
            "297/297 [==============================] - 9s 31ms/step - loss: 0.9936 - categorical_accuracy: 0.5550 - val_loss: 1.1977 - val_categorical_accuracy: 0.5180\n",
            "Epoch 155/200\n",
            "297/297 [==============================] - 9s 32ms/step - loss: 1.0025 - categorical_accuracy: 0.5629 - val_loss: 1.2166 - val_categorical_accuracy: 0.5256\n",
            "Epoch 156/200\n",
            "297/297 [==============================] - 9s 31ms/step - loss: 1.0153 - categorical_accuracy: 0.5704 - val_loss: 1.2139 - val_categorical_accuracy: 0.5085\n",
            "Epoch 157/200\n",
            "297/297 [==============================] - 9s 32ms/step - loss: 0.9931 - categorical_accuracy: 0.5784 - val_loss: 1.2108 - val_categorical_accuracy: 0.5275\n",
            "Epoch 158/200\n",
            "297/297 [==============================] - 9s 32ms/step - loss: 1.0070 - categorical_accuracy: 0.5644 - val_loss: 1.2087 - val_categorical_accuracy: 0.5142\n",
            "Epoch 159/200\n",
            "297/297 [==============================] - 9s 32ms/step - loss: 0.9872 - categorical_accuracy: 0.5691 - val_loss: 1.2068 - val_categorical_accuracy: 0.5047\n",
            "Epoch 160/200\n",
            "297/297 [==============================] - 9s 32ms/step - loss: 1.0075 - categorical_accuracy: 0.5521 - val_loss: 1.1966 - val_categorical_accuracy: 0.5294\n",
            "Epoch 161/200\n",
            "297/297 [==============================] - 9s 32ms/step - loss: 1.0003 - categorical_accuracy: 0.5776 - val_loss: 1.2006 - val_categorical_accuracy: 0.5332\n",
            "Epoch 162/200\n",
            "297/297 [==============================] - 9s 32ms/step - loss: 1.0038 - categorical_accuracy: 0.5741 - val_loss: 1.2024 - val_categorical_accuracy: 0.5332\n",
            "Epoch 163/200\n",
            "297/297 [==============================] - 9s 32ms/step - loss: 0.9892 - categorical_accuracy: 0.5685 - val_loss: 1.1930 - val_categorical_accuracy: 0.5199\n",
            "Epoch 164/200\n",
            "297/297 [==============================] - 10s 32ms/step - loss: 0.9862 - categorical_accuracy: 0.5661 - val_loss: 1.1965 - val_categorical_accuracy: 0.5275\n",
            "Epoch 165/200\n",
            "297/297 [==============================] - 9s 31ms/step - loss: 0.9998 - categorical_accuracy: 0.5675 - val_loss: 1.1978 - val_categorical_accuracy: 0.5237\n",
            "Epoch 166/200\n",
            "297/297 [==============================] - 9s 32ms/step - loss: 0.9948 - categorical_accuracy: 0.5777 - val_loss: 1.2023 - val_categorical_accuracy: 0.5123\n",
            "Epoch 167/200\n",
            "297/297 [==============================] - 9s 31ms/step - loss: 0.9819 - categorical_accuracy: 0.5722 - val_loss: 1.2031 - val_categorical_accuracy: 0.5256\n",
            "Epoch 168/200\n",
            "297/297 [==============================] - 9s 32ms/step - loss: 1.0032 - categorical_accuracy: 0.5733 - val_loss: 1.2154 - val_categorical_accuracy: 0.5142\n",
            "Epoch 169/200\n",
            "297/297 [==============================] - 9s 31ms/step - loss: 0.9875 - categorical_accuracy: 0.5736 - val_loss: 1.2108 - val_categorical_accuracy: 0.5256\n",
            "Epoch 170/200\n",
            "297/297 [==============================] - 9s 32ms/step - loss: 1.0000 - categorical_accuracy: 0.5691 - val_loss: 1.2317 - val_categorical_accuracy: 0.5085\n",
            "Epoch 171/200\n",
            "297/297 [==============================] - 9s 31ms/step - loss: 0.9838 - categorical_accuracy: 0.5781 - val_loss: 1.2230 - val_categorical_accuracy: 0.5142\n",
            "Epoch 172/200\n",
            "297/297 [==============================] - 9s 31ms/step - loss: 0.9641 - categorical_accuracy: 0.5838 - val_loss: 1.1957 - val_categorical_accuracy: 0.5237\n",
            "Epoch 173/200\n",
            "297/297 [==============================] - 9s 31ms/step - loss: 0.9927 - categorical_accuracy: 0.5804 - val_loss: 1.2100 - val_categorical_accuracy: 0.5256\n",
            "Epoch 174/200\n",
            "297/297 [==============================] - 9s 32ms/step - loss: 0.9955 - categorical_accuracy: 0.5793 - val_loss: 1.2101 - val_categorical_accuracy: 0.5199\n",
            "Epoch 175/200\n",
            "297/297 [==============================] - 9s 31ms/step - loss: 1.0024 - categorical_accuracy: 0.5695 - val_loss: 1.2040 - val_categorical_accuracy: 0.5256\n",
            "Epoch 176/200\n",
            "297/297 [==============================] - 9s 31ms/step - loss: 0.9898 - categorical_accuracy: 0.5735 - val_loss: 1.2068 - val_categorical_accuracy: 0.5313\n",
            "Epoch 177/200\n",
            "297/297 [==============================] - 9s 32ms/step - loss: 0.9758 - categorical_accuracy: 0.5750 - val_loss: 1.1965 - val_categorical_accuracy: 0.5313\n",
            "Epoch 178/200\n",
            "297/297 [==============================] - 9s 32ms/step - loss: 1.0121 - categorical_accuracy: 0.5691 - val_loss: 1.1999 - val_categorical_accuracy: 0.5142\n",
            "Epoch 179/200\n",
            "297/297 [==============================] - 9s 31ms/step - loss: 0.9885 - categorical_accuracy: 0.5711 - val_loss: 1.2164 - val_categorical_accuracy: 0.5009\n",
            "Epoch 180/200\n",
            "297/297 [==============================] - 9s 31ms/step - loss: 0.9764 - categorical_accuracy: 0.5791 - val_loss: 1.1972 - val_categorical_accuracy: 0.5180\n",
            "Epoch 181/200\n",
            "297/297 [==============================] - 9s 32ms/step - loss: 0.9898 - categorical_accuracy: 0.5690 - val_loss: 1.2203 - val_categorical_accuracy: 0.5180\n",
            "Epoch 182/200\n",
            "297/297 [==============================] - 10s 33ms/step - loss: 0.9782 - categorical_accuracy: 0.5749 - val_loss: 1.2137 - val_categorical_accuracy: 0.5142\n",
            "Epoch 183/200\n",
            "297/297 [==============================] - 9s 32ms/step - loss: 1.0246 - categorical_accuracy: 0.5601 - val_loss: 1.2146 - val_categorical_accuracy: 0.5123\n",
            "Epoch 184/200\n",
            "297/297 [==============================] - 9s 32ms/step - loss: 0.9923 - categorical_accuracy: 0.5674 - val_loss: 1.2082 - val_categorical_accuracy: 0.5294\n",
            "Epoch 185/200\n",
            "297/297 [==============================] - 9s 31ms/step - loss: 0.9806 - categorical_accuracy: 0.5729 - val_loss: 1.2263 - val_categorical_accuracy: 0.5351\n",
            "Epoch 186/200\n",
            "297/297 [==============================] - 9s 32ms/step - loss: 0.9790 - categorical_accuracy: 0.5768 - val_loss: 1.1937 - val_categorical_accuracy: 0.5180\n",
            "Epoch 187/200\n",
            "297/297 [==============================] - 10s 33ms/step - loss: 0.9823 - categorical_accuracy: 0.5739 - val_loss: 1.2149 - val_categorical_accuracy: 0.5104\n",
            "Epoch 188/200\n",
            "297/297 [==============================] - 9s 32ms/step - loss: 0.9686 - categorical_accuracy: 0.5775 - val_loss: 1.2066 - val_categorical_accuracy: 0.5066\n",
            "Epoch 189/200\n",
            "297/297 [==============================] - 9s 32ms/step - loss: 0.9846 - categorical_accuracy: 0.5761 - val_loss: 1.2168 - val_categorical_accuracy: 0.5313\n",
            "Epoch 190/200\n",
            "297/297 [==============================] - 9s 32ms/step - loss: 0.9683 - categorical_accuracy: 0.5773 - val_loss: 1.2143 - val_categorical_accuracy: 0.5009\n",
            "Epoch 191/200\n",
            "297/297 [==============================] - 9s 32ms/step - loss: 0.9735 - categorical_accuracy: 0.5831 - val_loss: 1.2222 - val_categorical_accuracy: 0.5142\n",
            "Epoch 192/200\n",
            "297/297 [==============================] - 9s 32ms/step - loss: 0.9902 - categorical_accuracy: 0.5742 - val_loss: 1.1900 - val_categorical_accuracy: 0.5313\n",
            "Epoch 193/200\n",
            "297/297 [==============================] - 9s 32ms/step - loss: 0.9799 - categorical_accuracy: 0.5909 - val_loss: 1.2042 - val_categorical_accuracy: 0.5161\n",
            "Epoch 194/200\n",
            "297/297 [==============================] - 9s 32ms/step - loss: 0.9690 - categorical_accuracy: 0.5706 - val_loss: 1.1950 - val_categorical_accuracy: 0.5161\n",
            "Epoch 195/200\n",
            "297/297 [==============================] - 9s 32ms/step - loss: 0.9611 - categorical_accuracy: 0.5865 - val_loss: 1.2134 - val_categorical_accuracy: 0.5218\n",
            "Epoch 196/200\n",
            "297/297 [==============================] - 9s 32ms/step - loss: 0.9624 - categorical_accuracy: 0.5863 - val_loss: 1.2067 - val_categorical_accuracy: 0.5161\n",
            "Epoch 197/200\n",
            "297/297 [==============================] - 9s 32ms/step - loss: 0.9863 - categorical_accuracy: 0.5687 - val_loss: 1.1975 - val_categorical_accuracy: 0.5237\n",
            "Epoch 198/200\n",
            "297/297 [==============================] - 10s 33ms/step - loss: 0.9549 - categorical_accuracy: 0.5811 - val_loss: 1.2082 - val_categorical_accuracy: 0.5199\n",
            "Epoch 199/200\n",
            "297/297 [==============================] - 10s 33ms/step - loss: 0.9622 - categorical_accuracy: 0.5853 - val_loss: 1.2229 - val_categorical_accuracy: 0.5237\n",
            "Epoch 200/200\n",
            "297/297 [==============================] - 10s 33ms/step - loss: 0.9615 - categorical_accuracy: 0.5867 - val_loss: 1.2049 - val_categorical_accuracy: 0.5218\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_CZ-oFJW3bd"
      },
      "source": [
        "model.save('/content/drive/MyDrive/Colab Notebooks/speech/dataset/conv2D_melspec_merged.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "onU0xMuWmGmQ"
      },
      "source": [
        "###test_result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cTZvr8tmGmS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95fc0a22-2f7e-402a-cdc3-fd1b6755620e"
      },
      "source": [
        "d = {0: 'happy',\n",
        "     1: 'sad',\n",
        "     2: 'angry',\n",
        "     3: 'fear'}\n",
        "Y_test_pred = np.argmax(model.predict(X_test), axis=-1)\n",
        "Y_test_pred = list(map(lambda x: d[x], Y_test_pred))\n",
        "y_test = np.argmax(y_test, axis=-1)\n",
        "y_test = list(map(lambda x: d[x], y_test))\n",
        "print(classification_report(y_test, Y_test_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.76      0.43      0.55       155\n",
            "        fear       0.44      0.33      0.38       144\n",
            "       happy       0.44      0.38      0.41       151\n",
            "         sad       0.47      0.90      0.62       136\n",
            "\n",
            "    accuracy                           0.50       586\n",
            "   macro avg       0.53      0.51      0.49       586\n",
            "weighted avg       0.53      0.50      0.48       586\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N6d8QlF3mGmT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 483
        },
        "outputId": "5fad0db4-2761-431d-c782-894fc42ac575"
      },
      "source": [
        "import scikitplot as skplt\n",
        "\n",
        "skplt.metrics.plot_confusion_matrix(\n",
        "    y_test, \n",
        "    Y_test_pred,\n",
        "    figsize=(8,8))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fb6a24be690>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8FTW3csmGmU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52xgoS68UfhO"
      },
      "source": [
        "# Tempogram + basic model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRIEg1lhUfhZ"
      },
      "source": [
        "features = []\n",
        "labels = []\n",
        "for i in range(len(Ravdess_DF['Paths'])):\n",
        "  if ((Ravdess_DF['Emotion'][i] == '03') | (Ravdess_DF['Emotion'][i] == '04') | \n",
        "      (Ravdess_DF['Emotion'][i] == '05') | (Ravdess_DF['Emotion'][i] == '06')):\n",
        "    signal, sr = librosa.load(Ravdess_DF['Paths'][i])\n",
        "    tempogram = np.mean(librosa.feature.tempogram(signal, sr).T, axis=0)\n",
        "    features.append(tempogram)\n",
        "    if Ravdess_DF['Emotion'][i] == '03':\n",
        "      labels.append(0)\n",
        "    elif Ravdess_DF['Emotion'][i] == '04':\n",
        "      labels.append(1)\n",
        "    elif Ravdess_DF['Emotion'][i] == '05':\n",
        "      labels.append(2)\n",
        "    elif Ravdess_DF['Emotion'][i] == '06':\n",
        "      labels.append(3)\n",
        "\n",
        "\n",
        "for i in range(len(CREMA_D_df)):\n",
        "  if ((CREMA_D_df['Emotion'][i] == 'HAP') | (CREMA_D_df['Emotion'][i] == 'SAD') | \n",
        "      (CREMA_D_df['Emotion'][i] == 'ANG') | (CREMA_D_df['Emotion'][i] == 'FEA')):\n",
        "    \n",
        "    if CREMA_D_df['Emotion'][i] == 'HAP':\n",
        "      labels.append(0)\n",
        "    elif CREMA_D_df['Emotion'][i] == 'SAD':\n",
        "      labels.append(1)\n",
        "    elif CREMA_D_df['Emotion'][i] == 'ANG':\n",
        "      labels.append(2)\n",
        "    elif CREMA_D_df['Emotion'][i] == 'FEA':\n",
        "      labels.append(3)\n",
        "\n",
        "\n",
        "    signal, sr =  librosa.load(CREMA_D_df['Paths'][i])\n",
        "\n",
        "    tempogram = np.mean(librosa.feature.tempogram(signal, sr).T, axis=0)\n",
        "    features.append(tempogram)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_thKlW8Ufhb"
      },
      "source": [
        "X = features\n",
        "y = labels\n",
        "\n",
        "y = np.array(y)\n",
        "y = to_categorical(y)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=0)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=0)\n",
        "\n",
        "X_train = np.array(X_train)\n",
        "X_test = np.array(X_test)\n",
        "X_val = np.array(X_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dOcjtFWYUfhc"
      },
      "source": [
        "## basic models:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rkfYHWSJUfhd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "388c4a84-43b8-4a0e-cadc-dbde182f97e5"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(384, input_shape=(384, ), activation = 'relu'))\n",
        "#model.add(Dropout(0.1))\n",
        "model.add(Dense(128, activation = 'relu'))\n",
        "#model.add(Dropout(0.25))\n",
        "model.add(Dense(128, activation = 'relu'))\n",
        "#model.add(Dropout(0.2))\n",
        "model.add(Dense(4, activation = 'softmax'))\n",
        "\n",
        "optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
        "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer=optimizer)\n",
        "early_stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=100, verbose=1, mode='auto')\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 384)               147840    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 128)               49280     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 4)                 516       \n",
            "=================================================================\n",
            "Total params: 214,148\n",
            "Trainable params: 214,148\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RtMiNrW1Ufhf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6a3b628-045c-46ca-d87a-d2024beb5b5c"
      },
      "source": [
        "history = model.fit(X_train, y_train, batch_size=64, epochs=200, \n",
        "                    validation_data=(X_val, y_val))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "75/75 [==============================] - 14s 8ms/step - loss: 1.3353 - accuracy: 0.3311 - val_loss: 1.2254 - val_accuracy: 0.4535\n",
            "Epoch 2/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.2242 - accuracy: 0.4299 - val_loss: 1.1903 - val_accuracy: 0.4364\n",
            "Epoch 3/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.1709 - accuracy: 0.4505 - val_loss: 1.0957 - val_accuracy: 0.5028\n",
            "Epoch 4/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.1565 - accuracy: 0.4644 - val_loss: 1.0961 - val_accuracy: 0.5028\n",
            "Epoch 5/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.1679 - accuracy: 0.4572 - val_loss: 1.1719 - val_accuracy: 0.4668\n",
            "Epoch 6/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.1635 - accuracy: 0.4635 - val_loss: 1.0529 - val_accuracy: 0.5123\n",
            "Epoch 7/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.1196 - accuracy: 0.4817 - val_loss: 1.0687 - val_accuracy: 0.5332\n",
            "Epoch 8/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.1146 - accuracy: 0.4768 - val_loss: 1.0489 - val_accuracy: 0.5313\n",
            "Epoch 9/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.1332 - accuracy: 0.4874 - val_loss: 1.0907 - val_accuracy: 0.5085\n",
            "Epoch 10/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.1344 - accuracy: 0.4783 - val_loss: 1.0676 - val_accuracy: 0.5237\n",
            "Epoch 11/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.1226 - accuracy: 0.4708 - val_loss: 1.0447 - val_accuracy: 0.5389\n",
            "Epoch 12/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.1078 - accuracy: 0.4885 - val_loss: 1.0557 - val_accuracy: 0.5256\n",
            "Epoch 13/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.1000 - accuracy: 0.5060 - val_loss: 1.0682 - val_accuracy: 0.5332\n",
            "Epoch 14/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.1082 - accuracy: 0.4936 - val_loss: 1.0310 - val_accuracy: 0.5408\n",
            "Epoch 15/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.1061 - accuracy: 0.4883 - val_loss: 1.0581 - val_accuracy: 0.5294\n",
            "Epoch 16/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.1015 - accuracy: 0.4857 - val_loss: 1.1659 - val_accuracy: 0.4801\n",
            "Epoch 17/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.1941 - accuracy: 0.4501 - val_loss: 1.1421 - val_accuracy: 0.4706\n",
            "Epoch 18/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.1333 - accuracy: 0.4775 - val_loss: 1.0761 - val_accuracy: 0.5237\n",
            "Epoch 19/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.1105 - accuracy: 0.4806 - val_loss: 1.0488 - val_accuracy: 0.5275\n",
            "Epoch 20/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.1167 - accuracy: 0.4718 - val_loss: 1.0291 - val_accuracy: 0.5446\n",
            "Epoch 21/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0861 - accuracy: 0.5100 - val_loss: 1.0499 - val_accuracy: 0.5142\n",
            "Epoch 22/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0953 - accuracy: 0.5062 - val_loss: 1.0135 - val_accuracy: 0.5427\n",
            "Epoch 23/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0679 - accuracy: 0.5022 - val_loss: 1.1324 - val_accuracy: 0.4839\n",
            "Epoch 24/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.1111 - accuracy: 0.4963 - val_loss: 1.0425 - val_accuracy: 0.5161\n",
            "Epoch 25/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0900 - accuracy: 0.4999 - val_loss: 1.0381 - val_accuracy: 0.5256\n",
            "Epoch 26/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0959 - accuracy: 0.4971 - val_loss: 1.0800 - val_accuracy: 0.4915\n",
            "Epoch 27/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.1359 - accuracy: 0.4723 - val_loss: 1.0224 - val_accuracy: 0.5579\n",
            "Epoch 28/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0930 - accuracy: 0.5091 - val_loss: 1.0370 - val_accuracy: 0.5218\n",
            "Epoch 29/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0692 - accuracy: 0.5147 - val_loss: 1.0484 - val_accuracy: 0.5408\n",
            "Epoch 30/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0861 - accuracy: 0.5051 - val_loss: 1.0161 - val_accuracy: 0.5142\n",
            "Epoch 31/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0873 - accuracy: 0.5061 - val_loss: 1.0238 - val_accuracy: 0.5427\n",
            "Epoch 32/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.1049 - accuracy: 0.4940 - val_loss: 1.0640 - val_accuracy: 0.5275\n",
            "Epoch 33/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0681 - accuracy: 0.5092 - val_loss: 1.0201 - val_accuracy: 0.5332\n",
            "Epoch 34/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0720 - accuracy: 0.4959 - val_loss: 1.0125 - val_accuracy: 0.5351\n",
            "Epoch 35/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0595 - accuracy: 0.5167 - val_loss: 1.0033 - val_accuracy: 0.5313\n",
            "Epoch 36/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0705 - accuracy: 0.5070 - val_loss: 1.0156 - val_accuracy: 0.5047\n",
            "Epoch 37/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0564 - accuracy: 0.5306 - val_loss: 0.9993 - val_accuracy: 0.5484\n",
            "Epoch 38/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0382 - accuracy: 0.5369 - val_loss: 1.0079 - val_accuracy: 0.5351\n",
            "Epoch 39/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0834 - accuracy: 0.5000 - val_loss: 1.0150 - val_accuracy: 0.5332\n",
            "Epoch 40/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0605 - accuracy: 0.5121 - val_loss: 1.0079 - val_accuracy: 0.5408\n",
            "Epoch 41/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0328 - accuracy: 0.5357 - val_loss: 1.0086 - val_accuracy: 0.5218\n",
            "Epoch 42/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0621 - accuracy: 0.5016 - val_loss: 1.0141 - val_accuracy: 0.5123\n",
            "Epoch 43/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0585 - accuracy: 0.5148 - val_loss: 1.0291 - val_accuracy: 0.5351\n",
            "Epoch 44/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0672 - accuracy: 0.5168 - val_loss: 1.0333 - val_accuracy: 0.5522\n",
            "Epoch 45/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0238 - accuracy: 0.5344 - val_loss: 1.0326 - val_accuracy: 0.5237\n",
            "Epoch 46/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0593 - accuracy: 0.5169 - val_loss: 1.0903 - val_accuracy: 0.5104\n",
            "Epoch 47/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.1447 - accuracy: 0.4836 - val_loss: 1.0853 - val_accuracy: 0.5199\n",
            "Epoch 48/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0563 - accuracy: 0.5217 - val_loss: 1.0084 - val_accuracy: 0.5161\n",
            "Epoch 49/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0489 - accuracy: 0.5123 - val_loss: 1.0855 - val_accuracy: 0.4630\n",
            "Epoch 50/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0296 - accuracy: 0.5249 - val_loss: 1.0301 - val_accuracy: 0.5161\n",
            "Epoch 51/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0341 - accuracy: 0.5275 - val_loss: 1.0382 - val_accuracy: 0.5161\n",
            "Epoch 52/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0366 - accuracy: 0.5370 - val_loss: 1.0237 - val_accuracy: 0.5180\n",
            "Epoch 53/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0369 - accuracy: 0.5173 - val_loss: 1.0973 - val_accuracy: 0.5028\n",
            "Epoch 54/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0479 - accuracy: 0.5265 - val_loss: 1.0079 - val_accuracy: 0.5237\n",
            "Epoch 55/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0293 - accuracy: 0.5315 - val_loss: 0.9905 - val_accuracy: 0.5237\n",
            "Epoch 56/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0054 - accuracy: 0.5480 - val_loss: 1.0013 - val_accuracy: 0.5408\n",
            "Epoch 57/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0260 - accuracy: 0.5384 - val_loss: 1.0481 - val_accuracy: 0.5351\n",
            "Epoch 58/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0406 - accuracy: 0.5302 - val_loss: 1.0034 - val_accuracy: 0.5465\n",
            "Epoch 59/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0286 - accuracy: 0.5374 - val_loss: 1.0475 - val_accuracy: 0.4877\n",
            "Epoch 60/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0470 - accuracy: 0.5204 - val_loss: 1.1010 - val_accuracy: 0.4934\n",
            "Epoch 61/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0702 - accuracy: 0.5142 - val_loss: 1.0065 - val_accuracy: 0.5427\n",
            "Epoch 62/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0438 - accuracy: 0.5368 - val_loss: 1.0132 - val_accuracy: 0.5541\n",
            "Epoch 63/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0517 - accuracy: 0.5204 - val_loss: 1.0384 - val_accuracy: 0.5256\n",
            "Epoch 64/200\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 1.0304 - accuracy: 0.5258 - val_loss: 0.9995 - val_accuracy: 0.5484\n",
            "Epoch 65/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0219 - accuracy: 0.5496 - val_loss: 0.9935 - val_accuracy: 0.5465\n",
            "Epoch 66/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0486 - accuracy: 0.5279 - val_loss: 1.0393 - val_accuracy: 0.5370\n",
            "Epoch 67/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0053 - accuracy: 0.5399 - val_loss: 0.9968 - val_accuracy: 0.5427\n",
            "Epoch 68/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0093 - accuracy: 0.5490 - val_loss: 1.0283 - val_accuracy: 0.5142\n",
            "Epoch 69/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0126 - accuracy: 0.5477 - val_loss: 1.0091 - val_accuracy: 0.5446\n",
            "Epoch 70/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0045 - accuracy: 0.5411 - val_loss: 1.0103 - val_accuracy: 0.5465\n",
            "Epoch 71/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0144 - accuracy: 0.5510 - val_loss: 1.0024 - val_accuracy: 0.5161\n",
            "Epoch 72/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0076 - accuracy: 0.5418 - val_loss: 1.0032 - val_accuracy: 0.5370\n",
            "Epoch 73/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0246 - accuracy: 0.5265 - val_loss: 1.0050 - val_accuracy: 0.5465\n",
            "Epoch 74/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0126 - accuracy: 0.5435 - val_loss: 0.9999 - val_accuracy: 0.5389\n",
            "Epoch 75/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0091 - accuracy: 0.5524 - val_loss: 1.0652 - val_accuracy: 0.4896\n",
            "Epoch 76/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0111 - accuracy: 0.5334 - val_loss: 1.0168 - val_accuracy: 0.5465\n",
            "Epoch 77/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.9956 - accuracy: 0.5528 - val_loss: 1.0104 - val_accuracy: 0.5446\n",
            "Epoch 78/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0136 - accuracy: 0.5452 - val_loss: 1.0256 - val_accuracy: 0.5389\n",
            "Epoch 79/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0200 - accuracy: 0.5486 - val_loss: 0.9971 - val_accuracy: 0.5332\n",
            "Epoch 80/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.9754 - accuracy: 0.5684 - val_loss: 1.0030 - val_accuracy: 0.5541\n",
            "Epoch 81/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.9801 - accuracy: 0.5655 - val_loss: 0.9951 - val_accuracy: 0.5693\n",
            "Epoch 82/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.9928 - accuracy: 0.5601 - val_loss: 1.0072 - val_accuracy: 0.5446\n",
            "Epoch 83/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0121 - accuracy: 0.5356 - val_loss: 0.9883 - val_accuracy: 0.5503\n",
            "Epoch 84/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.9836 - accuracy: 0.5556 - val_loss: 1.0424 - val_accuracy: 0.5313\n",
            "Epoch 85/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0011 - accuracy: 0.5457 - val_loss: 1.0191 - val_accuracy: 0.5237\n",
            "Epoch 86/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0090 - accuracy: 0.5400 - val_loss: 0.9886 - val_accuracy: 0.5617\n",
            "Epoch 87/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0120 - accuracy: 0.5467 - val_loss: 1.0221 - val_accuracy: 0.5427\n",
            "Epoch 88/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0152 - accuracy: 0.5327 - val_loss: 1.0188 - val_accuracy: 0.5560\n",
            "Epoch 89/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.9755 - accuracy: 0.5576 - val_loss: 1.0269 - val_accuracy: 0.5522\n",
            "Epoch 90/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0056 - accuracy: 0.5400 - val_loss: 1.0180 - val_accuracy: 0.5332\n",
            "Epoch 91/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.9763 - accuracy: 0.5611 - val_loss: 1.0031 - val_accuracy: 0.5579\n",
            "Epoch 92/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0016 - accuracy: 0.5518 - val_loss: 1.0098 - val_accuracy: 0.5408\n",
            "Epoch 93/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0074 - accuracy: 0.5511 - val_loss: 1.0127 - val_accuracy: 0.5408\n",
            "Epoch 94/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.9984 - accuracy: 0.5406 - val_loss: 1.0185 - val_accuracy: 0.5465\n",
            "Epoch 95/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.9730 - accuracy: 0.5687 - val_loss: 0.9904 - val_accuracy: 0.5655\n",
            "Epoch 96/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0171 - accuracy: 0.5496 - val_loss: 0.9949 - val_accuracy: 0.5674\n",
            "Epoch 97/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.9979 - accuracy: 0.5667 - val_loss: 1.0031 - val_accuracy: 0.5731\n",
            "Epoch 98/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.9800 - accuracy: 0.5594 - val_loss: 1.0241 - val_accuracy: 0.5484\n",
            "Epoch 99/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.9387 - accuracy: 0.5756 - val_loss: 1.0117 - val_accuracy: 0.5522\n",
            "Epoch 100/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.9621 - accuracy: 0.5678 - val_loss: 1.0103 - val_accuracy: 0.5465\n",
            "Epoch 101/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.9713 - accuracy: 0.5609 - val_loss: 1.0141 - val_accuracy: 0.5617\n",
            "Epoch 102/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0034 - accuracy: 0.5539 - val_loss: 1.0117 - val_accuracy: 0.5503\n",
            "Epoch 103/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.9486 - accuracy: 0.5824 - val_loss: 1.0153 - val_accuracy: 0.5636\n",
            "Epoch 104/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.9461 - accuracy: 0.5877 - val_loss: 1.0043 - val_accuracy: 0.5655\n",
            "Epoch 105/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.9829 - accuracy: 0.5591 - val_loss: 1.0200 - val_accuracy: 0.5693\n",
            "Epoch 106/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.9555 - accuracy: 0.5835 - val_loss: 1.0171 - val_accuracy: 0.5579\n",
            "Epoch 107/200\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.9658 - accuracy: 0.5624 - val_loss: 1.0238 - val_accuracy: 0.5674\n",
            "Epoch 108/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.9772 - accuracy: 0.5598 - val_loss: 1.0075 - val_accuracy: 0.5598\n",
            "Epoch 109/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.9692 - accuracy: 0.5557 - val_loss: 1.0118 - val_accuracy: 0.5617\n",
            "Epoch 110/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.9551 - accuracy: 0.5769 - val_loss: 1.0371 - val_accuracy: 0.5579\n",
            "Epoch 111/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.9578 - accuracy: 0.5749 - val_loss: 1.0170 - val_accuracy: 0.5560\n",
            "Epoch 112/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.9576 - accuracy: 0.5713 - val_loss: 1.0203 - val_accuracy: 0.5712\n",
            "Epoch 113/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.9679 - accuracy: 0.5619 - val_loss: 1.0582 - val_accuracy: 0.5560\n",
            "Epoch 114/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.9312 - accuracy: 0.5848 - val_loss: 1.0403 - val_accuracy: 0.5598\n",
            "Epoch 115/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.9552 - accuracy: 0.5642 - val_loss: 1.0337 - val_accuracy: 0.5769\n",
            "Epoch 116/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.9577 - accuracy: 0.5745 - val_loss: 1.0611 - val_accuracy: 0.5693\n",
            "Epoch 117/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.9590 - accuracy: 0.5780 - val_loss: 1.0483 - val_accuracy: 0.5408\n",
            "Epoch 118/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.9335 - accuracy: 0.5796 - val_loss: 1.0173 - val_accuracy: 0.5655\n",
            "Epoch 119/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.9557 - accuracy: 0.5645 - val_loss: 1.0313 - val_accuracy: 0.5446\n",
            "Epoch 120/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.9518 - accuracy: 0.5778 - val_loss: 1.0500 - val_accuracy: 0.5769\n",
            "Epoch 121/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.9602 - accuracy: 0.5649 - val_loss: 1.0501 - val_accuracy: 0.5579\n",
            "Epoch 122/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.9692 - accuracy: 0.5684 - val_loss: 1.0674 - val_accuracy: 0.5541\n",
            "Epoch 123/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.9651 - accuracy: 0.5542 - val_loss: 1.0748 - val_accuracy: 0.5484\n",
            "Epoch 124/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.9933 - accuracy: 0.5540 - val_loss: 1.0362 - val_accuracy: 0.5598\n",
            "Epoch 125/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.9285 - accuracy: 0.5861 - val_loss: 1.1663 - val_accuracy: 0.5047\n",
            "Epoch 126/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.9452 - accuracy: 0.5770 - val_loss: 1.0283 - val_accuracy: 0.5465\n",
            "Epoch 127/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.9194 - accuracy: 0.5916 - val_loss: 1.0345 - val_accuracy: 0.5427\n",
            "Epoch 128/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.9211 - accuracy: 0.5943 - val_loss: 1.1218 - val_accuracy: 0.5541\n",
            "Epoch 129/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0270 - accuracy: 0.5469 - val_loss: 1.0182 - val_accuracy: 0.5598\n",
            "Epoch 130/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.9374 - accuracy: 0.5753 - val_loss: 1.0502 - val_accuracy: 0.5636\n",
            "Epoch 131/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.9308 - accuracy: 0.5797 - val_loss: 1.0465 - val_accuracy: 0.5503\n",
            "Epoch 132/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.9189 - accuracy: 0.5837 - val_loss: 1.0439 - val_accuracy: 0.5636\n",
            "Epoch 133/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.9344 - accuracy: 0.5878 - val_loss: 1.0583 - val_accuracy: 0.5598\n",
            "Epoch 134/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.9570 - accuracy: 0.5698 - val_loss: 1.0352 - val_accuracy: 0.5598\n",
            "Epoch 135/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.9165 - accuracy: 0.5903 - val_loss: 1.0622 - val_accuracy: 0.5617\n",
            "Epoch 136/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.9126 - accuracy: 0.5991 - val_loss: 1.0511 - val_accuracy: 0.5655\n",
            "Epoch 137/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.9242 - accuracy: 0.5928 - val_loss: 1.0648 - val_accuracy: 0.5503\n",
            "Epoch 138/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.9291 - accuracy: 0.5945 - val_loss: 1.0407 - val_accuracy: 0.5693\n",
            "Epoch 139/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.9320 - accuracy: 0.5880 - val_loss: 1.0415 - val_accuracy: 0.5541\n",
            "Epoch 140/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.9427 - accuracy: 0.5891 - val_loss: 1.0588 - val_accuracy: 0.5560\n",
            "Epoch 141/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.8895 - accuracy: 0.5998 - val_loss: 1.0635 - val_accuracy: 0.5522\n",
            "Epoch 142/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.9171 - accuracy: 0.5934 - val_loss: 1.1038 - val_accuracy: 0.5617\n",
            "Epoch 143/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.9178 - accuracy: 0.5946 - val_loss: 1.0622 - val_accuracy: 0.5617\n",
            "Epoch 144/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.9122 - accuracy: 0.5850 - val_loss: 1.1196 - val_accuracy: 0.5522\n",
            "Epoch 145/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.9674 - accuracy: 0.5744 - val_loss: 1.1280 - val_accuracy: 0.5256\n",
            "Epoch 146/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.9084 - accuracy: 0.5925 - val_loss: 1.0747 - val_accuracy: 0.5560\n",
            "Epoch 147/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.8984 - accuracy: 0.6079 - val_loss: 1.0678 - val_accuracy: 0.5579\n",
            "Epoch 148/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.8823 - accuracy: 0.6206 - val_loss: 1.0695 - val_accuracy: 0.5522\n",
            "Epoch 149/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.8909 - accuracy: 0.6020 - val_loss: 1.0869 - val_accuracy: 0.5655\n",
            "Epoch 150/200\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.8911 - accuracy: 0.6177 - val_loss: 1.1044 - val_accuracy: 0.5541\n",
            "Epoch 151/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.8824 - accuracy: 0.5997 - val_loss: 1.0994 - val_accuracy: 0.5541\n",
            "Epoch 152/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.8784 - accuracy: 0.6143 - val_loss: 1.0798 - val_accuracy: 0.5465\n",
            "Epoch 153/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.9013 - accuracy: 0.5982 - val_loss: 1.0700 - val_accuracy: 0.5579\n",
            "Epoch 154/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.8779 - accuracy: 0.6110 - val_loss: 1.0784 - val_accuracy: 0.5712\n",
            "Epoch 155/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.8953 - accuracy: 0.5962 - val_loss: 1.1240 - val_accuracy: 0.5484\n",
            "Epoch 156/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.8840 - accuracy: 0.6197 - val_loss: 1.0720 - val_accuracy: 0.5674\n",
            "Epoch 157/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.8552 - accuracy: 0.6277 - val_loss: 1.1647 - val_accuracy: 0.5389\n",
            "Epoch 158/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.9455 - accuracy: 0.5927 - val_loss: 1.0919 - val_accuracy: 0.5427\n",
            "Epoch 159/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.8718 - accuracy: 0.6146 - val_loss: 1.1123 - val_accuracy: 0.5427\n",
            "Epoch 160/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.8661 - accuracy: 0.6174 - val_loss: 1.1094 - val_accuracy: 0.5712\n",
            "Epoch 161/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.8614 - accuracy: 0.6194 - val_loss: 1.1444 - val_accuracy: 0.5085\n",
            "Epoch 162/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.9733 - accuracy: 0.5776 - val_loss: 1.0905 - val_accuracy: 0.5674\n",
            "Epoch 163/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.8609 - accuracy: 0.6092 - val_loss: 1.0999 - val_accuracy: 0.5674\n",
            "Epoch 164/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.9006 - accuracy: 0.5974 - val_loss: 1.0698 - val_accuracy: 0.5617\n",
            "Epoch 165/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.8658 - accuracy: 0.6171 - val_loss: 1.1698 - val_accuracy: 0.5427\n",
            "Epoch 166/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.8780 - accuracy: 0.6070 - val_loss: 1.1215 - val_accuracy: 0.5636\n",
            "Epoch 167/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.8722 - accuracy: 0.6013 - val_loss: 1.1896 - val_accuracy: 0.5332\n",
            "Epoch 168/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.8725 - accuracy: 0.6134 - val_loss: 1.1138 - val_accuracy: 0.5655\n",
            "Epoch 169/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.8623 - accuracy: 0.6240 - val_loss: 1.1260 - val_accuracy: 0.5522\n",
            "Epoch 170/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.8818 - accuracy: 0.6120 - val_loss: 1.1416 - val_accuracy: 0.5313\n",
            "Epoch 171/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.9160 - accuracy: 0.5924 - val_loss: 1.1141 - val_accuracy: 0.5579\n",
            "Epoch 172/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.9209 - accuracy: 0.5996 - val_loss: 1.1165 - val_accuracy: 0.5332\n",
            "Epoch 173/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.8902 - accuracy: 0.5997 - val_loss: 1.1127 - val_accuracy: 0.5617\n",
            "Epoch 174/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.8696 - accuracy: 0.6146 - val_loss: 1.1110 - val_accuracy: 0.5560\n",
            "Epoch 175/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.8403 - accuracy: 0.6239 - val_loss: 1.1100 - val_accuracy: 0.5579\n",
            "Epoch 176/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.8315 - accuracy: 0.6350 - val_loss: 1.1378 - val_accuracy: 0.5712\n",
            "Epoch 177/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.8378 - accuracy: 0.6288 - val_loss: 1.1329 - val_accuracy: 0.5617\n",
            "Epoch 178/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.8449 - accuracy: 0.6347 - val_loss: 1.1119 - val_accuracy: 0.5598\n",
            "Epoch 179/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.8397 - accuracy: 0.6237 - val_loss: 1.1185 - val_accuracy: 0.5446\n",
            "Epoch 180/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.8347 - accuracy: 0.6371 - val_loss: 1.1639 - val_accuracy: 0.5465\n",
            "Epoch 181/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.8629 - accuracy: 0.6170 - val_loss: 1.1874 - val_accuracy: 0.5617\n",
            "Epoch 182/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.8669 - accuracy: 0.6056 - val_loss: 1.1773 - val_accuracy: 0.5636\n",
            "Epoch 183/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.8425 - accuracy: 0.6214 - val_loss: 1.1644 - val_accuracy: 0.5256\n",
            "Epoch 184/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.9491 - accuracy: 0.5683 - val_loss: 1.1637 - val_accuracy: 0.5712\n",
            "Epoch 185/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.8503 - accuracy: 0.6259 - val_loss: 1.1471 - val_accuracy: 0.5351\n",
            "Epoch 186/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.8170 - accuracy: 0.6413 - val_loss: 1.2809 - val_accuracy: 0.5446\n",
            "Epoch 187/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.8926 - accuracy: 0.5986 - val_loss: 1.1704 - val_accuracy: 0.5598\n",
            "Epoch 188/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.8292 - accuracy: 0.6275 - val_loss: 1.1804 - val_accuracy: 0.5484\n",
            "Epoch 189/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.8302 - accuracy: 0.6272 - val_loss: 1.1810 - val_accuracy: 0.5522\n",
            "Epoch 190/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.8205 - accuracy: 0.6288 - val_loss: 1.1843 - val_accuracy: 0.5579\n",
            "Epoch 191/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.8258 - accuracy: 0.6267 - val_loss: 1.1687 - val_accuracy: 0.5465\n",
            "Epoch 192/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.8224 - accuracy: 0.6468 - val_loss: 1.1857 - val_accuracy: 0.5370\n",
            "Epoch 193/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.8077 - accuracy: 0.6454 - val_loss: 1.1812 - val_accuracy: 0.5465\n",
            "Epoch 194/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.8197 - accuracy: 0.6361 - val_loss: 1.1679 - val_accuracy: 0.5617\n",
            "Epoch 195/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.8190 - accuracy: 0.6414 - val_loss: 1.2138 - val_accuracy: 0.5484\n",
            "Epoch 196/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.8200 - accuracy: 0.6365 - val_loss: 1.2009 - val_accuracy: 0.5351\n",
            "Epoch 197/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.8644 - accuracy: 0.6172 - val_loss: 1.1833 - val_accuracy: 0.5408\n",
            "Epoch 198/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.8039 - accuracy: 0.6436 - val_loss: 1.1943 - val_accuracy: 0.5598\n",
            "Epoch 199/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.8268 - accuracy: 0.6463 - val_loss: 1.2767 - val_accuracy: 0.5161\n",
            "Epoch 200/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.8107 - accuracy: 0.6493 - val_loss: 1.2077 - val_accuracy: 0.5541\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eMBkex9tUfhf"
      },
      "source": [
        "model.save('/content/drive/MyDrive/Colab Notebooks/speech/dataset/basic_tempogram_merged.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IkazhV_OUfhg"
      },
      "source": [
        "###test_result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AHzPRDEUUfhh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20b72476-67b4-4d74-f1c5-63dfe0696387"
      },
      "source": [
        "d = {0: 'happy',\n",
        "     1: 'sad',\n",
        "     2: 'angry',\n",
        "     3: 'fear'}\n",
        "Y_test_pred = np.argmax(model.predict(X_test), axis=-1)\n",
        "Y_test_pred = list(map(lambda x: d[x], Y_test_pred))\n",
        "y_test = np.argmax(y_test, axis=-1)\n",
        "y_test = list(map(lambda x: d[x], y_test))\n",
        "print(classification_report(y_test, Y_test_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.67      0.61      0.64       155\n",
            "        fear       0.41      0.27      0.33       144\n",
            "       happy       0.49      0.56      0.52       151\n",
            "         sad       0.54      0.70      0.61       136\n",
            "\n",
            "    accuracy                           0.54       586\n",
            "   macro avg       0.53      0.54      0.53       586\n",
            "weighted avg       0.53      0.54      0.53       586\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPqHBDBhUfhj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 483
        },
        "outputId": "2e62bab8-88b9-4ff4-c776-a7ae81cfb3e9"
      },
      "source": [
        "import scikitplot as skplt\n",
        "skplt.metrics.plot_confusion_matrix(\n",
        "    y_test, \n",
        "    Y_test_pred,\n",
        "    figsize=(8,8))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f0b60412390>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y4YWk4_ZW4wc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q8JULeSZXNcL"
      },
      "source": [
        "# Tempogram + conv1D"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDbzABof490v"
      },
      "source": [
        "audio_duration = 2\n",
        "sampling_rate = 44100\n",
        "input_length = sampling_rate * audio_duration\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sOUqwufbXNcd"
      },
      "source": [
        "features = []\n",
        "labels = []\n",
        "for i in range(len(Ravdess_DF['Paths'])):\n",
        "  if ((Ravdess_DF['Emotion'][i] == '03') | (Ravdess_DF['Emotion'][i] == '04') | \n",
        "      (Ravdess_DF['Emotion'][i] == '05') | (Ravdess_DF['Emotion'][i] == '06')):\n",
        "    \n",
        "    signal, sr = librosa.load(Ravdess_DF['Paths'][i])\n",
        "    if len(signal) > input_length:\n",
        "        signal = signal[0:input_length]\n",
        "    elif  input_length > len(signal):\n",
        "        max_offset = input_length - len(signal)  \n",
        "        signal = np.pad(signal, (0, max_offset), \"constant\")\n",
        "    tempogram = librosa.feature.tempogram(signal, sr)\n",
        "    features.append(tempogram)\n",
        "    if Ravdess_DF['Emotion'][i] == '03':\n",
        "      labels.append(0)\n",
        "    elif Ravdess_DF['Emotion'][i] == '04':\n",
        "      labels.append(1)\n",
        "    elif Ravdess_DF['Emotion'][i] == '05':\n",
        "      labels.append(2)\n",
        "    elif Ravdess_DF['Emotion'][i] == '06':\n",
        "      labels.append(3)\n",
        "\n",
        "\n",
        "for i in range(len(CREMA_D_df)):\n",
        "  if ((CREMA_D_df['Emotion'][i] == 'HAP') | (CREMA_D_df['Emotion'][i] == 'SAD') | \n",
        "      (CREMA_D_df['Emotion'][i] == 'ANG') | (CREMA_D_df['Emotion'][i] == 'FEA')):\n",
        "    \n",
        "    if CREMA_D_df['Emotion'][i] == 'HAP':\n",
        "      labels.append(0)\n",
        "    elif CREMA_D_df['Emotion'][i] == 'SAD':\n",
        "      labels.append(1)\n",
        "    elif CREMA_D_df['Emotion'][i] == 'ANG':\n",
        "      labels.append(2)\n",
        "    elif CREMA_D_df['Emotion'][i] == 'FEA':\n",
        "      labels.append(3)\n",
        "\n",
        "\n",
        "    signal, sr =  librosa.load(CREMA_D_df['Paths'][i])\n",
        "    if len(signal) > input_length:\n",
        "        signal = signal[0:input_length]\n",
        "    elif  input_length > len(signal):\n",
        "        max_offset = input_length - len(signal)  \n",
        "        signal = np.pad(signal, (0, max_offset), \"constant\")\n",
        "    tempogram = librosa.feature.tempogram(signal, sr)\n",
        "    features.append(tempogram)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDZ1IDBSXNce"
      },
      "source": [
        "X = features\n",
        "y = labels\n",
        "\n",
        "y = np.array(y)\n",
        "y = to_categorical(y)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=0)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=0)\n",
        "\n",
        "X_train = np.array(X_train)\n",
        "X_test = np.array(X_test)\n",
        "X_val = np.array(X_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ytS1moepYT3l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34d0ee3a-ed47-4d0b-cd4f-542093262ce5"
      },
      "source": [
        "X_train.shape,X_test.shape,y_train.shape,y_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((4739, 384, 173), (586, 384, 173), (4739, 4), (586, 4))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RKGOhIllYlwH"
      },
      "source": [
        "### conv1D"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0yrT1F9IYlwI"
      },
      "source": [
        "\n",
        "# CNN I/P Config\n",
        "num_classes = 4\n",
        "input_shape = X_train.shape[1:]\n",
        "learning_rate = 0.0001\n",
        "decay = 1e-6\n",
        "momentum = 0.9\n",
        "\n",
        "#LSTM Configuration\n",
        "num_lstm = 256"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHg7H9sOYlwK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f5efd5a-447b-4990-9c7a-b747fded422b"
      },
      "source": [
        "model = Sequential(name='Audio_CNN_1D')\n",
        "\n",
        "# LFLB1\n",
        "model.add(Conv1D(filters=64, kernel_size=(3), strides=1, padding='same', data_format='channels_last',input_shape=input_shape))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('elu'))\n",
        "model.add(MaxPooling1D(pool_size=4, strides=4))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "# LFLB2\n",
        "model.add(Conv1D(filters=64, kernel_size=3, strides=1, padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('elu'))\n",
        "model.add(MaxPooling1D(pool_size=4, strides=4))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# LFLB3\n",
        "model.add(Conv1D(filters=128, kernel_size=3, strides=1, padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('elu'))\n",
        "model.add(MaxPooling1D(pool_size=4, strides=4))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# LFLB4\n",
        "model.add(Conv1D(filters=128, kernel_size=3, strides=1, padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('elu'))\n",
        "model.add(MaxPooling1D(pool_size=4, strides=4))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# LSTM\n",
        "model.add(LSTM(units=num_lstm))\n",
        "\n",
        "# FC\n",
        "model.add(Dense(units=num_classes, activation='softmax'))\n",
        "\n",
        "# Model compilation\n",
        "opt= keras.optimizers.Adam(lr=0.01, beta_1=0.9,  beta_2=0.999, amsgrad=False)\n",
        "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
        "\n",
        "model.summary()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"Audio_CNN_1D\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 384, 64)           33280     \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 384, 64)           256       \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 384, 64)           0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D) (None, 96, 64)            0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 96, 64)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 96, 64)            12352     \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 96, 64)            256       \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 96, 64)            0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1 (None, 24, 64)            0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 24, 64)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 24, 128)           24704     \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 24, 128)           512       \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 24, 128)           0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_2 (MaxPooling1 (None, 6, 128)            0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 6, 128)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 6, 128)            49280     \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 6, 128)            512       \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 6, 128)            0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_3 (MaxPooling1 (None, 1, 128)            0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 1, 128)            0         \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 256)               394240    \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 4)                 1028      \n",
            "=================================================================\n",
            "Total params: 516,420\n",
            "Trainable params: 515,652\n",
            "Non-trainable params: 768\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xGb90pjgYlwM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f9d6619-fe09-4177-cec3-b8cbfc0d6308"
      },
      "source": [
        "#Train Config\n",
        "\n",
        "batch_size = 16\n",
        "num_epochs = 200\n",
        "\n",
        "# Model Training\n",
        "lr_reduce = ReduceLROnPlateau(monitor='val_loss', factor=0.9, patience=20, min_lr=0.000001)\n",
        "# Please change the model name accordingly.\n",
        "mcp_save = ModelCheckpoint('/content/Audio_1DCNN.h5', save_best_only=True, monitor='val_categorical_accuracy', mode='max')\n",
        "cnnhistory=model.fit(X_train, y_train, batch_size=batch_size, epochs=num_epochs,validation_data=(X_val, y_val), callbacks=[mcp_save, lr_reduce])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "297/297 [==============================] - 55s 15ms/step - loss: 1.3757 - categorical_accuracy: 0.3172 - val_loss: 1.2310 - val_categorical_accuracy: 0.4288\n",
            "Epoch 2/200\n",
            "297/297 [==============================] - 3s 10ms/step - loss: 1.2784 - categorical_accuracy: 0.3888 - val_loss: 1.1686 - val_categorical_accuracy: 0.4421\n",
            "Epoch 3/200\n",
            "297/297 [==============================] - 3s 10ms/step - loss: 1.2690 - categorical_accuracy: 0.3897 - val_loss: 1.3972 - val_categorical_accuracy: 0.2827\n",
            "Epoch 4/200\n",
            "297/297 [==============================] - 3s 10ms/step - loss: 1.2441 - categorical_accuracy: 0.4150 - val_loss: 1.2183 - val_categorical_accuracy: 0.3852\n",
            "Epoch 5/200\n",
            "297/297 [==============================] - 3s 11ms/step - loss: 1.2282 - categorical_accuracy: 0.4291 - val_loss: 1.5317 - val_categorical_accuracy: 0.2922\n",
            "Epoch 6/200\n",
            "297/297 [==============================] - 3s 10ms/step - loss: 1.2426 - categorical_accuracy: 0.4095 - val_loss: 1.3484 - val_categorical_accuracy: 0.3795\n",
            "Epoch 7/200\n",
            "297/297 [==============================] - 3s 10ms/step - loss: 1.2377 - categorical_accuracy: 0.4020 - val_loss: 1.1512 - val_categorical_accuracy: 0.4934\n",
            "Epoch 8/200\n",
            "297/297 [==============================] - 3s 10ms/step - loss: 1.2262 - categorical_accuracy: 0.4164 - val_loss: 1.3981 - val_categorical_accuracy: 0.1973\n",
            "Epoch 9/200\n",
            "297/297 [==============================] - 3s 10ms/step - loss: 1.2416 - categorical_accuracy: 0.4150 - val_loss: 1.3068 - val_categorical_accuracy: 0.3567\n",
            "Epoch 10/200\n",
            "297/297 [==============================] - 3s 10ms/step - loss: 1.2087 - categorical_accuracy: 0.4351 - val_loss: 1.3562 - val_categorical_accuracy: 0.3093\n",
            "Epoch 11/200\n",
            "297/297 [==============================] - 3s 10ms/step - loss: 1.2264 - categorical_accuracy: 0.4147 - val_loss: 1.6067 - val_categorical_accuracy: 0.2770\n",
            "Epoch 12/200\n",
            "297/297 [==============================] - 3s 10ms/step - loss: 1.2268 - categorical_accuracy: 0.4308 - val_loss: 1.5710 - val_categorical_accuracy: 0.2676\n",
            "Epoch 13/200\n",
            "297/297 [==============================] - 3s 10ms/step - loss: 1.2570 - categorical_accuracy: 0.4027 - val_loss: 1.6887 - val_categorical_accuracy: 0.2979\n",
            "Epoch 14/200\n",
            "297/297 [==============================] - 3s 10ms/step - loss: 1.2169 - categorical_accuracy: 0.4353 - val_loss: 1.2180 - val_categorical_accuracy: 0.3985\n",
            "Epoch 15/200\n",
            "297/297 [==============================] - 3s 10ms/step - loss: 1.2325 - categorical_accuracy: 0.4146 - val_loss: 1.2165 - val_categorical_accuracy: 0.4649\n",
            "Epoch 16/200\n",
            "297/297 [==============================] - 3s 10ms/step - loss: 1.2239 - categorical_accuracy: 0.4261 - val_loss: 1.1978 - val_categorical_accuracy: 0.4649\n",
            "Epoch 17/200\n",
            "297/297 [==============================] - 3s 10ms/step - loss: 1.2228 - categorical_accuracy: 0.4240 - val_loss: 1.5491 - val_categorical_accuracy: 0.2846\n",
            "Epoch 18/200\n",
            "297/297 [==============================] - 3s 10ms/step - loss: 1.2248 - categorical_accuracy: 0.4405 - val_loss: 1.2850 - val_categorical_accuracy: 0.3757\n",
            "Epoch 19/200\n",
            "297/297 [==============================] - 3s 10ms/step - loss: 1.2153 - categorical_accuracy: 0.4342 - val_loss: 1.2062 - val_categorical_accuracy: 0.4763\n",
            "Epoch 20/200\n",
            "297/297 [==============================] - 3s 10ms/step - loss: 1.2199 - categorical_accuracy: 0.4321 - val_loss: 1.1818 - val_categorical_accuracy: 0.5104\n",
            "Epoch 21/200\n",
            "297/297 [==============================] - 3s 11ms/step - loss: 1.2100 - categorical_accuracy: 0.4410 - val_loss: 1.5246 - val_categorical_accuracy: 0.2922\n",
            "Epoch 22/200\n",
            "297/297 [==============================] - 3s 10ms/step - loss: 1.2164 - categorical_accuracy: 0.4170 - val_loss: 1.2381 - val_categorical_accuracy: 0.4630\n",
            "Epoch 23/200\n",
            "297/297 [==============================] - 3s 10ms/step - loss: 1.2302 - categorical_accuracy: 0.4292 - val_loss: 1.1887 - val_categorical_accuracy: 0.5142\n",
            "Epoch 24/200\n",
            "297/297 [==============================] - 3s 11ms/step - loss: 1.2211 - categorical_accuracy: 0.4257 - val_loss: 1.2933 - val_categorical_accuracy: 0.4175\n",
            "Epoch 25/200\n",
            "297/297 [==============================] - 3s 10ms/step - loss: 1.2119 - categorical_accuracy: 0.4293 - val_loss: 1.2472 - val_categorical_accuracy: 0.4516\n",
            "Epoch 26/200\n",
            "297/297 [==============================] - 3s 11ms/step - loss: 1.2317 - categorical_accuracy: 0.4311 - val_loss: 1.5318 - val_categorical_accuracy: 0.2751\n",
            "Epoch 27/200\n",
            "297/297 [==============================] - 3s 10ms/step - loss: 1.2200 - categorical_accuracy: 0.4333 - val_loss: 1.4421 - val_categorical_accuracy: 0.3074\n",
            "Epoch 28/200\n",
            "297/297 [==============================] - 3s 10ms/step - loss: 1.2279 - categorical_accuracy: 0.4310 - val_loss: 1.2659 - val_categorical_accuracy: 0.3909\n",
            "Epoch 29/200\n",
            "297/297 [==============================] - 3s 10ms/step - loss: 1.2047 - categorical_accuracy: 0.4368 - val_loss: 1.2755 - val_categorical_accuracy: 0.3814\n",
            "Epoch 30/200\n",
            "297/297 [==============================] - 3s 10ms/step - loss: 1.2047 - categorical_accuracy: 0.4288 - val_loss: 1.2441 - val_categorical_accuracy: 0.5085\n",
            "Epoch 31/200\n",
            "297/297 [==============================] - 3s 10ms/step - loss: 1.2111 - categorical_accuracy: 0.4372 - val_loss: 1.3256 - val_categorical_accuracy: 0.3871\n",
            "Epoch 32/200\n",
            "297/297 [==============================] - 3s 10ms/step - loss: 1.1767 - categorical_accuracy: 0.4539 - val_loss: 1.1768 - val_categorical_accuracy: 0.4118\n",
            "Epoch 33/200\n",
            "297/297 [==============================] - 3s 10ms/step - loss: 1.1947 - categorical_accuracy: 0.4405 - val_loss: 1.2148 - val_categorical_accuracy: 0.3947\n",
            "Epoch 34/200\n",
            "297/297 [==============================] - 3s 10ms/step - loss: 1.2131 - categorical_accuracy: 0.4297 - val_loss: 1.1460 - val_categorical_accuracy: 0.4896\n",
            "Epoch 35/200\n",
            "297/297 [==============================] - 3s 10ms/step - loss: 1.1993 - categorical_accuracy: 0.4556 - val_loss: 1.2459 - val_categorical_accuracy: 0.3510\n",
            "Epoch 36/200\n",
            "297/297 [==============================] - 3s 10ms/step - loss: 1.2027 - categorical_accuracy: 0.4453 - val_loss: 1.1407 - val_categorical_accuracy: 0.4972\n",
            "Epoch 37/200\n",
            "297/297 [==============================] - 3s 10ms/step - loss: 1.1944 - categorical_accuracy: 0.4459 - val_loss: 1.2372 - val_categorical_accuracy: 0.4250\n",
            "Epoch 38/200\n",
            "297/297 [==============================] - 3s 10ms/step - loss: 1.2045 - categorical_accuracy: 0.4355 - val_loss: 1.1517 - val_categorical_accuracy: 0.4535\n",
            "Epoch 39/200\n",
            "297/297 [==============================] - 3s 10ms/step - loss: 1.2289 - categorical_accuracy: 0.4250 - val_loss: 1.1705 - val_categorical_accuracy: 0.4326\n",
            "Epoch 40/200\n",
            "297/297 [==============================] - 3s 11ms/step - loss: 1.2050 - categorical_accuracy: 0.4390 - val_loss: 1.1460 - val_categorical_accuracy: 0.4877\n",
            "Epoch 41/200\n",
            "297/297 [==============================] - 3s 10ms/step - loss: 1.2143 - categorical_accuracy: 0.4350 - val_loss: 1.1929 - val_categorical_accuracy: 0.4554\n",
            "Epoch 42/200\n",
            "297/297 [==============================] - 3s 11ms/step - loss: 1.1993 - categorical_accuracy: 0.4389 - val_loss: 1.3155 - val_categorical_accuracy: 0.3795\n",
            "Epoch 43/200\n",
            "297/297 [==============================] - 3s 10ms/step - loss: 1.2174 - categorical_accuracy: 0.4271 - val_loss: 1.2834 - val_categorical_accuracy: 0.3605\n",
            "Epoch 44/200\n",
            "297/297 [==============================] - 3s 10ms/step - loss: 1.1991 - categorical_accuracy: 0.4412 - val_loss: 1.3293 - val_categorical_accuracy: 0.3624\n",
            "Epoch 45/200\n",
            "297/297 [==============================] - 3s 10ms/step - loss: 1.1860 - categorical_accuracy: 0.4513 - val_loss: 1.1888 - val_categorical_accuracy: 0.4194\n",
            "Epoch 46/200\n",
            "297/297 [==============================] - 3s 10ms/step - loss: 1.2308 - categorical_accuracy: 0.4284 - val_loss: 1.4768 - val_categorical_accuracy: 0.2808\n",
            "Epoch 47/200\n",
            "297/297 [==============================] - 3s 11ms/step - loss: 1.2134 - categorical_accuracy: 0.4377 - val_loss: 1.3651 - val_categorical_accuracy: 0.3397\n",
            "Epoch 48/200\n",
            "297/297 [==============================] - 3s 10ms/step - loss: 1.2011 - categorical_accuracy: 0.4490 - val_loss: 1.3919 - val_categorical_accuracy: 0.3719\n",
            "Epoch 49/200\n",
            "297/297 [==============================] - 3s 10ms/step - loss: 1.2032 - categorical_accuracy: 0.4300 - val_loss: 1.3222 - val_categorical_accuracy: 0.3719\n",
            "Epoch 50/200\n",
            "297/297 [==============================] - 3s 10ms/step - loss: 1.2223 - categorical_accuracy: 0.4209 - val_loss: 1.2530 - val_categorical_accuracy: 0.3719\n",
            "Epoch 51/200\n",
            "297/297 [==============================] - 3s 10ms/step - loss: 1.2140 - categorical_accuracy: 0.4432 - val_loss: 1.2333 - val_categorical_accuracy: 0.3757\n",
            "Epoch 52/200\n",
            "297/297 [==============================] - 3s 10ms/step - loss: 1.2053 - categorical_accuracy: 0.4577 - val_loss: 1.3090 - val_categorical_accuracy: 0.3529\n",
            "Epoch 53/200\n",
            "297/297 [==============================] - 3s 10ms/step - loss: 1.2093 - categorical_accuracy: 0.4372 - val_loss: 1.4262 - val_categorical_accuracy: 0.3264\n",
            "Epoch 54/200\n",
            "297/297 [==============================] - 3s 11ms/step - loss: 1.2060 - categorical_accuracy: 0.4346 - val_loss: 1.4273 - val_categorical_accuracy: 0.3074\n",
            "Epoch 55/200\n",
            "297/297 [==============================] - 3s 10ms/step - loss: 1.2004 - categorical_accuracy: 0.4427 - val_loss: 1.3075 - val_categorical_accuracy: 0.3795\n",
            "Epoch 56/200\n",
            "297/297 [==============================] - 3s 10ms/step - loss: 1.2235 - categorical_accuracy: 0.4304 - val_loss: 1.2077 - val_categorical_accuracy: 0.4478\n",
            "Epoch 57/200\n",
            "297/297 [==============================] - 3s 10ms/step - loss: 1.2041 - categorical_accuracy: 0.4390 - val_loss: 1.2323 - val_categorical_accuracy: 0.4231\n",
            "Epoch 58/200\n",
            "297/297 [==============================] - 3s 10ms/step - loss: 1.1907 - categorical_accuracy: 0.4624 - val_loss: 1.3034 - val_categorical_accuracy: 0.3643\n",
            "Epoch 59/200\n",
            "297/297 [==============================] - 3s 10ms/step - loss: 1.1895 - categorical_accuracy: 0.4484 - val_loss: 1.3349 - val_categorical_accuracy: 0.3852\n",
            "Epoch 60/200\n",
            "297/297 [==============================] - 3s 10ms/step - loss: 1.1842 - categorical_accuracy: 0.4494 - val_loss: 1.3244 - val_categorical_accuracy: 0.3852\n",
            "Epoch 61/200\n",
            "297/297 [==============================] - 3s 10ms/step - loss: 1.1990 - categorical_accuracy: 0.4362 - val_loss: 1.1225 - val_categorical_accuracy: 0.4611\n",
            "Epoch 62/200\n",
            "297/297 [==============================] - 3s 10ms/step - loss: 1.2280 - categorical_accuracy: 0.4267 - val_loss: 1.4777 - val_categorical_accuracy: 0.2657\n",
            "Epoch 63/200\n",
            "297/297 [==============================] - 3s 10ms/step - loss: 1.2017 - categorical_accuracy: 0.4470 - val_loss: 1.1871 - val_categorical_accuracy: 0.4421\n",
            "Epoch 64/200\n",
            "297/297 [==============================] - 3s 11ms/step - loss: 1.1922 - categorical_accuracy: 0.4413 - val_loss: 1.1615 - val_categorical_accuracy: 0.4611\n",
            "Epoch 65/200\n",
            "297/297 [==============================] - 3s 11ms/step - loss: 1.1866 - categorical_accuracy: 0.4653 - val_loss: 1.2076 - val_categorical_accuracy: 0.3795\n",
            "Epoch 66/200\n",
            "297/297 [==============================] - 3s 11ms/step - loss: 1.1880 - categorical_accuracy: 0.4514 - val_loss: 1.1266 - val_categorical_accuracy: 0.4611\n",
            "Epoch 67/200\n",
            "297/297 [==============================] - 3s 10ms/step - loss: 1.2090 - categorical_accuracy: 0.4545 - val_loss: 1.2637 - val_categorical_accuracy: 0.3605\n",
            "Epoch 68/200\n",
            "297/297 [==============================] - 3s 10ms/step - loss: 1.1939 - categorical_accuracy: 0.4537 - val_loss: 1.1948 - val_categorical_accuracy: 0.4478\n",
            "Epoch 69/200\n",
            "297/297 [==============================] - 3s 10ms/step - loss: 1.1944 - categorical_accuracy: 0.4591 - val_loss: 1.1597 - val_categorical_accuracy: 0.4801\n",
            "Epoch 70/200\n",
            "297/297 [==============================] - 3s 10ms/step - loss: 1.2037 - categorical_accuracy: 0.4352 - val_loss: 1.2535 - val_categorical_accuracy: 0.4137\n",
            "Epoch 71/200\n",
            "297/297 [==============================] - 3s 10ms/step - loss: 1.1816 - categorical_accuracy: 0.4573 - val_loss: 1.2614 - val_categorical_accuracy: 0.4080\n",
            "Epoch 72/200\n",
            "297/297 [==============================] - 3s 10ms/step - loss: 1.1984 - categorical_accuracy: 0.4499 - val_loss: 1.2134 - val_categorical_accuracy: 0.4250\n",
            "Epoch 73/200\n",
            "297/297 [==============================] - 3s 10ms/step - loss: 1.1744 - categorical_accuracy: 0.4644 - val_loss: 1.3050 - val_categorical_accuracy: 0.3871\n",
            "Epoch 74/200\n",
            "297/297 [==============================] - 3s 11ms/step - loss: 1.1868 - categorical_accuracy: 0.4562 - val_loss: 1.1902 - val_categorical_accuracy: 0.4497\n",
            "Epoch 75/200\n",
            "297/297 [==============================] - 3s 11ms/step - loss: 1.2014 - categorical_accuracy: 0.4422 - val_loss: 1.1374 - val_categorical_accuracy: 0.4991\n",
            "Epoch 76/200\n",
            "297/297 [==============================] - 3s 10ms/step - loss: 1.1710 - categorical_accuracy: 0.4589 - val_loss: 1.1646 - val_categorical_accuracy: 0.4877\n",
            "Epoch 77/200\n",
            "297/297 [==============================] - 3s 10ms/step - loss: 1.1883 - categorical_accuracy: 0.4570 - val_loss: 1.0776 - val_categorical_accuracy: 0.5218\n",
            "Epoch 78/200\n",
            "297/297 [==============================] - 3s 10ms/step - loss: 1.1988 - categorical_accuracy: 0.4458 - val_loss: 1.3202 - val_categorical_accuracy: 0.4440\n",
            "Epoch 79/200\n",
            "297/297 [==============================] - 3s 11ms/step - loss: 1.1864 - categorical_accuracy: 0.4656 - val_loss: 1.1102 - val_categorical_accuracy: 0.5180\n",
            "Epoch 80/200\n",
            "297/297 [==============================] - 3s 11ms/step - loss: 1.1813 - categorical_accuracy: 0.4641 - val_loss: 1.1362 - val_categorical_accuracy: 0.4877\n",
            "Epoch 81/200\n",
            "297/297 [==============================] - 3s 11ms/step - loss: 1.1706 - categorical_accuracy: 0.4692 - val_loss: 1.4346 - val_categorical_accuracy: 0.3055\n",
            "Epoch 82/200\n",
            "297/297 [==============================] - 3s 11ms/step - loss: 1.1775 - categorical_accuracy: 0.4419 - val_loss: 1.1910 - val_categorical_accuracy: 0.4231\n",
            "Epoch 83/200\n",
            "297/297 [==============================] - 3s 10ms/step - loss: 1.1875 - categorical_accuracy: 0.4502 - val_loss: 1.0777 - val_categorical_accuracy: 0.5028\n",
            "Epoch 84/200\n",
            "297/297 [==============================] - 3s 10ms/step - loss: 1.1660 - categorical_accuracy: 0.4593 - val_loss: 1.2468 - val_categorical_accuracy: 0.3890\n",
            "Epoch 85/200\n",
            "297/297 [==============================] - 3s 10ms/step - loss: 1.1778 - categorical_accuracy: 0.4556 - val_loss: 1.3344 - val_categorical_accuracy: 0.3852\n",
            "Epoch 86/200\n",
            "297/297 [==============================] - 3s 11ms/step - loss: 1.1885 - categorical_accuracy: 0.4632 - val_loss: 1.2669 - val_categorical_accuracy: 0.3852\n",
            "Epoch 87/200\n",
            "297/297 [==============================] - 3s 10ms/step - loss: 1.1933 - categorical_accuracy: 0.4479 - val_loss: 1.1307 - val_categorical_accuracy: 0.5370\n",
            "Epoch 88/200\n",
            "297/297 [==============================] - 3s 10ms/step - loss: 1.1734 - categorical_accuracy: 0.4599 - val_loss: 1.3775 - val_categorical_accuracy: 0.3283\n",
            "Epoch 89/200\n",
            "297/297 [==============================] - 3s 10ms/step - loss: 1.1881 - categorical_accuracy: 0.4594 - val_loss: 1.1316 - val_categorical_accuracy: 0.4953\n",
            "Epoch 90/200\n",
            "297/297 [==============================] - 3s 10ms/step - loss: 1.1702 - categorical_accuracy: 0.4618 - val_loss: 1.1478 - val_categorical_accuracy: 0.4934\n",
            "Epoch 91/200\n",
            "297/297 [==============================] - 3s 10ms/step - loss: 1.1806 - categorical_accuracy: 0.4574 - val_loss: 1.1400 - val_categorical_accuracy: 0.4592\n",
            "Epoch 92/200\n",
            "297/297 [==============================] - 3s 10ms/step - loss: 1.1738 - categorical_accuracy: 0.4616 - val_loss: 1.1955 - val_categorical_accuracy: 0.4288\n",
            "Epoch 93/200\n",
            "297/297 [==============================] - 3s 11ms/step - loss: 1.1936 - categorical_accuracy: 0.4515 - val_loss: 1.1809 - val_categorical_accuracy: 0.4592\n",
            "Epoch 94/200\n",
            "297/297 [==============================] - 3s 11ms/step - loss: 1.1815 - categorical_accuracy: 0.4558 - val_loss: 1.3487 - val_categorical_accuracy: 0.3283\n",
            "Epoch 95/200\n",
            "297/297 [==============================] - 3s 10ms/step - loss: 1.1894 - categorical_accuracy: 0.4410 - val_loss: 1.1980 - val_categorical_accuracy: 0.4763\n",
            "Epoch 96/200\n",
            "297/297 [==============================] - 3s 11ms/step - loss: 1.1621 - categorical_accuracy: 0.4663 - val_loss: 1.5166 - val_categorical_accuracy: 0.3245\n",
            "Epoch 97/200\n",
            "297/297 [==============================] - 3s 10ms/step - loss: 1.1874 - categorical_accuracy: 0.4622 - val_loss: 1.1272 - val_categorical_accuracy: 0.4744\n",
            "Epoch 98/200\n",
            "297/297 [==============================] - 3s 10ms/step - loss: 1.1788 - categorical_accuracy: 0.4538 - val_loss: 1.2777 - val_categorical_accuracy: 0.4231\n",
            "Epoch 99/200\n",
            "297/297 [==============================] - 3s 10ms/step - loss: 1.1624 - categorical_accuracy: 0.4753 - val_loss: 1.0928 - val_categorical_accuracy: 0.4972\n",
            "Epoch 100/200\n",
            "297/297 [==============================] - 3s 11ms/step - loss: 1.1703 - categorical_accuracy: 0.4484 - val_loss: 1.1546 - val_categorical_accuracy: 0.5066\n",
            "Epoch 101/200\n",
            "297/297 [==============================] - 3s 10ms/step - loss: 1.1763 - categorical_accuracy: 0.4531 - val_loss: 1.2677 - val_categorical_accuracy: 0.3757\n",
            "Epoch 102/200\n",
            "297/297 [==============================] - 3s 11ms/step - loss: 1.1922 - categorical_accuracy: 0.4473 - val_loss: 1.3867 - val_categorical_accuracy: 0.3472\n",
            "Epoch 103/200\n",
            "297/297 [==============================] - 3s 10ms/step - loss: 1.1854 - categorical_accuracy: 0.4413 - val_loss: 1.2238 - val_categorical_accuracy: 0.4137\n",
            "Epoch 104/200\n",
            "297/297 [==============================] - 3s 11ms/step - loss: 1.1818 - categorical_accuracy: 0.4424 - val_loss: 1.3395 - val_categorical_accuracy: 0.3548\n",
            "Epoch 105/200\n",
            "297/297 [==============================] - 3s 10ms/step - loss: 1.1809 - categorical_accuracy: 0.4530 - val_loss: 1.6467 - val_categorical_accuracy: 0.2903\n",
            "Epoch 106/200\n",
            "297/297 [==============================] - 3s 10ms/step - loss: 1.1883 - categorical_accuracy: 0.4445 - val_loss: 1.3237 - val_categorical_accuracy: 0.3472\n",
            "Epoch 107/200\n",
            "297/297 [==============================] - 3s 11ms/step - loss: 1.1950 - categorical_accuracy: 0.4420 - val_loss: 1.2231 - val_categorical_accuracy: 0.4611\n",
            "Epoch 108/200\n",
            "297/297 [==============================] - 3s 11ms/step - loss: 1.1793 - categorical_accuracy: 0.4622 - val_loss: 1.1775 - val_categorical_accuracy: 0.4744\n",
            "Epoch 109/200\n",
            "297/297 [==============================] - 3s 11ms/step - loss: 1.2025 - categorical_accuracy: 0.4492 - val_loss: 1.1410 - val_categorical_accuracy: 0.4991\n",
            "Epoch 110/200\n",
            "297/297 [==============================] - 3s 10ms/step - loss: 1.1741 - categorical_accuracy: 0.4548 - val_loss: 1.1328 - val_categorical_accuracy: 0.4915\n",
            "Epoch 111/200\n",
            "297/297 [==============================] - 3s 10ms/step - loss: 1.1884 - categorical_accuracy: 0.4577 - val_loss: 1.2143 - val_categorical_accuracy: 0.4288\n",
            "Epoch 112/200\n",
            "297/297 [==============================] - 3s 10ms/step - loss: 1.1782 - categorical_accuracy: 0.4653 - val_loss: 1.2782 - val_categorical_accuracy: 0.4213\n",
            "Epoch 113/200\n",
            "297/297 [==============================] - 3s 11ms/step - loss: 1.1920 - categorical_accuracy: 0.4513 - val_loss: 1.0833 - val_categorical_accuracy: 0.5294\n",
            "Epoch 114/200\n",
            "297/297 [==============================] - 3s 11ms/step - loss: 1.1906 - categorical_accuracy: 0.4561 - val_loss: 1.3033 - val_categorical_accuracy: 0.4364\n",
            "Epoch 115/200\n",
            "297/297 [==============================] - 3s 10ms/step - loss: 1.1655 - categorical_accuracy: 0.4707 - val_loss: 1.2232 - val_categorical_accuracy: 0.4307\n",
            "Epoch 116/200\n",
            "297/297 [==============================] - 3s 10ms/step - loss: 1.1752 - categorical_accuracy: 0.4785 - val_loss: 1.0807 - val_categorical_accuracy: 0.4725\n",
            "Epoch 117/200\n",
            "297/297 [==============================] - 3s 11ms/step - loss: 1.1849 - categorical_accuracy: 0.4545 - val_loss: 1.0811 - val_categorical_accuracy: 0.5294\n",
            "Epoch 118/200\n",
            "297/297 [==============================] - 3s 10ms/step - loss: 1.2014 - categorical_accuracy: 0.4527 - val_loss: 1.2350 - val_categorical_accuracy: 0.4364\n",
            "Epoch 119/200\n",
            "297/297 [==============================] - 3s 11ms/step - loss: 1.1791 - categorical_accuracy: 0.4527 - val_loss: 1.1254 - val_categorical_accuracy: 0.4763\n",
            "Epoch 120/200\n",
            "297/297 [==============================] - 3s 11ms/step - loss: 1.1738 - categorical_accuracy: 0.4482 - val_loss: 1.2541 - val_categorical_accuracy: 0.4004\n",
            "Epoch 121/200\n",
            "297/297 [==============================] - 3s 10ms/step - loss: 1.1798 - categorical_accuracy: 0.4553 - val_loss: 1.1297 - val_categorical_accuracy: 0.4801\n",
            "Epoch 122/200\n",
            "297/297 [==============================] - 3s 11ms/step - loss: 1.1856 - categorical_accuracy: 0.4406 - val_loss: 1.2218 - val_categorical_accuracy: 0.4535\n",
            "Epoch 123/200\n",
            "297/297 [==============================] - 3s 11ms/step - loss: 1.1671 - categorical_accuracy: 0.4639 - val_loss: 1.6294 - val_categorical_accuracy: 0.3093\n",
            "Epoch 124/200\n",
            "297/297 [==============================] - 3s 10ms/step - loss: 1.1709 - categorical_accuracy: 0.4609 - val_loss: 1.1361 - val_categorical_accuracy: 0.4991\n",
            "Epoch 125/200\n",
            "297/297 [==============================] - 3s 10ms/step - loss: 1.1578 - categorical_accuracy: 0.4764 - val_loss: 1.1445 - val_categorical_accuracy: 0.4877\n",
            "Epoch 126/200\n",
            "297/297 [==============================] - 3s 10ms/step - loss: 1.1826 - categorical_accuracy: 0.4419 - val_loss: 1.2706 - val_categorical_accuracy: 0.4307\n",
            "Epoch 127/200\n",
            "297/297 [==============================] - 3s 11ms/step - loss: 1.1872 - categorical_accuracy: 0.4602 - val_loss: 1.3877 - val_categorical_accuracy: 0.3662\n",
            "Epoch 128/200\n",
            "297/297 [==============================] - 3s 12ms/step - loss: 1.1775 - categorical_accuracy: 0.4583 - val_loss: 1.2713 - val_categorical_accuracy: 0.3909\n",
            "Epoch 129/200\n",
            "297/297 [==============================] - 3s 11ms/step - loss: 1.1770 - categorical_accuracy: 0.4618 - val_loss: 1.1743 - val_categorical_accuracy: 0.4535\n",
            "Epoch 130/200\n",
            "297/297 [==============================] - 3s 11ms/step - loss: 1.1676 - categorical_accuracy: 0.4647 - val_loss: 1.3122 - val_categorical_accuracy: 0.3624\n",
            "Epoch 131/200\n",
            "297/297 [==============================] - 3s 11ms/step - loss: 1.1921 - categorical_accuracy: 0.4510 - val_loss: 1.0963 - val_categorical_accuracy: 0.5161\n",
            "Epoch 132/200\n",
            "297/297 [==============================] - 3s 11ms/step - loss: 1.1628 - categorical_accuracy: 0.4618 - val_loss: 1.1515 - val_categorical_accuracy: 0.4649\n",
            "Epoch 133/200\n",
            "297/297 [==============================] - 3s 11ms/step - loss: 1.1713 - categorical_accuracy: 0.4413 - val_loss: 1.2304 - val_categorical_accuracy: 0.4250\n",
            "Epoch 134/200\n",
            "297/297 [==============================] - 3s 11ms/step - loss: 1.1738 - categorical_accuracy: 0.4649 - val_loss: 1.0405 - val_categorical_accuracy: 0.5256\n",
            "Epoch 135/200\n",
            "297/297 [==============================] - 3s 11ms/step - loss: 1.1582 - categorical_accuracy: 0.4751 - val_loss: 1.3079 - val_categorical_accuracy: 0.4137\n",
            "Epoch 136/200\n",
            "297/297 [==============================] - 3s 11ms/step - loss: 1.1720 - categorical_accuracy: 0.4594 - val_loss: 1.1868 - val_categorical_accuracy: 0.4478\n",
            "Epoch 137/200\n",
            "297/297 [==============================] - 3s 11ms/step - loss: 1.1805 - categorical_accuracy: 0.4588 - val_loss: 1.2472 - val_categorical_accuracy: 0.4118\n",
            "Epoch 138/200\n",
            "297/297 [==============================] - 3s 11ms/step - loss: 1.1565 - categorical_accuracy: 0.4688 - val_loss: 1.1833 - val_categorical_accuracy: 0.4383\n",
            "Epoch 139/200\n",
            "297/297 [==============================] - 3s 11ms/step - loss: 1.1625 - categorical_accuracy: 0.4568 - val_loss: 1.0925 - val_categorical_accuracy: 0.4687\n",
            "Epoch 140/200\n",
            "297/297 [==============================] - 3s 10ms/step - loss: 1.1644 - categorical_accuracy: 0.4604 - val_loss: 1.2539 - val_categorical_accuracy: 0.3985\n",
            "Epoch 141/200\n",
            "297/297 [==============================] - 3s 10ms/step - loss: 1.1768 - categorical_accuracy: 0.4418 - val_loss: 1.2076 - val_categorical_accuracy: 0.4080\n",
            "Epoch 142/200\n",
            "297/297 [==============================] - 3s 11ms/step - loss: 1.1601 - categorical_accuracy: 0.4611 - val_loss: 1.3843 - val_categorical_accuracy: 0.3397\n",
            "Epoch 143/200\n",
            "297/297 [==============================] - 3s 11ms/step - loss: 1.1607 - categorical_accuracy: 0.4662 - val_loss: 1.1628 - val_categorical_accuracy: 0.4421\n",
            "Epoch 144/200\n",
            "297/297 [==============================] - 3s 10ms/step - loss: 1.1624 - categorical_accuracy: 0.4648 - val_loss: 1.0945 - val_categorical_accuracy: 0.5028\n",
            "Epoch 145/200\n",
            "297/297 [==============================] - 3s 10ms/step - loss: 1.1551 - categorical_accuracy: 0.4621 - val_loss: 1.3012 - val_categorical_accuracy: 0.4156\n",
            "Epoch 146/200\n",
            "297/297 [==============================] - 3s 10ms/step - loss: 1.1621 - categorical_accuracy: 0.4667 - val_loss: 1.1682 - val_categorical_accuracy: 0.4763\n",
            "Epoch 147/200\n",
            "297/297 [==============================] - 3s 11ms/step - loss: 1.1781 - categorical_accuracy: 0.4633 - val_loss: 1.1671 - val_categorical_accuracy: 0.4915\n",
            "Epoch 148/200\n",
            "297/297 [==============================] - 3s 11ms/step - loss: 1.1666 - categorical_accuracy: 0.4639 - val_loss: 1.1736 - val_categorical_accuracy: 0.4706\n",
            "Epoch 149/200\n",
            "297/297 [==============================] - 3s 11ms/step - loss: 1.1593 - categorical_accuracy: 0.4611 - val_loss: 1.3100 - val_categorical_accuracy: 0.3928\n",
            "Epoch 150/200\n",
            "297/297 [==============================] - 3s 10ms/step - loss: 1.1654 - categorical_accuracy: 0.4749 - val_loss: 1.1472 - val_categorical_accuracy: 0.4744\n",
            "Epoch 151/200\n",
            "297/297 [==============================] - 3s 11ms/step - loss: 1.1742 - categorical_accuracy: 0.4653 - val_loss: 1.1417 - val_categorical_accuracy: 0.4744\n",
            "Epoch 152/200\n",
            "297/297 [==============================] - 3s 11ms/step - loss: 1.1871 - categorical_accuracy: 0.4485 - val_loss: 1.2401 - val_categorical_accuracy: 0.4250\n",
            "Epoch 153/200\n",
            "297/297 [==============================] - 3s 11ms/step - loss: 1.1665 - categorical_accuracy: 0.4640 - val_loss: 1.2006 - val_categorical_accuracy: 0.4459\n",
            "Epoch 154/200\n",
            "297/297 [==============================] - 3s 11ms/step - loss: 1.1791 - categorical_accuracy: 0.4572 - val_loss: 1.3866 - val_categorical_accuracy: 0.3624\n",
            "Epoch 155/200\n",
            "297/297 [==============================] - 3s 10ms/step - loss: 1.1750 - categorical_accuracy: 0.4592 - val_loss: 1.1584 - val_categorical_accuracy: 0.4934\n",
            "Epoch 156/200\n",
            "297/297 [==============================] - 3s 11ms/step - loss: 1.1708 - categorical_accuracy: 0.4709 - val_loss: 1.2057 - val_categorical_accuracy: 0.4364\n",
            "Epoch 157/200\n",
            "297/297 [==============================] - 3s 11ms/step - loss: 1.1468 - categorical_accuracy: 0.4796 - val_loss: 1.3721 - val_categorical_accuracy: 0.4023\n",
            "Epoch 158/200\n",
            "297/297 [==============================] - 3s 11ms/step - loss: 1.1677 - categorical_accuracy: 0.4597 - val_loss: 1.1952 - val_categorical_accuracy: 0.4307\n",
            "Epoch 159/200\n",
            "297/297 [==============================] - 3s 11ms/step - loss: 1.1712 - categorical_accuracy: 0.4634 - val_loss: 1.1290 - val_categorical_accuracy: 0.4744\n",
            "Epoch 160/200\n",
            "297/297 [==============================] - 3s 10ms/step - loss: 1.1512 - categorical_accuracy: 0.4597 - val_loss: 1.3410 - val_categorical_accuracy: 0.3662\n",
            "Epoch 161/200\n",
            "297/297 [==============================] - 3s 11ms/step - loss: 1.1632 - categorical_accuracy: 0.4645 - val_loss: 1.0832 - val_categorical_accuracy: 0.4630\n",
            "Epoch 162/200\n",
            "297/297 [==============================] - 3s 11ms/step - loss: 1.1508 - categorical_accuracy: 0.4636 - val_loss: 1.2050 - val_categorical_accuracy: 0.4706\n",
            "Epoch 163/200\n",
            "297/297 [==============================] - 3s 11ms/step - loss: 1.1458 - categorical_accuracy: 0.4759 - val_loss: 1.1394 - val_categorical_accuracy: 0.4839\n",
            "Epoch 164/200\n",
            "297/297 [==============================] - 3s 11ms/step - loss: 1.1869 - categorical_accuracy: 0.4467 - val_loss: 1.2383 - val_categorical_accuracy: 0.4687\n",
            "Epoch 165/200\n",
            "297/297 [==============================] - 3s 11ms/step - loss: 1.1652 - categorical_accuracy: 0.4659 - val_loss: 1.1807 - val_categorical_accuracy: 0.4763\n",
            "Epoch 166/200\n",
            "297/297 [==============================] - 3s 11ms/step - loss: 1.1736 - categorical_accuracy: 0.4667 - val_loss: 1.1035 - val_categorical_accuracy: 0.4972\n",
            "Epoch 167/200\n",
            "297/297 [==============================] - 3s 11ms/step - loss: 1.1484 - categorical_accuracy: 0.4792 - val_loss: 1.0646 - val_categorical_accuracy: 0.5370\n",
            "Epoch 168/200\n",
            "297/297 [==============================] - 3s 11ms/step - loss: 1.1705 - categorical_accuracy: 0.4680 - val_loss: 1.2435 - val_categorical_accuracy: 0.4421\n",
            "Epoch 169/200\n",
            "297/297 [==============================] - 3s 11ms/step - loss: 1.1572 - categorical_accuracy: 0.4650 - val_loss: 1.2541 - val_categorical_accuracy: 0.4175\n",
            "Epoch 170/200\n",
            "297/297 [==============================] - 3s 11ms/step - loss: 1.1395 - categorical_accuracy: 0.4744 - val_loss: 1.1834 - val_categorical_accuracy: 0.4687\n",
            "Epoch 171/200\n",
            "297/297 [==============================] - 3s 11ms/step - loss: 1.1558 - categorical_accuracy: 0.4653 - val_loss: 1.2163 - val_categorical_accuracy: 0.4383\n",
            "Epoch 172/200\n",
            "297/297 [==============================] - 3s 11ms/step - loss: 1.1413 - categorical_accuracy: 0.4802 - val_loss: 1.0675 - val_categorical_accuracy: 0.5199\n",
            "Epoch 173/200\n",
            "297/297 [==============================] - 3s 11ms/step - loss: 1.1719 - categorical_accuracy: 0.4528 - val_loss: 1.2833 - val_categorical_accuracy: 0.3947\n",
            "Epoch 174/200\n",
            "297/297 [==============================] - 3s 10ms/step - loss: 1.1406 - categorical_accuracy: 0.4786 - val_loss: 1.1543 - val_categorical_accuracy: 0.4839\n",
            "Epoch 175/200\n",
            "297/297 [==============================] - 3s 11ms/step - loss: 1.1613 - categorical_accuracy: 0.4826 - val_loss: 1.0590 - val_categorical_accuracy: 0.5180\n",
            "Epoch 176/200\n",
            "297/297 [==============================] - 3s 11ms/step - loss: 1.1218 - categorical_accuracy: 0.4939 - val_loss: 1.2136 - val_categorical_accuracy: 0.4099\n",
            "Epoch 177/200\n",
            "297/297 [==============================] - 3s 11ms/step - loss: 1.1567 - categorical_accuracy: 0.4740 - val_loss: 1.2052 - val_categorical_accuracy: 0.4611\n",
            "Epoch 178/200\n",
            "297/297 [==============================] - 3s 11ms/step - loss: 1.1490 - categorical_accuracy: 0.4831 - val_loss: 1.2797 - val_categorical_accuracy: 0.3852\n",
            "Epoch 179/200\n",
            "297/297 [==============================] - 3s 12ms/step - loss: 1.1450 - categorical_accuracy: 0.4841 - val_loss: 1.1904 - val_categorical_accuracy: 0.4231\n",
            "Epoch 180/200\n",
            "297/297 [==============================] - 3s 11ms/step - loss: 1.1526 - categorical_accuracy: 0.4735 - val_loss: 1.2875 - val_categorical_accuracy: 0.3890\n",
            "Epoch 181/200\n",
            "297/297 [==============================] - 3s 11ms/step - loss: 1.1491 - categorical_accuracy: 0.4710 - val_loss: 1.0848 - val_categorical_accuracy: 0.5199\n",
            "Epoch 182/200\n",
            "297/297 [==============================] - 3s 11ms/step - loss: 1.1605 - categorical_accuracy: 0.4708 - val_loss: 1.1327 - val_categorical_accuracy: 0.4725\n",
            "Epoch 183/200\n",
            "297/297 [==============================] - 3s 11ms/step - loss: 1.1513 - categorical_accuracy: 0.4790 - val_loss: 1.1247 - val_categorical_accuracy: 0.4611\n",
            "Epoch 184/200\n",
            "297/297 [==============================] - 3s 11ms/step - loss: 1.1555 - categorical_accuracy: 0.4615 - val_loss: 1.1922 - val_categorical_accuracy: 0.4383\n",
            "Epoch 185/200\n",
            "297/297 [==============================] - 3s 11ms/step - loss: 1.1364 - categorical_accuracy: 0.4766 - val_loss: 1.2218 - val_categorical_accuracy: 0.4440\n",
            "Epoch 186/200\n",
            "297/297 [==============================] - 3s 11ms/step - loss: 1.1299 - categorical_accuracy: 0.4860 - val_loss: 1.1008 - val_categorical_accuracy: 0.5009\n",
            "Epoch 187/200\n",
            "297/297 [==============================] - 3s 11ms/step - loss: 1.1524 - categorical_accuracy: 0.4754 - val_loss: 1.1177 - val_categorical_accuracy: 0.5218\n",
            "Epoch 188/200\n",
            "297/297 [==============================] - 3s 11ms/step - loss: 1.1617 - categorical_accuracy: 0.4630 - val_loss: 1.1092 - val_categorical_accuracy: 0.4896\n",
            "Epoch 189/200\n",
            "297/297 [==============================] - 3s 11ms/step - loss: 1.1303 - categorical_accuracy: 0.4817 - val_loss: 1.2214 - val_categorical_accuracy: 0.4440\n",
            "Epoch 190/200\n",
            "297/297 [==============================] - 3s 11ms/step - loss: 1.1458 - categorical_accuracy: 0.4731 - val_loss: 1.2439 - val_categorical_accuracy: 0.4687\n",
            "Epoch 191/200\n",
            "297/297 [==============================] - 3s 11ms/step - loss: 1.1649 - categorical_accuracy: 0.4641 - val_loss: 1.1439 - val_categorical_accuracy: 0.4820\n",
            "Epoch 192/200\n",
            "297/297 [==============================] - 3s 11ms/step - loss: 1.1501 - categorical_accuracy: 0.4791 - val_loss: 1.1295 - val_categorical_accuracy: 0.5275\n",
            "Epoch 193/200\n",
            "297/297 [==============================] - 3s 11ms/step - loss: 1.1377 - categorical_accuracy: 0.4859 - val_loss: 1.1130 - val_categorical_accuracy: 0.5009\n",
            "Epoch 194/200\n",
            "297/297 [==============================] - 3s 11ms/step - loss: 1.1360 - categorical_accuracy: 0.4696 - val_loss: 1.1690 - val_categorical_accuracy: 0.4687\n",
            "Epoch 195/200\n",
            "297/297 [==============================] - 3s 11ms/step - loss: 1.1359 - categorical_accuracy: 0.4875 - val_loss: 1.1739 - val_categorical_accuracy: 0.4725\n",
            "Epoch 196/200\n",
            "297/297 [==============================] - 3s 11ms/step - loss: 1.1402 - categorical_accuracy: 0.4722 - val_loss: 1.0770 - val_categorical_accuracy: 0.5161\n",
            "Epoch 197/200\n",
            "297/297 [==============================] - 3s 11ms/step - loss: 1.1374 - categorical_accuracy: 0.4762 - val_loss: 1.2463 - val_categorical_accuracy: 0.4459\n",
            "Epoch 198/200\n",
            "297/297 [==============================] - 3s 11ms/step - loss: 1.1253 - categorical_accuracy: 0.4746 - val_loss: 1.1514 - val_categorical_accuracy: 0.4972\n",
            "Epoch 199/200\n",
            "297/297 [==============================] - 3s 11ms/step - loss: 1.1413 - categorical_accuracy: 0.4848 - val_loss: 1.1791 - val_categorical_accuracy: 0.4383\n",
            "Epoch 200/200\n",
            "297/297 [==============================] - 3s 11ms/step - loss: 1.1337 - categorical_accuracy: 0.4712 - val_loss: 1.2027 - val_categorical_accuracy: 0.4004\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7EK00Y1YlwN"
      },
      "source": [
        "model.save('/content/drive/MyDrive/Colab Notebooks/speech/dataset/conv1D_tempogram_merged.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-IJkqk5GYqZv"
      },
      "source": [
        "###test_result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6xsvUv0uYqZw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6dd4f27d-19fc-4ea0-fe10-2d921d119529"
      },
      "source": [
        "d = {0: 'happy',\n",
        "     1: 'sad',\n",
        "     2: 'angry',\n",
        "     3: 'fear'}\n",
        "Y_test_pred = np.argmax(model.predict(X_test), axis=-1)\n",
        "Y_test_pred = list(map(lambda x: d[x], Y_test_pred))\n",
        "y_test = np.argmax(y_test, axis=-1)\n",
        "y_test = list(map(lambda x: d[x], y_test))\n",
        "print(classification_report(y_test, Y_test_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.35      0.97      0.52       155\n",
            "        fear       0.35      0.18      0.24       144\n",
            "       happy       0.41      0.11      0.17       151\n",
            "         sad       0.70      0.24      0.35       136\n",
            "\n",
            "    accuracy                           0.38       586\n",
            "   macro avg       0.45      0.37      0.32       586\n",
            "weighted avg       0.45      0.38      0.32       586\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4BqxboO8YqZx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 483
        },
        "outputId": "3631a9e3-2706-4e95-c06d-675ede524c9a"
      },
      "source": [
        "import scikitplot as skplt\n",
        "\n",
        "skplt.metrics.plot_confusion_matrix(\n",
        "    y_test, \n",
        "    Y_test_pred,\n",
        "    figsize=(8,8))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f1aa05500d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPjLuB-oYqZ_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ncl1wszZ1Ds"
      },
      "source": [
        "# Tempogram + conv2D"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6Ur96d1Z1D0"
      },
      "source": [
        "features = []\n",
        "labels = []\n",
        "for i in range(len(Ravdess_DF['Paths'])):\n",
        "  if ((Ravdess_DF['Emotion'][i] == '03') | (Ravdess_DF['Emotion'][i] == '04') | \n",
        "      (Ravdess_DF['Emotion'][i] == '05') | (Ravdess_DF['Emotion'][i] == '06')):\n",
        "    \n",
        "    signal, sr = librosa.load(Ravdess_DF['Paths'][i])\n",
        "    if len(signal) > input_length:\n",
        "        signal = signal[0:input_length]\n",
        "    elif  input_length > len(signal):\n",
        "        max_offset = input_length - len(signal)  \n",
        "        signal = np.pad(signal, (0, max_offset), \"constant\")\n",
        "    tempogram = librosa.feature.tempogram(signal, sr)\n",
        "    tempogram = np.expand_dims(tempogram, axis=-1)\n",
        "    features.append(tempogram)\n",
        "    if Ravdess_DF['Emotion'][i] == '03':\n",
        "      labels.append(0)\n",
        "    elif Ravdess_DF['Emotion'][i] == '04':\n",
        "      labels.append(1)\n",
        "    elif Ravdess_DF['Emotion'][i] == '05':\n",
        "      labels.append(2)\n",
        "    elif Ravdess_DF['Emotion'][i] == '06':\n",
        "      labels.append(3)\n",
        "\n",
        "\n",
        "for i in range(len(CREMA_D_df)):\n",
        "  if ((CREMA_D_df['Emotion'][i] == 'HAP') | (CREMA_D_df['Emotion'][i] == 'SAD') | \n",
        "      (CREMA_D_df['Emotion'][i] == 'ANG') | (CREMA_D_df['Emotion'][i] == 'FEA')):\n",
        "    \n",
        "    if CREMA_D_df['Emotion'][i] == 'HAP':\n",
        "      labels.append(0)\n",
        "    elif CREMA_D_df['Emotion'][i] == 'SAD':\n",
        "      labels.append(1)\n",
        "    elif CREMA_D_df['Emotion'][i] == 'ANG':\n",
        "      labels.append(2)\n",
        "    elif CREMA_D_df['Emotion'][i] == 'FEA':\n",
        "      labels.append(3)\n",
        "\n",
        "\n",
        "    signal, sr =  librosa.load(CREMA_D_df['Paths'][i])\n",
        "    if len(signal) > input_length:\n",
        "        signal = signal[0:input_length]\n",
        "    elif  input_length > len(signal):\n",
        "        max_offset = input_length - len(signal)  \n",
        "        signal = np.pad(signal, (0, max_offset), \"constant\")\n",
        "    tempogram = librosa.feature.tempogram(signal, sr)\n",
        "    tempogram = np.expand_dims(tempogram, axis=-1)\n",
        "    features.append(tempogram)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bnzxRACvZ1D1"
      },
      "source": [
        "X = features\n",
        "y = labels\n",
        "\n",
        "y = np.array(y)\n",
        "y = to_categorical(y)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=0)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=0)\n",
        "\n",
        "X_train = np.array(X_train)\n",
        "X_test = np.array(X_test)\n",
        "X_val = np.array(X_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZkj391HZ1D1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca32906a-7728-4fc5-9b8a-ec3722a76973"
      },
      "source": [
        "X_train.shape,X_test.shape,y_train.shape,y_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((4739, 384, 173, 1), (586, 384, 173, 1), (4739, 4), (586, 4))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OAXECwCLaYWp"
      },
      "source": [
        "### conv2D"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c4RsyEHoaYW5"
      },
      "source": [
        "# CNN I/P Config\n",
        "num_classes = 4\n",
        "input_shape = X_train.shape[1:]\n",
        "learning_rate = 0.0001\n",
        "decay = 1e-6\n",
        "momentum = 0.9"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6xX_1MaMaYW7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bba92e5d-6062-49b6-d139-d2ab1b7c40b2"
      },
      "source": [
        "model = Sequential(name='Audio_CNN_2D')\n",
        "\n",
        "# LFLB1\n",
        "model.add(Conv2D(filters=64, kernel_size=(3,3), strides=(1,1), padding='same',input_shape=input_shape))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Conv2D(filters=64, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(4,4), strides=(4,4)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(units=num_classes, activation='softmax'))\n",
        "\n",
        "# Model compilation\n",
        "opt = optimizers.SGD(lr=learning_rate, decay=decay, momentum=momentum, nesterov=True)\n",
        "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"Audio_CNN_2D\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 384, 173, 64)      640       \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 384, 173, 64)      256       \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 384, 173, 64)      0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 192, 86, 64)       0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 192, 86, 64)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 192, 86, 64)       36928     \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 192, 86, 64)       256       \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 192, 86, 64)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 48, 21, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 48, 21, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 64512)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 4)                 258052    \n",
            "=================================================================\n",
            "Total params: 296,132\n",
            "Trainable params: 295,876\n",
            "Non-trainable params: 256\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yHM3CD7YaYW9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a100f7bd-47a3-466a-fb29-47701ed59184"
      },
      "source": [
        "#Train Config\n",
        "\n",
        "batch_size = 16\n",
        "num_epochs = 200\n",
        "\n",
        "# Model Training\n",
        "lr_reduce = ReduceLROnPlateau(monitor='val_loss', factor=0.9, patience=20, min_lr=0.000001)\n",
        "# Please change the model name accordingly.\n",
        "mcp_save = ModelCheckpoint('/content/Modelfull_2_1.h5', save_best_only=True, monitor='val_categorical_accuracy', mode='max')\n",
        "cnnhistory=model.fit(X_train, y_train, batch_size=batch_size, epochs=num_epochs,validation_data=(X_val, y_val), callbacks=[mcp_save, lr_reduce])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "297/297 [==============================] - 65s 65ms/step - loss: 5.0002 - categorical_accuracy: 0.3232 - val_loss: 2.3896 - val_categorical_accuracy: 0.2581\n",
            "Epoch 2/200\n",
            "297/297 [==============================] - 18s 61ms/step - loss: 1.9740 - categorical_accuracy: 0.3631 - val_loss: 1.3024 - val_categorical_accuracy: 0.4383\n",
            "Epoch 3/200\n",
            "297/297 [==============================] - 18s 61ms/step - loss: 1.7586 - categorical_accuracy: 0.3837 - val_loss: 3.2090 - val_categorical_accuracy: 0.2751\n",
            "Epoch 4/200\n",
            "297/297 [==============================] - 18s 61ms/step - loss: 1.7016 - categorical_accuracy: 0.3922 - val_loss: 1.2770 - val_categorical_accuracy: 0.4573\n",
            "Epoch 5/200\n",
            "297/297 [==============================] - 18s 61ms/step - loss: 1.5908 - categorical_accuracy: 0.3975 - val_loss: 2.1401 - val_categorical_accuracy: 0.2372\n",
            "Epoch 6/200\n",
            "297/297 [==============================] - 18s 61ms/step - loss: 1.5694 - categorical_accuracy: 0.3934 - val_loss: 1.6726 - val_categorical_accuracy: 0.2941\n",
            "Epoch 7/200\n",
            "297/297 [==============================] - 18s 61ms/step - loss: 1.5440 - categorical_accuracy: 0.3957 - val_loss: 2.0138 - val_categorical_accuracy: 0.2789\n",
            "Epoch 8/200\n",
            "297/297 [==============================] - 18s 61ms/step - loss: 1.5396 - categorical_accuracy: 0.3835 - val_loss: 2.1805 - val_categorical_accuracy: 0.2732\n",
            "Epoch 9/200\n",
            "297/297 [==============================] - 18s 61ms/step - loss: 1.4471 - categorical_accuracy: 0.4227 - val_loss: 1.6202 - val_categorical_accuracy: 0.3795\n",
            "Epoch 10/200\n",
            "297/297 [==============================] - 18s 61ms/step - loss: 1.4305 - categorical_accuracy: 0.4136 - val_loss: 2.8023 - val_categorical_accuracy: 0.2448\n",
            "Epoch 11/200\n",
            "297/297 [==============================] - 18s 61ms/step - loss: 1.4747 - categorical_accuracy: 0.4158 - val_loss: 1.1902 - val_categorical_accuracy: 0.4516\n",
            "Epoch 12/200\n",
            "297/297 [==============================] - 18s 61ms/step - loss: 1.3950 - categorical_accuracy: 0.4056 - val_loss: 1.5041 - val_categorical_accuracy: 0.3454\n",
            "Epoch 13/200\n",
            "297/297 [==============================] - 18s 61ms/step - loss: 1.3891 - categorical_accuracy: 0.4157 - val_loss: 1.3933 - val_categorical_accuracy: 0.3207\n",
            "Epoch 14/200\n",
            "297/297 [==============================] - 18s 61ms/step - loss: 1.3957 - categorical_accuracy: 0.4285 - val_loss: 1.6841 - val_categorical_accuracy: 0.2543\n",
            "Epoch 15/200\n",
            "297/297 [==============================] - 18s 61ms/step - loss: 1.3554 - categorical_accuracy: 0.4215 - val_loss: 2.1162 - val_categorical_accuracy: 0.2581\n",
            "Epoch 16/200\n",
            "297/297 [==============================] - 18s 61ms/step - loss: 1.3629 - categorical_accuracy: 0.4302 - val_loss: 1.4569 - val_categorical_accuracy: 0.2941\n",
            "Epoch 17/200\n",
            "297/297 [==============================] - 18s 61ms/step - loss: 1.3619 - categorical_accuracy: 0.4319 - val_loss: 1.2797 - val_categorical_accuracy: 0.3738\n",
            "Epoch 18/200\n",
            "297/297 [==============================] - 18s 61ms/step - loss: 1.3553 - categorical_accuracy: 0.4237 - val_loss: 1.5229 - val_categorical_accuracy: 0.3643\n",
            "Epoch 19/200\n",
            "297/297 [==============================] - 18s 61ms/step - loss: 1.2792 - categorical_accuracy: 0.4656 - val_loss: 1.4238 - val_categorical_accuracy: 0.2884\n",
            "Epoch 20/200\n",
            "297/297 [==============================] - 18s 61ms/step - loss: 1.3100 - categorical_accuracy: 0.4537 - val_loss: 1.8528 - val_categorical_accuracy: 0.2732\n",
            "Epoch 21/200\n",
            "297/297 [==============================] - 18s 61ms/step - loss: 1.2876 - categorical_accuracy: 0.4553 - val_loss: 1.7980 - val_categorical_accuracy: 0.3150\n",
            "Epoch 22/200\n",
            "297/297 [==============================] - 18s 61ms/step - loss: 1.3078 - categorical_accuracy: 0.4350 - val_loss: 1.6537 - val_categorical_accuracy: 0.3188\n",
            "Epoch 23/200\n",
            "297/297 [==============================] - 18s 61ms/step - loss: 1.3364 - categorical_accuracy: 0.4255 - val_loss: 1.2942 - val_categorical_accuracy: 0.4118\n",
            "Epoch 24/200\n",
            "297/297 [==============================] - 18s 61ms/step - loss: 1.2598 - categorical_accuracy: 0.4539 - val_loss: 1.5376 - val_categorical_accuracy: 0.3776\n",
            "Epoch 25/200\n",
            "297/297 [==============================] - 18s 61ms/step - loss: 1.2843 - categorical_accuracy: 0.4553 - val_loss: 1.2144 - val_categorical_accuracy: 0.4345\n",
            "Epoch 26/200\n",
            "297/297 [==============================] - 18s 61ms/step - loss: 1.2836 - categorical_accuracy: 0.4435 - val_loss: 1.1749 - val_categorical_accuracy: 0.5123\n",
            "Epoch 27/200\n",
            "297/297 [==============================] - 18s 61ms/step - loss: 1.2677 - categorical_accuracy: 0.4422 - val_loss: 1.1385 - val_categorical_accuracy: 0.4668\n",
            "Epoch 28/200\n",
            "297/297 [==============================] - 18s 61ms/step - loss: 1.2263 - categorical_accuracy: 0.4676 - val_loss: 1.3415 - val_categorical_accuracy: 0.3548\n",
            "Epoch 29/200\n",
            "297/297 [==============================] - 18s 61ms/step - loss: 1.2467 - categorical_accuracy: 0.4626 - val_loss: 1.5679 - val_categorical_accuracy: 0.2713\n",
            "Epoch 30/200\n",
            "297/297 [==============================] - 18s 61ms/step - loss: 1.2667 - categorical_accuracy: 0.4365 - val_loss: 1.3004 - val_categorical_accuracy: 0.3378\n",
            "Epoch 31/200\n",
            "297/297 [==============================] - 18s 61ms/step - loss: 1.2633 - categorical_accuracy: 0.4340 - val_loss: 1.3956 - val_categorical_accuracy: 0.3150\n",
            "Epoch 32/200\n",
            "297/297 [==============================] - 18s 61ms/step - loss: 1.2440 - categorical_accuracy: 0.4490 - val_loss: 1.2353 - val_categorical_accuracy: 0.4459\n",
            "Epoch 33/200\n",
            "297/297 [==============================] - 18s 61ms/step - loss: 1.2571 - categorical_accuracy: 0.4476 - val_loss: 1.3090 - val_categorical_accuracy: 0.3245\n",
            "Epoch 34/200\n",
            "297/297 [==============================] - 18s 61ms/step - loss: 1.2523 - categorical_accuracy: 0.4535 - val_loss: 1.2571 - val_categorical_accuracy: 0.4630\n",
            "Epoch 35/200\n",
            "297/297 [==============================] - 18s 61ms/step - loss: 1.2411 - categorical_accuracy: 0.4625 - val_loss: 1.1786 - val_categorical_accuracy: 0.4972\n",
            "Epoch 36/200\n",
            "297/297 [==============================] - 18s 61ms/step - loss: 1.2214 - categorical_accuracy: 0.4574 - val_loss: 1.3400 - val_categorical_accuracy: 0.3378\n",
            "Epoch 37/200\n",
            "297/297 [==============================] - 18s 61ms/step - loss: 1.2458 - categorical_accuracy: 0.4591 - val_loss: 1.3161 - val_categorical_accuracy: 0.4118\n",
            "Epoch 38/200\n",
            "297/297 [==============================] - 18s 61ms/step - loss: 1.2479 - categorical_accuracy: 0.4500 - val_loss: 1.2451 - val_categorical_accuracy: 0.3852\n",
            "Epoch 39/200\n",
            "297/297 [==============================] - 18s 61ms/step - loss: 1.2220 - categorical_accuracy: 0.4633 - val_loss: 1.3344 - val_categorical_accuracy: 0.3966\n",
            "Epoch 40/200\n",
            "297/297 [==============================] - 18s 61ms/step - loss: 1.2109 - categorical_accuracy: 0.4688 - val_loss: 1.2231 - val_categorical_accuracy: 0.4099\n",
            "Epoch 41/200\n",
            "297/297 [==============================] - 18s 61ms/step - loss: 1.2457 - categorical_accuracy: 0.4535 - val_loss: 1.2365 - val_categorical_accuracy: 0.4630\n",
            "Epoch 42/200\n",
            "297/297 [==============================] - 18s 61ms/step - loss: 1.2335 - categorical_accuracy: 0.4496 - val_loss: 1.2423 - val_categorical_accuracy: 0.4156\n",
            "Epoch 43/200\n",
            "297/297 [==============================] - 18s 61ms/step - loss: 1.1678 - categorical_accuracy: 0.4770 - val_loss: 1.4004 - val_categorical_accuracy: 0.3036\n",
            "Epoch 44/200\n",
            "297/297 [==============================] - 18s 61ms/step - loss: 1.1892 - categorical_accuracy: 0.4827 - val_loss: 1.3198 - val_categorical_accuracy: 0.3909\n",
            "Epoch 45/200\n",
            "297/297 [==============================] - 18s 61ms/step - loss: 1.2150 - categorical_accuracy: 0.4572 - val_loss: 1.1212 - val_categorical_accuracy: 0.4668\n",
            "Epoch 46/200\n",
            "297/297 [==============================] - 18s 61ms/step - loss: 1.1920 - categorical_accuracy: 0.4726 - val_loss: 1.5495 - val_categorical_accuracy: 0.3169\n",
            "Epoch 47/200\n",
            "297/297 [==============================] - 18s 61ms/step - loss: 1.2015 - categorical_accuracy: 0.4635 - val_loss: 1.2203 - val_categorical_accuracy: 0.3871\n",
            "Epoch 48/200\n",
            "297/297 [==============================] - 18s 60ms/step - loss: 1.1704 - categorical_accuracy: 0.4824 - val_loss: 1.2638 - val_categorical_accuracy: 0.4061\n",
            "Epoch 49/200\n",
            "297/297 [==============================] - 18s 60ms/step - loss: 1.1799 - categorical_accuracy: 0.4620 - val_loss: 1.1254 - val_categorical_accuracy: 0.5123\n",
            "Epoch 50/200\n",
            "297/297 [==============================] - 18s 61ms/step - loss: 1.1952 - categorical_accuracy: 0.4706 - val_loss: 1.1297 - val_categorical_accuracy: 0.5161\n",
            "Epoch 51/200\n",
            "297/297 [==============================] - 18s 61ms/step - loss: 1.1639 - categorical_accuracy: 0.4849 - val_loss: 1.4183 - val_categorical_accuracy: 0.2941\n",
            "Epoch 52/200\n",
            "297/297 [==============================] - 18s 61ms/step - loss: 1.1722 - categorical_accuracy: 0.4776 - val_loss: 1.1473 - val_categorical_accuracy: 0.4497\n",
            "Epoch 53/200\n",
            "297/297 [==============================] - 18s 61ms/step - loss: 1.1561 - categorical_accuracy: 0.4844 - val_loss: 1.2854 - val_categorical_accuracy: 0.3681\n",
            "Epoch 54/200\n",
            "297/297 [==============================] - 18s 61ms/step - loss: 1.1829 - categorical_accuracy: 0.4912 - val_loss: 1.1541 - val_categorical_accuracy: 0.4478\n",
            "Epoch 55/200\n",
            "297/297 [==============================] - 18s 61ms/step - loss: 1.1944 - categorical_accuracy: 0.4613 - val_loss: 1.2118 - val_categorical_accuracy: 0.4004\n",
            "Epoch 56/200\n",
            "297/297 [==============================] - 18s 61ms/step - loss: 1.1839 - categorical_accuracy: 0.4725 - val_loss: 1.1450 - val_categorical_accuracy: 0.4364\n",
            "Epoch 57/200\n",
            "297/297 [==============================] - 18s 61ms/step - loss: 1.1805 - categorical_accuracy: 0.4697 - val_loss: 1.2737 - val_categorical_accuracy: 0.4288\n",
            "Epoch 58/200\n",
            "297/297 [==============================] - 18s 60ms/step - loss: 1.1736 - categorical_accuracy: 0.4726 - val_loss: 1.1411 - val_categorical_accuracy: 0.4896\n",
            "Epoch 59/200\n",
            "297/297 [==============================] - 18s 61ms/step - loss: 1.1821 - categorical_accuracy: 0.4697 - val_loss: 1.2542 - val_categorical_accuracy: 0.3852\n",
            "Epoch 60/200\n",
            "297/297 [==============================] - 18s 61ms/step - loss: 1.1828 - categorical_accuracy: 0.4683 - val_loss: 1.3528 - val_categorical_accuracy: 0.3302\n",
            "Epoch 61/200\n",
            "297/297 [==============================] - 18s 61ms/step - loss: 1.1476 - categorical_accuracy: 0.4958 - val_loss: 1.1306 - val_categorical_accuracy: 0.4896\n",
            "Epoch 62/200\n",
            "297/297 [==============================] - 18s 61ms/step - loss: 1.1683 - categorical_accuracy: 0.4718 - val_loss: 1.4510 - val_categorical_accuracy: 0.2998\n",
            "Epoch 63/200\n",
            "297/297 [==============================] - 18s 61ms/step - loss: 1.1685 - categorical_accuracy: 0.4569 - val_loss: 1.3159 - val_categorical_accuracy: 0.3700\n",
            "Epoch 64/200\n",
            "297/297 [==============================] - 18s 61ms/step - loss: 1.1534 - categorical_accuracy: 0.4808 - val_loss: 1.2573 - val_categorical_accuracy: 0.4061\n",
            "Epoch 65/200\n",
            "297/297 [==============================] - 18s 61ms/step - loss: 1.1457 - categorical_accuracy: 0.4855 - val_loss: 1.1682 - val_categorical_accuracy: 0.4687\n",
            "Epoch 66/200\n",
            "297/297 [==============================] - 18s 61ms/step - loss: 1.1443 - categorical_accuracy: 0.4947 - val_loss: 1.3028 - val_categorical_accuracy: 0.3188\n",
            "Epoch 67/200\n",
            "297/297 [==============================] - 18s 61ms/step - loss: 1.1081 - categorical_accuracy: 0.4885 - val_loss: 1.1176 - val_categorical_accuracy: 0.4782\n",
            "Epoch 68/200\n",
            "297/297 [==============================] - 18s 61ms/step - loss: 1.1152 - categorical_accuracy: 0.4958 - val_loss: 1.2562 - val_categorical_accuracy: 0.3928\n",
            "Epoch 69/200\n",
            "297/297 [==============================] - 18s 61ms/step - loss: 1.1332 - categorical_accuracy: 0.4981 - val_loss: 1.2393 - val_categorical_accuracy: 0.3928\n",
            "Epoch 70/200\n",
            "297/297 [==============================] - 18s 61ms/step - loss: 1.1228 - categorical_accuracy: 0.4800 - val_loss: 1.2099 - val_categorical_accuracy: 0.4118\n",
            "Epoch 71/200\n",
            "297/297 [==============================] - 18s 61ms/step - loss: 1.1213 - categorical_accuracy: 0.4992 - val_loss: 1.3182 - val_categorical_accuracy: 0.3150\n",
            "Epoch 72/200\n",
            "297/297 [==============================] - 18s 61ms/step - loss: 1.1400 - categorical_accuracy: 0.4742 - val_loss: 1.2586 - val_categorical_accuracy: 0.4288\n",
            "Epoch 73/200\n",
            "297/297 [==============================] - 18s 61ms/step - loss: 1.1248 - categorical_accuracy: 0.4950 - val_loss: 1.4181 - val_categorical_accuracy: 0.3814\n",
            "Epoch 74/200\n",
            "297/297 [==============================] - 18s 62ms/step - loss: 1.1307 - categorical_accuracy: 0.4884 - val_loss: 1.1581 - val_categorical_accuracy: 0.3909\n",
            "Epoch 75/200\n",
            "297/297 [==============================] - 18s 62ms/step - loss: 1.1414 - categorical_accuracy: 0.4710 - val_loss: 1.0906 - val_categorical_accuracy: 0.5085\n",
            "Epoch 76/200\n",
            "297/297 [==============================] - 18s 62ms/step - loss: 1.1281 - categorical_accuracy: 0.4924 - val_loss: 1.1350 - val_categorical_accuracy: 0.4516\n",
            "Epoch 77/200\n",
            "297/297 [==============================] - 18s 61ms/step - loss: 1.1201 - categorical_accuracy: 0.4838 - val_loss: 1.4542 - val_categorical_accuracy: 0.2770\n",
            "Epoch 78/200\n",
            "297/297 [==============================] - 18s 61ms/step - loss: 1.1329 - categorical_accuracy: 0.4940 - val_loss: 1.1107 - val_categorical_accuracy: 0.5199\n",
            "Epoch 79/200\n",
            "297/297 [==============================] - 18s 61ms/step - loss: 1.1261 - categorical_accuracy: 0.5042 - val_loss: 1.1732 - val_categorical_accuracy: 0.4478\n",
            "Epoch 80/200\n",
            "297/297 [==============================] - 18s 61ms/step - loss: 1.1189 - categorical_accuracy: 0.4837 - val_loss: 1.1581 - val_categorical_accuracy: 0.4744\n",
            "Epoch 81/200\n",
            "297/297 [==============================] - 18s 61ms/step - loss: 1.1074 - categorical_accuracy: 0.4955 - val_loss: 1.1154 - val_categorical_accuracy: 0.4782\n",
            "Epoch 82/200\n",
            "297/297 [==============================] - 18s 61ms/step - loss: 1.1144 - categorical_accuracy: 0.4916 - val_loss: 1.1304 - val_categorical_accuracy: 0.4725\n",
            "Epoch 83/200\n",
            "297/297 [==============================] - 18s 61ms/step - loss: 1.1077 - categorical_accuracy: 0.5046 - val_loss: 1.1464 - val_categorical_accuracy: 0.4345\n",
            "Epoch 84/200\n",
            "297/297 [==============================] - 18s 61ms/step - loss: 1.1088 - categorical_accuracy: 0.4930 - val_loss: 1.2243 - val_categorical_accuracy: 0.3985\n",
            "Epoch 85/200\n",
            "297/297 [==============================] - 18s 61ms/step - loss: 1.1146 - categorical_accuracy: 0.4886 - val_loss: 1.3018 - val_categorical_accuracy: 0.3397\n",
            "Epoch 86/200\n",
            "297/297 [==============================] - 18s 61ms/step - loss: 1.1312 - categorical_accuracy: 0.4888 - val_loss: 1.1516 - val_categorical_accuracy: 0.4478\n",
            "Epoch 87/200\n",
            "297/297 [==============================] - 18s 61ms/step - loss: 1.1310 - categorical_accuracy: 0.4912 - val_loss: 1.1337 - val_categorical_accuracy: 0.5104\n",
            "Epoch 88/200\n",
            "297/297 [==============================] - 18s 61ms/step - loss: 1.1025 - categorical_accuracy: 0.5032 - val_loss: 1.2592 - val_categorical_accuracy: 0.4023\n",
            "Epoch 89/200\n",
            "297/297 [==============================] - 18s 61ms/step - loss: 1.1252 - categorical_accuracy: 0.4942 - val_loss: 1.1626 - val_categorical_accuracy: 0.4042\n",
            "Epoch 90/200\n",
            "297/297 [==============================] - 18s 61ms/step - loss: 1.0962 - categorical_accuracy: 0.5105 - val_loss: 1.1922 - val_categorical_accuracy: 0.4023\n",
            "Epoch 91/200\n",
            "297/297 [==============================] - 18s 61ms/step - loss: 1.1033 - categorical_accuracy: 0.4906 - val_loss: 1.1418 - val_categorical_accuracy: 0.4649\n",
            "Epoch 92/200\n",
            "297/297 [==============================] - 18s 61ms/step - loss: 1.1119 - categorical_accuracy: 0.4980 - val_loss: 1.1577 - val_categorical_accuracy: 0.4516\n",
            "Epoch 93/200\n",
            "297/297 [==============================] - 18s 61ms/step - loss: 1.0939 - categorical_accuracy: 0.5000 - val_loss: 1.1366 - val_categorical_accuracy: 0.4972\n",
            "Epoch 94/200\n",
            "297/297 [==============================] - 18s 61ms/step - loss: 1.1046 - categorical_accuracy: 0.4912 - val_loss: 1.1617 - val_categorical_accuracy: 0.4516\n",
            "Epoch 95/200\n",
            "297/297 [==============================] - 18s 60ms/step - loss: 1.0971 - categorical_accuracy: 0.5014 - val_loss: 1.1427 - val_categorical_accuracy: 0.4288\n",
            "Epoch 96/200\n",
            "297/297 [==============================] - 18s 61ms/step - loss: 1.0799 - categorical_accuracy: 0.5087 - val_loss: 1.1295 - val_categorical_accuracy: 0.4877\n",
            "Epoch 97/200\n",
            "297/297 [==============================] - 18s 61ms/step - loss: 1.0709 - categorical_accuracy: 0.5205 - val_loss: 1.2968 - val_categorical_accuracy: 0.3264\n",
            "Epoch 98/200\n",
            "297/297 [==============================] - 18s 61ms/step - loss: 1.1021 - categorical_accuracy: 0.4909 - val_loss: 1.2203 - val_categorical_accuracy: 0.3472\n",
            "Epoch 99/200\n",
            "297/297 [==============================] - 18s 61ms/step - loss: 1.0981 - categorical_accuracy: 0.5003 - val_loss: 1.1156 - val_categorical_accuracy: 0.4763\n",
            "Epoch 100/200\n",
            "297/297 [==============================] - 18s 61ms/step - loss: 1.0870 - categorical_accuracy: 0.5065 - val_loss: 1.0887 - val_categorical_accuracy: 0.5066\n",
            "Epoch 101/200\n",
            "297/297 [==============================] - 18s 61ms/step - loss: 1.0934 - categorical_accuracy: 0.5089 - val_loss: 1.1487 - val_categorical_accuracy: 0.4194\n",
            "Epoch 102/200\n",
            "297/297 [==============================] - 18s 61ms/step - loss: 1.1229 - categorical_accuracy: 0.4998 - val_loss: 1.0792 - val_categorical_accuracy: 0.5161\n",
            "Epoch 103/200\n",
            "297/297 [==============================] - 18s 61ms/step - loss: 1.0849 - categorical_accuracy: 0.5110 - val_loss: 1.2170 - val_categorical_accuracy: 0.3814\n",
            "Epoch 104/200\n",
            "297/297 [==============================] - 18s 61ms/step - loss: 1.1052 - categorical_accuracy: 0.4851 - val_loss: 1.1056 - val_categorical_accuracy: 0.4858\n",
            "Epoch 105/200\n",
            "297/297 [==============================] - 18s 61ms/step - loss: 1.0799 - categorical_accuracy: 0.5103 - val_loss: 1.2952 - val_categorical_accuracy: 0.3359\n",
            "Epoch 106/200\n",
            "297/297 [==============================] - 18s 61ms/step - loss: 1.1113 - categorical_accuracy: 0.4868 - val_loss: 1.1655 - val_categorical_accuracy: 0.4307\n",
            "Epoch 107/200\n",
            "297/297 [==============================] - 18s 61ms/step - loss: 1.0821 - categorical_accuracy: 0.5007 - val_loss: 1.1684 - val_categorical_accuracy: 0.4554\n",
            "Epoch 108/200\n",
            "297/297 [==============================] - 18s 61ms/step - loss: 1.0861 - categorical_accuracy: 0.5070 - val_loss: 1.1100 - val_categorical_accuracy: 0.4972\n",
            "Epoch 109/200\n",
            "297/297 [==============================] - 18s 61ms/step - loss: 1.0969 - categorical_accuracy: 0.5037 - val_loss: 1.1355 - val_categorical_accuracy: 0.4858\n",
            "Epoch 110/200\n",
            "297/297 [==============================] - 18s 61ms/step - loss: 1.0880 - categorical_accuracy: 0.5073 - val_loss: 1.1716 - val_categorical_accuracy: 0.4440\n",
            "Epoch 111/200\n",
            "297/297 [==============================] - 18s 61ms/step - loss: 1.0883 - categorical_accuracy: 0.5112 - val_loss: 1.1439 - val_categorical_accuracy: 0.4118\n",
            "Epoch 112/200\n",
            "297/297 [==============================] - 18s 61ms/step - loss: 1.0898 - categorical_accuracy: 0.5012 - val_loss: 1.1388 - val_categorical_accuracy: 0.4554\n",
            "Epoch 113/200\n",
            "297/297 [==============================] - 18s 61ms/step - loss: 1.0464 - categorical_accuracy: 0.5335 - val_loss: 1.2146 - val_categorical_accuracy: 0.4118\n",
            "Epoch 114/200\n",
            "297/297 [==============================] - 18s 61ms/step - loss: 1.0815 - categorical_accuracy: 0.5076 - val_loss: 1.2199 - val_categorical_accuracy: 0.4213\n",
            "Epoch 115/200\n",
            "297/297 [==============================] - 18s 61ms/step - loss: 1.0857 - categorical_accuracy: 0.5163 - val_loss: 1.2849 - val_categorical_accuracy: 0.3340\n",
            "Epoch 116/200\n",
            "297/297 [==============================] - 18s 61ms/step - loss: 1.0797 - categorical_accuracy: 0.5114 - val_loss: 1.2391 - val_categorical_accuracy: 0.3605\n",
            "Epoch 117/200\n",
            "297/297 [==============================] - 18s 61ms/step - loss: 1.0633 - categorical_accuracy: 0.5126 - val_loss: 1.1847 - val_categorical_accuracy: 0.4269\n",
            "Epoch 118/200\n",
            "297/297 [==============================] - 18s 61ms/step - loss: 1.0584 - categorical_accuracy: 0.5197 - val_loss: 1.2984 - val_categorical_accuracy: 0.3605\n",
            "Epoch 119/200\n",
            "297/297 [==============================] - 18s 61ms/step - loss: 1.0939 - categorical_accuracy: 0.5025 - val_loss: 1.1070 - val_categorical_accuracy: 0.5085\n",
            "Epoch 120/200\n",
            "297/297 [==============================] - 18s 62ms/step - loss: 1.0901 - categorical_accuracy: 0.5115 - val_loss: 1.1108 - val_categorical_accuracy: 0.5009\n",
            "Epoch 121/200\n",
            "297/297 [==============================] - 18s 61ms/step - loss: 1.0791 - categorical_accuracy: 0.4985 - val_loss: 1.1687 - val_categorical_accuracy: 0.4345\n",
            "Epoch 122/200\n",
            "297/297 [==============================] - 18s 61ms/step - loss: 1.0854 - categorical_accuracy: 0.5012 - val_loss: 1.1038 - val_categorical_accuracy: 0.5389\n",
            "Epoch 123/200\n",
            "297/297 [==============================] - 18s 61ms/step - loss: 1.0761 - categorical_accuracy: 0.5127 - val_loss: 1.0945 - val_categorical_accuracy: 0.4972\n",
            "Epoch 124/200\n",
            "297/297 [==============================] - 18s 61ms/step - loss: 1.0536 - categorical_accuracy: 0.5218 - val_loss: 1.3110 - val_categorical_accuracy: 0.3359\n",
            "Epoch 125/200\n",
            "297/297 [==============================] - 18s 61ms/step - loss: 1.0958 - categorical_accuracy: 0.4994 - val_loss: 1.1962 - val_categorical_accuracy: 0.4042\n",
            "Epoch 126/200\n",
            "297/297 [==============================] - 18s 61ms/step - loss: 1.0872 - categorical_accuracy: 0.5165 - val_loss: 1.1121 - val_categorical_accuracy: 0.4934\n",
            "Epoch 127/200\n",
            "297/297 [==============================] - 18s 61ms/step - loss: 1.0684 - categorical_accuracy: 0.5248 - val_loss: 1.1174 - val_categorical_accuracy: 0.5028\n",
            "Epoch 128/200\n",
            "297/297 [==============================] - 18s 61ms/step - loss: 1.0719 - categorical_accuracy: 0.5080 - val_loss: 1.1270 - val_categorical_accuracy: 0.4972\n",
            "Epoch 129/200\n",
            "297/297 [==============================] - 18s 62ms/step - loss: 1.0577 - categorical_accuracy: 0.5371 - val_loss: 1.1283 - val_categorical_accuracy: 0.4611\n",
            "Epoch 130/200\n",
            "297/297 [==============================] - 18s 61ms/step - loss: 1.0561 - categorical_accuracy: 0.5165 - val_loss: 1.1309 - val_categorical_accuracy: 0.4896\n",
            "Epoch 131/200\n",
            "297/297 [==============================] - 18s 61ms/step - loss: 1.0674 - categorical_accuracy: 0.5123 - val_loss: 1.1694 - val_categorical_accuracy: 0.4668\n",
            "Epoch 132/200\n",
            "297/297 [==============================] - 18s 61ms/step - loss: 1.0769 - categorical_accuracy: 0.5160 - val_loss: 1.1795 - val_categorical_accuracy: 0.4250\n",
            "Epoch 133/200\n",
            "297/297 [==============================] - 18s 61ms/step - loss: 1.0644 - categorical_accuracy: 0.5136 - val_loss: 1.1145 - val_categorical_accuracy: 0.4687\n",
            "Epoch 134/200\n",
            "297/297 [==============================] - 18s 61ms/step - loss: 1.0651 - categorical_accuracy: 0.5145 - val_loss: 1.1632 - val_categorical_accuracy: 0.4573\n",
            "Epoch 135/200\n",
            "297/297 [==============================] - 18s 61ms/step - loss: 1.0706 - categorical_accuracy: 0.5055 - val_loss: 1.1128 - val_categorical_accuracy: 0.4801\n",
            "Epoch 136/200\n",
            "297/297 [==============================] - 18s 61ms/step - loss: 1.0679 - categorical_accuracy: 0.5224 - val_loss: 1.1173 - val_categorical_accuracy: 0.5085\n",
            "Epoch 137/200\n",
            "297/297 [==============================] - 18s 61ms/step - loss: 1.0807 - categorical_accuracy: 0.5085 - val_loss: 1.1308 - val_categorical_accuracy: 0.4953\n",
            "Epoch 138/200\n",
            "297/297 [==============================] - 18s 62ms/step - loss: 1.0523 - categorical_accuracy: 0.5195 - val_loss: 1.1499 - val_categorical_accuracy: 0.4915\n",
            "Epoch 139/200\n",
            "297/297 [==============================] - 18s 62ms/step - loss: 1.0716 - categorical_accuracy: 0.5322 - val_loss: 1.1137 - val_categorical_accuracy: 0.5180\n",
            "Epoch 140/200\n",
            "297/297 [==============================] - 19s 63ms/step - loss: 1.0449 - categorical_accuracy: 0.5328 - val_loss: 1.1648 - val_categorical_accuracy: 0.4478\n",
            "Epoch 141/200\n",
            "297/297 [==============================] - 18s 61ms/step - loss: 1.0442 - categorical_accuracy: 0.5243 - val_loss: 1.1254 - val_categorical_accuracy: 0.4953\n",
            "Epoch 142/200\n",
            "297/297 [==============================] - 18s 61ms/step - loss: 1.0794 - categorical_accuracy: 0.5104 - val_loss: 1.2173 - val_categorical_accuracy: 0.3852\n",
            "Epoch 143/200\n",
            "297/297 [==============================] - 18s 62ms/step - loss: 1.0536 - categorical_accuracy: 0.5313 - val_loss: 1.1402 - val_categorical_accuracy: 0.4744\n",
            "Epoch 144/200\n",
            "297/297 [==============================] - 18s 61ms/step - loss: 1.0481 - categorical_accuracy: 0.5185 - val_loss: 1.2150 - val_categorical_accuracy: 0.3890\n",
            "Epoch 145/200\n",
            "297/297 [==============================] - 18s 61ms/step - loss: 1.0924 - categorical_accuracy: 0.5019 - val_loss: 1.1360 - val_categorical_accuracy: 0.4801\n",
            "Epoch 146/200\n",
            "297/297 [==============================] - 18s 61ms/step - loss: 1.0633 - categorical_accuracy: 0.5242 - val_loss: 1.1804 - val_categorical_accuracy: 0.4383\n",
            "Epoch 147/200\n",
            "297/297 [==============================] - 18s 61ms/step - loss: 1.0609 - categorical_accuracy: 0.5204 - val_loss: 1.1493 - val_categorical_accuracy: 0.4516\n",
            "Epoch 148/200\n",
            "297/297 [==============================] - 18s 61ms/step - loss: 1.0627 - categorical_accuracy: 0.5256 - val_loss: 1.1233 - val_categorical_accuracy: 0.4706\n",
            "Epoch 149/200\n",
            "297/297 [==============================] - 18s 61ms/step - loss: 1.0620 - categorical_accuracy: 0.5173 - val_loss: 1.1353 - val_categorical_accuracy: 0.4839\n",
            "Epoch 150/200\n",
            "297/297 [==============================] - 18s 61ms/step - loss: 1.0621 - categorical_accuracy: 0.5246 - val_loss: 1.1634 - val_categorical_accuracy: 0.4801\n",
            "Epoch 151/200\n",
            "297/297 [==============================] - 18s 62ms/step - loss: 1.0365 - categorical_accuracy: 0.5445 - val_loss: 1.1640 - val_categorical_accuracy: 0.4421\n",
            "Epoch 152/200\n",
            "297/297 [==============================] - 18s 61ms/step - loss: 1.0521 - categorical_accuracy: 0.5195 - val_loss: 1.1022 - val_categorical_accuracy: 0.5180\n",
            "Epoch 153/200\n",
            "297/297 [==============================] - 18s 61ms/step - loss: 1.0388 - categorical_accuracy: 0.5291 - val_loss: 1.1171 - val_categorical_accuracy: 0.4991\n",
            "Epoch 154/200\n",
            "297/297 [==============================] - 18s 62ms/step - loss: 1.0365 - categorical_accuracy: 0.5351 - val_loss: 1.1178 - val_categorical_accuracy: 0.5275\n",
            "Epoch 155/200\n",
            "297/297 [==============================] - 18s 61ms/step - loss: 1.0516 - categorical_accuracy: 0.5314 - val_loss: 1.0895 - val_categorical_accuracy: 0.5256\n",
            "Epoch 156/200\n",
            "297/297 [==============================] - 18s 61ms/step - loss: 1.0310 - categorical_accuracy: 0.5403 - val_loss: 1.1215 - val_categorical_accuracy: 0.4877\n",
            "Epoch 157/200\n",
            "297/297 [==============================] - 18s 61ms/step - loss: 1.0441 - categorical_accuracy: 0.5323 - val_loss: 1.1121 - val_categorical_accuracy: 0.5047\n",
            "Epoch 158/200\n",
            "297/297 [==============================] - 18s 62ms/step - loss: 1.0470 - categorical_accuracy: 0.5235 - val_loss: 1.1081 - val_categorical_accuracy: 0.5142\n",
            "Epoch 159/200\n",
            "297/297 [==============================] - 18s 62ms/step - loss: 1.0367 - categorical_accuracy: 0.5332 - val_loss: 1.1494 - val_categorical_accuracy: 0.4763\n",
            "Epoch 160/200\n",
            "297/297 [==============================] - 18s 62ms/step - loss: 1.0565 - categorical_accuracy: 0.5276 - val_loss: 1.1755 - val_categorical_accuracy: 0.4440\n",
            "Epoch 161/200\n",
            "297/297 [==============================] - 18s 62ms/step - loss: 1.0406 - categorical_accuracy: 0.5325 - val_loss: 1.1036 - val_categorical_accuracy: 0.5123\n",
            "Epoch 162/200\n",
            "297/297 [==============================] - 18s 62ms/step - loss: 1.0581 - categorical_accuracy: 0.5143 - val_loss: 1.1238 - val_categorical_accuracy: 0.4383\n",
            "Epoch 163/200\n",
            "297/297 [==============================] - 18s 62ms/step - loss: 1.0590 - categorical_accuracy: 0.5180 - val_loss: 1.1346 - val_categorical_accuracy: 0.4763\n",
            "Epoch 164/200\n",
            "297/297 [==============================] - 18s 62ms/step - loss: 1.0150 - categorical_accuracy: 0.5552 - val_loss: 1.0979 - val_categorical_accuracy: 0.5123\n",
            "Epoch 165/200\n",
            "297/297 [==============================] - 18s 62ms/step - loss: 1.0442 - categorical_accuracy: 0.5375 - val_loss: 1.1310 - val_categorical_accuracy: 0.4858\n",
            "Epoch 166/200\n",
            "297/297 [==============================] - 19s 63ms/step - loss: 1.0346 - categorical_accuracy: 0.5384 - val_loss: 1.1080 - val_categorical_accuracy: 0.5218\n",
            "Epoch 167/200\n",
            "297/297 [==============================] - 18s 62ms/step - loss: 1.0263 - categorical_accuracy: 0.5558 - val_loss: 1.1175 - val_categorical_accuracy: 0.4972\n",
            "Epoch 168/200\n",
            "297/297 [==============================] - 18s 62ms/step - loss: 1.0397 - categorical_accuracy: 0.5383 - val_loss: 1.0982 - val_categorical_accuracy: 0.5142\n",
            "Epoch 169/200\n",
            "297/297 [==============================] - 18s 62ms/step - loss: 1.0456 - categorical_accuracy: 0.5307 - val_loss: 1.1305 - val_categorical_accuracy: 0.4763\n",
            "Epoch 170/200\n",
            "297/297 [==============================] - 19s 63ms/step - loss: 1.0453 - categorical_accuracy: 0.5254 - val_loss: 1.1174 - val_categorical_accuracy: 0.5142\n",
            "Epoch 171/200\n",
            "297/297 [==============================] - 18s 62ms/step - loss: 1.0310 - categorical_accuracy: 0.5346 - val_loss: 1.1280 - val_categorical_accuracy: 0.4345\n",
            "Epoch 172/200\n",
            "297/297 [==============================] - 19s 62ms/step - loss: 1.0420 - categorical_accuracy: 0.5296 - val_loss: 1.1488 - val_categorical_accuracy: 0.4459\n",
            "Epoch 173/200\n",
            "297/297 [==============================] - 18s 62ms/step - loss: 1.0294 - categorical_accuracy: 0.5382 - val_loss: 1.0974 - val_categorical_accuracy: 0.5009\n",
            "Epoch 174/200\n",
            "297/297 [==============================] - 19s 62ms/step - loss: 1.0329 - categorical_accuracy: 0.5348 - val_loss: 1.1298 - val_categorical_accuracy: 0.4668\n",
            "Epoch 175/200\n",
            "297/297 [==============================] - 19s 62ms/step - loss: 1.0392 - categorical_accuracy: 0.5327 - val_loss: 1.1209 - val_categorical_accuracy: 0.4953\n",
            "Epoch 176/200\n",
            "297/297 [==============================] - 18s 62ms/step - loss: 1.0322 - categorical_accuracy: 0.5265 - val_loss: 1.1133 - val_categorical_accuracy: 0.4630\n",
            "Epoch 177/200\n",
            "297/297 [==============================] - 18s 62ms/step - loss: 1.0373 - categorical_accuracy: 0.5364 - val_loss: 1.1342 - val_categorical_accuracy: 0.4858\n",
            "Epoch 178/200\n",
            "297/297 [==============================] - 18s 62ms/step - loss: 1.0347 - categorical_accuracy: 0.5304 - val_loss: 1.1535 - val_categorical_accuracy: 0.4630\n",
            "Epoch 179/200\n",
            "297/297 [==============================] - 19s 63ms/step - loss: 1.0427 - categorical_accuracy: 0.5266 - val_loss: 1.1114 - val_categorical_accuracy: 0.5237\n",
            "Epoch 180/200\n",
            "297/297 [==============================] - 19s 63ms/step - loss: 1.0405 - categorical_accuracy: 0.5302 - val_loss: 1.1502 - val_categorical_accuracy: 0.4402\n",
            "Epoch 181/200\n",
            "297/297 [==============================] - 19s 64ms/step - loss: 1.0414 - categorical_accuracy: 0.5347 - val_loss: 1.1342 - val_categorical_accuracy: 0.4687\n",
            "Epoch 182/200\n",
            "297/297 [==============================] - 19s 62ms/step - loss: 1.0352 - categorical_accuracy: 0.5318 - val_loss: 1.1455 - val_categorical_accuracy: 0.4706\n",
            "Epoch 183/200\n",
            "297/297 [==============================] - 18s 62ms/step - loss: 1.0293 - categorical_accuracy: 0.5305 - val_loss: 1.1701 - val_categorical_accuracy: 0.4497\n",
            "Epoch 184/200\n",
            "297/297 [==============================] - 19s 62ms/step - loss: 1.0290 - categorical_accuracy: 0.5310 - val_loss: 1.0916 - val_categorical_accuracy: 0.5199\n",
            "Epoch 185/200\n",
            "297/297 [==============================] - 19s 63ms/step - loss: 1.0330 - categorical_accuracy: 0.5362 - val_loss: 1.1822 - val_categorical_accuracy: 0.4099\n",
            "Epoch 186/200\n",
            "297/297 [==============================] - 18s 62ms/step - loss: 1.0479 - categorical_accuracy: 0.5207 - val_loss: 1.0971 - val_categorical_accuracy: 0.5180\n",
            "Epoch 187/200\n",
            "297/297 [==============================] - 19s 63ms/step - loss: 1.0237 - categorical_accuracy: 0.5444 - val_loss: 1.1572 - val_categorical_accuracy: 0.4516\n",
            "Epoch 188/200\n",
            "297/297 [==============================] - 19s 62ms/step - loss: 1.0200 - categorical_accuracy: 0.5456 - val_loss: 1.1095 - val_categorical_accuracy: 0.5142\n",
            "Epoch 189/200\n",
            "297/297 [==============================] - 19s 63ms/step - loss: 1.0164 - categorical_accuracy: 0.5518 - val_loss: 1.1206 - val_categorical_accuracy: 0.4972\n",
            "Epoch 190/200\n",
            "297/297 [==============================] - 19s 62ms/step - loss: 1.0413 - categorical_accuracy: 0.5331 - val_loss: 1.1124 - val_categorical_accuracy: 0.5161\n",
            "Epoch 191/200\n",
            "297/297 [==============================] - 18s 62ms/step - loss: 1.0297 - categorical_accuracy: 0.5440 - val_loss: 1.0959 - val_categorical_accuracy: 0.5123\n",
            "Epoch 192/200\n",
            "297/297 [==============================] - 19s 62ms/step - loss: 1.0177 - categorical_accuracy: 0.5406 - val_loss: 1.1205 - val_categorical_accuracy: 0.4478\n",
            "Epoch 193/200\n",
            "297/297 [==============================] - 19s 63ms/step - loss: 1.0018 - categorical_accuracy: 0.5482 - val_loss: 1.1378 - val_categorical_accuracy: 0.4231\n",
            "Epoch 194/200\n",
            "297/297 [==============================] - 19s 63ms/step - loss: 1.0203 - categorical_accuracy: 0.5353 - val_loss: 1.1022 - val_categorical_accuracy: 0.5294\n",
            "Epoch 195/200\n",
            "297/297 [==============================] - 19s 63ms/step - loss: 1.0257 - categorical_accuracy: 0.5278 - val_loss: 1.1463 - val_categorical_accuracy: 0.4611\n",
            "Epoch 196/200\n",
            "297/297 [==============================] - 18s 62ms/step - loss: 1.0191 - categorical_accuracy: 0.5436 - val_loss: 1.1190 - val_categorical_accuracy: 0.4915\n",
            "Epoch 197/200\n",
            "297/297 [==============================] - 19s 63ms/step - loss: 0.9974 - categorical_accuracy: 0.5595 - val_loss: 1.1394 - val_categorical_accuracy: 0.4535\n",
            "Epoch 198/200\n",
            "297/297 [==============================] - 19s 62ms/step - loss: 1.0044 - categorical_accuracy: 0.5504 - val_loss: 1.1199 - val_categorical_accuracy: 0.4858\n",
            "Epoch 199/200\n",
            "297/297 [==============================] - 19s 63ms/step - loss: 1.0039 - categorical_accuracy: 0.5451 - val_loss: 1.1097 - val_categorical_accuracy: 0.5009\n",
            "Epoch 200/200\n",
            "297/297 [==============================] - 19s 63ms/step - loss: 1.0360 - categorical_accuracy: 0.5362 - val_loss: 1.1178 - val_categorical_accuracy: 0.4801\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wbd4kBYxaYW-"
      },
      "source": [
        "model.save('/content/drive/MyDrive/Colab Notebooks/speech/dataset/conv2D_tempogram_merged.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BFVwS5gkZ1D6"
      },
      "source": [
        "###test_result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ayz0uTrCZ1D7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af5d3ddb-1908-4fbb-f936-7e4084aeae39"
      },
      "source": [
        "d = {0: 'happy',\n",
        "     1: 'sad',\n",
        "     2: 'angry',\n",
        "     3: 'fear'}\n",
        "Y_test_pred = np.argmax(model.predict(X_test), axis=-1)\n",
        "Y_test_pred = list(map(lambda x: d[x], Y_test_pred))\n",
        "y_test = np.argmax(y_test, axis=-1)\n",
        "y_test = list(map(lambda x: d[x], y_test))\n",
        "print(classification_report(y_test, Y_test_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.62      0.49      0.55       155\n",
            "        fear       0.44      0.46      0.45       144\n",
            "       happy       0.37      0.57      0.45       151\n",
            "         sad       0.64      0.40      0.49       136\n",
            "\n",
            "    accuracy                           0.48       586\n",
            "   macro avg       0.52      0.48      0.49       586\n",
            "weighted avg       0.52      0.48      0.49       586\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQ2f7Tp7Z1D8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 483
        },
        "outputId": "24b4f78e-0c1b-4a6f-ad35-4e280ed4c681"
      },
      "source": [
        "import scikitplot as skplt\n",
        "\n",
        "skplt.metrics.plot_confusion_matrix(\n",
        "    y_test, \n",
        "    Y_test_pred,\n",
        "    figsize=(8,8))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fdabc2650d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAecAAAHBCAYAAABT+HN/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd5xU5dnG8d+1gDQpIoioQVARFRQVRKyxBGNLVOwaxRZrbNEkGo0aS6JJ3kQTowYr9o5dUFGDDRQLNuyIgkgTUJqwcL9/zAGXDewuMLtnztnr6+d8dk6ZZ+4Zl7n3fs5znqOIwMzMzEpHWdoBmJmZ2ZKcnM3MzEqMk7OZmVmJcXI2MzMrMU7OZmZmJcbJ2czMrMQ0TDsAMzOzYmvQct2I8jlFbTPmTB4SEbsXtdFlcHI2M7PcifI5NO56UFHbnPvWv9sWtcEqODmbmVkOCZTdM7fZjdzMzCynXDmbmVn+CJDSjmKFuXI2MzMrMa6czcwsnzJ8ztnJ2czM8snd2mZmZlYsrpzNzCyHfCmVmZmZFZErZzMzy6cMn3N2cjYzs/wR7tY2MzOz4nHlbGZmOaRMd2u7cjYzMysxrpzNzCyfMnzO2cnZzMzyyd3aZmZmViyunM3MLIc8Q5iZmZkVkStnMzPLH+FzzmZmZlY8Ts5mRSKpqaRHJc2QdN9KtHO4pKeKGVsaJD0pqX/acVg9prLiLnXIydnqHUmHSRopaaakCUkS2b4ITR8AtAdWj4gDV7SRiLgjInYrQjxLkLSTpJA0qNL2Hsn252vYzkWSbq/uuIjYIyIGrmC4ZitJTs5mWSHp18CVwJ8oJNKOwDXAPkVofl3go4goL0JbtWUysI2k1Sts6w98VKwXUIG/W8xWgv8BWb0hqRVwMXBKRDwYEbMiYn5EPBoRv0mOaSzpSklfJcuVkhon+3aSNE7SWZImJVX30cm+PwIXAAcnFfmxlStMSZ2SCrVhsn6UpM8kfSdpjKTDK2x/scLztpX0WtJd/pqkbSvse17SJZJeStp5SlLbKj6GecBDwCHJ8xsABwN3VPqsrpL0paRvJb0uaYdk++7A7yu8z1EV4rhM0kvAbGC9ZNtxyf5rJT1Qof0rJA2VMjxix0pfmYq71GXodfpqZunaBmgCDKrimPOAPsDmQA+gN3B+hf1rAq2AtYFjgX9LWi0iLqRQjd8TEatGxI1VBSKpOfBPYI+IaAFsC7y1lOPaAI8nx64O/B14vFLlexhwNLAGsApwdlWvDdwKHJk8/inwLvBVpWNeo/AZtAHuBO6T1CQiBld6nz0qPOcI4HigBTC2UntnAZsmf3jsQOGz6x8RUU2sZvWSk7PVJ6sDU6rpdj4cuDgiJkXEZOCPFJLOIvOT/fMj4glgJtB1BeNZCHSX1DQiJkTEe0s5Zi/g44i4LSLKI+Iu4APgZxWOuTkiPoqIOcC9FJLqMkXEy0AbSV0pJOlbl3LM7RExNXnN/wMaU/37vCUi3kueM79Se7MpfI5/B24HTo2IcdW0Z7biFt3P2eeczUreVKDtom7lZViLJau+scm2xW1USu6zgVWXN5CImEWhO/lEYIKkxyVtVIN4FsW0doX1r1cgntuAXwE7s5SeBElnSxqddKVPp9BbUFV3OcCXVe2MiBHAZxS+Nu+tQYxmK0cq7lKjl9SZkt6T9K6kuyQ1kdRZ0ghJn0i6R9Iq1bXj5Gz1ySvA98C+VRzzFYWBXYt05H+7fGtqFtCswvqaFXdGxJCI6At0oFANX1+DeBbFNH4FY1rkNuBk4Imkql0s6Xb+LXAQsFpEtAZmUEiqAMvqiq6yi1rSKRQq8K+S9s1yRdLawGlAr4joDjSgML7jCuAfEbEBMI3CaZ0qOTlbvRERMygM2vq3pH0lNZPUSNIekv6SHHYXcL6kdsnAqgsodMOuiLeAHSV1TAajnbtoh6T2kvZJzj1/T6F7fOFS2ngC2DC5/KuhpIOBTYDHVjAmACJiDPBjCufYK2sBlFMY2d1Q0gVAywr7JwKdlmdEtqQNgUuBX1Do3v6tpCq7381WTmqXUjUEmiY9dM2ACcAuwP3J/oFUXSAATs5WzyTnT39NYZDXZApdsb+iMIIZCglkJPA28A7wRrJtRV7raeCepK3XWTKhliVxfAV8QyFRnrSUNqYCe1MYUDWVQsW5d0RMWZGYKrX9YkQsrVdgCDCYwuVVY4G5LNllvWiClamS3qjudZIvqduBKyJiVER8TGHE922LRsKb5UFEjAf+BnxBISnPoPBvf3qF02HjWPK01FLJgyXNzCxvylquE423PrWobc595pyxQMU/jAdExIBFK5JWAx6gMJ5kOoU/ZO8HLkq6tJH0I+DJpNt7mXzjCzMzy6fij7CeEhG9qtj/E2BMcqUHkh4EtgNaS2qYVM/rUIMxI+7WNjMzK44vgD7JeBYBuwLvA89RmN4XCjPyPVxdQ07OZmaWP8W+jKoGl1IllwveT2GsyjsUcuwA4HfAryV9QmG+hSonKQJ3a5uZmRVNMlvghZU2f0ZhtsEac3I2M7N8yvD9V+pVclbjFqFmq1d/oK2wTTv5860Ln02ZlXYIuddljeWe+M2W0xdjP2fKlCm1d0eJDN9XpX4l52ar03jnP6QdRq49edMR1R9kK+2wW15LO4Tce/zkbas/yFbKDttslXYIJateJWczM6svlOlu7exGbmZmllOunM3MLJ8yfM7ZlbOZmVmJceVsZmb5IzJ9ztnJ2czMcsgDwszMzKyIXDmbmVk+eUCYmZmZFYsrZzMzy6cMn3N2cjYzs3xyt7aZmZkViytnMzPLH/lSKjMzMysiV85mZpZPGT7n7ORsZma5pAwnZ3drm5mZlRhXzmZmljvClbOZmZkVkStnMzPLHyVLRrlyNjMzKzGunM3MLIeU6XPOTs5mZpZLWU7O7tY2MzMrMa6czcwsl1w5m5mZWdG4cjYzs1zKcuXs5GxmZvnj65zNzMysmFw5m5lZ7ijj1zm7cjYzMysxrpzNzCyXslw5OzmbmVkuZTk5u1vbzMysxLhyNjOzXHLlbGZmZkXjytnMzPLHk5CYmZlZMblyLhFd1mrFbWftvHi9c/sWXHL3G1z92HuctOcmnLD7xixYGAx+/UvOu+21FCPNtl//6nieGfIEbdu249lX3lxi33VX/4NL/nAO73wynjart00pwny4+5iezJ63gIURLFgIJ9w1igv27ErH1ZoAsGrjhsz8vpzj7hiVcqT5cPVV/+CWm29EEt26b8p1199EkyZN0g4rdVk+5+zkXCI+/moGfc56CICyMvHp9YfwyIix7Ni9A3tv1ZHevx7EvPKFtGvlf3Ar46BDj+DoX57E6Sces8T28eO+ZNhzz7D2Oh1Tiix/zrz/XWbMLV+8fvETHy5+fNIOnZg1b0EaYeXOV+PHc+2//8XIUe/RtGlTjjjsYO6/925+ceRRaYeWKs8QlgJJuf6jYudN12LMxO/4YvJMjv/pRvxt0NvMK18IwOQZc1OOLtv6bLcDrVdb7X+2X3Tebzjvoj9n+h9zluy8YVuGfjg57TByo3xBOXPmzKG8vJw5s2fTocNaaYdkK6lOkrOkhyS9Luk9Sccn22ZKukzSKEnDJbVPtq+frL8j6VJJM5PtO0l6QdIjwPuSLpZ0RoXXuEzS6XXxfmrbgduvx70vfArABmu1YruN2zPs8p/x1CV70nMDd7cW25AnHqFDh7XotulmaYeSGxHw137d+M+hPdi7e/sl9m22dkumzZ7P+On+Q7MY1lp7bU474yw23mBd1l93LVq2asWufXdLO6ySIKmoS12qq8r5mIjoCfQCTpO0OtAcGB4RPYBhwC+TY68CroqITYFxldrZEjg9IjYEbgKOBJBUBhwC3F75hSUdL2mkpJHx/Xe18NaKq1HDMvbaqiMPvjwGgIYNymjTojE7nvMovx/4KreftUvKEebLnNmz+dff/8LZ516Ydii5cuq973D8naP43UPvs2+PDmy2dsvF+3bt6qq5mKZNm8bjjz3Cux9+xiefj2f2rFncfef/fBVaxtRVcj5N0ihgOPAjoAswD3gs2f860Cl5vA1wX/L4zkrtvBoRYwAi4nNgqqQtgN2ANyNiauUXjogBEdErInqpcYvivaNa8tMt1uGtz6YyKem+Hj91Fg8NHwvAyE+msDCCti193rlYPh/zGV+M/Zy+O2zF1pttyISvxvHTH/dh0sSv0w4t06bMmgfA9DnzefHTqWzcflUAGgh2WH91nvtoSprh5cpzzz5Dp06daNeuHY0aNeLn++7H8FdeTjus0qAiL9W9nNRV0lsVlm8lnSGpjaSnJX2c/Pzfc2uV1HpylrQT8BNgm6RKfhNoAsyPiEgOW0DNBqfNqrR+A3AUcDSFSjrzDtphfe598dPF64+OGMuPu3cAYIMOLVmlYRlTvnV3YLFs3K07b388jhFvf8SItz+iw1rrMOS/w1mj/Zpph5ZZTRqW0bRRg8WPe3VszZipswHo2bE1X0ybw+SZ89IMMVd+9KOOvDpiBLNnzyYieP65Z+m60cZph5U+1X23dkR8GBGbR8TmQE9gNjAIOAcYGhFdgKHJepXqonJuBUyLiNmSNgL6VHP8cGD/5PEh1Rw7CNgd2AoYslJRloBmjRuyS4+1eHj454u3DXz2Izq3b8HIK/tx61k7c9w/h6UXYA6cfOwR/Hy3H/PpJx/Rs9t63HXbzWmHlDurNWvEvw7alBsO35xrD+3B8DHTeHXsdAB26dqWZz901VxMW/Xemn377c92W/ek95absXDhQo457vi0wzLYFfg0IsYC+wADk+0DgX2re3JdjHoeDJwoaTTwIYXkW5UzgNslnZc8d8ayDoyIeZKeA6ZHROavy5j9fTnr9L9jiW3zyxdyzFX/TSmi/Lnmxtuq3D/i7Y/qKJL8mvDt9xx3x1tL3Xf5U5/UcTT1w/kX/JHzL/hj2mGUnJSvvjgEuCt53D4iJiSPvwbaL/0pP6j15BwR3wN7LGXXqhWOuR+4P1kdD/SJiJB0CNA1OeZ54PmKDSQDwfoABxY9cDMzsyW1lTSywvqAiBhQ+SBJqwA/B86tvC/JbVF5e2WleL1wT+BqFf7kmQ4cs7SDJG1CYUDZoIj4uA7jMzOzDKiFynlKRPSqwXF7AG9ExMRkfaKkDhExQVIHYFJ1DZRcco6IF4AeNTjufWC92o/IzMyyJuUZwg7lhy5tgEeA/sDlyc+Hq2sgkzOEmZmZlSJJzYG+wIMVNl8O9JX0MYWrly6vrp2Sq5zNzMyKIoXCOSJmAatX2jaVwujtGnPlbGZmVmJcOZuZWf4o9UupVoorZzMzsxLjytnMzHIpy5Wzk7OZmeVSlpOzu7XNzMxKjCtnMzPLp+wWzq6czczMSo0rZzMzy6Usn3N2cjYzs9yRUp1be6W5W9vMzKzEuHI2M7NccuVsZmZmRePK2czMcinLlbOTs5mZ5VN2c7O7tc3MzEqNK2czM8ulLHdru3I2MzMrMa6czcwsf+TK2czMzIrIlbOZmeWOgAwXzk7OZmaWR55b28zMzIrIlbOZmeVShgtnV85mZmalxpWzmZnlUpbPOTs5m5lZ/sjd2mZmZlZErpzNzCx3BJSVZbd0duVsZmZWYlw5m5lZLmX5nLOTs5mZ5VKWR2u7W9vMzKzEuHI2M7P8yfilVPUqOW/WeXWeHnhk2mHk2tYXPp12CPXCZpuskXYIuTdzbnnaIeTegoWRdgglq14lZzMzqx8Kt4zMbunsc85mZmYlxpWzmZnlULbv5+zkbGZmuZTh3OxubTMzs1LjytnMzHIpy93arpzNzMxKjCtnMzPLH09CYmZmVlp8nbOZmZkVlStnMzPLpQwXzq6czczMikVSa0n3S/pA0mhJ20hqI+lpSR8nP1errh0nZzMzyyVJRV1q6CpgcERsBPQARgPnAEMjogswNFmvkpOzmZnlklTcpfrXUytgR+BGgIiYFxHTgX2AgclhA4F9q2vLydnMzKw4OgOTgZslvSnpBknNgfYRMSE55mugfXUNOTmbmVn+qFa6tdtKGllhOb7SqzYEtgSujYgtgFlU6sKOiACqvZG1R2ubmZnVzJSI6FXF/nHAuIgYkazfTyE5T5TUISImSOoATKruhVw5m5lZ7hQmIanbc84R8TXwpaSuyaZdgfeBR4D+ybb+wMPVteXK2czMrHhOBe6QtArwGXA0hUL4XknHAmOBg6prxMnZzMxyaLkufyqaiHgLWFrX967L046Ts5mZ5ZJnCDMzM7OiceVsZma55LtSmZmZWdG4cjYzs/yp4eVPpcrJ2czMcqdwnXN2s7O7tc3MzEqMK2czM8slV85mZmZWNK6czcwslzJcODs5m5lZPrlb28zMzIrGlbOZmeVPxq9zduVsZmZWYlw5m5lZ7iilW0YWi5OzmZnlUoZzs7u1zczMSo0rZzMzy6WyDJfOrpzNzMxKjCtnMzPLpQwXzk7OpeL0k3/J04OfoG27dgwb8RYAF51/Dk89+RiNVlmFTp3X45/X3ECr1q1TjjTbWjRpyOUHb8qGa7YggN/d/TZvjp3OkduvyxHbrcuCCJ57fxJXPPZh2qFm2oCDN2XO/AUsDFiwMDj74dEc1nMteq/bmgiYMWc+Vw37nGmz56cdaiadccoP3xf/HV74vrji0gsZ/MSjlJWV0bbtGlx17Q2s2WGtlCO1FVUS3dqSTpM0WtIdaceSlkMOP5K7H3xsiW0/3nlXho14i/++8gbrb9CFq/5+RUrR5ccF+23Cfz+YTN8rhrHX317gk4kz6bNBG/p2b89ef3uR3f/yAjc8PybtMHPh/Mc/4sxB73P2w6MBGPT215zx4PucOeh9XvtyBgdv0SHlCLPr4MOO5K4Hlvy+OPm0s3ju5TcY+uJI+u6+J3+/4rKUoisNUmH6zmIudakkkjNwMtA3Ig5f0QYkZboXYJvtdqD1aqstsW3nXfvSsGHhbfXcamu+Gj8+jdByo0WThvRerw33jhgHwPwFwXdzyzl823W5buinzFuwEICpM+elGWZuzZm/cPHjJg3LiBRjybqlfV+0aNly8ePZs2Zlu0+3SMpU3KUupZ7QJF0HrAc8KeluYH2gO9AIuCgiHpbUCbgNaJ487VcR8bKknYBLgGnARsCGdRt93bnrtlvYp9+BaYeRaeu0aco3s+bxl0M2Y+O1WvDuuG+5+KH36dyuOVut14az9uzK9+UL+PMjH/D2lzPSDjfTArhojy4ADBk9mac+nALA4b3WZucNVmfWvAX84QmfOii2P1/8B+67+w5atGzJA489nXY4thJSr5wj4kTgK2BnCsn32Yjonaz/VVJzYBKFynpL4GDgnxWa2BI4PSJym5j/8dc/06BhQw44+LC0Q8m0hmVldFu7JXe8PJaf/f0lZs8r58Rd1qNBmWjVrBH9rnqZPz/6Af86cou0Q828cx/9gLMeGs3Fgz9mj03WYJM1VwXgjpHjOe7utxn26VT23GSNlKPMn3MvuIQ33v+M/Q88lJsGXJN2OKlzt3bx7AacI+kt4HmgCdCRQhV9vaR3gPuATSo859WIWOZJQknHSxopaeTUKVNqL/Jacvcdt/LU4Ce49oZbMz0VXSmYMGMOX8+Yy6gvClXx4FFf032dVnw9Yy5D3vkagLe/mMHCCNo0XyXNUDPvm2Sg14y55YwYO50u7Zovsf+/n3zDNp1WW9pTrQj6HXQojz8yKO0wbCWUWnIWsH9EbJ4sHSNiNHAmMBHoAfQCKn5zzqqqwYgYEBG9IqLX6m3b1lrgteHZp4dw9ZV/47Z7HqRZs2Zph5N5U76bx4Tpc+mcJIptN2zLxxNn8vQ7E+mzweoAdG7XnEYNyvhmls87r6jGDcto0qhs8ePN127JF9Pm0KFl48XHbL1ua8bPmJNWiLn02acfL348+IlH2aBL1xSjKQ1ScZe6lPo550qGAKdKOjUiQtIWEfEm0AoYFxELJfUHGqQbZvGdcPQveOnFYXwzdQo9NurMb39/AVf931+YN+97DtxnD6AwKOxvV/475Uiz7aIH3+PKX2xOowbii6mz+e3dbzNn3gKuOGQznvzNDsxfsJDf3PV22mFmWuumDTnnJxsA0KBMDPv0G94c9y2/23V91mrVhCCYPHMe1744NuVIs+vEY37By8n3xRYbd+Y3517A0Kee5JNPPqKsrIx1ftSRv/yjfn9XiMLNL7JKEemPmZT0OYWKeBZwJbAthap+TETsLakL8ACFcSaDgVMiYtVkQNjZEbF3TV5n8y17xtP/HV4L78AW2fpCD0KpC5v5fG2t+89BPdIOIfd2+3EfRr35eq1k0Nbrbhzb//7Worb5+Im9X4+IXkVtdBlKonKOiE4VVk9Yyv6Pgc0qbPpdsv15CuemzczMllDXlz8VU6mdczYzM6v3SqJyNjMzK6oULn8qJidnMzPLpQznZndrm5mZlRpXzmZmljsCyjJcOrtyNjMzKzGunM3MLJcyXDi7cjYzMys1rpzNzCyXfCmVmZlZCUnjZhXF5G5tMzOzEuPK2czMcsmXUpmZmVnRuHI2M7Ncym7d7ORsZmY5leXR2u7WNjMzKzGunM3MLHcKc2un8LrS58B3wAKgPCJ6SWoD3AN0Aj4HDoqIaVW1s8zkLOlfQCxrf0ScttxRm5mZ5d/OETGlwvo5wNCIuFzSOcn676pqoKrKeWQRAjQzM6t7Uimdc94H2Cl5PBB4nhVNzhExsOK6pGYRMXvl4jMzM6sbKeXmAJ6SFMB/ImIA0D4iJiT7vwbaV9dItQPCJG0j6X3gg2S9h6RrVjxuMzOzTGoraWSF5filHLN9RGwJ7AGcImnHijsjIqjilPEiNRkQdiXwU+CRpOFRlV/MzMys1NRCt/aUiOhV1QERMT75OUnSIKA3MFFSh4iYIKkDMKm6F6rRpVQR8WWlTQtq8jwzM7P6QlJzSS0WPQZ2A96lUNz2Tw7rDzxcXVs1qZy/lLQtEJIaAacDo1ckcDMzs7qQ0qVU7YFBScXeELgzIgZLeg24V9KxwFjgoOoaqklyPhG4Clgb+AoYApyygoGbmZnlUkR8BvRYyvapwK7L01a1yTm5Vuvw5WnUzMwsbSV0KdVyq8lo7fUkPSppsqRJkh6WtF5dBGdmZraiVOSlLtVkQNidwL1AB2At4D7grtoMyszMrD6rSXJuFhG3RUR5stwONKntwMzMzFaUBGVSUZe6VNXc2m2Sh08mc4HeTeHC6YOBJ+ogNjMzs3qpqgFhr1NIxov+XDihwr4Azq2toMzMzFZWhseDVTm3due6DMTMzKyYsjxau0b3c5bUHdiECueaI+LW2grKzMysPqs2OUu6kMKtrjahcK55D+BFwMnZzMxKVoYL5xqN1j6AwswmX0fE0RRmP2lVq1GZmZnVYzXp1p4TEQsllUtqSeFuGj+q5bjMzMxWmKj7y5+KqSbJeaSk1sD1FEZwzwReqdWozMzMVoay3a1dk7m1T04eXidpMNAyIt6u3bDMzMzqr6omIdmyqn0R8UbthGRmZrby8nop1f9VsS+AXYocS62bO38hH389M+0wcu3643unHUK9sPehF6UdQu41+8U/0w4h9xqkcMPlrKhqEpKd6zIQMzOzYqrJ5UilKsuxm5mZ5VKNZggzMzPLEpHfc85mZmaZleVT2tV2a6vgF5IuSNY7SvKoHzMzs1pSk3PO1wDbAIcm698B/661iMzMzIqgTMVd6lJNurW3jogtJb0JEBHTJK1Sy3GZmZnVWzVJzvMlNaBwbTOS2gELazUqMzOzlSDlf0DYP4FBwBqSLqNwl6rzazUqMzOzlZTlAWE1mVv7DkmvU7htpIB9I2J0rUdmZmZWT1WbnCV1BGYDj1bcFhFf1GZgZmZmKyPDvdo16tZ+nML5ZgFNgM7Ah0C3WozLzMys3qpJt/amFdeTu1WdvIzDzczMUiegLMOl83LPEBYRb0jaujaCMTMzK5Ys3zyiJuecf11htQzYEviq1iIyMzOr52pSObeo8LicwjnoB2onHDMzs+LIcK921ck5mXykRUScXUfxmJmZ1XvLTM6SGkZEuaTt6jIgMzOzlSUptwPCXqVwfvktSY8A9wGzFu2MiAdrOTYzM7N6qSbnnJsAU4Fd+OF65wCcnM3MrGRluHCuMjmvkYzUfpcfkvIiUatRmZmZraS8zq3dAFiVJZPyIk7OZmZmtaSq5DwhIi6us0jMzMyKJOszhFU1gUp235WZmVmGVVU571pnUZiZmRVZhgvnZSfniPimLgMxMzMrGmV7QFiW5wU3MzPLpeW+K5WZmVkWKMNDp1w5m5mZlRhXzmZmljuFS6nSjmLFOTmbmVkuZTk5u1vbzMysiCQ1kPSmpMeS9c6SRkj6RNI9klaprg0nZzMzyyVJRV2Ww+nA6ArrVwD/iIgNgGnAsdU14ORsZmZWJJLWAfYCbkjWReGujvcnhwwE9q2uHZ9zNjOz3ElxQNiVwG+BFsn66sD0iChP1scBa1fXiCtnMzOzmmkraWSF5fiKOyXtDUyKiNdX9oVcOZuZWf6oVubWnhIRvarYvx3wc0l7Ak2AlsBVQGtJDZPqeR1gfHUv5MrZzMxyqUwq6lKdiDg3ItaJiE7AIcCzEXE48BxwQHJYf+DhamNf8bdtZmZmNfA74NeSPqFwDvrG6p7gbu0SMXHCOC757clMmzIJJPY5uD8H9T+RP5x+DF+M+QSAmd/NYNUWrRj4yLCUo82mSRPGc8U5pzBt6mSE2OugI+h35Al8+sG7XHnRb5gzexZrrv0jzv3rdTRftUX1DdoynXr4zhy137ZEBO998hXHX3g7388r56JTfka/vluwYMFCrr//Ba65679ph5oL11z9TwbefAMRQf+jj+OUU09PO6TUpT1DWEQ8DzyfPP4M6L08z6+15CypE/BYRHSvrdfIkwYNGnLqOZfQtVsPZs38jmP77cJW2+3EJVfdtPiYf/35fJq3aJlilNnWoEEDTvztH+nSrQezZ83kpP13pee2O/F/fziTE35zET16b8eTD9zBvTdezdGnn5t2uJm1VrtWnHzoj9li/8uY+/18br/iGA78aU8ksc6aremx3yVEBO1WWzXtUHPh/ffeZeDNN/DcC8NZZZVV6PfzPdl9z71Yf/0N0g7NVi1nbCMAABi3SURBVIK7tUtE2zXWpGu3HgA0X7UF666/IZMnTli8PyJ49smH6Lv3/mmFmHmrr7EmXZLPuFnzVem4/oZMmTiBcZ9/ymZbbQtAz2134oWnH0szzFxo2KABTRs3okGDMpo2WYUJk2dw/IHb86cBTxIRAEyeNjPlKPPhww9G02ur3jRr1oyGDRuy3Q478uhDg9IOqyRIxV3qUm0n5waSrpf0nqSnJDWV9EtJr0kaJekBSc0AJN0i6bpkePpHyZB0JB0l6WFJz0v6WNKFyfaLJZ2x6IUkXSYpF305E8Z9wcfvv023Hj0Xbxs18hVWa7sGP+q0foqR5cfX47/gk9HvsFGPnnTaYCNeHvokAMOGPMLkCdUOpLQqfDV5BlfeOpSPnryEMU9fxrcz5zB0+Ad0XqcdB+zWkxfv+C0PXX0S63dsl3aoubBJt+68/NKLTJ06ldmzZ/PU4CcZN+7LtMMqAaKsyEtdqu3k3AX4d0R0A6YD+wMPRsRWEdGDwvRmFacx60ShX34v4DpJTZLtvZPnbgYcKKkXcBNwJICkMgoj426v5fdT62bPmsl5p/bntN//iear/tCF/fRjD9B3r34pRpYfc2bN5I+nHc3J51xK81VbcPZlV/HIXTdz0v67MnvWTBo2qnbaW6tC6xZN2XunTdl47wtZb7fzaN50FQ7Zcysar9KQ7+fNZ/vD/8LND77Mfy48PO1Qc6HrRhtz5lm/Yb+f7U6/n+/JZj160KBBg7TDspVU28l5TES8lTx+nULy7S7pBUnvAIcD3Socf29ELIyIj4HPgI2S7U9HxNSImAM8CGwfEZ8DUyVtAewGvBkRUysHIOn4RReMT/9mSm28x6Ipnz+f807tz24/O4CdfvqzH7aXl/Pfpx5j1732SzG6fCifP5+LTj+aXX92ADvstjcAHdfrwhU33se1Dwxllz37sVbHTukGmXG7bL0Rn381lSnTZlJevpCHnh1Fnx6dGT9xGg8NHQXAw8+OonuXaidJsho68qhjGfbyawx+5nlat16NDbpsmHZIqRPu1q7K9xUeL6AwAO0W4FcRsSnwRwoXai8SlZ4f1Wy/ATgKOJpCJf0/ImJARPSKiF6t27Rd3vjrTETw59+fxrrrb8ghx5yyxL6RLz/Puut1YY01/WW2MiKCv51/BuuutyEHHHXS4u3Tpk4GYOHChdx+3d/Z++D+aYWYC19+/Q29N+1M0yaNANi5d1c+HDORR59/mx9v1QWAHXp24ZMvJqUZZq5MnlT4LL/84gseeXgQBx58aMoR2cpK41KqFsAESY0oVM4VT/AdKGkg0BlYD/gQ2ALoK6kNMIfChOHHJMcPAi4GGgGH1U34tePt10cw+OF7WL/rJvT/+Y4AnPDrP7DtTn155vFB/MQDwVbau2+M4JlH7qXzhptwwn47AXDMGecxfuxnPHxn4W+77fvuxe79Mv2rlLrX3h3LoGfe5JU7f0f5goWM+mAcNz7wEk0bN+LmP/Xn1MN3Ydac7znp4jvTDjU3fnHogXzzzVQaNWrE/135L1q3bp12SOlTtu/nnEZy/gMwApic/Kx4QekXwKsUpjw7MSLmJrfpehV4gMK0Z7dHxEiAiJgn6TkKk4ovqLu3UHw9evXhpY++Weq+86/4dx1Hk0+b9uzDM6MnL3VfvyNPqONo8u3S657g0uueWGLbvPnl9DvtupQiyrchQ329+NLUZFavUlVryTk5J9y9wvrfKuy+dhlPeyYiTlzK9nER8T+32EoGgvUBDlyJUM3MzEpKZq9zlrQJ8AkwNBlAZmZmBmR/QFjJTN8ZEUctY/stFAaRVd7+PoXz0mZmZrlSMsnZzMysmLJ8zjmz3dpmZmZ55crZzMxyKcOFs5OzmZnlj8h213CWYzczM8slV85mZpY/AmW4X9uVs5mZWYlx5WxmZrmU3brZydnMzHJI+DpnMzMzKyJXzmZmlkvZrZtdOZuZmZUcV85mZpZLGT7l7ORsZmZ5JF/nbGZmZsXjytnMzHLHc2ubmZlZUblyNjOzXPI5ZzMzMysaV85mZpZL2a2bnZzNzCyPfMtIMzMzKyZXzmZmlju+lMrMzMyKypWzmZnlUpbPOTs5m5lZLmU3Nbtb28zMrOS4cjYzs1zKcK+2K2czM7NS48rZzMxyp3ApVXZLZydnMzPLJXdrm5mZWdG4cjYzsxwSynC3titnMzOzEuPK2czMcsnnnM3MzErIotHaxVyqfU2piaRXJY2S9J6kPybbO0saIekTSfdIWqW6tpyczczMiuN7YJeI6AFsDuwuqQ9wBfCPiNgAmAYcW11D9apbu/kqDdiy82pph5FrVw77NO0Q6oVbbjo37RBy79CBI9MOIfc+mzKr9hpX3XdrR0QAM5PVRskSwC7AYcn2gcBFwLVVteXK2czMrEgkNZD0FjAJeBr4FJgeEeXJIeOAtatrp15VzmZmVn/UQuXcVlLFLpUBETGg4gERsQDYXFJrYBCw0Yq8kJOzmZlZzUyJiF41OTAipkt6DtgGaC2pYVI9rwOMr+757tY2M7NcUpH/q/b1pHZJxYykpkBfYDTwHHBAclh/4OHq2nLlbGZmuSOgrO6vc+4ADJTUgELxe29EPCbpfeBuSZcCbwI3VteQk7OZmVkRRMTbwBZL2f4Z0Ht52nJyNjOzXPLc2mZmZlY0rpzNzCyXsjy3tpOzmZnlkru1zczMrGhcOZuZWe6kdClV0bhyNjMzKzGunM3MLIdqNqtXqXJyNjOz/EnhlpHF5G5tMzOzEuPK2czMcinDhbMrZzMzs1LjytnMzHKncClVdmtnV85mZmYlxpWzmZnlUnbrZidnMzPLqwxnZ3drm5mZlRhXzmZmlktZniHMlbOZmVmJceVsZma5lOErqZyczcwsnzKcm92tbWZmVmpcOZuZWT5luHR25WxmZlZiXDmbmVnuiGxfSuXkbGZm+aNsj9Z2t7aZmVmJceVsZma5lOHC2ZWzmZlZqXHlbGZm+ZTh0tmVs5mZWYlx5WxmZjkkX0plZmZWanwplZmZmRWNk3MJ+ujDD9m65+aLlzXatORfV12Zdli5sXDBAv55ws+45fe/BODlh27lr0fswrm7bsCsGd+kHF32zft+LucdsRe/PbgvZx+wC/dd+7cl9t/ylz/Qf7sNU4ouP248rAdXH9Cdf+7fjX/067bEvv02W5PHTuhNyyb1t3NUtbDUpVz8n5PUCXgsIrqnHEpRbNi1KyNefwuABQsWsP66a/PzffdLOar8eOnBW1ij4wbMnTUTgE7derJxn10Y8OvDU44sHxqt0pg//OdemjRrTvn8+Vx47H5svt3OdNmsJ5++P4qZ385IO8Tc+P1jH/Dt3PIltrVtvgpbrNOKSd99n1JUVgyunEvcc88OpfN667PuuuumHUouzJg8gQ9HPM9Wex60eNtaXbqx2prrpBhVvkiiSbPmACwoL2dBeTlILFywgDuuvJTDTz8v5Qjz7ZfbduTm4V8QaQdSCjJcOpdU5SypOXAvsA7QALgE6Ar8DGgKvAycEBEhqSdwU/LUp1IIt07cd8/dHHTwoWmHkRuP/ftS9jj+d3w/e2baoeTawgULOPfwPfj6y8/Z7aD+dNl0S5648wZ67rgbq7Vrn3Z4uRABF+/ZFYAnR09iyOjJbL1ua6bOmseYb+akHF1pyPJo7VKrnHcHvoqIHkkX9WDg6ojYKllvCuydHHszcGpE9KiqQUnHSxopaeTkKZNrNfhimzdvHo8/9gj9Djgw7VByYfQrz9J8tdVZe8NcnP0oaWUNGnDF3U9xzeDX+PS9txj9+nBGPPM4ux9ydNqh5cbvHn6fMx58jwuf+JC9u7WnW4cWHLTFWtw+cnzaoVkRlFpyfgfoK+kKSTtExAxgZ0kjJL0D7AJ0k9QaaB0Rw5Ln3basBiNiQET0iohe7dq2q/13UERDBj/J5ltsSfv2rjSKYex7rzP65aFccdiPuevSM/jsrVe450+/TjusXGveohXdem3LeyNf5usvP+f0fbbnV3v1Yd7cOZz+8+3SDi/Tps6eD8CMueW8MmYam3ZoQfuWjfnXAd258bAetG2+Clf260brpo1SjjQ9UnGXulRS3doR8ZGkLYE9gUslDQVOAXpFxJeSLgKapBljXbr3nrvcpV1Eux/3G3Y/7jcAfPbWcIbdeyMH//7vKUeVP99Om0qDhg1p3qIV8+bO4e3hL/Dzo07mP0+/ufiY/tttyFWPvJRilNnWuGEZZYI58xfSuGEZW6zTkrve+Ipf3PrDZ3zjYT0488H3/mfAmGVDSSVnSWsB30TE7ZKmA8clu6ZIWhU4ALg/IqZLmi5p+4h4EcjdMNtZs2bx7DNPc/U1/0k7lNx76cGBDLtnADO/mcJVv9ybrr1/zP5n/zntsDJr2uSJXHvhmSxcsICFEWzTd2967viTtMPKldZNG3H+T7sAUCb47ydTeeNLj4KvLLtnnEssOQObAn+VtBCYD5wE7Au8C3wNvFbh2KOBmyQFORwQ1rx5c8ZPnJp2GLm13uZ9WG/zPgBs168/2/Xrn3JE+bHuhptw+V1Dqjxm4Esf1VE0+TTxu+859f53qzzm2DtH1VE0JSqNi5OLqKSSc0QMASr/qx4JnL+UY18HKg4G+20thmZmZlZnSio5m5mZFYsvpTIzM7OiceVsZma5I3xXKjMzs3pP0o8kPSfpfUnvSTo92d5G0tOSPk5+rlZdW07OZmaWSylMrV0OnBURmwB9gFMkbQKcAwyNiC7A0GS9Sk7OZmaWT3WcnSNiQkS8kTz+DhgNrA3sAwxMDhtI4RLhKvmcs5mZWc20lTSywvqAiBiwtAOTWxlvAYwA2kfEhGTX10C1czI7OZuZWS7VwqVUUyKiV7WvW5jR8gHgjIj4VhVGpiV3Vaz2jp7u1jYzMysSSY0oJOY7IuLBZPNESR2S/R2ASdW14+RsZma5VNd3pVKhRL4RGB0RFe+q8wiwaI7g/sDD1bXlbm0zM8ulFC5z3g44AnhH0lvJtt8DlwP3SjoWGAscVF1DTs5mZmZFkNwlcVl/E+y6PG05OZuZWT55hjAzMzMrFlfOZmaWO4V5Q7JbOjs5m5lZ/tRwhHWpcre2mZlZiXHlbGZmuZThwtmVs5mZWalx5WxmZvmU4dLZlbOZmVmJceVsZmY5JF9KZWZmVmp8KZWZmZkVjStnMzPLHZHp8WCunM3MzEqNK2czM8unDJfOTs5mZpZLWR6t7W5tMzOzEuPK2czMcsmXUpmZmVnRuHI2M7NcynDh7ORsZmY5JHdrm5mZWRG5cjYzs5zKbunsytnMzKzEuHI2M7PcET7nbGZmZkXkytnMzHIpw4Vz/UrOb7zx+pSmjTQ27TiWU1tgStpB5Jw/49rnz7huZO1zXrc2G89yt3a9Ss4R0S7tGJaXpJER0SvtOPLMn3Ht82dcN/w550e9Ss5mZlZ/+K5UZmZmVjSunEvfgLQDqAf8Gdc+f8Z1w59zRdktnJ2cS11E+B9bLfNnXPv8GdcNf85LynBudre2mZlZqXFytlyTdJqk0ZLuSDuWPJDUSdK7acdhNVdf/59JxV/qkru1M0xSw4goTzuOEncy8JOIGLeiDfhzNrO65sq5Dkl6SNLrkt6TdHyybaakyySNkjRcUvtk+/rJ+juSLpU0M9m+k6QXJD0CvC/pYklnVHiNyySdnsobLDGSrgPWA56UdJ6kmyS9KulNSfskx3RKPs83kmXbZPsSn3OKb6MUNZB0ffJ7/JSkppJ+Kem15Pf4AUnNACTdIuk6SSMlfSRp72T7UZIelvS8pI8lXZhs9+/zMkhqLunx5DN+V9LBki5IPvd3JQ2QCvWdpJ7JcaOAU1IOPTUq8n91ycm5bh0TET2BXsBpklYHmgPDI6IHMAz4ZXLsVcBVEbEpULnq2xI4PSI2BG4CjgSQVAYcAtxe6+8kAyLiROArYGcKn/OzEdE7Wf+rpObAJKBvRGwJHAz8s0ITFT9n+0EX4N8R0Q2YDuwPPBgRWyW/x6OBYysc3wnoDewFXCepSbK9d/LczYADJfXCv89V2R34KiJ6RER3YDBwdfK5dweaAnsnx94MnJr8/6i/VOSlDjk5163Tkr9khwM/ovAlNw94LNn/OoUvMoBtgPuSx3dWaufViBgDEBGfA1MlbQHsBrwZEVNr6w1k2G7AOZLeAp4HmgAdgUbA9ZLeofB5b1LhOYs/Z1vCmIh4K3m86He2e9LT8A5wONCtwvH3RsTCiPgY+AzYKNn+dERMjYg5wIPA9v59rtI7QF9JV0jaISJmADtLGpF87rsA3SS1BlpHxLDkebelFbCtOJ9zriOSdgJ+AmwTEbMlPU8hQcyPiEgOW0DN/p/MqrR+A3AUsCaFysP+l4D9I+LDJTZKFwETgR4U/lidW2F35c/ZCr6v8HgBhYrtFmDfiBgl6ShgpwrHBEuKarb793kpIuIjSVsCewKXShpKocu6V0R8mfwuN6mqjfrGl1JZTbQCpiWJeSOgTzXHD6fQ5QeFrr2qDKLQ5bUVMGSlosyvIcCpFc7JbZFsbwVMiIiFwBFAg5Tiy7oWwARJjShUzhUdKKlM0voUxgAs+gOpr6Q2kpoC+wIvJdv9+7wUktYCZkfE7cBfKZx2AZgiaVXgAICImA5Ml7R9sr/y/w/LAFfOdWcwcKKk0RS+nIZXc/wZwO2SzkueO2NZB0bEPEnPAdMjYkGxAs6ZS4ArgbeTc5ljKJyfuwZ4QNKRFD5nV8sr5g/ACGBy8rNFhX1fAK8CLYETI2Ju8jfSq8ADwDrA7RExEvz7XIVNKYyVWAjMB06i8EfNu8DXwGsVjj0auElSAE/VdaClIst3pdIPPapWSpLRrnMiIiQdAhwaEfss49gy4A3gwOS8nllJkHQL8FhE3F9p+1EUumN/tZTn+PfZVtrmW/aMoS+MKGqbbVdt9Hpd3fXLlXPp6glcnXTDTgeOWdpBkjahMKBskL/ILOv8+2zFU/eXPxWTK2czM8udLbbsFc++WNzKuU3zhnVWOXtAmJmZWYlxcjYzMyuCZBbCSaowl3lyRcLTyUx4T0tarSZtOTmbmZkVxy0ULgOs6BxgaER0AYYm69VycjarhqQFkt5K5i++b9G80SvY1i2SDkge35AMgFrWsTstmut7OV/jc0lta7q90jEzl/O1LpJ09vLGaFYX6vquVMmsbN9U2rwPMDB5PJDC5W/VcnI2q96ciNg8mb94HnBixZ2SVuiqh4g4LiKquqnGTsByJ2czK6iFG1+0TW7ismg5vgZhtI+ICcnjr4H2NYndydls+bwAbFD5rlWSGkj6a3KHoLclnQCggqslfSjpGWCNRQ0ld2TqlTzeXYW7Yo2SNFRSJwp/BJyZVO07SGqnwh2fXkuW7ZLnrq7C3aHek3QDNZi1UEu5Q1qFff9Itg+V1C7Ztr6kwclzXkhmuTOrb6ZERK8Ky4DleXIyVXONLpHydc5mNZRUyHtQmEkMCtMndo+IMUmCmxERW0lqDLwk6SlgC6ArhRtqtKdw+8mbKrXbDrge2DFpq01EfKPCLS9nRsTfkuPuBP4RES9K6khhasuNgQuBFyPiYkl7seQdoZblmOQ1mgKvSXogucFEc2BkRJwp6YKk7V8BAyjM7vWxpK0pzKy2ywp8jGZ1o4Zd0XVgoqQOETFBUgcKd8KrlpOzWfWaqnA3KyhUzjdS6G6ueNeq3YDNFp1PpjBndxdgR+CuZBrKryQ9u5T2+wDDKtxprPI5q0V+AmyiH75xWiZzKu8I9Eue+7ikaTV4T6dJ2i95vOgOaVOBhcA9yfbbgQeT19gWuK/CazeuwWuYGTwC9AcuT34+XJMnOTmbVW9ORGxecUOSpCrOwy0K988dUum4PYsYRxnQJyIq3jkLLWd5oGXfIW1pInnd6ZU/A7NSlsItmJF0F4WxIm0ljaPQ83Q5cK+kY4GxwEE1acvnnM2KYwhwkgp3ZULShpKaA8OAg5Nz0h2AnZfy3OHAjpI6J89tk2z/jiVvIPEUcOqiFUmLkuUw4LBk2x5AdddRVnWHtDKSuxslbb4YEd8CYyQdmLyGJPWo5jXM0qciL9WIiEMjokNENIqIdSLixuSe5btGRJeI+EkVPWNLcHI2K44bKJxPfiOZgOA/FHqmBgEfJ/tuBV6p/MSImAwcT6ELeRQ/dCs/Cuy3aEAYcBrQKxlw9j4/jBr/I4Xk/h6F7u0vqol1MNBQhTukXc6Sd0ibBfRO3sMuwMXJ9sOBY5P43qNweYiZ1RLPrW1mZrmzZc9eMezl16o/cDm0aFLmubXNzMzqKw8IMzOzXCqRS6lWiCtnMzOzEuPK2czMcinDhbOTs5mZ5VSGs7O7tc3MzEqMK2czM8slZbh0duVsZmZWYlw5m5lZ7ohsX0rlGcLMzCx3JA0G2ha52SkRsXuR21wqJ2czM7MS43POZmZmJcbJ2czMrMQ4OZuZmZUYJ2czM7MS4+RsZmZWYv4fi4ONks14JVcAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 576x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2x9nMZ6DZ1D8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qLKgMiv0bNC8"
      },
      "source": [
        "# Combined feature + basic model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVHB0C0fbNDK"
      },
      "source": [
        "features = []\n",
        "labels = []\n",
        "for i in range(len(Ravdess_DF['Paths'])):\n",
        "  if ((Ravdess_DF['Emotion'][i] == '03') | (Ravdess_DF['Emotion'][i] == '04') | \n",
        "      (Ravdess_DF['Emotion'][i] == '05') | (Ravdess_DF['Emotion'][i] == '06')):\n",
        "    signal, sr = librosa.load(Ravdess_DF['Paths'][i])\n",
        "    if len(signal) > input_length:\n",
        "        signal = signal[0:input_length]\n",
        "    elif  input_length > len(signal):\n",
        "        max_offset = input_length - len(signal)  \n",
        "        signal = np.pad(signal, (0, max_offset), \"constant\")\n",
        "    mfcc = np.mean(librosa.feature.mfcc(y=signal, sr=sr, n_mfcc=39).T,axis=0)\n",
        "    mel_spec = np.mean(librosa.feature.melspectrogram(signal, sr, n_mels=28).T, axis=0)\n",
        "    tempogram = np.mean(librosa.feature.tempogram(signal, sr, win_length=24).T, axis=0)\n",
        "\n",
        "    mfcc = pd.DataFrame(mfcc)\n",
        "    mel_spec = pd.DataFrame(mel_spec)\n",
        "    tempogram = pd.DataFrame(tempogram)\n",
        "    feature = mfcc.append(mel_spec).append(tempogram)\n",
        "    feature = np.array(feature[0])\n",
        "    features.append(feature)\n",
        "    if Ravdess_DF['Emotion'][i] == '03':\n",
        "      labels.append(0)\n",
        "    elif Ravdess_DF['Emotion'][i] == '04':\n",
        "      labels.append(1)\n",
        "    elif Ravdess_DF['Emotion'][i] == '05':\n",
        "      labels.append(2)\n",
        "    elif Ravdess_DF['Emotion'][i] == '06':\n",
        "      labels.append(3)\n",
        "\n",
        "\n",
        "\n",
        "for i in range(len(CREMA_D_df)):\n",
        "  if ((CREMA_D_df['Emotion'][i] == 'HAP') | (CREMA_D_df['Emotion'][i] == 'SAD') | \n",
        "      (CREMA_D_df['Emotion'][i] == 'ANG') | (CREMA_D_df['Emotion'][i] == 'FEA')):\n",
        "    \n",
        "    if CREMA_D_df['Emotion'][i] == 'HAP':\n",
        "      labels.append(0)\n",
        "    elif CREMA_D_df['Emotion'][i] == 'SAD':\n",
        "      labels.append(1)\n",
        "    elif CREMA_D_df['Emotion'][i] == 'ANG':\n",
        "      labels.append(2)\n",
        "    elif CREMA_D_df['Emotion'][i] == 'FEA':\n",
        "      labels.append(3)\n",
        "\n",
        "\n",
        "    signal, sr =  librosa.load(CREMA_D_df['Paths'][i])\n",
        "    if len(signal) > input_length:\n",
        "        signal = signal[0:input_length]\n",
        "    elif  input_length > len(signal):\n",
        "        max_offset = input_length - len(signal)  \n",
        "        signal = np.pad(signal, (0, max_offset), \"constant\")\n",
        "    mfcc = np.mean(librosa.feature.mfcc(y=signal, sr=sr, n_mfcc=39).T,axis=0)\n",
        "    mel_spec = np.mean(librosa.feature.melspectrogram(signal, sr, n_mels=28).T, axis=0)\n",
        "    tempogram = np.mean(librosa.feature.tempogram(signal, sr, win_length=24).T, axis=0)\n",
        "\n",
        "    mfcc = pd.DataFrame(mfcc)\n",
        "    mel_spec = pd.DataFrame(mel_spec)\n",
        "    tempogram = pd.DataFrame(tempogram)\n",
        "    feature = mfcc.append(mel_spec).append(tempogram)\n",
        "    feature = np.array(feature[0])\n",
        "    features.append(feature)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6e2Kzf1whcUF"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "sc = StandardScaler()\n",
        "features = sc.fit_transform(features)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HdJCV4lVbNDL"
      },
      "source": [
        "X = features\n",
        "y = labels\n",
        "\n",
        "y = np.array(y)\n",
        "y = to_categorical(y)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=0)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=0)\n",
        "\n",
        "X_train = np.array(X_train)\n",
        "X_test = np.array(X_test)\n",
        "X_val = np.array(X_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "raK241T-jG41",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5da13e17-4987-4af6-d48f-e9e4c4d70cdf"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4739, 91)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XSNUyBRPbNDM"
      },
      "source": [
        "## basic models:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MtpRYpB3bNDN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "715f7429-964c-4860-db2c-ce22e96b46d6"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(91, input_shape=(91, ), activation = 'relu'))\n",
        "#model.add(Dropout(0.1))\n",
        "model.add(Dense(128, activation = 'relu'))\n",
        "#model.add(Dropout(0.25))\n",
        "model.add(Dense(128, activation = 'relu'))\n",
        "#model.add(Dropout(0.2))\n",
        "model.add(Dense(4, activation = 'softmax'))\n",
        "\n",
        "optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
        "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer=optimizer)\n",
        "early_stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=100, verbose=1, mode='auto')\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 91)                8372      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 128)               11776     \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 4)                 516       \n",
            "=================================================================\n",
            "Total params: 37,176\n",
            "Trainable params: 37,176\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xwrMDDGabNDN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e66d3385-a1c0-4cee-e905-1713ec8260ea"
      },
      "source": [
        "history = model.fit(X_train, y_train, batch_size=64, epochs=200, \n",
        "                    validation_data=(X_val, y_val))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "75/75 [==============================] - 1s 6ms/step - loss: 1.1968 - accuracy: 0.4508 - val_loss: 0.9375 - val_accuracy: 0.6015\n",
            "Epoch 2/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.9391 - accuracy: 0.5872 - val_loss: 0.8403 - val_accuracy: 0.6319\n",
            "Epoch 3/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.8514 - accuracy: 0.6350 - val_loss: 0.8108 - val_accuracy: 0.6509\n",
            "Epoch 4/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.8285 - accuracy: 0.6517 - val_loss: 0.8297 - val_accuracy: 0.6319\n",
            "Epoch 5/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.7633 - accuracy: 0.6788 - val_loss: 0.7867 - val_accuracy: 0.6584\n",
            "Epoch 6/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.7068 - accuracy: 0.6955 - val_loss: 0.8593 - val_accuracy: 0.6186\n",
            "Epoch 7/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.7223 - accuracy: 0.6914 - val_loss: 0.7707 - val_accuracy: 0.6641\n",
            "Epoch 8/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.6724 - accuracy: 0.7202 - val_loss: 0.7522 - val_accuracy: 0.6698\n",
            "Epoch 9/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.6028 - accuracy: 0.7500 - val_loss: 0.7485 - val_accuracy: 0.6755\n",
            "Epoch 10/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.5840 - accuracy: 0.7599 - val_loss: 0.7940 - val_accuracy: 0.6755\n",
            "Epoch 11/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.5453 - accuracy: 0.7878 - val_loss: 0.8589 - val_accuracy: 0.6755\n",
            "Epoch 12/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.5518 - accuracy: 0.7817 - val_loss: 0.8492 - val_accuracy: 0.6812\n",
            "Epoch 13/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.5001 - accuracy: 0.7928 - val_loss: 0.8149 - val_accuracy: 0.6736\n",
            "Epoch 14/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.4539 - accuracy: 0.8220 - val_loss: 0.8094 - val_accuracy: 0.6717\n",
            "Epoch 15/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.4490 - accuracy: 0.8234 - val_loss: 0.8120 - val_accuracy: 0.7040\n",
            "Epoch 16/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.3805 - accuracy: 0.8590 - val_loss: 0.8847 - val_accuracy: 0.6774\n",
            "Epoch 17/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.4001 - accuracy: 0.8559 - val_loss: 0.9381 - val_accuracy: 0.6622\n",
            "Epoch 18/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.3639 - accuracy: 0.8630 - val_loss: 0.9475 - val_accuracy: 0.6546\n",
            "Epoch 19/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.3549 - accuracy: 0.8611 - val_loss: 0.9612 - val_accuracy: 0.6679\n",
            "Epoch 20/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.4102 - accuracy: 0.8476 - val_loss: 0.9755 - val_accuracy: 0.6584\n",
            "Epoch 21/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.2971 - accuracy: 0.8958 - val_loss: 0.9807 - val_accuracy: 0.6584\n",
            "Epoch 22/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.2750 - accuracy: 0.8996 - val_loss: 1.0311 - val_accuracy: 0.6831\n",
            "Epoch 23/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.3105 - accuracy: 0.8786 - val_loss: 1.0073 - val_accuracy: 0.6907\n",
            "Epoch 24/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.2438 - accuracy: 0.9089 - val_loss: 1.0768 - val_accuracy: 0.6660\n",
            "Epoch 25/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.2555 - accuracy: 0.9022 - val_loss: 1.0850 - val_accuracy: 0.6584\n",
            "Epoch 26/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.2441 - accuracy: 0.9041 - val_loss: 1.1974 - val_accuracy: 0.6357\n",
            "Epoch 27/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.2777 - accuracy: 0.8950 - val_loss: 1.1668 - val_accuracy: 0.6433\n",
            "Epoch 28/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.2091 - accuracy: 0.9292 - val_loss: 1.2589 - val_accuracy: 0.6509\n",
            "Epoch 29/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.2059 - accuracy: 0.9245 - val_loss: 1.3247 - val_accuracy: 0.6698\n",
            "Epoch 30/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.1581 - accuracy: 0.9506 - val_loss: 1.2866 - val_accuracy: 0.6603\n",
            "Epoch 31/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.1304 - accuracy: 0.9629 - val_loss: 1.3739 - val_accuracy: 0.6679\n",
            "Epoch 32/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.1115 - accuracy: 0.9677 - val_loss: 1.4346 - val_accuracy: 0.6888\n",
            "Epoch 33/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.1359 - accuracy: 0.9552 - val_loss: 1.4796 - val_accuracy: 0.6490\n",
            "Epoch 34/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.1843 - accuracy: 0.9366 - val_loss: 1.5398 - val_accuracy: 0.6490\n",
            "Epoch 35/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.2617 - accuracy: 0.9052 - val_loss: 1.5393 - val_accuracy: 0.6584\n",
            "Epoch 36/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.1881 - accuracy: 0.9365 - val_loss: 1.3939 - val_accuracy: 0.6509\n",
            "Epoch 37/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.1001 - accuracy: 0.9755 - val_loss: 1.4509 - val_accuracy: 0.6603\n",
            "Epoch 38/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.1364 - accuracy: 0.9514 - val_loss: 1.4590 - val_accuracy: 0.6812\n",
            "Epoch 39/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.1679 - accuracy: 0.9391 - val_loss: 1.5510 - val_accuracy: 0.6679\n",
            "Epoch 40/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.1201 - accuracy: 0.9610 - val_loss: 1.6183 - val_accuracy: 0.6641\n",
            "Epoch 41/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0733 - accuracy: 0.9795 - val_loss: 1.6795 - val_accuracy: 0.6490\n",
            "Epoch 42/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0700 - accuracy: 0.9819 - val_loss: 1.7034 - val_accuracy: 0.6509\n",
            "Epoch 43/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0570 - accuracy: 0.9857 - val_loss: 1.7966 - val_accuracy: 0.6357\n",
            "Epoch 44/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0692 - accuracy: 0.9794 - val_loss: 1.9008 - val_accuracy: 0.6546\n",
            "Epoch 45/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0453 - accuracy: 0.9914 - val_loss: 1.9281 - val_accuracy: 0.6490\n",
            "Epoch 46/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0576 - accuracy: 0.9814 - val_loss: 1.9432 - val_accuracy: 0.6490\n",
            "Epoch 47/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0397 - accuracy: 0.9946 - val_loss: 2.0043 - val_accuracy: 0.6433\n",
            "Epoch 48/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.2983 - accuracy: 0.9182 - val_loss: 1.7735 - val_accuracy: 0.6433\n",
            "Epoch 49/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.1710 - accuracy: 0.9491 - val_loss: 1.7816 - val_accuracy: 0.6281\n",
            "Epoch 50/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.1016 - accuracy: 0.9699 - val_loss: 1.7360 - val_accuracy: 0.6565\n",
            "Epoch 51/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0726 - accuracy: 0.9843 - val_loss: 1.8292 - val_accuracy: 0.6565\n",
            "Epoch 52/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0332 - accuracy: 0.9952 - val_loss: 1.8608 - val_accuracy: 0.6452\n",
            "Epoch 53/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0308 - accuracy: 0.9970 - val_loss: 1.9309 - val_accuracy: 0.6433\n",
            "Epoch 54/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0295 - accuracy: 0.9943 - val_loss: 1.9804 - val_accuracy: 0.6584\n",
            "Epoch 55/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0213 - accuracy: 0.9974 - val_loss: 2.0601 - val_accuracy: 0.6490\n",
            "Epoch 56/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0178 - accuracy: 0.9984 - val_loss: 2.1496 - val_accuracy: 0.6471\n",
            "Epoch 57/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0129 - accuracy: 0.9999 - val_loss: 2.1676 - val_accuracy: 0.6509\n",
            "Epoch 58/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0120 - accuracy: 1.0000 - val_loss: 2.2592 - val_accuracy: 0.6528\n",
            "Epoch 59/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0122 - accuracy: 0.9992 - val_loss: 2.2529 - val_accuracy: 0.6452\n",
            "Epoch 60/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 2.3234 - val_accuracy: 0.6357\n",
            "Epoch 61/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0091 - accuracy: 0.9999 - val_loss: 2.3498 - val_accuracy: 0.6433\n",
            "Epoch 62/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0093 - accuracy: 0.9999 - val_loss: 2.3910 - val_accuracy: 0.6433\n",
            "Epoch 63/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 2.4416 - val_accuracy: 0.6509\n",
            "Epoch 64/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 2.4344 - val_accuracy: 0.6490\n",
            "Epoch 65/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 2.4919 - val_accuracy: 0.6509\n",
            "Epoch 66/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 2.5359 - val_accuracy: 0.6490\n",
            "Epoch 67/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 2.5661 - val_accuracy: 0.6471\n",
            "Epoch 68/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 2.5994 - val_accuracy: 0.6471\n",
            "Epoch 69/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 2.6267 - val_accuracy: 0.6471\n",
            "Epoch 70/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 2.6753 - val_accuracy: 0.6433\n",
            "Epoch 71/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 2.6971 - val_accuracy: 0.6509\n",
            "Epoch 72/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 2.7205 - val_accuracy: 0.6471\n",
            "Epoch 73/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 2.7895 - val_accuracy: 0.6414\n",
            "Epoch 74/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 2.8098 - val_accuracy: 0.6452\n",
            "Epoch 75/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0242 - accuracy: 0.9948 - val_loss: 2.9603 - val_accuracy: 0.6338\n",
            "Epoch 76/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.5311 - accuracy: 0.8525 - val_loss: 1.7454 - val_accuracy: 0.6319\n",
            "Epoch 77/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.1420 - accuracy: 0.9489 - val_loss: 1.9167 - val_accuracy: 0.6622\n",
            "Epoch 78/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0636 - accuracy: 0.9833 - val_loss: 1.9713 - val_accuracy: 0.6509\n",
            "Epoch 79/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.1132 - accuracy: 0.9708 - val_loss: 2.1614 - val_accuracy: 0.6205\n",
            "Epoch 80/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0492 - accuracy: 0.9854 - val_loss: 2.1630 - val_accuracy: 0.6395\n",
            "Epoch 81/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0178 - accuracy: 0.9967 - val_loss: 2.2322 - val_accuracy: 0.6376\n",
            "Epoch 82/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0195 - accuracy: 0.9964 - val_loss: 2.2701 - val_accuracy: 0.6452\n",
            "Epoch 83/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 2.3344 - val_accuracy: 0.6603\n",
            "Epoch 84/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 2.3963 - val_accuracy: 0.6528\n",
            "Epoch 85/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 2.4473 - val_accuracy: 0.6509\n",
            "Epoch 86/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 2.4765 - val_accuracy: 0.6452\n",
            "Epoch 87/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.5280 - val_accuracy: 0.6509\n",
            "Epoch 88/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.5551 - val_accuracy: 0.6452\n",
            "Epoch 89/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.5811 - val_accuracy: 0.6509\n",
            "Epoch 90/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.6136 - val_accuracy: 0.6490\n",
            "Epoch 91/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.6359 - val_accuracy: 0.6471\n",
            "Epoch 92/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 2.6672 - val_accuracy: 0.6471\n",
            "Epoch 93/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 2.6929 - val_accuracy: 0.6528\n",
            "Epoch 94/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 2.7289 - val_accuracy: 0.6452\n",
            "Epoch 95/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 2.7444 - val_accuracy: 0.6528\n",
            "Epoch 96/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 2.7782 - val_accuracy: 0.6471\n",
            "Epoch 97/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 2.7994 - val_accuracy: 0.6509\n",
            "Epoch 98/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.8125 - val_accuracy: 0.6509\n",
            "Epoch 99/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.8400 - val_accuracy: 0.6490\n",
            "Epoch 100/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 2.8625 - val_accuracy: 0.6528\n",
            "Epoch 101/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 9.7845e-04 - accuracy: 1.0000 - val_loss: 2.8940 - val_accuracy: 0.6452\n",
            "Epoch 102/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 9.2637e-04 - accuracy: 1.0000 - val_loss: 2.9029 - val_accuracy: 0.6471\n",
            "Epoch 103/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 8.4878e-04 - accuracy: 1.0000 - val_loss: 2.9211 - val_accuracy: 0.6490\n",
            "Epoch 104/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 8.1358e-04 - accuracy: 1.0000 - val_loss: 2.9427 - val_accuracy: 0.6528\n",
            "Epoch 105/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 7.7536e-04 - accuracy: 1.0000 - val_loss: 2.9583 - val_accuracy: 0.6546\n",
            "Epoch 106/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 7.3872e-04 - accuracy: 1.0000 - val_loss: 2.9791 - val_accuracy: 0.6565\n",
            "Epoch 107/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 6.5559e-04 - accuracy: 1.0000 - val_loss: 3.0054 - val_accuracy: 0.6471\n",
            "Epoch 108/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 6.2102e-04 - accuracy: 1.0000 - val_loss: 3.0295 - val_accuracy: 0.6528\n",
            "Epoch 109/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 6.5490e-04 - accuracy: 1.0000 - val_loss: 3.0510 - val_accuracy: 0.6471\n",
            "Epoch 110/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 5.7429e-04 - accuracy: 1.0000 - val_loss: 3.0568 - val_accuracy: 0.6452\n",
            "Epoch 111/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 5.3791e-04 - accuracy: 1.0000 - val_loss: 3.0782 - val_accuracy: 0.6490\n",
            "Epoch 112/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 5.4748e-04 - accuracy: 1.0000 - val_loss: 3.1028 - val_accuracy: 0.6546\n",
            "Epoch 113/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 4.7116e-04 - accuracy: 1.0000 - val_loss: 3.1076 - val_accuracy: 0.6471\n",
            "Epoch 114/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 4.7577e-04 - accuracy: 1.0000 - val_loss: 3.1466 - val_accuracy: 0.6509\n",
            "Epoch 115/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 4.8567e-04 - accuracy: 1.0000 - val_loss: 3.1470 - val_accuracy: 0.6603\n",
            "Epoch 116/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 4.3937e-04 - accuracy: 1.0000 - val_loss: 3.1637 - val_accuracy: 0.6509\n",
            "Epoch 117/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 4.3575e-04 - accuracy: 1.0000 - val_loss: 3.1918 - val_accuracy: 0.6452\n",
            "Epoch 118/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 4.0246e-04 - accuracy: 1.0000 - val_loss: 3.2091 - val_accuracy: 0.6509\n",
            "Epoch 119/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 3.9018e-04 - accuracy: 1.0000 - val_loss: 3.2295 - val_accuracy: 0.6490\n",
            "Epoch 120/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 3.4206e-04 - accuracy: 1.0000 - val_loss: 3.2513 - val_accuracy: 0.6452\n",
            "Epoch 121/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 3.4528e-04 - accuracy: 1.0000 - val_loss: 3.2642 - val_accuracy: 0.6528\n",
            "Epoch 122/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 3.1518e-04 - accuracy: 1.0000 - val_loss: 3.2879 - val_accuracy: 0.6490\n",
            "Epoch 123/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 2.8741e-04 - accuracy: 1.0000 - val_loss: 3.3012 - val_accuracy: 0.6509\n",
            "Epoch 124/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 4.1660e-04 - accuracy: 1.0000 - val_loss: 3.3208 - val_accuracy: 0.6565\n",
            "Epoch 125/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 3.1048e-04 - accuracy: 1.0000 - val_loss: 3.3279 - val_accuracy: 0.6471\n",
            "Epoch 126/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 2.6968e-04 - accuracy: 1.0000 - val_loss: 3.3516 - val_accuracy: 0.6471\n",
            "Epoch 127/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 2.3905e-04 - accuracy: 1.0000 - val_loss: 3.3782 - val_accuracy: 0.6509\n",
            "Epoch 128/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 2.4796e-04 - accuracy: 1.0000 - val_loss: 3.3991 - val_accuracy: 0.6490\n",
            "Epoch 129/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 3.5937e-04 - accuracy: 1.0000 - val_loss: 3.4317 - val_accuracy: 0.6546\n",
            "Epoch 130/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 2.4063e-04 - accuracy: 1.0000 - val_loss: 3.4332 - val_accuracy: 0.6471\n",
            "Epoch 131/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 2.0720e-04 - accuracy: 1.0000 - val_loss: 3.4528 - val_accuracy: 0.6471\n",
            "Epoch 132/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 2.0380e-04 - accuracy: 1.0000 - val_loss: 3.4675 - val_accuracy: 0.6546\n",
            "Epoch 133/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.8725e-04 - accuracy: 1.0000 - val_loss: 3.4784 - val_accuracy: 0.6546\n",
            "Epoch 134/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.7111e-04 - accuracy: 1.0000 - val_loss: 3.5027 - val_accuracy: 0.6528\n",
            "Epoch 135/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.7304e-04 - accuracy: 1.0000 - val_loss: 3.5173 - val_accuracy: 0.6509\n",
            "Epoch 136/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.5896e-04 - accuracy: 1.0000 - val_loss: 3.5426 - val_accuracy: 0.6528\n",
            "Epoch 137/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.5564e-04 - accuracy: 1.0000 - val_loss: 3.5512 - val_accuracy: 0.6528\n",
            "Epoch 138/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.4532e-04 - accuracy: 1.0000 - val_loss: 3.5619 - val_accuracy: 0.6509\n",
            "Epoch 139/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.3898e-04 - accuracy: 1.0000 - val_loss: 3.5899 - val_accuracy: 0.6490\n",
            "Epoch 140/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.3635e-04 - accuracy: 1.0000 - val_loss: 3.6019 - val_accuracy: 0.6528\n",
            "Epoch 141/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.3482e-04 - accuracy: 1.0000 - val_loss: 3.6241 - val_accuracy: 0.6471\n",
            "Epoch 142/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.3858e-04 - accuracy: 1.0000 - val_loss: 3.6297 - val_accuracy: 0.6546\n",
            "Epoch 143/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.2559e-04 - accuracy: 1.0000 - val_loss: 3.6634 - val_accuracy: 0.6490\n",
            "Epoch 144/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.2889e-04 - accuracy: 1.0000 - val_loss: 3.6640 - val_accuracy: 0.6509\n",
            "Epoch 145/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0908e-04 - accuracy: 1.0000 - val_loss: 3.6913 - val_accuracy: 0.6546\n",
            "Epoch 146/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0943e-04 - accuracy: 1.0000 - val_loss: 3.6954 - val_accuracy: 0.6509\n",
            "Epoch 147/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 9.4156e-05 - accuracy: 1.0000 - val_loss: 3.7175 - val_accuracy: 0.6509\n",
            "Epoch 148/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 9.1329e-05 - accuracy: 1.0000 - val_loss: 3.7321 - val_accuracy: 0.6509\n",
            "Epoch 149/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 9.5609e-05 - accuracy: 1.0000 - val_loss: 3.7528 - val_accuracy: 0.6584\n",
            "Epoch 150/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 9.2618e-05 - accuracy: 1.0000 - val_loss: 3.7741 - val_accuracy: 0.6471\n",
            "Epoch 151/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 8.5220e-05 - accuracy: 1.0000 - val_loss: 3.7851 - val_accuracy: 0.6509\n",
            "Epoch 152/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 8.1776e-05 - accuracy: 1.0000 - val_loss: 3.8092 - val_accuracy: 0.6509\n",
            "Epoch 153/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 7.7365e-05 - accuracy: 1.0000 - val_loss: 3.8358 - val_accuracy: 0.6490\n",
            "Epoch 154/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 7.2070e-05 - accuracy: 1.0000 - val_loss: 3.8544 - val_accuracy: 0.6452\n",
            "Epoch 155/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 6.9585e-05 - accuracy: 1.0000 - val_loss: 3.8578 - val_accuracy: 0.6528\n",
            "Epoch 156/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 6.8190e-05 - accuracy: 1.0000 - val_loss: 3.8623 - val_accuracy: 0.6528\n",
            "Epoch 157/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 6.8540e-05 - accuracy: 1.0000 - val_loss: 3.8930 - val_accuracy: 0.6509\n",
            "Epoch 158/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 6.0132e-05 - accuracy: 1.0000 - val_loss: 3.8964 - val_accuracy: 0.6490\n",
            "Epoch 159/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 5.8678e-05 - accuracy: 1.0000 - val_loss: 3.9306 - val_accuracy: 0.6452\n",
            "Epoch 160/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 5.9478e-05 - accuracy: 1.0000 - val_loss: 3.9335 - val_accuracy: 0.6471\n",
            "Epoch 161/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 5.5700e-05 - accuracy: 1.0000 - val_loss: 3.9461 - val_accuracy: 0.6509\n",
            "Epoch 162/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 5.1541e-05 - accuracy: 1.0000 - val_loss: 3.9708 - val_accuracy: 0.6471\n",
            "Epoch 163/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 4.9235e-05 - accuracy: 1.0000 - val_loss: 3.9837 - val_accuracy: 0.6528\n",
            "Epoch 164/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 5.0849e-05 - accuracy: 1.0000 - val_loss: 3.9957 - val_accuracy: 0.6433\n",
            "Epoch 165/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 4.4768e-05 - accuracy: 1.0000 - val_loss: 4.0197 - val_accuracy: 0.6433\n",
            "Epoch 166/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 4.2965e-05 - accuracy: 1.0000 - val_loss: 4.0481 - val_accuracy: 0.6414\n",
            "Epoch 167/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 4.0556e-05 - accuracy: 1.0000 - val_loss: 4.0580 - val_accuracy: 0.6509\n",
            "Epoch 168/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 3.9438e-05 - accuracy: 1.0000 - val_loss: 4.0739 - val_accuracy: 0.6433\n",
            "Epoch 169/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 3.8262e-05 - accuracy: 1.0000 - val_loss: 4.0852 - val_accuracy: 0.6471\n",
            "Epoch 170/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 3.9224e-05 - accuracy: 1.0000 - val_loss: 4.1037 - val_accuracy: 0.6414\n",
            "Epoch 171/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 3.3309e-05 - accuracy: 1.0000 - val_loss: 4.1352 - val_accuracy: 0.6376\n",
            "Epoch 172/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 3.4123e-05 - accuracy: 1.0000 - val_loss: 4.1468 - val_accuracy: 0.6452\n",
            "Epoch 173/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 3.5143e-05 - accuracy: 1.0000 - val_loss: 4.1642 - val_accuracy: 0.6433\n",
            "Epoch 174/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 3.0747e-05 - accuracy: 1.0000 - val_loss: 4.1803 - val_accuracy: 0.6414\n",
            "Epoch 175/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 3.1099e-05 - accuracy: 1.0000 - val_loss: 4.1919 - val_accuracy: 0.6471\n",
            "Epoch 176/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 2.9186e-05 - accuracy: 1.0000 - val_loss: 4.2063 - val_accuracy: 0.6433\n",
            "Epoch 177/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 2.8983e-05 - accuracy: 1.0000 - val_loss: 4.2197 - val_accuracy: 0.6433\n",
            "Epoch 178/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 2.5795e-05 - accuracy: 1.0000 - val_loss: 4.2549 - val_accuracy: 0.6395\n",
            "Epoch 179/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 2.4529e-05 - accuracy: 1.0000 - val_loss: 4.2511 - val_accuracy: 0.6433\n",
            "Epoch 180/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 2.3204e-05 - accuracy: 1.0000 - val_loss: 4.2809 - val_accuracy: 0.6452\n",
            "Epoch 181/200\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 2.3516e-05 - accuracy: 1.0000 - val_loss: 4.3021 - val_accuracy: 0.6433\n",
            "Epoch 182/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 2.2746e-05 - accuracy: 1.0000 - val_loss: 4.3132 - val_accuracy: 0.6414\n",
            "Epoch 183/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 2.3402e-05 - accuracy: 1.0000 - val_loss: 4.3447 - val_accuracy: 0.6452\n",
            "Epoch 184/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 2.0171e-05 - accuracy: 1.0000 - val_loss: 4.3510 - val_accuracy: 0.6433\n",
            "Epoch 185/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.9508e-05 - accuracy: 1.0000 - val_loss: 4.3666 - val_accuracy: 0.6376\n",
            "Epoch 186/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.8807e-05 - accuracy: 1.0000 - val_loss: 4.3914 - val_accuracy: 0.6452\n",
            "Epoch 187/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.9213e-05 - accuracy: 1.0000 - val_loss: 4.3902 - val_accuracy: 0.6433\n",
            "Epoch 188/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.6158e-05 - accuracy: 1.0000 - val_loss: 4.4218 - val_accuracy: 0.6376\n",
            "Epoch 189/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.6308e-05 - accuracy: 1.0000 - val_loss: 4.4420 - val_accuracy: 0.6452\n",
            "Epoch 190/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.5456e-05 - accuracy: 1.0000 - val_loss: 4.4495 - val_accuracy: 0.6471\n",
            "Epoch 191/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.7945e-05 - accuracy: 1.0000 - val_loss: 4.4653 - val_accuracy: 0.6433\n",
            "Epoch 192/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.4434e-05 - accuracy: 1.0000 - val_loss: 4.4932 - val_accuracy: 0.6471\n",
            "Epoch 193/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.4117e-05 - accuracy: 1.0000 - val_loss: 4.5085 - val_accuracy: 0.6509\n",
            "Epoch 194/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.3524e-05 - accuracy: 1.0000 - val_loss: 4.5247 - val_accuracy: 0.6452\n",
            "Epoch 195/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.2987e-05 - accuracy: 1.0000 - val_loss: 4.5605 - val_accuracy: 0.6433\n",
            "Epoch 196/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.2032e-05 - accuracy: 1.0000 - val_loss: 4.5701 - val_accuracy: 0.6433\n",
            "Epoch 197/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.1412e-05 - accuracy: 1.0000 - val_loss: 4.5788 - val_accuracy: 0.6509\n",
            "Epoch 198/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0925e-05 - accuracy: 1.0000 - val_loss: 4.5894 - val_accuracy: 0.6490\n",
            "Epoch 199/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.0350e-05 - accuracy: 1.0000 - val_loss: 4.6005 - val_accuracy: 0.6490\n",
            "Epoch 200/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 1.1195e-05 - accuracy: 1.0000 - val_loss: 4.6414 - val_accuracy: 0.6471\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ktsOoIOXbNDO"
      },
      "source": [
        "model.save('/content/drive/MyDrive/Colab Notebooks/speech/dataset/basic_combined_merged.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FwsQwDu7bNDQ"
      },
      "source": [
        "###test_result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vej6UJ74bNDQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3c7114f-358a-40ef-a9cb-d58491a92f98"
      },
      "source": [
        "d = {0: 'happy',\n",
        "     1: 'sad',\n",
        "     2: 'angry',\n",
        "     3: 'fear'}\n",
        "Y_test_pred = np.argmax(model.predict(X_test), axis=-1)\n",
        "Y_test_pred = list(map(lambda x: d[x], Y_test_pred))\n",
        "y_test = np.argmax(y_test, axis=-1)\n",
        "y_test = list(map(lambda x: d[x], y_test))\n",
        "print(classification_report(y_test, Y_test_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.70      0.64      0.67       155\n",
            "        fear       0.53      0.46      0.49       144\n",
            "       happy       0.54      0.59      0.56       151\n",
            "         sad       0.64      0.72      0.68       136\n",
            "\n",
            "    accuracy                           0.60       586\n",
            "   macro avg       0.60      0.60      0.60       586\n",
            "weighted avg       0.60      0.60      0.60       586\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1DdBxgcIbNDR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 483
        },
        "outputId": "9f6ee4a1-3564-4e71-e208-f1ec3edee734"
      },
      "source": [
        "skplt.metrics.plot_confusion_matrix(\n",
        "    y_test, \n",
        "    Y_test_pred,\n",
        "    figsize=(8,8))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fdaaa6a3dd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ExtfqtTnbNDS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}