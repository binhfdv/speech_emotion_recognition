{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ravdess_4emo.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "zC9OZpzBP4JY",
        "2D5jL4vXsxFE",
        "vyVivXklxo6-",
        "2tpfXhgWh0Dz",
        "ccuTw71436-g",
        "0zRQZ1nG8Lxk",
        "bP7WeLYGFjiN",
        "8JPwepBQ2ndF",
        "4C8Zhxb9HjOz",
        "UbMzp6IWHwqK",
        "_7YOAt2TIKPI",
        "jNEbmeonPxXR",
        "vQHiqzXuW3ay",
        "LzVUl83kaRQt",
        "52xgoS68UfhO",
        "dOcjtFWYUfhc",
        "Q8JULeSZXNcL",
        "RKGOhIllYlwH",
        "-IJkqk5GYqZv",
        "7ncl1wszZ1Ds",
        "qLKgMiv0bNC8"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D4DZKDv9sTgr",
        "outputId": "645a2f92-40b2-48cb-e4fb-3c87e92bcaaa"
      },
      "source": [
        "pip install scikit-plot"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting scikit-plot\n",
            "  Downloading https://files.pythonhosted.org/packages/7c/47/32520e259340c140a4ad27c1b97050dd3254fdc517b1d59974d47037510e/scikit_plot-0.3.7-py3-none-any.whl\n",
            "Requirement already satisfied: scipy>=0.9 in /usr/local/lib/python3.7/dist-packages (from scikit-plot) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.7/dist-packages (from scikit-plot) (0.22.2.post1)\n",
            "Requirement already satisfied: joblib>=0.10 in /usr/local/lib/python3.7/dist-packages (from scikit-plot) (1.0.1)\n",
            "Requirement already satisfied: matplotlib>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from scikit-plot) (3.2.2)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scipy>=0.9->scikit-plot) (1.19.5)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.4.0->scikit-plot) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.4.0->scikit-plot) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.4.0->scikit-plot) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.4.0->scikit-plot) (2.8.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib>=1.4.0->scikit-plot) (1.15.0)\n",
            "Installing collected packages: scikit-plot\n",
            "Successfully installed scikit-plot-0.3.7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QToA8uhqnD17"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import librosa\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from keras.utils.np_utils import to_categorical\n",
        "import keras \n",
        "from keras.models import Sequential\n",
        "from keras import optimizers\n",
        "from keras.layers import Conv2D, Conv1D, Dense, Dropout, Flatten, AveragePooling2D, BatchNormalization, MaxPool2D, MaxPooling1D, Activation, MaxPooling2D, LSTM\n",
        "from keras.optimizers import Adam\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "\n",
        "import scipy\n",
        "from sklearn.model_selection import train_test_split\n",
        "import scikitplot as skplt\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unG9GUtlnI45"
      },
      "source": [
        "DATA_PATH = \"/content/drive/MyDrive/Colab Notebooks/SPEECH_EMOTION_Recognition/datasets/archive/\"\n",
        "\n",
        "Modality = []\n",
        "Vocal_channel = []\n",
        "Emotion  = []\n",
        "Emotional_intensity = []\n",
        "Statement = []\n",
        "Repetition = []\n",
        "Actor = []\n",
        "Paths = []\n",
        "\n",
        "for i, (dirpath, dirnames, filenames) in enumerate(os.walk(DATA_PATH)):\n",
        "  if dirpath is not DATA_PATH:\n",
        "    for f in filenames:\n",
        "      if '(1)' not in f: #eliminate coincidences\n",
        "        file_path = os.path.join(dirpath, f)\n",
        "        Paths.append(file_path)\n",
        "        Modality.append(f.split('.')[0].split('-')[0])\n",
        "        Vocal_channel.append(f.split('.')[0].split('-')[1])\n",
        "        Emotion.append(f.split('.')[0].split('-')[2])\n",
        "        Emotional_intensity.append(f.split('.')[0].split('-')[3])\n",
        "        Statement.append(f.split('.')[0].split('-')[4])\n",
        "        Repetition.append(f.split('.')[0].split('-')[5])\n",
        "        Actor.append(int(f.split('.')[0].split('-')[6]))\n",
        "\n",
        "Ravdess_DF = pd.DataFrame()\n",
        "Ravdess_DF['Paths'] = Paths\n",
        "Ravdess_DF['Modality'] = Modality\n",
        "Ravdess_DF['Vocal_channel'] = Vocal_channel\n",
        "Ravdess_DF['Emotion'] = Emotion\n",
        "Ravdess_DF['Emotional_intensity'] = Emotional_intensity\n",
        "Ravdess_DF['Statement'] = Statement\n",
        "Ravdess_DF['Repetition'] = Repetition\n",
        "Ravdess_DF['Actor'] = Actor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zC9OZpzBP4JY"
      },
      "source": [
        "# mfcc_13 + basic model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9exJA3uAP2tM"
      },
      "source": [
        "features = []\n",
        "labels = []\n",
        "for i in range(len(Ravdess_DF['Paths'])):\n",
        "  if ((Ravdess_DF['Emotion'][i] == '03') | (Ravdess_DF['Emotion'][i] == '04') | \n",
        "      (Ravdess_DF['Emotion'][i] == '05') | (Ravdess_DF['Emotion'][i] == '06')):\n",
        "    signal, sr = librosa.load(Ravdess_DF['Paths'][i])\n",
        "    mfcc = np.mean(librosa.feature.mfcc(y=signal, sr=sr, n_mfcc=13).T,axis=0).tolist()\n",
        "    features.append(mfcc)\n",
        "    if Ravdess_DF['Emotion'][i] == '03':\n",
        "      labels.append(0)\n",
        "    elif Ravdess_DF['Emotion'][i] == '04':\n",
        "      labels.append(1)\n",
        "    elif Ravdess_DF['Emotion'][i] == '05':\n",
        "      labels.append(2)\n",
        "    elif Ravdess_DF['Emotion'][i] == '06':\n",
        "      labels.append(3)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qhD6rKgHQpQj"
      },
      "source": [
        "X = features\n",
        "y = labels\n",
        "\n",
        "y = np.array(y)\n",
        "y = to_categorical(y)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=0)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=0)\n",
        "\n",
        "X_train = np.array(X_train)\n",
        "X_test = np.array(X_test)\n",
        "X_val = np.array(X_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDxtjQVG2X8w"
      },
      "source": [
        "## basic models:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B5p5Od0R2X80",
        "outputId": "460e067d-3312-45d2-c8f9-0e4c42c9467a"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(13, input_shape=(13, ), activation = 'relu'))\n",
        "#model.add(Dropout(0.1))\n",
        "model.add(Dense(128, activation = 'relu'))\n",
        "#model.add(Dropout(0.25))\n",
        "model.add(Dense(128, activation = 'relu'))\n",
        "#model.add(Dropout(0.2))\n",
        "model.add(Dense(4, activation = 'softmax'))\n",
        "\n",
        "optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
        "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer=optimizer)\n",
        "early_stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=100, verbose=1, mode='auto')\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_8 (Dense)              (None, 13)                182       \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 128)               1792      \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 4)                 516       \n",
            "=================================================================\n",
            "Total params: 19,002\n",
            "Trainable params: 19,002\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IUxdvY4H2X81",
        "outputId": "a2da07fb-a36c-4980-baa4-c177fba626a8"
      },
      "source": [
        "history = model.fit(X_train, y_train, batch_size=64, epochs=200, \n",
        "                    validation_data=(X_val, y_val))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "10/10 [==============================] - 1s 37ms/step - loss: 29.4399 - accuracy: 0.2400 - val_loss: 9.8778 - val_accuracy: 0.2857\n",
            "Epoch 2/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 8.0001 - accuracy: 0.2403 - val_loss: 5.2537 - val_accuracy: 0.2286\n",
            "Epoch 3/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 4.2250 - accuracy: 0.2930 - val_loss: 2.5745 - val_accuracy: 0.2857\n",
            "Epoch 4/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 2.2918 - accuracy: 0.2889 - val_loss: 1.5745 - val_accuracy: 0.1714\n",
            "Epoch 5/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.7860 - accuracy: 0.2212 - val_loss: 1.5346 - val_accuracy: 0.1857\n",
            "Epoch 6/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.6829 - accuracy: 0.2727 - val_loss: 1.4873 - val_accuracy: 0.2714\n",
            "Epoch 7/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.5826 - accuracy: 0.3012 - val_loss: 1.5418 - val_accuracy: 0.2857\n",
            "Epoch 8/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.5310 - accuracy: 0.2796 - val_loss: 1.4005 - val_accuracy: 0.2571\n",
            "Epoch 9/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4070 - accuracy: 0.3052 - val_loss: 1.5024 - val_accuracy: 0.2286\n",
            "Epoch 10/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4134 - accuracy: 0.3284 - val_loss: 1.6452 - val_accuracy: 0.2000\n",
            "Epoch 11/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.5530 - accuracy: 0.2745 - val_loss: 1.6329 - val_accuracy: 0.2857\n",
            "Epoch 12/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.6990 - accuracy: 0.2655 - val_loss: 1.7545 - val_accuracy: 0.2286\n",
            "Epoch 13/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.5581 - accuracy: 0.2907 - val_loss: 1.5910 - val_accuracy: 0.2571\n",
            "Epoch 14/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4969 - accuracy: 0.3450 - val_loss: 1.4978 - val_accuracy: 0.2429\n",
            "Epoch 15/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4345 - accuracy: 0.3451 - val_loss: 1.4672 - val_accuracy: 0.2857\n",
            "Epoch 16/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3549 - accuracy: 0.3288 - val_loss: 1.7237 - val_accuracy: 0.2143\n",
            "Epoch 17/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.4552 - accuracy: 0.3451 - val_loss: 1.6130 - val_accuracy: 0.2857\n",
            "Epoch 18/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.4402 - accuracy: 0.3300 - val_loss: 1.4770 - val_accuracy: 0.2143\n",
            "Epoch 19/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.3618 - accuracy: 0.3365 - val_loss: 1.4779 - val_accuracy: 0.2857\n",
            "Epoch 20/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4380 - accuracy: 0.3040 - val_loss: 1.7085 - val_accuracy: 0.3429\n",
            "Epoch 21/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.4345 - accuracy: 0.3671 - val_loss: 1.3802 - val_accuracy: 0.3571\n",
            "Epoch 22/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3498 - accuracy: 0.3949 - val_loss: 1.3819 - val_accuracy: 0.3000\n",
            "Epoch 23/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.3201 - accuracy: 0.3812 - val_loss: 1.3797 - val_accuracy: 0.3429\n",
            "Epoch 24/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4254 - accuracy: 0.3467 - val_loss: 1.7764 - val_accuracy: 0.2286\n",
            "Epoch 25/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4445 - accuracy: 0.3284 - val_loss: 1.4378 - val_accuracy: 0.3714\n",
            "Epoch 26/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.4688 - accuracy: 0.3586 - val_loss: 1.9531 - val_accuracy: 0.2286\n",
            "Epoch 27/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.6409 - accuracy: 0.3112 - val_loss: 1.7683 - val_accuracy: 0.2571\n",
            "Epoch 28/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.5776 - accuracy: 0.3082 - val_loss: 1.8135 - val_accuracy: 0.3429\n",
            "Epoch 29/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.6154 - accuracy: 0.3416 - val_loss: 1.7370 - val_accuracy: 0.2857\n",
            "Epoch 30/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.5469 - accuracy: 0.3819 - val_loss: 1.4183 - val_accuracy: 0.3857\n",
            "Epoch 31/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.3996 - accuracy: 0.4167 - val_loss: 1.6471 - val_accuracy: 0.3857\n",
            "Epoch 32/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4445 - accuracy: 0.3934 - val_loss: 1.7103 - val_accuracy: 0.2857\n",
            "Epoch 33/200\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.5348 - accuracy: 0.3252 - val_loss: 1.4678 - val_accuracy: 0.2857\n",
            "Epoch 34/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3685 - accuracy: 0.3893 - val_loss: 1.5681 - val_accuracy: 0.3571\n",
            "Epoch 35/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.4924 - accuracy: 0.3458 - val_loss: 1.3664 - val_accuracy: 0.3571\n",
            "Epoch 36/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2868 - accuracy: 0.4126 - val_loss: 1.4815 - val_accuracy: 0.3143\n",
            "Epoch 37/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4539 - accuracy: 0.3517 - val_loss: 1.4631 - val_accuracy: 0.3571\n",
            "Epoch 38/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3490 - accuracy: 0.3863 - val_loss: 1.3224 - val_accuracy: 0.3714\n",
            "Epoch 39/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3117 - accuracy: 0.3706 - val_loss: 1.2991 - val_accuracy: 0.4000\n",
            "Epoch 40/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2784 - accuracy: 0.3808 - val_loss: 1.3016 - val_accuracy: 0.4000\n",
            "Epoch 41/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.3310 - accuracy: 0.3999 - val_loss: 1.8010 - val_accuracy: 0.3286\n",
            "Epoch 42/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4648 - accuracy: 0.3542 - val_loss: 1.4112 - val_accuracy: 0.3714\n",
            "Epoch 43/200\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.3401 - accuracy: 0.4048 - val_loss: 1.5638 - val_accuracy: 0.3143\n",
            "Epoch 44/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.5429 - accuracy: 0.3240 - val_loss: 1.7061 - val_accuracy: 0.3143\n",
            "Epoch 45/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.5246 - accuracy: 0.3528 - val_loss: 1.6006 - val_accuracy: 0.2857\n",
            "Epoch 46/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4079 - accuracy: 0.3843 - val_loss: 1.2736 - val_accuracy: 0.3714\n",
            "Epoch 47/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3341 - accuracy: 0.4228 - val_loss: 1.4087 - val_accuracy: 0.3714\n",
            "Epoch 48/200\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.4056 - accuracy: 0.4580 - val_loss: 2.0028 - val_accuracy: 0.4286\n",
            "Epoch 49/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.7082 - accuracy: 0.3585 - val_loss: 1.5476 - val_accuracy: 0.4143\n",
            "Epoch 50/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.4083 - accuracy: 0.4278 - val_loss: 1.5611 - val_accuracy: 0.3000\n",
            "Epoch 51/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.3634 - accuracy: 0.3655 - val_loss: 1.4400 - val_accuracy: 0.4143\n",
            "Epoch 52/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.3435 - accuracy: 0.3838 - val_loss: 1.2625 - val_accuracy: 0.4286\n",
            "Epoch 53/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.2161 - accuracy: 0.4291 - val_loss: 1.2937 - val_accuracy: 0.3714\n",
            "Epoch 54/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.2736 - accuracy: 0.4481 - val_loss: 1.2286 - val_accuracy: 0.4571\n",
            "Epoch 55/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2184 - accuracy: 0.4632 - val_loss: 1.3113 - val_accuracy: 0.3571\n",
            "Epoch 56/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2295 - accuracy: 0.4342 - val_loss: 1.3441 - val_accuracy: 0.4286\n",
            "Epoch 57/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.3102 - accuracy: 0.4285 - val_loss: 1.3149 - val_accuracy: 0.4714\n",
            "Epoch 58/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.2985 - accuracy: 0.4103 - val_loss: 1.5268 - val_accuracy: 0.3000\n",
            "Epoch 59/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.3789 - accuracy: 0.3890 - val_loss: 1.3489 - val_accuracy: 0.3857\n",
            "Epoch 60/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.2626 - accuracy: 0.4377 - val_loss: 1.3449 - val_accuracy: 0.4000\n",
            "Epoch 61/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.2990 - accuracy: 0.4097 - val_loss: 1.2794 - val_accuracy: 0.4000\n",
            "Epoch 62/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.2171 - accuracy: 0.4459 - val_loss: 1.2427 - val_accuracy: 0.4143\n",
            "Epoch 63/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.2241 - accuracy: 0.4587 - val_loss: 1.2643 - val_accuracy: 0.4571\n",
            "Epoch 64/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.2592 - accuracy: 0.4242 - val_loss: 1.3748 - val_accuracy: 0.3714\n",
            "Epoch 65/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3350 - accuracy: 0.3893 - val_loss: 1.3831 - val_accuracy: 0.3714\n",
            "Epoch 66/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3175 - accuracy: 0.3921 - val_loss: 1.2261 - val_accuracy: 0.4143\n",
            "Epoch 67/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.2705 - accuracy: 0.4269 - val_loss: 1.5751 - val_accuracy: 0.3143\n",
            "Epoch 68/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.4329 - accuracy: 0.4017 - val_loss: 1.7501 - val_accuracy: 0.3857\n",
            "Epoch 69/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.4784 - accuracy: 0.4035 - val_loss: 1.2581 - val_accuracy: 0.4143\n",
            "Epoch 70/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.2635 - accuracy: 0.4346 - val_loss: 1.3625 - val_accuracy: 0.3714\n",
            "Epoch 71/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.2807 - accuracy: 0.4011 - val_loss: 1.1938 - val_accuracy: 0.4286\n",
            "Epoch 72/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2484 - accuracy: 0.4445 - val_loss: 1.6844 - val_accuracy: 0.2857\n",
            "Epoch 73/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.4070 - accuracy: 0.4232 - val_loss: 1.1751 - val_accuracy: 0.4571\n",
            "Epoch 74/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.2131 - accuracy: 0.4859 - val_loss: 1.2614 - val_accuracy: 0.3714\n",
            "Epoch 75/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.1788 - accuracy: 0.4778 - val_loss: 1.2367 - val_accuracy: 0.4143\n",
            "Epoch 76/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.1915 - accuracy: 0.4810 - val_loss: 1.3600 - val_accuracy: 0.3714\n",
            "Epoch 77/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.2981 - accuracy: 0.4248 - val_loss: 1.2599 - val_accuracy: 0.4714\n",
            "Epoch 78/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.2122 - accuracy: 0.4476 - val_loss: 1.2750 - val_accuracy: 0.4286\n",
            "Epoch 79/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1788 - accuracy: 0.4865 - val_loss: 1.2100 - val_accuracy: 0.4714\n",
            "Epoch 80/200\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.1918 - accuracy: 0.4685 - val_loss: 1.1705 - val_accuracy: 0.5000\n",
            "Epoch 81/200\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.1745 - accuracy: 0.4415 - val_loss: 1.3385 - val_accuracy: 0.4143\n",
            "Epoch 82/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.1521 - accuracy: 0.4703 - val_loss: 1.2109 - val_accuracy: 0.4429\n",
            "Epoch 83/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.1252 - accuracy: 0.4839 - val_loss: 1.3681 - val_accuracy: 0.4143\n",
            "Epoch 84/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.3514 - accuracy: 0.4103 - val_loss: 1.3094 - val_accuracy: 0.4286\n",
            "Epoch 85/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.2672 - accuracy: 0.4419 - val_loss: 1.2210 - val_accuracy: 0.4714\n",
            "Epoch 86/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.1807 - accuracy: 0.4810 - val_loss: 1.1811 - val_accuracy: 0.4429\n",
            "Epoch 87/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.1872 - accuracy: 0.4664 - val_loss: 1.1384 - val_accuracy: 0.5143\n",
            "Epoch 88/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1941 - accuracy: 0.4416 - val_loss: 1.4594 - val_accuracy: 0.3857\n",
            "Epoch 89/200\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.2321 - accuracy: 0.4676 - val_loss: 1.1255 - val_accuracy: 0.4714\n",
            "Epoch 90/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.2069 - accuracy: 0.4635 - val_loss: 1.4731 - val_accuracy: 0.3000\n",
            "Epoch 91/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.3680 - accuracy: 0.3900 - val_loss: 1.1633 - val_accuracy: 0.4714\n",
            "Epoch 92/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1753 - accuracy: 0.4538 - val_loss: 1.1626 - val_accuracy: 0.4857\n",
            "Epoch 93/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.1867 - accuracy: 0.4758 - val_loss: 1.1799 - val_accuracy: 0.4571\n",
            "Epoch 94/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1257 - accuracy: 0.4740 - val_loss: 1.1700 - val_accuracy: 0.5429\n",
            "Epoch 95/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.1875 - accuracy: 0.4826 - val_loss: 1.2904 - val_accuracy: 0.4429\n",
            "Epoch 96/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1707 - accuracy: 0.4681 - val_loss: 1.3230 - val_accuracy: 0.4143\n",
            "Epoch 97/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.1582 - accuracy: 0.4793 - val_loss: 1.1252 - val_accuracy: 0.4571\n",
            "Epoch 98/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.1648 - accuracy: 0.5062 - val_loss: 1.1780 - val_accuracy: 0.5143\n",
            "Epoch 99/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.1652 - accuracy: 0.5200 - val_loss: 1.2285 - val_accuracy: 0.3857\n",
            "Epoch 100/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.1631 - accuracy: 0.4404 - val_loss: 1.3026 - val_accuracy: 0.4571\n",
            "Epoch 101/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.1942 - accuracy: 0.4751 - val_loss: 1.2342 - val_accuracy: 0.5000\n",
            "Epoch 102/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.1408 - accuracy: 0.4959 - val_loss: 1.1631 - val_accuracy: 0.5286\n",
            "Epoch 103/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.2513 - accuracy: 0.4848 - val_loss: 1.2727 - val_accuracy: 0.3714\n",
            "Epoch 104/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.0970 - accuracy: 0.5141 - val_loss: 1.2278 - val_accuracy: 0.4000\n",
            "Epoch 105/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0879 - accuracy: 0.5236 - val_loss: 1.1176 - val_accuracy: 0.5714\n",
            "Epoch 106/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0784 - accuracy: 0.5301 - val_loss: 1.1404 - val_accuracy: 0.4857\n",
            "Epoch 107/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1647 - accuracy: 0.4843 - val_loss: 1.1244 - val_accuracy: 0.5143\n",
            "Epoch 108/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.1271 - accuracy: 0.5135 - val_loss: 1.2314 - val_accuracy: 0.4286\n",
            "Epoch 109/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.1747 - accuracy: 0.4930 - val_loss: 1.1282 - val_accuracy: 0.5286\n",
            "Epoch 110/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.2503 - accuracy: 0.4387 - val_loss: 1.6841 - val_accuracy: 0.3143\n",
            "Epoch 111/200\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.2589 - accuracy: 0.4369 - val_loss: 1.0867 - val_accuracy: 0.4714\n",
            "Epoch 112/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.0990 - accuracy: 0.5259 - val_loss: 1.2363 - val_accuracy: 0.4714\n",
            "Epoch 113/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2164 - accuracy: 0.4699 - val_loss: 1.2919 - val_accuracy: 0.4143\n",
            "Epoch 114/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.1507 - accuracy: 0.4995 - val_loss: 1.1662 - val_accuracy: 0.4857\n",
            "Epoch 115/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0851 - accuracy: 0.5358 - val_loss: 1.1527 - val_accuracy: 0.4143\n",
            "Epoch 116/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0874 - accuracy: 0.5365 - val_loss: 1.1987 - val_accuracy: 0.4857\n",
            "Epoch 117/200\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.1830 - accuracy: 0.4683 - val_loss: 1.2429 - val_accuracy: 0.4571\n",
            "Epoch 118/200\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.1902 - accuracy: 0.4937 - val_loss: 1.1109 - val_accuracy: 0.4857\n",
            "Epoch 119/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.0705 - accuracy: 0.5397 - val_loss: 1.1010 - val_accuracy: 0.5000\n",
            "Epoch 120/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.1067 - accuracy: 0.5149 - val_loss: 1.2082 - val_accuracy: 0.4571\n",
            "Epoch 121/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.0977 - accuracy: 0.5349 - val_loss: 1.1770 - val_accuracy: 0.5000\n",
            "Epoch 122/200\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.1593 - accuracy: 0.5081 - val_loss: 1.1477 - val_accuracy: 0.5143\n",
            "Epoch 123/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.1078 - accuracy: 0.4845 - val_loss: 1.1691 - val_accuracy: 0.4571\n",
            "Epoch 124/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.0832 - accuracy: 0.5154 - val_loss: 1.2146 - val_accuracy: 0.5143\n",
            "Epoch 125/200\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.1422 - accuracy: 0.5049 - val_loss: 1.1672 - val_accuracy: 0.5000\n",
            "Epoch 126/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0643 - accuracy: 0.5432 - val_loss: 1.1774 - val_accuracy: 0.5143\n",
            "Epoch 127/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2015 - accuracy: 0.4683 - val_loss: 1.3293 - val_accuracy: 0.4143\n",
            "Epoch 128/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2338 - accuracy: 0.4549 - val_loss: 1.1558 - val_accuracy: 0.4571\n",
            "Epoch 129/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.1096 - accuracy: 0.5126 - val_loss: 1.4488 - val_accuracy: 0.5000\n",
            "Epoch 130/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.3700 - accuracy: 0.4554 - val_loss: 1.5503 - val_accuracy: 0.3714\n",
            "Epoch 131/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2215 - accuracy: 0.4840 - val_loss: 1.3878 - val_accuracy: 0.4857\n",
            "Epoch 132/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1894 - accuracy: 0.4690 - val_loss: 1.3126 - val_accuracy: 0.4429\n",
            "Epoch 133/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1373 - accuracy: 0.4954 - val_loss: 1.4998 - val_accuracy: 0.4571\n",
            "Epoch 134/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2981 - accuracy: 0.4959 - val_loss: 1.1459 - val_accuracy: 0.5143\n",
            "Epoch 135/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.0810 - accuracy: 0.5330 - val_loss: 1.3088 - val_accuracy: 0.4143\n",
            "Epoch 136/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.0648 - accuracy: 0.5426 - val_loss: 1.1502 - val_accuracy: 0.5000\n",
            "Epoch 137/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.0235 - accuracy: 0.5470 - val_loss: 1.0908 - val_accuracy: 0.5286\n",
            "Epoch 138/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.0632 - accuracy: 0.5568 - val_loss: 1.2649 - val_accuracy: 0.4857\n",
            "Epoch 139/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1489 - accuracy: 0.5073 - val_loss: 1.2130 - val_accuracy: 0.5143\n",
            "Epoch 140/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1085 - accuracy: 0.5261 - val_loss: 1.2259 - val_accuracy: 0.5143\n",
            "Epoch 141/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2113 - accuracy: 0.5147 - val_loss: 1.2831 - val_accuracy: 0.5143\n",
            "Epoch 142/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.2422 - accuracy: 0.4823 - val_loss: 1.1337 - val_accuracy: 0.5286\n",
            "Epoch 143/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0857 - accuracy: 0.5367 - val_loss: 1.1007 - val_accuracy: 0.5571\n",
            "Epoch 144/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0858 - accuracy: 0.5223 - val_loss: 1.2382 - val_accuracy: 0.4286\n",
            "Epoch 145/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.0893 - accuracy: 0.5306 - val_loss: 1.0782 - val_accuracy: 0.5571\n",
            "Epoch 146/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.0825 - accuracy: 0.5145 - val_loss: 1.2293 - val_accuracy: 0.4571\n",
            "Epoch 147/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0626 - accuracy: 0.5537 - val_loss: 1.0708 - val_accuracy: 0.5429\n",
            "Epoch 148/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.9994 - accuracy: 0.5636 - val_loss: 1.1912 - val_accuracy: 0.5000\n",
            "Epoch 149/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.0642 - accuracy: 0.5310 - val_loss: 1.1247 - val_accuracy: 0.4429\n",
            "Epoch 150/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1451 - accuracy: 0.5176 - val_loss: 1.5714 - val_accuracy: 0.4000\n",
            "Epoch 151/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2552 - accuracy: 0.4935 - val_loss: 1.2491 - val_accuracy: 0.5000\n",
            "Epoch 152/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.1314 - accuracy: 0.4798 - val_loss: 1.0536 - val_accuracy: 0.5143\n",
            "Epoch 153/200\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.0536 - accuracy: 0.5463 - val_loss: 1.1495 - val_accuracy: 0.5000\n",
            "Epoch 154/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.0714 - accuracy: 0.5150 - val_loss: 1.2293 - val_accuracy: 0.4571\n",
            "Epoch 155/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.0984 - accuracy: 0.4941 - val_loss: 1.0942 - val_accuracy: 0.5000\n",
            "Epoch 156/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.0393 - accuracy: 0.5509 - val_loss: 1.0798 - val_accuracy: 0.5143\n",
            "Epoch 157/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.0085 - accuracy: 0.5762 - val_loss: 1.0938 - val_accuracy: 0.5000\n",
            "Epoch 158/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0762 - accuracy: 0.5270 - val_loss: 1.1204 - val_accuracy: 0.5286\n",
            "Epoch 159/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.0567 - accuracy: 0.5486 - val_loss: 1.1176 - val_accuracy: 0.4571\n",
            "Epoch 160/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.0884 - accuracy: 0.5300 - val_loss: 1.0975 - val_accuracy: 0.5143\n",
            "Epoch 161/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1501 - accuracy: 0.5130 - val_loss: 1.1635 - val_accuracy: 0.5286\n",
            "Epoch 162/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1671 - accuracy: 0.5211 - val_loss: 1.1800 - val_accuracy: 0.4429\n",
            "Epoch 163/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0420 - accuracy: 0.5549 - val_loss: 1.0657 - val_accuracy: 0.5857\n",
            "Epoch 164/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.9985 - accuracy: 0.5646 - val_loss: 1.0625 - val_accuracy: 0.5143\n",
            "Epoch 165/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0177 - accuracy: 0.5663 - val_loss: 1.1161 - val_accuracy: 0.5286\n",
            "Epoch 166/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.0502 - accuracy: 0.5512 - val_loss: 1.1407 - val_accuracy: 0.5000\n",
            "Epoch 167/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0443 - accuracy: 0.5406 - val_loss: 1.0539 - val_accuracy: 0.5286\n",
            "Epoch 168/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.9969 - accuracy: 0.5800 - val_loss: 1.0504 - val_accuracy: 0.5286\n",
            "Epoch 169/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0024 - accuracy: 0.5778 - val_loss: 1.1647 - val_accuracy: 0.4429\n",
            "Epoch 170/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9829 - accuracy: 0.5607 - val_loss: 1.1976 - val_accuracy: 0.5143\n",
            "Epoch 171/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.0659 - accuracy: 0.5396 - val_loss: 1.2463 - val_accuracy: 0.5000\n",
            "Epoch 172/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.1058 - accuracy: 0.5041 - val_loss: 1.2595 - val_accuracy: 0.4571\n",
            "Epoch 173/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0464 - accuracy: 0.5602 - val_loss: 1.2912 - val_accuracy: 0.4000\n",
            "Epoch 174/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.1341 - accuracy: 0.4888 - val_loss: 1.2127 - val_accuracy: 0.4857\n",
            "Epoch 175/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.0675 - accuracy: 0.5469 - val_loss: 1.0995 - val_accuracy: 0.4571\n",
            "Epoch 176/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.0650 - accuracy: 0.5711 - val_loss: 1.4138 - val_accuracy: 0.4571\n",
            "Epoch 177/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1275 - accuracy: 0.5128 - val_loss: 1.2434 - val_accuracy: 0.4857\n",
            "Epoch 178/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.1622 - accuracy: 0.5223 - val_loss: 1.1970 - val_accuracy: 0.5429\n",
            "Epoch 179/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.1078 - accuracy: 0.5372 - val_loss: 1.0872 - val_accuracy: 0.4857\n",
            "Epoch 180/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.0156 - accuracy: 0.5733 - val_loss: 1.1360 - val_accuracy: 0.5429\n",
            "Epoch 181/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0894 - accuracy: 0.5435 - val_loss: 1.2717 - val_accuracy: 0.4429\n",
            "Epoch 182/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.1659 - accuracy: 0.4835 - val_loss: 1.1245 - val_accuracy: 0.5571\n",
            "Epoch 183/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.0883 - accuracy: 0.5256 - val_loss: 1.1203 - val_accuracy: 0.4857\n",
            "Epoch 184/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.0374 - accuracy: 0.5311 - val_loss: 1.0956 - val_accuracy: 0.5000\n",
            "Epoch 185/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9722 - accuracy: 0.5868 - val_loss: 1.0556 - val_accuracy: 0.5000\n",
            "Epoch 186/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0463 - accuracy: 0.5393 - val_loss: 1.1072 - val_accuracy: 0.5429\n",
            "Epoch 187/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.0243 - accuracy: 0.5407 - val_loss: 1.2977 - val_accuracy: 0.4286\n",
            "Epoch 188/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.1198 - accuracy: 0.5077 - val_loss: 1.0904 - val_accuracy: 0.4857\n",
            "Epoch 189/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0129 - accuracy: 0.5685 - val_loss: 1.1121 - val_accuracy: 0.5429\n",
            "Epoch 190/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0237 - accuracy: 0.5520 - val_loss: 1.1571 - val_accuracy: 0.4571\n",
            "Epoch 191/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0650 - accuracy: 0.5684 - val_loss: 1.1131 - val_accuracy: 0.5571\n",
            "Epoch 192/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0179 - accuracy: 0.5277 - val_loss: 1.0666 - val_accuracy: 0.5286\n",
            "Epoch 193/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.0415 - accuracy: 0.5804 - val_loss: 1.1490 - val_accuracy: 0.5000\n",
            "Epoch 194/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.0529 - accuracy: 0.5490 - val_loss: 1.2450 - val_accuracy: 0.5000\n",
            "Epoch 195/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.1270 - accuracy: 0.5079 - val_loss: 1.0890 - val_accuracy: 0.4714\n",
            "Epoch 196/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.0562 - accuracy: 0.5708 - val_loss: 1.2860 - val_accuracy: 0.4286\n",
            "Epoch 197/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.1838 - accuracy: 0.5087 - val_loss: 1.2610 - val_accuracy: 0.4429\n",
            "Epoch 198/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0486 - accuracy: 0.5596 - val_loss: 1.1317 - val_accuracy: 0.4714\n",
            "Epoch 199/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9747 - accuracy: 0.5616 - val_loss: 1.0242 - val_accuracy: 0.5143\n",
            "Epoch 200/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0858 - accuracy: 0.5640 - val_loss: 1.0550 - val_accuracy: 0.5429\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vLiX73Yat1BZ"
      },
      "source": [
        "model.save('/content/drive/MyDrive/Colab Notebooks/SPEECH_EMOTION_Recognition/Nộp bài(chốt hạ)/model_saver/basic_mfcc13_ravdess.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zy5l6YUakCQp"
      },
      "source": [
        "###test_result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VyJOB76K5VzA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abbaa8bf-516b-44f2-9874-2b858cb30d80"
      },
      "source": [
        "d = {0: 'happy',\n",
        "     1: 'sad',\n",
        "     2: 'angry',\n",
        "     3: 'fear'}\n",
        "Y_test_pred = np.argmax(model.predict(X_test), axis=-1)\n",
        "Y_test_pred = list(map(lambda x: d[x], Y_test_pred))\n",
        "y_test = np.argmax(y_test, axis=-1)\n",
        "y_test = list(map(lambda x: d[x], y_test))\n",
        "print(classification_report(y_test, Y_test_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.34      0.92      0.50        13\n",
            "        fear       0.40      0.10      0.15        21\n",
            "       happy       0.48      0.52      0.50        23\n",
            "         sad       0.67      0.40      0.50        20\n",
            "\n",
            "    accuracy                           0.44        77\n",
            "   macro avg       0.47      0.49      0.41        77\n",
            "weighted avg       0.48      0.44      0.41        77\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmwdO_F15VzC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "outputId": "0a9f738a-7464-4adb-c719-1ea595bd9a31"
      },
      "source": [
        "skplt.metrics.plot_confusion_matrix(\n",
        "    y_test, \n",
        "    Y_test_pred,\n",
        "    figsize=(8,8))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f15dcac3050>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2D5jL4vXsxFE"
      },
      "source": [
        "# mfcc_26 + basic model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ERMKKGwsxFp"
      },
      "source": [
        "features = []\n",
        "labels = []\n",
        "for i in range(len(Ravdess_DF['Paths'])):\n",
        "  if ((Ravdess_DF['Emotion'][i] == '03') | (Ravdess_DF['Emotion'][i] == '04') | \n",
        "      (Ravdess_DF['Emotion'][i] == '05') | (Ravdess_DF['Emotion'][i] == '06')):\n",
        "    signal, sr = librosa.load(Ravdess_DF['Paths'][i])\n",
        "    mfcc = np.mean(librosa.feature.mfcc(y=signal, sr=sr, n_mfcc=26).T,axis=0).tolist()\n",
        "    features.append(mfcc)\n",
        "    if Ravdess_DF['Emotion'][i] == '03':\n",
        "      labels.append(0)\n",
        "    elif Ravdess_DF['Emotion'][i] == '04':\n",
        "      labels.append(1)\n",
        "    elif Ravdess_DF['Emotion'][i] == '05':\n",
        "      labels.append(2)\n",
        "    elif Ravdess_DF['Emotion'][i] == '06':\n",
        "      labels.append(3)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qC9_5HaesxFq"
      },
      "source": [
        "X = features\n",
        "y = labels\n",
        "\n",
        "y = np.array(y)\n",
        "y = to_categorical(y)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=0)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=0)\n",
        "\n",
        "X_train = np.array(X_train)\n",
        "X_test = np.array(X_test)\n",
        "X_val = np.array(X_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_3KDiZvsxFq"
      },
      "source": [
        "## basic models:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kocMmlKasxFr",
        "outputId": "297c4c87-6081-43fc-ecc5-85717d544b18"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(26, input_shape=(26, ), activation = 'relu'))\n",
        "#model.add(Dropout(0.1))\n",
        "model.add(Dense(128, activation = 'relu'))\n",
        "#model.add(Dropout(0.25))\n",
        "model.add(Dense(128, activation = 'relu'))\n",
        "#model.add(Dropout(0.2))\n",
        "model.add(Dense(4, activation = 'softmax'))\n",
        "\n",
        "optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
        "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer=optimizer)\n",
        "early_stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=100, verbose=1, mode='auto')\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_4 (Dense)              (None, 26)                702       \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 128)               3456      \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 4)                 516       \n",
            "=================================================================\n",
            "Total params: 21,186\n",
            "Trainable params: 21,186\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vzx5KTQ-sxFs",
        "outputId": "dce0eef4-1279-4709-ddf7-df63c45d4d89"
      },
      "source": [
        "history = model.fit(X_train, y_train, batch_size=64, epochs=200, \n",
        "                    validation_data=(X_val, y_val))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "10/10 [==============================] - 1s 36ms/step - loss: 12.2251 - accuracy: 0.2722 - val_loss: 7.2771 - val_accuracy: 0.2286\n",
            "Epoch 2/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 5.3027 - accuracy: 0.2803 - val_loss: 2.1272 - val_accuracy: 0.2714\n",
            "Epoch 3/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 2.0043 - accuracy: 0.3322 - val_loss: 2.1571 - val_accuracy: 0.2857\n",
            "Epoch 4/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.7827 - accuracy: 0.2715 - val_loss: 1.8919 - val_accuracy: 0.1714\n",
            "Epoch 5/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.5591 - accuracy: 0.3184 - val_loss: 1.7870 - val_accuracy: 0.2143\n",
            "Epoch 6/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.5187 - accuracy: 0.3564 - val_loss: 1.7788 - val_accuracy: 0.2000\n",
            "Epoch 7/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4099 - accuracy: 0.3607 - val_loss: 1.6211 - val_accuracy: 0.2286\n",
            "Epoch 8/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4421 - accuracy: 0.3662 - val_loss: 1.5198 - val_accuracy: 0.3143\n",
            "Epoch 9/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.4023 - accuracy: 0.3616 - val_loss: 1.4367 - val_accuracy: 0.3571\n",
            "Epoch 10/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3719 - accuracy: 0.3821 - val_loss: 1.6678 - val_accuracy: 0.2571\n",
            "Epoch 11/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.3977 - accuracy: 0.3884 - val_loss: 1.4028 - val_accuracy: 0.3429\n",
            "Epoch 12/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3507 - accuracy: 0.3740 - val_loss: 1.6176 - val_accuracy: 0.2571\n",
            "Epoch 13/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4006 - accuracy: 0.3522 - val_loss: 1.3442 - val_accuracy: 0.3857\n",
            "Epoch 14/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.4195 - accuracy: 0.3427 - val_loss: 1.4714 - val_accuracy: 0.3286\n",
            "Epoch 15/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.4057 - accuracy: 0.3761 - val_loss: 1.6324 - val_accuracy: 0.2714\n",
            "Epoch 16/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3866 - accuracy: 0.3738 - val_loss: 1.6497 - val_accuracy: 0.3714\n",
            "Epoch 17/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3269 - accuracy: 0.4517 - val_loss: 1.3406 - val_accuracy: 0.4286\n",
            "Epoch 18/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2897 - accuracy: 0.4071 - val_loss: 1.5020 - val_accuracy: 0.3286\n",
            "Epoch 19/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2898 - accuracy: 0.4512 - val_loss: 1.3148 - val_accuracy: 0.4571\n",
            "Epoch 20/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2901 - accuracy: 0.4344 - val_loss: 1.7076 - val_accuracy: 0.2857\n",
            "Epoch 21/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.3349 - accuracy: 0.4410 - val_loss: 1.3423 - val_accuracy: 0.3571\n",
            "Epoch 22/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2462 - accuracy: 0.4706 - val_loss: 1.4422 - val_accuracy: 0.4286\n",
            "Epoch 23/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2853 - accuracy: 0.4333 - val_loss: 1.4162 - val_accuracy: 0.3286\n",
            "Epoch 24/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1977 - accuracy: 0.4277 - val_loss: 1.3684 - val_accuracy: 0.4429\n",
            "Epoch 25/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1925 - accuracy: 0.4684 - val_loss: 1.5456 - val_accuracy: 0.3286\n",
            "Epoch 26/200\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.2049 - accuracy: 0.4717 - val_loss: 1.2718 - val_accuracy: 0.4429\n",
            "Epoch 27/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.2722 - accuracy: 0.4600 - val_loss: 1.4653 - val_accuracy: 0.3571\n",
            "Epoch 28/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2231 - accuracy: 0.4840 - val_loss: 1.2675 - val_accuracy: 0.4286\n",
            "Epoch 29/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1499 - accuracy: 0.5119 - val_loss: 1.4559 - val_accuracy: 0.4000\n",
            "Epoch 30/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3998 - accuracy: 0.4279 - val_loss: 1.5167 - val_accuracy: 0.4000\n",
            "Epoch 31/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.2887 - accuracy: 0.4328 - val_loss: 1.5558 - val_accuracy: 0.4000\n",
            "Epoch 32/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2548 - accuracy: 0.4810 - val_loss: 1.2962 - val_accuracy: 0.4429\n",
            "Epoch 33/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1474 - accuracy: 0.5198 - val_loss: 1.1560 - val_accuracy: 0.5000\n",
            "Epoch 34/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.0502 - accuracy: 0.5616 - val_loss: 1.2140 - val_accuracy: 0.4143\n",
            "Epoch 35/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.1121 - accuracy: 0.5059 - val_loss: 1.2594 - val_accuracy: 0.4000\n",
            "Epoch 36/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.0972 - accuracy: 0.5340 - val_loss: 1.2789 - val_accuracy: 0.4286\n",
            "Epoch 37/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1266 - accuracy: 0.5120 - val_loss: 1.2715 - val_accuracy: 0.4429\n",
            "Epoch 38/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1142 - accuracy: 0.4864 - val_loss: 1.1902 - val_accuracy: 0.4571\n",
            "Epoch 39/200\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.0782 - accuracy: 0.5365 - val_loss: 1.4205 - val_accuracy: 0.4000\n",
            "Epoch 40/200\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.1145 - accuracy: 0.5129 - val_loss: 1.1786 - val_accuracy: 0.4571\n",
            "Epoch 41/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.0031 - accuracy: 0.5779 - val_loss: 1.1674 - val_accuracy: 0.5000\n",
            "Epoch 42/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1047 - accuracy: 0.5431 - val_loss: 1.5355 - val_accuracy: 0.4000\n",
            "Epoch 43/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1760 - accuracy: 0.4953 - val_loss: 1.3503 - val_accuracy: 0.4857\n",
            "Epoch 44/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2228 - accuracy: 0.4728 - val_loss: 1.1122 - val_accuracy: 0.4857\n",
            "Epoch 45/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.0306 - accuracy: 0.5727 - val_loss: 1.2137 - val_accuracy: 0.4857\n",
            "Epoch 46/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.0129 - accuracy: 0.5824 - val_loss: 1.1409 - val_accuracy: 0.4429\n",
            "Epoch 47/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0835 - accuracy: 0.5397 - val_loss: 1.4248 - val_accuracy: 0.4429\n",
            "Epoch 48/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1396 - accuracy: 0.5223 - val_loss: 1.1029 - val_accuracy: 0.5000\n",
            "Epoch 49/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.0146 - accuracy: 0.5804 - val_loss: 1.1860 - val_accuracy: 0.5000\n",
            "Epoch 50/200\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.0048 - accuracy: 0.5809 - val_loss: 1.1459 - val_accuracy: 0.5143\n",
            "Epoch 51/200\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.9880 - accuracy: 0.5582 - val_loss: 1.1255 - val_accuracy: 0.5286\n",
            "Epoch 52/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9634 - accuracy: 0.5861 - val_loss: 1.3531 - val_accuracy: 0.4857\n",
            "Epoch 53/200\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.0775 - accuracy: 0.5577 - val_loss: 1.2382 - val_accuracy: 0.4857\n",
            "Epoch 54/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0139 - accuracy: 0.5645 - val_loss: 1.1444 - val_accuracy: 0.4714\n",
            "Epoch 55/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0264 - accuracy: 0.5481 - val_loss: 1.0582 - val_accuracy: 0.5429\n",
            "Epoch 56/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9713 - accuracy: 0.5735 - val_loss: 1.0807 - val_accuracy: 0.5571\n",
            "Epoch 57/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.8820 - accuracy: 0.6680 - val_loss: 1.1036 - val_accuracy: 0.5286\n",
            "Epoch 58/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.9249 - accuracy: 0.6081 - val_loss: 1.0481 - val_accuracy: 0.5429\n",
            "Epoch 59/200\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.9361 - accuracy: 0.6103 - val_loss: 1.0933 - val_accuracy: 0.4857\n",
            "Epoch 60/200\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.0007 - accuracy: 0.5738 - val_loss: 1.2815 - val_accuracy: 0.5143\n",
            "Epoch 61/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9823 - accuracy: 0.6175 - val_loss: 1.0650 - val_accuracy: 0.4857\n",
            "Epoch 62/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.9674 - accuracy: 0.6077 - val_loss: 1.0557 - val_accuracy: 0.5000\n",
            "Epoch 63/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0440 - accuracy: 0.5535 - val_loss: 1.3586 - val_accuracy: 0.4429\n",
            "Epoch 64/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.0475 - accuracy: 0.5502 - val_loss: 1.1588 - val_accuracy: 0.4714\n",
            "Epoch 65/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0062 - accuracy: 0.5578 - val_loss: 1.0094 - val_accuracy: 0.5857\n",
            "Epoch 66/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.8785 - accuracy: 0.6364 - val_loss: 1.2869 - val_accuracy: 0.4714\n",
            "Epoch 67/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9549 - accuracy: 0.6077 - val_loss: 1.0559 - val_accuracy: 0.4714\n",
            "Epoch 68/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8876 - accuracy: 0.6492 - val_loss: 1.0395 - val_accuracy: 0.5571\n",
            "Epoch 69/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8570 - accuracy: 0.6622 - val_loss: 1.0139 - val_accuracy: 0.5286\n",
            "Epoch 70/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.9353 - accuracy: 0.5863 - val_loss: 1.0397 - val_accuracy: 0.5143\n",
            "Epoch 71/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.9413 - accuracy: 0.5977 - val_loss: 1.4350 - val_accuracy: 0.5143\n",
            "Epoch 72/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9652 - accuracy: 0.6243 - val_loss: 1.0227 - val_accuracy: 0.5286\n",
            "Epoch 73/200\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.9345 - accuracy: 0.6053 - val_loss: 1.0801 - val_accuracy: 0.5286\n",
            "Epoch 74/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9279 - accuracy: 0.6241 - val_loss: 1.0479 - val_accuracy: 0.5286\n",
            "Epoch 75/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.9670 - accuracy: 0.5696 - val_loss: 1.4791 - val_accuracy: 0.5143\n",
            "Epoch 76/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1912 - accuracy: 0.5388 - val_loss: 1.1469 - val_accuracy: 0.5286\n",
            "Epoch 77/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0051 - accuracy: 0.5551 - val_loss: 1.0555 - val_accuracy: 0.5143\n",
            "Epoch 78/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9373 - accuracy: 0.6026 - val_loss: 1.0502 - val_accuracy: 0.5571\n",
            "Epoch 79/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9471 - accuracy: 0.6063 - val_loss: 1.0123 - val_accuracy: 0.5429\n",
            "Epoch 80/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.8213 - accuracy: 0.6705 - val_loss: 1.0673 - val_accuracy: 0.5000\n",
            "Epoch 81/200\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8200 - accuracy: 0.6614 - val_loss: 0.9887 - val_accuracy: 0.5571\n",
            "Epoch 82/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.8420 - accuracy: 0.6772 - val_loss: 1.0182 - val_accuracy: 0.5286\n",
            "Epoch 83/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.8481 - accuracy: 0.6471 - val_loss: 1.1475 - val_accuracy: 0.5286\n",
            "Epoch 84/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9258 - accuracy: 0.6013 - val_loss: 1.0917 - val_accuracy: 0.4714\n",
            "Epoch 85/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.9542 - accuracy: 0.5690 - val_loss: 1.0776 - val_accuracy: 0.5429\n",
            "Epoch 86/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.9308 - accuracy: 0.5899 - val_loss: 1.1052 - val_accuracy: 0.5143\n",
            "Epoch 87/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8644 - accuracy: 0.6042 - val_loss: 1.0330 - val_accuracy: 0.5429\n",
            "Epoch 88/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8695 - accuracy: 0.6311 - val_loss: 1.0659 - val_accuracy: 0.5714\n",
            "Epoch 89/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9655 - accuracy: 0.6025 - val_loss: 1.0638 - val_accuracy: 0.5714\n",
            "Epoch 90/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.8655 - accuracy: 0.6479 - val_loss: 1.0263 - val_accuracy: 0.5429\n",
            "Epoch 91/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.8669 - accuracy: 0.6349 - val_loss: 1.1264 - val_accuracy: 0.5429\n",
            "Epoch 92/200\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.9796 - accuracy: 0.5881 - val_loss: 1.2005 - val_accuracy: 0.4571\n",
            "Epoch 93/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8912 - accuracy: 0.6397 - val_loss: 1.1548 - val_accuracy: 0.5429\n",
            "Epoch 94/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0271 - accuracy: 0.5945 - val_loss: 1.0422 - val_accuracy: 0.5143\n",
            "Epoch 95/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8790 - accuracy: 0.6390 - val_loss: 1.0453 - val_accuracy: 0.5714\n",
            "Epoch 96/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.8565 - accuracy: 0.6281 - val_loss: 1.2219 - val_accuracy: 0.5000\n",
            "Epoch 97/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.9470 - accuracy: 0.6233 - val_loss: 1.0916 - val_accuracy: 0.5000\n",
            "Epoch 98/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.8861 - accuracy: 0.6117 - val_loss: 1.0690 - val_accuracy: 0.5143\n",
            "Epoch 99/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8946 - accuracy: 0.6443 - val_loss: 1.0685 - val_accuracy: 0.5286\n",
            "Epoch 100/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.8658 - accuracy: 0.6363 - val_loss: 1.0135 - val_accuracy: 0.5429\n",
            "Epoch 101/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8394 - accuracy: 0.6662 - val_loss: 0.9741 - val_accuracy: 0.5286\n",
            "Epoch 102/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.8186 - accuracy: 0.6460 - val_loss: 1.0922 - val_accuracy: 0.5000\n",
            "Epoch 103/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9624 - accuracy: 0.5800 - val_loss: 1.1807 - val_accuracy: 0.5286\n",
            "Epoch 104/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1228 - accuracy: 0.5302 - val_loss: 1.1122 - val_accuracy: 0.5429\n",
            "Epoch 105/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9923 - accuracy: 0.5607 - val_loss: 1.1279 - val_accuracy: 0.5143\n",
            "Epoch 106/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.8797 - accuracy: 0.6345 - val_loss: 1.0116 - val_accuracy: 0.5286\n",
            "Epoch 107/200\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8655 - accuracy: 0.6259 - val_loss: 1.1261 - val_accuracy: 0.5286\n",
            "Epoch 108/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.9264 - accuracy: 0.6401 - val_loss: 1.0993 - val_accuracy: 0.5429\n",
            "Epoch 109/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.8537 - accuracy: 0.6112 - val_loss: 1.2168 - val_accuracy: 0.4857\n",
            "Epoch 110/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.0158 - accuracy: 0.5531 - val_loss: 0.9718 - val_accuracy: 0.5857\n",
            "Epoch 111/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.9227 - accuracy: 0.6314 - val_loss: 1.0050 - val_accuracy: 0.5286\n",
            "Epoch 112/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8412 - accuracy: 0.6629 - val_loss: 1.1881 - val_accuracy: 0.5143\n",
            "Epoch 113/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.0237 - accuracy: 0.5668 - val_loss: 1.0881 - val_accuracy: 0.5143\n",
            "Epoch 114/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.9324 - accuracy: 0.6248 - val_loss: 1.1395 - val_accuracy: 0.4286\n",
            "Epoch 115/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.9948 - accuracy: 0.5710 - val_loss: 1.1781 - val_accuracy: 0.4857\n",
            "Epoch 116/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.8319 - accuracy: 0.6360 - val_loss: 1.0409 - val_accuracy: 0.5429\n",
            "Epoch 117/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8193 - accuracy: 0.6569 - val_loss: 1.0379 - val_accuracy: 0.5857\n",
            "Epoch 118/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8382 - accuracy: 0.6432 - val_loss: 1.0488 - val_accuracy: 0.5429\n",
            "Epoch 119/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.8548 - accuracy: 0.6251 - val_loss: 1.0397 - val_accuracy: 0.5000\n",
            "Epoch 120/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.8324 - accuracy: 0.6507 - val_loss: 1.1719 - val_accuracy: 0.4857\n",
            "Epoch 121/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.8955 - accuracy: 0.6204 - val_loss: 1.0348 - val_accuracy: 0.5571\n",
            "Epoch 122/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.8223 - accuracy: 0.6580 - val_loss: 0.9695 - val_accuracy: 0.5714\n",
            "Epoch 123/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7723 - accuracy: 0.6667 - val_loss: 0.9847 - val_accuracy: 0.5286\n",
            "Epoch 124/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7837 - accuracy: 0.6889 - val_loss: 0.9945 - val_accuracy: 0.5571\n",
            "Epoch 125/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.8255 - accuracy: 0.6452 - val_loss: 1.1860 - val_accuracy: 0.5000\n",
            "Epoch 126/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9025 - accuracy: 0.6275 - val_loss: 1.0984 - val_accuracy: 0.5429\n",
            "Epoch 127/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7555 - accuracy: 0.6997 - val_loss: 1.1365 - val_accuracy: 0.5571\n",
            "Epoch 128/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7511 - accuracy: 0.6957 - val_loss: 0.9773 - val_accuracy: 0.5714\n",
            "Epoch 129/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7641 - accuracy: 0.6751 - val_loss: 0.9452 - val_accuracy: 0.5571\n",
            "Epoch 130/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7674 - accuracy: 0.6674 - val_loss: 1.0123 - val_accuracy: 0.5857\n",
            "Epoch 131/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7176 - accuracy: 0.7061 - val_loss: 0.9713 - val_accuracy: 0.5429\n",
            "Epoch 132/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7606 - accuracy: 0.6728 - val_loss: 1.0841 - val_accuracy: 0.5143\n",
            "Epoch 133/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8389 - accuracy: 0.6547 - val_loss: 1.0941 - val_accuracy: 0.5429\n",
            "Epoch 134/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7634 - accuracy: 0.6976 - val_loss: 1.0297 - val_accuracy: 0.5429\n",
            "Epoch 135/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7714 - accuracy: 0.6738 - val_loss: 1.0766 - val_accuracy: 0.5571\n",
            "Epoch 136/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.8042 - accuracy: 0.6486 - val_loss: 0.9179 - val_accuracy: 0.6000\n",
            "Epoch 137/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7260 - accuracy: 0.7029 - val_loss: 1.0316 - val_accuracy: 0.5571\n",
            "Epoch 138/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8838 - accuracy: 0.6353 - val_loss: 0.9839 - val_accuracy: 0.5571\n",
            "Epoch 139/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7167 - accuracy: 0.7034 - val_loss: 1.0008 - val_accuracy: 0.5286\n",
            "Epoch 140/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7671 - accuracy: 0.6986 - val_loss: 0.9224 - val_accuracy: 0.5143\n",
            "Epoch 141/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7392 - accuracy: 0.6932 - val_loss: 1.0289 - val_accuracy: 0.5286\n",
            "Epoch 142/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7601 - accuracy: 0.6867 - val_loss: 0.9923 - val_accuracy: 0.5286\n",
            "Epoch 143/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6930 - accuracy: 0.7045 - val_loss: 1.0087 - val_accuracy: 0.5286\n",
            "Epoch 144/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7726 - accuracy: 0.6810 - val_loss: 1.0106 - val_accuracy: 0.5429\n",
            "Epoch 145/200\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8288 - accuracy: 0.6505 - val_loss: 1.1092 - val_accuracy: 0.5143\n",
            "Epoch 146/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7850 - accuracy: 0.7056 - val_loss: 1.1381 - val_accuracy: 0.5286\n",
            "Epoch 147/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7401 - accuracy: 0.6796 - val_loss: 0.9233 - val_accuracy: 0.6000\n",
            "Epoch 148/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7377 - accuracy: 0.6727 - val_loss: 0.9544 - val_accuracy: 0.6143\n",
            "Epoch 149/200\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.7322 - accuracy: 0.6849 - val_loss: 0.9853 - val_accuracy: 0.5143\n",
            "Epoch 150/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7774 - accuracy: 0.6698 - val_loss: 1.0260 - val_accuracy: 0.5714\n",
            "Epoch 151/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8291 - accuracy: 0.6263 - val_loss: 0.9875 - val_accuracy: 0.5571\n",
            "Epoch 152/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7635 - accuracy: 0.6763 - val_loss: 0.9593 - val_accuracy: 0.5571\n",
            "Epoch 153/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7311 - accuracy: 0.6778 - val_loss: 0.9911 - val_accuracy: 0.5143\n",
            "Epoch 154/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7100 - accuracy: 0.6998 - val_loss: 0.9293 - val_accuracy: 0.5714\n",
            "Epoch 155/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6645 - accuracy: 0.7268 - val_loss: 0.9887 - val_accuracy: 0.5571\n",
            "Epoch 156/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7424 - accuracy: 0.6907 - val_loss: 0.9844 - val_accuracy: 0.6429\n",
            "Epoch 157/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7574 - accuracy: 0.6674 - val_loss: 1.0236 - val_accuracy: 0.5143\n",
            "Epoch 158/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7830 - accuracy: 0.6950 - val_loss: 1.0207 - val_accuracy: 0.5571\n",
            "Epoch 159/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7472 - accuracy: 0.6659 - val_loss: 1.0050 - val_accuracy: 0.5571\n",
            "Epoch 160/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7258 - accuracy: 0.7008 - val_loss: 0.9252 - val_accuracy: 0.5857\n",
            "Epoch 161/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6676 - accuracy: 0.7140 - val_loss: 0.9263 - val_accuracy: 0.5571\n",
            "Epoch 162/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6491 - accuracy: 0.7481 - val_loss: 0.8781 - val_accuracy: 0.6143\n",
            "Epoch 163/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7160 - accuracy: 0.6965 - val_loss: 0.9484 - val_accuracy: 0.5714\n",
            "Epoch 164/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7049 - accuracy: 0.6848 - val_loss: 1.1316 - val_accuracy: 0.5143\n",
            "Epoch 165/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8084 - accuracy: 0.6650 - val_loss: 0.9038 - val_accuracy: 0.6143\n",
            "Epoch 166/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7520 - accuracy: 0.6869 - val_loss: 1.0720 - val_accuracy: 0.5143\n",
            "Epoch 167/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7925 - accuracy: 0.6524 - val_loss: 0.9936 - val_accuracy: 0.5429\n",
            "Epoch 168/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7174 - accuracy: 0.7078 - val_loss: 0.8753 - val_accuracy: 0.6000\n",
            "Epoch 169/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6381 - accuracy: 0.7406 - val_loss: 0.8869 - val_accuracy: 0.6000\n",
            "Epoch 170/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6474 - accuracy: 0.7308 - val_loss: 1.1515 - val_accuracy: 0.5571\n",
            "Epoch 171/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7886 - accuracy: 0.6752 - val_loss: 0.9700 - val_accuracy: 0.6000\n",
            "Epoch 172/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7141 - accuracy: 0.7126 - val_loss: 0.9293 - val_accuracy: 0.5143\n",
            "Epoch 173/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7388 - accuracy: 0.6767 - val_loss: 0.9908 - val_accuracy: 0.6000\n",
            "Epoch 174/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7876 - accuracy: 0.6722 - val_loss: 1.0000 - val_accuracy: 0.6000\n",
            "Epoch 175/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.8374 - accuracy: 0.6649 - val_loss: 1.0754 - val_accuracy: 0.5857\n",
            "Epoch 176/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7446 - accuracy: 0.6716 - val_loss: 0.9114 - val_accuracy: 0.5286\n",
            "Epoch 177/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6371 - accuracy: 0.7641 - val_loss: 0.9465 - val_accuracy: 0.5857\n",
            "Epoch 178/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6809 - accuracy: 0.7058 - val_loss: 0.8966 - val_accuracy: 0.5714\n",
            "Epoch 179/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6859 - accuracy: 0.7207 - val_loss: 0.9515 - val_accuracy: 0.5714\n",
            "Epoch 180/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6308 - accuracy: 0.7330 - val_loss: 0.9379 - val_accuracy: 0.6000\n",
            "Epoch 181/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6961 - accuracy: 0.7146 - val_loss: 0.9328 - val_accuracy: 0.5429\n",
            "Epoch 182/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6735 - accuracy: 0.7209 - val_loss: 1.0128 - val_accuracy: 0.5714\n",
            "Epoch 183/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7203 - accuracy: 0.7128 - val_loss: 0.9617 - val_accuracy: 0.5571\n",
            "Epoch 184/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6183 - accuracy: 0.7433 - val_loss: 0.9041 - val_accuracy: 0.5857\n",
            "Epoch 185/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6414 - accuracy: 0.7412 - val_loss: 0.8620 - val_accuracy: 0.6000\n",
            "Epoch 186/200\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.6285 - accuracy: 0.7266 - val_loss: 0.9466 - val_accuracy: 0.5857\n",
            "Epoch 187/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6638 - accuracy: 0.7275 - val_loss: 0.8916 - val_accuracy: 0.5857\n",
            "Epoch 188/200\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.6735 - accuracy: 0.6890 - val_loss: 0.8646 - val_accuracy: 0.6571\n",
            "Epoch 189/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.5994 - accuracy: 0.7542 - val_loss: 0.8971 - val_accuracy: 0.6000\n",
            "Epoch 190/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6348 - accuracy: 0.7320 - val_loss: 0.8814 - val_accuracy: 0.5286\n",
            "Epoch 191/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.5584 - accuracy: 0.7918 - val_loss: 0.8691 - val_accuracy: 0.5286\n",
            "Epoch 192/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.5940 - accuracy: 0.7579 - val_loss: 0.9088 - val_accuracy: 0.6143\n",
            "Epoch 193/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6105 - accuracy: 0.7562 - val_loss: 1.0026 - val_accuracy: 0.6000\n",
            "Epoch 194/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6405 - accuracy: 0.7250 - val_loss: 0.8562 - val_accuracy: 0.5857\n",
            "Epoch 195/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6429 - accuracy: 0.7302 - val_loss: 0.8805 - val_accuracy: 0.6000\n",
            "Epoch 196/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6563 - accuracy: 0.7269 - val_loss: 0.8476 - val_accuracy: 0.6286\n",
            "Epoch 197/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6197 - accuracy: 0.7510 - val_loss: 0.8363 - val_accuracy: 0.6143\n",
            "Epoch 198/200\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.6237 - accuracy: 0.7408 - val_loss: 1.0989 - val_accuracy: 0.5429\n",
            "Epoch 199/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7172 - accuracy: 0.6822 - val_loss: 0.8174 - val_accuracy: 0.6286\n",
            "Epoch 200/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.5998 - accuracy: 0.7456 - val_loss: 0.8547 - val_accuracy: 0.6429\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TbS4bgv_tU4F"
      },
      "source": [
        "model.save('/content/drive/MyDrive/Colab Notebooks/SPEECH_EMOTION_Recognition/Nộp bài(chốt hạ)/model_saver/basic_mfcc26_ravdess.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oVMJEBKLsxFs"
      },
      "source": [
        "###test_result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CdLJ7_O5sxFt",
        "outputId": "80e2da0d-5b62-48a8-c491-d1c51c12fe98"
      },
      "source": [
        "d = {0: 'happy',\n",
        "     1: 'sad',\n",
        "     2: 'angry',\n",
        "     3: 'fear'}\n",
        "Y_test_pred = np.argmax(model.predict(X_test), axis=-1)\n",
        "Y_test_pred = list(map(lambda x: d[x], Y_test_pred))\n",
        "y_test = np.argmax(y_test, axis=-1)\n",
        "y_test = list(map(lambda x: d[x], y_test))\n",
        "print(classification_report(y_test, Y_test_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.65      1.00      0.79        13\n",
            "        fear       0.65      0.62      0.63        21\n",
            "       happy       0.73      0.48      0.58        23\n",
            "         sad       0.59      0.65      0.62        20\n",
            "\n",
            "    accuracy                           0.65        77\n",
            "   macro avg       0.66      0.69      0.66        77\n",
            "weighted avg       0.66      0.65      0.64        77\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "id": "SCrvdfdYsxFu",
        "outputId": "8813a572-0a77-407c-94ba-9ab750ba8285"
      },
      "source": [
        "skplt.metrics.plot_confusion_matrix(\n",
        "    y_test, \n",
        "    Y_test_pred,\n",
        "    figsize=(8,8))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f15dba6d550>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BO4gPZsjtTeb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vyVivXklxo6-"
      },
      "source": [
        "# mfcc_39 + basic model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zWzn89-Pxo7T"
      },
      "source": [
        "features = []\n",
        "labels = []\n",
        "for i in range(len(Ravdess_DF['Paths'])):\n",
        "  if ((Ravdess_DF['Emotion'][i] == '03') | (Ravdess_DF['Emotion'][i] == '04') | \n",
        "      (Ravdess_DF['Emotion'][i] == '05') | (Ravdess_DF['Emotion'][i] == '06')):\n",
        "    signal, sr = librosa.load(Ravdess_DF['Paths'][i])\n",
        "    mfcc = np.mean(librosa.feature.mfcc(y=signal, sr=sr, n_mfcc=39).T,axis=0).tolist()\n",
        "    features.append(mfcc)\n",
        "    if Ravdess_DF['Emotion'][i] == '03':\n",
        "      labels.append(0)\n",
        "    elif Ravdess_DF['Emotion'][i] == '04':\n",
        "      labels.append(1)\n",
        "    elif Ravdess_DF['Emotion'][i] == '05':\n",
        "      labels.append(2)\n",
        "    elif Ravdess_DF['Emotion'][i] == '06':\n",
        "      labels.append(3)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vPEexKmSxo7W"
      },
      "source": [
        "X = features\n",
        "y = labels\n",
        "\n",
        "y = np.array(y)\n",
        "y = to_categorical(y)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=0)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=0)\n",
        "\n",
        "X_train = np.array(X_train)\n",
        "X_test = np.array(X_test)\n",
        "X_val = np.array(X_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XxWiM4Gaxo7X"
      },
      "source": [
        "## basic models:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QxMLoIo3xo7Z",
        "outputId": "73fc2289-3ff7-43e4-bc7d-33f938d91c16"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(39, input_shape=(39, ), activation = 'relu'))\n",
        "#model.add(Dropout(0.1))\n",
        "model.add(Dense(128, activation = 'relu'))\n",
        "#model.add(Dropout(0.25))\n",
        "model.add(Dense(128, activation = 'relu'))\n",
        "#model.add(Dropout(0.2))\n",
        "model.add(Dense(4, activation = 'softmax'))\n",
        "\n",
        "optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
        "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer=optimizer)\n",
        "early_stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=100, verbose=1, mode='auto')\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_12 (Dense)             (None, 39)                1560      \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 128)               5120      \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 4)                 516       \n",
            "=================================================================\n",
            "Total params: 23,708\n",
            "Trainable params: 23,708\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gHcgjBAMxo7d",
        "outputId": "885bd815-a014-42e4-9ae7-15108060e582"
      },
      "source": [
        "history = model.fit(X_train, y_train, batch_size=64, epochs=200, \n",
        "                    validation_data=(X_val, y_val))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "10/10 [==============================] - 1s 36ms/step - loss: 13.3817 - accuracy: 0.2085 - val_loss: 4.6035 - val_accuracy: 0.2857\n",
            "Epoch 2/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 4.8008 - accuracy: 0.2317 - val_loss: 1.9268 - val_accuracy: 0.3000\n",
            "Epoch 3/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.3835 - accuracy: 0.2541 - val_loss: 1.9489 - val_accuracy: 0.3286\n",
            "Epoch 4/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 2.0334 - accuracy: 0.2693 - val_loss: 1.5078 - val_accuracy: 0.3429\n",
            "Epoch 5/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.6560 - accuracy: 0.3394 - val_loss: 1.4570 - val_accuracy: 0.3429\n",
            "Epoch 6/200\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.3861 - accuracy: 0.3838 - val_loss: 1.6032 - val_accuracy: 0.4000\n",
            "Epoch 7/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.5907 - accuracy: 0.3687 - val_loss: 1.5467 - val_accuracy: 0.4000\n",
            "Epoch 8/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4907 - accuracy: 0.3548 - val_loss: 1.4491 - val_accuracy: 0.3429\n",
            "Epoch 9/200\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.4335 - accuracy: 0.3790 - val_loss: 1.6315 - val_accuracy: 0.3429\n",
            "Epoch 10/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.3991 - accuracy: 0.3985 - val_loss: 1.3938 - val_accuracy: 0.4571\n",
            "Epoch 11/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3875 - accuracy: 0.4072 - val_loss: 1.4190 - val_accuracy: 0.3571\n",
            "Epoch 12/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.3914 - accuracy: 0.4290 - val_loss: 1.3150 - val_accuracy: 0.4714\n",
            "Epoch 13/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.2517 - accuracy: 0.4420 - val_loss: 1.4012 - val_accuracy: 0.4143\n",
            "Epoch 14/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.2279 - accuracy: 0.4478 - val_loss: 1.2530 - val_accuracy: 0.4857\n",
            "Epoch 15/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2709 - accuracy: 0.4449 - val_loss: 1.3277 - val_accuracy: 0.4571\n",
            "Epoch 16/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2694 - accuracy: 0.4428 - val_loss: 1.4046 - val_accuracy: 0.3714\n",
            "Epoch 17/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.3337 - accuracy: 0.4405 - val_loss: 1.5915 - val_accuracy: 0.3429\n",
            "Epoch 18/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4022 - accuracy: 0.4150 - val_loss: 1.5493 - val_accuracy: 0.3429\n",
            "Epoch 19/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2157 - accuracy: 0.4431 - val_loss: 1.1839 - val_accuracy: 0.4714\n",
            "Epoch 20/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.1449 - accuracy: 0.5250 - val_loss: 1.1904 - val_accuracy: 0.4857\n",
            "Epoch 21/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1715 - accuracy: 0.4968 - val_loss: 1.1980 - val_accuracy: 0.4857\n",
            "Epoch 22/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1048 - accuracy: 0.5306 - val_loss: 1.4216 - val_accuracy: 0.4429\n",
            "Epoch 23/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.2684 - accuracy: 0.4461 - val_loss: 1.2367 - val_accuracy: 0.4857\n",
            "Epoch 24/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1967 - accuracy: 0.4793 - val_loss: 1.2426 - val_accuracy: 0.4571\n",
            "Epoch 25/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1439 - accuracy: 0.5116 - val_loss: 1.5143 - val_accuracy: 0.4000\n",
            "Epoch 26/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.4082 - accuracy: 0.3975 - val_loss: 1.3431 - val_accuracy: 0.4429\n",
            "Epoch 27/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3768 - accuracy: 0.4688 - val_loss: 1.6902 - val_accuracy: 0.2857\n",
            "Epoch 28/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.2916 - accuracy: 0.4731 - val_loss: 1.5156 - val_accuracy: 0.4000\n",
            "Epoch 29/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.1898 - accuracy: 0.5158 - val_loss: 1.1323 - val_accuracy: 0.4857\n",
            "Epoch 30/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.0521 - accuracy: 0.5897 - val_loss: 1.1539 - val_accuracy: 0.4857\n",
            "Epoch 31/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1598 - accuracy: 0.5172 - val_loss: 1.1305 - val_accuracy: 0.5143\n",
            "Epoch 32/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0529 - accuracy: 0.5484 - val_loss: 1.3406 - val_accuracy: 0.3571\n",
            "Epoch 33/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.1195 - accuracy: 0.5079 - val_loss: 1.5307 - val_accuracy: 0.3857\n",
            "Epoch 34/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.2430 - accuracy: 0.4989 - val_loss: 1.3313 - val_accuracy: 0.4286\n",
            "Epoch 35/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1873 - accuracy: 0.4796 - val_loss: 1.3251 - val_accuracy: 0.4286\n",
            "Epoch 36/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.2052 - accuracy: 0.4741 - val_loss: 1.5499 - val_accuracy: 0.4429\n",
            "Epoch 37/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.2583 - accuracy: 0.4828 - val_loss: 1.0958 - val_accuracy: 0.5286\n",
            "Epoch 38/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.0536 - accuracy: 0.5613 - val_loss: 1.4433 - val_accuracy: 0.4000\n",
            "Epoch 39/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0984 - accuracy: 0.5486 - val_loss: 1.1435 - val_accuracy: 0.4857\n",
            "Epoch 40/200\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.1299 - accuracy: 0.5373 - val_loss: 1.2214 - val_accuracy: 0.4857\n",
            "Epoch 41/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.1715 - accuracy: 0.5095 - val_loss: 1.3270 - val_accuracy: 0.4571\n",
            "Epoch 42/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.1852 - accuracy: 0.5194 - val_loss: 1.1344 - val_accuracy: 0.4714\n",
            "Epoch 43/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2348 - accuracy: 0.5252 - val_loss: 1.3653 - val_accuracy: 0.4429\n",
            "Epoch 44/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1742 - accuracy: 0.5137 - val_loss: 1.3642 - val_accuracy: 0.5000\n",
            "Epoch 45/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.3545 - accuracy: 0.4626 - val_loss: 1.4473 - val_accuracy: 0.4714\n",
            "Epoch 46/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1005 - accuracy: 0.5601 - val_loss: 1.2089 - val_accuracy: 0.5000\n",
            "Epoch 47/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.1829 - accuracy: 0.5288 - val_loss: 1.1846 - val_accuracy: 0.5143\n",
            "Epoch 48/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.0484 - accuracy: 0.5492 - val_loss: 1.1499 - val_accuracy: 0.5286\n",
            "Epoch 49/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.0610 - accuracy: 0.5356 - val_loss: 1.3677 - val_accuracy: 0.4143\n",
            "Epoch 50/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.1287 - accuracy: 0.5242 - val_loss: 1.6845 - val_accuracy: 0.4714\n",
            "Epoch 51/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.2745 - accuracy: 0.5194 - val_loss: 1.1493 - val_accuracy: 0.5000\n",
            "Epoch 52/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0232 - accuracy: 0.5604 - val_loss: 1.1110 - val_accuracy: 0.5286\n",
            "Epoch 53/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9369 - accuracy: 0.6234 - val_loss: 1.2448 - val_accuracy: 0.4571\n",
            "Epoch 54/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.1318 - accuracy: 0.5226 - val_loss: 1.5973 - val_accuracy: 0.4714\n",
            "Epoch 55/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.2308 - accuracy: 0.5182 - val_loss: 1.4261 - val_accuracy: 0.5143\n",
            "Epoch 56/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1630 - accuracy: 0.5699 - val_loss: 1.4603 - val_accuracy: 0.4429\n",
            "Epoch 57/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0527 - accuracy: 0.5831 - val_loss: 1.1887 - val_accuracy: 0.5429\n",
            "Epoch 58/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0315 - accuracy: 0.5657 - val_loss: 1.0693 - val_accuracy: 0.5429\n",
            "Epoch 59/200\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.9282 - accuracy: 0.6060 - val_loss: 1.4613 - val_accuracy: 0.4429\n",
            "Epoch 60/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1265 - accuracy: 0.5166 - val_loss: 1.2248 - val_accuracy: 0.5429\n",
            "Epoch 61/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.9963 - accuracy: 0.5795 - val_loss: 1.2032 - val_accuracy: 0.5000\n",
            "Epoch 62/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.0331 - accuracy: 0.5677 - val_loss: 1.0507 - val_accuracy: 0.5571\n",
            "Epoch 63/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.9461 - accuracy: 0.6169 - val_loss: 1.0424 - val_accuracy: 0.5429\n",
            "Epoch 64/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.0214 - accuracy: 0.5820 - val_loss: 1.4084 - val_accuracy: 0.4286\n",
            "Epoch 65/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.9778 - accuracy: 0.6021 - val_loss: 1.2107 - val_accuracy: 0.5143\n",
            "Epoch 66/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.9659 - accuracy: 0.5879 - val_loss: 1.0529 - val_accuracy: 0.5286\n",
            "Epoch 67/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8515 - accuracy: 0.6540 - val_loss: 1.0643 - val_accuracy: 0.5571\n",
            "Epoch 68/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8938 - accuracy: 0.6390 - val_loss: 1.1721 - val_accuracy: 0.4857\n",
            "Epoch 69/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.0720 - accuracy: 0.5656 - val_loss: 1.5364 - val_accuracy: 0.5286\n",
            "Epoch 70/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0990 - accuracy: 0.5766 - val_loss: 1.0708 - val_accuracy: 0.5429\n",
            "Epoch 71/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.9364 - accuracy: 0.6296 - val_loss: 1.3488 - val_accuracy: 0.4857\n",
            "Epoch 72/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0589 - accuracy: 0.5637 - val_loss: 1.3456 - val_accuracy: 0.5429\n",
            "Epoch 73/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9481 - accuracy: 0.5946 - val_loss: 1.0996 - val_accuracy: 0.5429\n",
            "Epoch 74/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.9490 - accuracy: 0.6131 - val_loss: 1.1565 - val_accuracy: 0.5571\n",
            "Epoch 75/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8488 - accuracy: 0.6493 - val_loss: 1.0610 - val_accuracy: 0.5143\n",
            "Epoch 76/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8832 - accuracy: 0.6512 - val_loss: 1.0396 - val_accuracy: 0.5286\n",
            "Epoch 77/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8663 - accuracy: 0.6670 - val_loss: 1.0534 - val_accuracy: 0.5571\n",
            "Epoch 78/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.8867 - accuracy: 0.6405 - val_loss: 1.1954 - val_accuracy: 0.5429\n",
            "Epoch 79/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.0267 - accuracy: 0.5741 - val_loss: 1.0408 - val_accuracy: 0.5571\n",
            "Epoch 80/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8949 - accuracy: 0.6507 - val_loss: 1.0907 - val_accuracy: 0.5571\n",
            "Epoch 81/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.8590 - accuracy: 0.6497 - val_loss: 1.0459 - val_accuracy: 0.5571\n",
            "Epoch 82/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.8660 - accuracy: 0.6501 - val_loss: 1.0853 - val_accuracy: 0.5000\n",
            "Epoch 83/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.8399 - accuracy: 0.6498 - val_loss: 1.0984 - val_accuracy: 0.5571\n",
            "Epoch 84/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.9001 - accuracy: 0.6368 - val_loss: 1.0694 - val_accuracy: 0.6000\n",
            "Epoch 85/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7999 - accuracy: 0.6707 - val_loss: 1.2062 - val_accuracy: 0.5143\n",
            "Epoch 86/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9199 - accuracy: 0.5889 - val_loss: 1.1783 - val_accuracy: 0.5429\n",
            "Epoch 87/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8775 - accuracy: 0.6236 - val_loss: 1.1315 - val_accuracy: 0.5286\n",
            "Epoch 88/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8534 - accuracy: 0.6619 - val_loss: 1.1509 - val_accuracy: 0.5143\n",
            "Epoch 89/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.8594 - accuracy: 0.6546 - val_loss: 1.0645 - val_accuracy: 0.5429\n",
            "Epoch 90/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.8857 - accuracy: 0.6344 - val_loss: 1.1006 - val_accuracy: 0.5571\n",
            "Epoch 91/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.8785 - accuracy: 0.6165 - val_loss: 1.2493 - val_accuracy: 0.4000\n",
            "Epoch 92/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.0509 - accuracy: 0.5355 - val_loss: 1.5655 - val_accuracy: 0.4714\n",
            "Epoch 93/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.1228 - accuracy: 0.5629 - val_loss: 1.1047 - val_accuracy: 0.5429\n",
            "Epoch 94/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.9286 - accuracy: 0.6075 - val_loss: 1.2436 - val_accuracy: 0.5286\n",
            "Epoch 95/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9153 - accuracy: 0.6068 - val_loss: 1.3372 - val_accuracy: 0.5000\n",
            "Epoch 96/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.9955 - accuracy: 0.6275 - val_loss: 1.2024 - val_accuracy: 0.5429\n",
            "Epoch 97/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0794 - accuracy: 0.5915 - val_loss: 1.5942 - val_accuracy: 0.4714\n",
            "Epoch 98/200\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.0989 - accuracy: 0.5901 - val_loss: 1.2540 - val_accuracy: 0.5286\n",
            "Epoch 99/200\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.1167 - accuracy: 0.5521 - val_loss: 1.4140 - val_accuracy: 0.5143\n",
            "Epoch 100/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.0789 - accuracy: 0.5519 - val_loss: 1.2552 - val_accuracy: 0.5000\n",
            "Epoch 101/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8237 - accuracy: 0.6591 - val_loss: 1.1355 - val_accuracy: 0.5429\n",
            "Epoch 102/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8228 - accuracy: 0.6760 - val_loss: 1.0447 - val_accuracy: 0.5571\n",
            "Epoch 103/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7818 - accuracy: 0.6904 - val_loss: 1.0925 - val_accuracy: 0.5429\n",
            "Epoch 104/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7965 - accuracy: 0.6876 - val_loss: 1.2603 - val_accuracy: 0.5286\n",
            "Epoch 105/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8823 - accuracy: 0.6644 - val_loss: 1.2762 - val_accuracy: 0.5571\n",
            "Epoch 106/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0512 - accuracy: 0.5744 - val_loss: 1.1140 - val_accuracy: 0.5714\n",
            "Epoch 107/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.8080 - accuracy: 0.6451 - val_loss: 1.0611 - val_accuracy: 0.5714\n",
            "Epoch 108/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7770 - accuracy: 0.7005 - val_loss: 1.0677 - val_accuracy: 0.5286\n",
            "Epoch 109/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7911 - accuracy: 0.6810 - val_loss: 1.1542 - val_accuracy: 0.5571\n",
            "Epoch 110/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9622 - accuracy: 0.6283 - val_loss: 1.0266 - val_accuracy: 0.5571\n",
            "Epoch 111/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7905 - accuracy: 0.6888 - val_loss: 1.1216 - val_accuracy: 0.5143\n",
            "Epoch 112/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7913 - accuracy: 0.6809 - val_loss: 1.1156 - val_accuracy: 0.5571\n",
            "Epoch 113/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.9252 - accuracy: 0.6142 - val_loss: 1.0699 - val_accuracy: 0.5429\n",
            "Epoch 114/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.8157 - accuracy: 0.6588 - val_loss: 1.0690 - val_accuracy: 0.6000\n",
            "Epoch 115/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.8284 - accuracy: 0.6503 - val_loss: 1.3144 - val_accuracy: 0.5286\n",
            "Epoch 116/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.9253 - accuracy: 0.6308 - val_loss: 1.0851 - val_accuracy: 0.6143\n",
            "Epoch 117/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.8142 - accuracy: 0.6769 - val_loss: 1.2234 - val_accuracy: 0.5143\n",
            "Epoch 118/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8679 - accuracy: 0.6206 - val_loss: 1.0460 - val_accuracy: 0.5857\n",
            "Epoch 119/200\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.6986 - accuracy: 0.7309 - val_loss: 1.1551 - val_accuracy: 0.5571\n",
            "Epoch 120/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.8996 - accuracy: 0.5878 - val_loss: 1.2916 - val_accuracy: 0.5000\n",
            "Epoch 121/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9488 - accuracy: 0.6312 - val_loss: 1.1521 - val_accuracy: 0.5286\n",
            "Epoch 122/200\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.7992 - accuracy: 0.6945 - val_loss: 1.4080 - val_accuracy: 0.4571\n",
            "Epoch 123/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.9466 - accuracy: 0.6191 - val_loss: 1.0688 - val_accuracy: 0.5571\n",
            "Epoch 124/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.8020 - accuracy: 0.6770 - val_loss: 1.0896 - val_accuracy: 0.5857\n",
            "Epoch 125/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.8575 - accuracy: 0.6378 - val_loss: 1.1508 - val_accuracy: 0.5429\n",
            "Epoch 126/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8536 - accuracy: 0.6599 - val_loss: 1.1687 - val_accuracy: 0.5000\n",
            "Epoch 127/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8358 - accuracy: 0.6568 - val_loss: 1.0692 - val_accuracy: 0.5143\n",
            "Epoch 128/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7999 - accuracy: 0.6394 - val_loss: 1.1447 - val_accuracy: 0.5143\n",
            "Epoch 129/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7746 - accuracy: 0.6881 - val_loss: 1.1514 - val_accuracy: 0.5714\n",
            "Epoch 130/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8427 - accuracy: 0.6607 - val_loss: 1.3050 - val_accuracy: 0.5286\n",
            "Epoch 131/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7819 - accuracy: 0.6454 - val_loss: 1.1940 - val_accuracy: 0.5714\n",
            "Epoch 132/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7978 - accuracy: 0.6635 - val_loss: 1.1312 - val_accuracy: 0.5714\n",
            "Epoch 133/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7830 - accuracy: 0.6553 - val_loss: 1.0854 - val_accuracy: 0.5571\n",
            "Epoch 134/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8249 - accuracy: 0.6775 - val_loss: 1.1041 - val_accuracy: 0.5143\n",
            "Epoch 135/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7324 - accuracy: 0.6757 - val_loss: 1.1182 - val_accuracy: 0.5571\n",
            "Epoch 136/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7627 - accuracy: 0.7052 - val_loss: 1.0852 - val_accuracy: 0.5143\n",
            "Epoch 137/200\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7502 - accuracy: 0.6846 - val_loss: 0.9955 - val_accuracy: 0.5857\n",
            "Epoch 138/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6852 - accuracy: 0.7326 - val_loss: 0.9945 - val_accuracy: 0.6000\n",
            "Epoch 139/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7891 - accuracy: 0.6506 - val_loss: 1.1241 - val_accuracy: 0.5286\n",
            "Epoch 140/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.8369 - accuracy: 0.6641 - val_loss: 1.0587 - val_accuracy: 0.5714\n",
            "Epoch 141/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.8037 - accuracy: 0.6565 - val_loss: 1.0524 - val_accuracy: 0.5286\n",
            "Epoch 142/200\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.7603 - accuracy: 0.6979 - val_loss: 1.1329 - val_accuracy: 0.5714\n",
            "Epoch 143/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7208 - accuracy: 0.7119 - val_loss: 1.0591 - val_accuracy: 0.5714\n",
            "Epoch 144/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7463 - accuracy: 0.6955 - val_loss: 1.1580 - val_accuracy: 0.5429\n",
            "Epoch 145/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8005 - accuracy: 0.6600 - val_loss: 1.2130 - val_accuracy: 0.5429\n",
            "Epoch 146/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.8399 - accuracy: 0.6529 - val_loss: 1.1214 - val_accuracy: 0.5143\n",
            "Epoch 147/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7444 - accuracy: 0.7118 - val_loss: 1.0749 - val_accuracy: 0.5857\n",
            "Epoch 148/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7310 - accuracy: 0.7210 - val_loss: 1.0257 - val_accuracy: 0.5571\n",
            "Epoch 149/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7309 - accuracy: 0.7100 - val_loss: 1.0667 - val_accuracy: 0.5571\n",
            "Epoch 150/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7289 - accuracy: 0.6969 - val_loss: 1.2483 - val_accuracy: 0.5429\n",
            "Epoch 151/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.8038 - accuracy: 0.6815 - val_loss: 1.1216 - val_accuracy: 0.5571\n",
            "Epoch 152/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.8363 - accuracy: 0.6434 - val_loss: 1.4396 - val_accuracy: 0.4714\n",
            "Epoch 153/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.9160 - accuracy: 0.6365 - val_loss: 1.1555 - val_accuracy: 0.5714\n",
            "Epoch 154/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8620 - accuracy: 0.6483 - val_loss: 1.3700 - val_accuracy: 0.5286\n",
            "Epoch 155/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7801 - accuracy: 0.6696 - val_loss: 1.2176 - val_accuracy: 0.6000\n",
            "Epoch 156/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.8844 - accuracy: 0.6515 - val_loss: 1.0424 - val_accuracy: 0.5857\n",
            "Epoch 157/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7466 - accuracy: 0.7071 - val_loss: 1.0603 - val_accuracy: 0.5857\n",
            "Epoch 158/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6930 - accuracy: 0.7063 - val_loss: 1.0585 - val_accuracy: 0.5571\n",
            "Epoch 159/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7980 - accuracy: 0.6631 - val_loss: 1.0233 - val_accuracy: 0.5571\n",
            "Epoch 160/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6643 - accuracy: 0.7188 - val_loss: 0.9892 - val_accuracy: 0.6429\n",
            "Epoch 161/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6895 - accuracy: 0.7432 - val_loss: 1.1617 - val_accuracy: 0.5714\n",
            "Epoch 162/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7765 - accuracy: 0.6552 - val_loss: 1.0496 - val_accuracy: 0.5286\n",
            "Epoch 163/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6995 - accuracy: 0.7019 - val_loss: 1.0720 - val_accuracy: 0.5429\n",
            "Epoch 164/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6345 - accuracy: 0.7299 - val_loss: 1.0564 - val_accuracy: 0.5429\n",
            "Epoch 165/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7008 - accuracy: 0.7080 - val_loss: 0.9946 - val_accuracy: 0.6000\n",
            "Epoch 166/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6642 - accuracy: 0.7432 - val_loss: 1.0135 - val_accuracy: 0.6286\n",
            "Epoch 167/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6925 - accuracy: 0.7113 - val_loss: 1.0506 - val_accuracy: 0.5714\n",
            "Epoch 168/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6235 - accuracy: 0.7397 - val_loss: 1.0066 - val_accuracy: 0.5857\n",
            "Epoch 169/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6612 - accuracy: 0.7345 - val_loss: 1.0304 - val_accuracy: 0.5571\n",
            "Epoch 170/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6589 - accuracy: 0.7564 - val_loss: 1.0485 - val_accuracy: 0.5714\n",
            "Epoch 171/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6791 - accuracy: 0.7316 - val_loss: 1.2453 - val_accuracy: 0.5429\n",
            "Epoch 172/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.8527 - accuracy: 0.6642 - val_loss: 1.1350 - val_accuracy: 0.5714\n",
            "Epoch 173/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7420 - accuracy: 0.6889 - val_loss: 1.2083 - val_accuracy: 0.5429\n",
            "Epoch 174/200\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.7658 - accuracy: 0.6921 - val_loss: 1.0220 - val_accuracy: 0.5714\n",
            "Epoch 175/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6945 - accuracy: 0.7465 - val_loss: 1.0155 - val_accuracy: 0.6571\n",
            "Epoch 176/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6646 - accuracy: 0.7111 - val_loss: 1.0062 - val_accuracy: 0.6286\n",
            "Epoch 177/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7135 - accuracy: 0.7110 - val_loss: 1.1008 - val_accuracy: 0.5429\n",
            "Epoch 178/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6693 - accuracy: 0.7292 - val_loss: 1.4861 - val_accuracy: 0.5714\n",
            "Epoch 179/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.8823 - accuracy: 0.6202 - val_loss: 1.1288 - val_accuracy: 0.5714\n",
            "Epoch 180/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7293 - accuracy: 0.6815 - val_loss: 1.1173 - val_accuracy: 0.6000\n",
            "Epoch 181/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6924 - accuracy: 0.7203 - val_loss: 1.3132 - val_accuracy: 0.5429\n",
            "Epoch 182/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7200 - accuracy: 0.6915 - val_loss: 0.9813 - val_accuracy: 0.5857\n",
            "Epoch 183/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6401 - accuracy: 0.7469 - val_loss: 1.0107 - val_accuracy: 0.6000\n",
            "Epoch 184/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7135 - accuracy: 0.7245 - val_loss: 1.1266 - val_accuracy: 0.5143\n",
            "Epoch 185/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6363 - accuracy: 0.7559 - val_loss: 1.0489 - val_accuracy: 0.5571\n",
            "Epoch 186/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6547 - accuracy: 0.7367 - val_loss: 1.0276 - val_accuracy: 0.5429\n",
            "Epoch 187/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6467 - accuracy: 0.7499 - val_loss: 1.1292 - val_accuracy: 0.5571\n",
            "Epoch 188/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6875 - accuracy: 0.7207 - val_loss: 1.0137 - val_accuracy: 0.5429\n",
            "Epoch 189/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7633 - accuracy: 0.6935 - val_loss: 1.1364 - val_accuracy: 0.5714\n",
            "Epoch 190/200\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7673 - accuracy: 0.6881 - val_loss: 1.4559 - val_accuracy: 0.5143\n",
            "Epoch 191/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.0576 - accuracy: 0.6424 - val_loss: 1.0174 - val_accuracy: 0.5714\n",
            "Epoch 192/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6936 - accuracy: 0.7169 - val_loss: 1.1262 - val_accuracy: 0.5571\n",
            "Epoch 193/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6659 - accuracy: 0.7270 - val_loss: 1.0515 - val_accuracy: 0.5714\n",
            "Epoch 194/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6940 - accuracy: 0.7325 - val_loss: 1.0287 - val_accuracy: 0.5857\n",
            "Epoch 195/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6703 - accuracy: 0.7528 - val_loss: 1.0817 - val_accuracy: 0.5857\n",
            "Epoch 196/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6505 - accuracy: 0.7098 - val_loss: 1.0064 - val_accuracy: 0.5429\n",
            "Epoch 197/200\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.6369 - accuracy: 0.7695 - val_loss: 0.9857 - val_accuracy: 0.6000\n",
            "Epoch 198/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.5676 - accuracy: 0.7864 - val_loss: 0.9609 - val_accuracy: 0.6571\n",
            "Epoch 199/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6795 - accuracy: 0.7196 - val_loss: 1.0369 - val_accuracy: 0.5286\n",
            "Epoch 200/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6077 - accuracy: 0.7554 - val_loss: 1.0773 - val_accuracy: 0.5286\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUZ6UQUIxo7f"
      },
      "source": [
        "model.save('/content/drive/MyDrive/Colab Notebooks/SPEECH_EMOTION_Recognition/Nộp bài(chốt hạ)/model_saver/basic_mfcc39_ravdess.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0cPXgRWmxo7g"
      },
      "source": [
        "###test_result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oWIpWzgQxo7i",
        "outputId": "b11cf213-503f-4a12-f6fa-0e108246f7ea"
      },
      "source": [
        "d = {0: 'happy',\n",
        "     1: 'sad',\n",
        "     2: 'angry',\n",
        "     3: 'fear'}\n",
        "Y_test_pred = np.argmax(model.predict(X_test), axis=-1)\n",
        "Y_test_pred = list(map(lambda x: d[x], Y_test_pred))\n",
        "y_test = np.argmax(y_test, axis=-1)\n",
        "y_test = list(map(lambda x: d[x], y_test))\n",
        "print(classification_report(y_test, Y_test_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.79      0.85      0.81        13\n",
            "        fear       1.00      0.43      0.60        21\n",
            "       happy       0.83      0.43      0.57        23\n",
            "         sad       0.48      1.00      0.65        20\n",
            "\n",
            "    accuracy                           0.65        77\n",
            "   macro avg       0.77      0.68      0.66        77\n",
            "weighted avg       0.78      0.65      0.64        77\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "id": "14x5PTeAxo7j",
        "outputId": "844528eb-447d-43dc-fa2d-6fddc51c523c"
      },
      "source": [
        "skplt.metrics.plot_confusion_matrix(\n",
        "    y_test, \n",
        "    Y_test_pred,\n",
        "    figsize=(8,8))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f15db93bf90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zy2-7kdQxo7m"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2tpfXhgWh0Dz"
      },
      "source": [
        "# mfcc_13 + conv1D:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHWhYBLWis47"
      },
      "source": [
        "audio_duration = 3\n",
        "sampling_rate = 22050\n",
        "input_length = sampling_rate * audio_duration"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3g-IT-nWh3aS"
      },
      "source": [
        "features = []\n",
        "labels = []\n",
        "for i in range(len(Ravdess_DF['Paths'])):\n",
        "  if ((Ravdess_DF['Emotion'][i] == '03') | (Ravdess_DF['Emotion'][i] == '04') | \n",
        "      (Ravdess_DF['Emotion'][i] == '05') | (Ravdess_DF['Emotion'][i] == '06')):\n",
        "    signal, sr = librosa.load(Ravdess_DF['Paths'][i])\n",
        "\n",
        "    if len(signal) > input_length:\n",
        "      signal = signal[0:input_length]\n",
        "    elif  input_length > len(signal):\n",
        "      max_offset = input_length - len(signal)  \n",
        "      signal = np.pad(signal, (0, max_offset), \"constant\")\n",
        "\n",
        "    mfcc = librosa.feature.mfcc(y=signal, sr=sr, n_mfcc=13).T\n",
        "    mfcc = mfcc.reshape(-1,1)\n",
        "    features.append(mfcc)\n",
        "\n",
        "    if Ravdess_DF['Emotion'][i] == '03':\n",
        "      labels.append(0)\n",
        "    elif Ravdess_DF['Emotion'][i] == '04':\n",
        "      labels.append(1)\n",
        "    elif Ravdess_DF['Emotion'][i] == '05':\n",
        "      labels.append(2)\n",
        "    elif Ravdess_DF['Emotion'][i] == '06':\n",
        "      labels.append(3)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wtQSaQ-BiCct"
      },
      "source": [
        "X = features\n",
        "y = labels\n",
        "\n",
        "y = np.array(y)\n",
        "y = to_categorical(y)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=0)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=0)\n",
        "\n",
        "X_train = np.array(X_train)\n",
        "X_test = np.array(X_test)\n",
        "X_val = np.array(X_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9NR4b-fbi-Mv",
        "outputId": "4345a50b-57b9-441d-f256-e76b25dccab5"
      },
      "source": [
        "X_train.shape,X_test.shape,y_train.shape,y_test.shape\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((621, 1690, 1), (77, 1690, 1), (621, 4), (77, 4))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6psnOJE7i-QE"
      },
      "source": [
        "\n",
        "# CNN I/P Config\n",
        "num_classes = 4\n",
        "input_shape = X_train.shape[1:]\n",
        "learning_rate = 0.0001\n",
        "decay = 1e-6\n",
        "momentum = 0.9\n",
        "\n",
        "#LSTM Configuration\n",
        "num_lstm = 256"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZMn8aEojFTC",
        "outputId": "74941c22-9dbf-407e-8d80-36cf0a2c9896"
      },
      "source": [
        "model = Sequential(name='Audio_CNN_1D')\n",
        "\n",
        "# LFLB1\n",
        "model.add(Conv1D(filters=64, kernel_size=(3), strides=1, padding='same', data_format='channels_last',input_shape=input_shape))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('elu'))\n",
        "model.add(MaxPooling1D(pool_size=4, strides=4))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "# LFLB2\n",
        "model.add(Conv1D(filters=64, kernel_size=3, strides=1, padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('elu'))\n",
        "model.add(MaxPooling1D(pool_size=4, strides=4))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# LFLB3\n",
        "model.add(Conv1D(filters=128, kernel_size=3, strides=1, padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('elu'))\n",
        "model.add(MaxPooling1D(pool_size=4, strides=4))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# LFLB4\n",
        "model.add(Conv1D(filters=128, kernel_size=3, strides=1, padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('elu'))\n",
        "model.add(MaxPooling1D(pool_size=4, strides=4))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# LSTM\n",
        "model.add(LSTM(units=num_lstm))\n",
        "\n",
        "# FC\n",
        "model.add(Dense(units=num_classes, activation='softmax'))\n",
        "\n",
        "# Model compilation\n",
        "opt= keras.optimizers.Adam(lr=0.01, beta_1=0.9,  beta_2=0.999, amsgrad=False)\n",
        "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
        "\n",
        "model.summary()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"Audio_CNN_1D\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 1690, 64)          256       \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 1690, 64)          256       \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 1690, 64)          0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D) (None, 422, 64)           0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 422, 64)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 422, 64)           12352     \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 422, 64)           256       \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 422, 64)           0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1 (None, 105, 64)           0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 105, 64)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 105, 128)          24704     \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 105, 128)          512       \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 105, 128)          0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_2 (MaxPooling1 (None, 26, 128)           0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 26, 128)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 26, 128)           49280     \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 26, 128)           512       \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 26, 128)           0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_3 (MaxPooling1 (None, 6, 128)            0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 6, 128)            0         \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 256)               394240    \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 4)                 1028      \n",
            "=================================================================\n",
            "Total params: 483,396\n",
            "Trainable params: 482,628\n",
            "Non-trainable params: 768\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4DXFmqfXjFaM",
        "outputId": "b59bd96e-4bcf-42a0-8a2c-16dae169a242"
      },
      "source": [
        "#Train Config\n",
        "\n",
        "batch_size = 16\n",
        "num_epochs = 200\n",
        "\n",
        "# Model Training\n",
        "lr_reduce = ReduceLROnPlateau(monitor='val_loss', factor=0.9, patience=20, min_lr=0.000001)\n",
        "# Please change the model name accordingly.\n",
        "mcp_save = ModelCheckpoint('/content/Audio_1DCNN.h5', save_best_only=True, monitor='val_categorical_accuracy', mode='max')\n",
        "cnnhistory=model.fit(X_train, y_train, batch_size=batch_size, epochs=num_epochs,validation_data=(X_val, y_val), callbacks=[mcp_save, lr_reduce])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "39/39 [==============================] - 18s 156ms/step - loss: 1.9610 - categorical_accuracy: 0.2953 - val_loss: 1.5584 - val_categorical_accuracy: 0.1857\n",
            "Epoch 2/200\n",
            "39/39 [==============================] - 5s 128ms/step - loss: 1.2561 - categorical_accuracy: 0.4271 - val_loss: 1.9221 - val_categorical_accuracy: 0.1857\n",
            "Epoch 3/200\n",
            "39/39 [==============================] - 5s 127ms/step - loss: 1.2181 - categorical_accuracy: 0.4612 - val_loss: 2.0510 - val_categorical_accuracy: 0.1857\n",
            "Epoch 4/200\n",
            "39/39 [==============================] - 5s 130ms/step - loss: 1.1965 - categorical_accuracy: 0.4731 - val_loss: 1.6126 - val_categorical_accuracy: 0.2429\n",
            "Epoch 5/200\n",
            "39/39 [==============================] - 5s 129ms/step - loss: 1.2549 - categorical_accuracy: 0.4062 - val_loss: 1.4981 - val_categorical_accuracy: 0.2286\n",
            "Epoch 6/200\n",
            "39/39 [==============================] - 5s 128ms/step - loss: 1.2130 - categorical_accuracy: 0.4402 - val_loss: 1.4579 - val_categorical_accuracy: 0.3429\n",
            "Epoch 7/200\n",
            "39/39 [==============================] - 5s 129ms/step - loss: 1.1872 - categorical_accuracy: 0.4598 - val_loss: 1.5927 - val_categorical_accuracy: 0.3429\n",
            "Epoch 8/200\n",
            "39/39 [==============================] - 5s 132ms/step - loss: 1.2171 - categorical_accuracy: 0.4634 - val_loss: 1.6548 - val_categorical_accuracy: 0.3143\n",
            "Epoch 9/200\n",
            "39/39 [==============================] - 5s 129ms/step - loss: 1.1710 - categorical_accuracy: 0.4156 - val_loss: 1.4700 - val_categorical_accuracy: 0.4143\n",
            "Epoch 10/200\n",
            "39/39 [==============================] - 5s 126ms/step - loss: 1.0702 - categorical_accuracy: 0.5145 - val_loss: 1.3138 - val_categorical_accuracy: 0.4143\n",
            "Epoch 11/200\n",
            "39/39 [==============================] - 5s 129ms/step - loss: 1.1022 - categorical_accuracy: 0.5503 - val_loss: 1.2307 - val_categorical_accuracy: 0.4857\n",
            "Epoch 12/200\n",
            "39/39 [==============================] - 5s 129ms/step - loss: 1.1062 - categorical_accuracy: 0.5119 - val_loss: 1.6329 - val_categorical_accuracy: 0.3143\n",
            "Epoch 13/200\n",
            "39/39 [==============================] - 5s 128ms/step - loss: 1.1089 - categorical_accuracy: 0.5125 - val_loss: 1.6851 - val_categorical_accuracy: 0.3571\n",
            "Epoch 14/200\n",
            "39/39 [==============================] - 5s 127ms/step - loss: 1.1593 - categorical_accuracy: 0.4882 - val_loss: 1.1847 - val_categorical_accuracy: 0.4429\n",
            "Epoch 15/200\n",
            "39/39 [==============================] - 5s 125ms/step - loss: 1.0476 - categorical_accuracy: 0.5380 - val_loss: 1.2854 - val_categorical_accuracy: 0.4429\n",
            "Epoch 16/200\n",
            "39/39 [==============================] - 5s 125ms/step - loss: 1.1032 - categorical_accuracy: 0.5017 - val_loss: 1.2453 - val_categorical_accuracy: 0.4143\n",
            "Epoch 17/200\n",
            "39/39 [==============================] - 5s 126ms/step - loss: 1.1765 - categorical_accuracy: 0.4744 - val_loss: 1.2690 - val_categorical_accuracy: 0.4714\n",
            "Epoch 18/200\n",
            "39/39 [==============================] - 5s 130ms/step - loss: 1.0762 - categorical_accuracy: 0.5198 - val_loss: 1.1394 - val_categorical_accuracy: 0.4571\n",
            "Epoch 19/200\n",
            "39/39 [==============================] - 5s 129ms/step - loss: 0.9604 - categorical_accuracy: 0.5823 - val_loss: 1.1615 - val_categorical_accuracy: 0.4429\n",
            "Epoch 20/200\n",
            "39/39 [==============================] - 5s 122ms/step - loss: 1.0134 - categorical_accuracy: 0.5558 - val_loss: 1.2590 - val_categorical_accuracy: 0.4143\n",
            "Epoch 21/200\n",
            "39/39 [==============================] - 5s 121ms/step - loss: 1.0016 - categorical_accuracy: 0.5530 - val_loss: 1.2070 - val_categorical_accuracy: 0.5000\n",
            "Epoch 22/200\n",
            "39/39 [==============================] - 5s 123ms/step - loss: 1.0591 - categorical_accuracy: 0.5185 - val_loss: 1.1178 - val_categorical_accuracy: 0.5143\n",
            "Epoch 23/200\n",
            "39/39 [==============================] - 5s 124ms/step - loss: 1.0274 - categorical_accuracy: 0.5374 - val_loss: 1.1729 - val_categorical_accuracy: 0.5143\n",
            "Epoch 24/200\n",
            "39/39 [==============================] - 5s 126ms/step - loss: 1.0490 - categorical_accuracy: 0.5537 - val_loss: 1.0793 - val_categorical_accuracy: 0.5429\n",
            "Epoch 25/200\n",
            "39/39 [==============================] - 5s 123ms/step - loss: 1.0032 - categorical_accuracy: 0.5931 - val_loss: 1.2185 - val_categorical_accuracy: 0.4857\n",
            "Epoch 26/200\n",
            "39/39 [==============================] - 5s 125ms/step - loss: 1.0135 - categorical_accuracy: 0.5680 - val_loss: 1.2332 - val_categorical_accuracy: 0.4571\n",
            "Epoch 27/200\n",
            "39/39 [==============================] - 5s 126ms/step - loss: 0.9775 - categorical_accuracy: 0.5864 - val_loss: 1.1654 - val_categorical_accuracy: 0.5143\n",
            "Epoch 28/200\n",
            "39/39 [==============================] - 5s 124ms/step - loss: 1.0045 - categorical_accuracy: 0.5734 - val_loss: 1.1270 - val_categorical_accuracy: 0.5000\n",
            "Epoch 29/200\n",
            "39/39 [==============================] - 5s 124ms/step - loss: 0.9703 - categorical_accuracy: 0.6052 - val_loss: 1.1366 - val_categorical_accuracy: 0.5143\n",
            "Epoch 30/200\n",
            "39/39 [==============================] - 5s 125ms/step - loss: 1.0274 - categorical_accuracy: 0.5236 - val_loss: 1.2440 - val_categorical_accuracy: 0.4571\n",
            "Epoch 31/200\n",
            "39/39 [==============================] - 5s 126ms/step - loss: 1.0330 - categorical_accuracy: 0.5487 - val_loss: 1.1092 - val_categorical_accuracy: 0.4714\n",
            "Epoch 32/200\n",
            "39/39 [==============================] - 5s 124ms/step - loss: 0.9621 - categorical_accuracy: 0.5849 - val_loss: 1.2360 - val_categorical_accuracy: 0.4714\n",
            "Epoch 33/200\n",
            "39/39 [==============================] - 5s 123ms/step - loss: 0.9128 - categorical_accuracy: 0.6105 - val_loss: 1.2484 - val_categorical_accuracy: 0.4429\n",
            "Epoch 34/200\n",
            "39/39 [==============================] - 5s 124ms/step - loss: 0.9930 - categorical_accuracy: 0.5940 - val_loss: 1.2934 - val_categorical_accuracy: 0.4714\n",
            "Epoch 35/200\n",
            "39/39 [==============================] - 5s 125ms/step - loss: 0.9568 - categorical_accuracy: 0.5683 - val_loss: 1.2218 - val_categorical_accuracy: 0.4571\n",
            "Epoch 36/200\n",
            "39/39 [==============================] - 5s 128ms/step - loss: 0.9069 - categorical_accuracy: 0.6359 - val_loss: 1.1924 - val_categorical_accuracy: 0.5143\n",
            "Epoch 37/200\n",
            "39/39 [==============================] - 5s 126ms/step - loss: 0.9492 - categorical_accuracy: 0.5823 - val_loss: 1.2468 - val_categorical_accuracy: 0.4571\n",
            "Epoch 38/200\n",
            "39/39 [==============================] - 5s 127ms/step - loss: 0.9871 - categorical_accuracy: 0.5721 - val_loss: 1.1791 - val_categorical_accuracy: 0.4714\n",
            "Epoch 39/200\n",
            "39/39 [==============================] - 5s 124ms/step - loss: 0.8344 - categorical_accuracy: 0.6637 - val_loss: 1.1798 - val_categorical_accuracy: 0.5429\n",
            "Epoch 40/200\n",
            "39/39 [==============================] - 5s 126ms/step - loss: 0.8834 - categorical_accuracy: 0.6043 - val_loss: 1.1562 - val_categorical_accuracy: 0.4857\n",
            "Epoch 41/200\n",
            "39/39 [==============================] - 5s 126ms/step - loss: 0.8927 - categorical_accuracy: 0.6273 - val_loss: 1.1476 - val_categorical_accuracy: 0.5571\n",
            "Epoch 42/200\n",
            "39/39 [==============================] - 5s 127ms/step - loss: 0.8639 - categorical_accuracy: 0.6454 - val_loss: 1.1057 - val_categorical_accuracy: 0.5429\n",
            "Epoch 43/200\n",
            "39/39 [==============================] - 5s 129ms/step - loss: 0.8649 - categorical_accuracy: 0.6241 - val_loss: 1.1538 - val_categorical_accuracy: 0.4714\n",
            "Epoch 44/200\n",
            "39/39 [==============================] - 5s 131ms/step - loss: 0.9237 - categorical_accuracy: 0.6206 - val_loss: 1.1659 - val_categorical_accuracy: 0.4857\n",
            "Epoch 45/200\n",
            "39/39 [==============================] - 5s 127ms/step - loss: 0.8541 - categorical_accuracy: 0.6653 - val_loss: 1.2116 - val_categorical_accuracy: 0.5429\n",
            "Epoch 46/200\n",
            "39/39 [==============================] - 5s 128ms/step - loss: 0.8541 - categorical_accuracy: 0.6545 - val_loss: 1.2573 - val_categorical_accuracy: 0.5143\n",
            "Epoch 47/200\n",
            "39/39 [==============================] - 5s 128ms/step - loss: 0.8562 - categorical_accuracy: 0.6812 - val_loss: 1.2334 - val_categorical_accuracy: 0.5143\n",
            "Epoch 48/200\n",
            "39/39 [==============================] - 5s 129ms/step - loss: 0.8268 - categorical_accuracy: 0.6799 - val_loss: 1.1177 - val_categorical_accuracy: 0.6000\n",
            "Epoch 49/200\n",
            "39/39 [==============================] - 5s 127ms/step - loss: 0.8345 - categorical_accuracy: 0.6613 - val_loss: 1.2350 - val_categorical_accuracy: 0.5286\n",
            "Epoch 50/200\n",
            "39/39 [==============================] - 5s 124ms/step - loss: 0.7430 - categorical_accuracy: 0.6861 - val_loss: 1.2136 - val_categorical_accuracy: 0.5143\n",
            "Epoch 51/200\n",
            "39/39 [==============================] - 5s 126ms/step - loss: 0.7663 - categorical_accuracy: 0.6684 - val_loss: 1.2029 - val_categorical_accuracy: 0.5286\n",
            "Epoch 52/200\n",
            "39/39 [==============================] - 5s 126ms/step - loss: 0.6732 - categorical_accuracy: 0.7427 - val_loss: 1.1377 - val_categorical_accuracy: 0.5143\n",
            "Epoch 53/200\n",
            "39/39 [==============================] - 5s 126ms/step - loss: 0.7597 - categorical_accuracy: 0.6564 - val_loss: 1.1943 - val_categorical_accuracy: 0.5143\n",
            "Epoch 54/200\n",
            "39/39 [==============================] - 5s 126ms/step - loss: 0.7106 - categorical_accuracy: 0.7099 - val_loss: 1.0946 - val_categorical_accuracy: 0.5857\n",
            "Epoch 55/200\n",
            "39/39 [==============================] - 5s 126ms/step - loss: 0.7081 - categorical_accuracy: 0.6948 - val_loss: 1.2918 - val_categorical_accuracy: 0.5429\n",
            "Epoch 56/200\n",
            "39/39 [==============================] - 5s 131ms/step - loss: 0.7618 - categorical_accuracy: 0.7053 - val_loss: 1.0840 - val_categorical_accuracy: 0.5714\n",
            "Epoch 57/200\n",
            "39/39 [==============================] - 5s 127ms/step - loss: 0.7190 - categorical_accuracy: 0.7178 - val_loss: 1.1465 - val_categorical_accuracy: 0.5571\n",
            "Epoch 58/200\n",
            "39/39 [==============================] - 5s 128ms/step - loss: 0.7149 - categorical_accuracy: 0.7314 - val_loss: 1.0441 - val_categorical_accuracy: 0.5286\n",
            "Epoch 59/200\n",
            "39/39 [==============================] - 5s 127ms/step - loss: 0.7467 - categorical_accuracy: 0.6857 - val_loss: 0.9334 - val_categorical_accuracy: 0.5857\n",
            "Epoch 60/200\n",
            "39/39 [==============================] - 5s 127ms/step - loss: 0.6762 - categorical_accuracy: 0.7202 - val_loss: 1.1219 - val_categorical_accuracy: 0.6286\n",
            "Epoch 61/200\n",
            "39/39 [==============================] - 5s 130ms/step - loss: 0.6857 - categorical_accuracy: 0.7154 - val_loss: 1.1298 - val_categorical_accuracy: 0.5571\n",
            "Epoch 62/200\n",
            "39/39 [==============================] - 5s 124ms/step - loss: 0.6975 - categorical_accuracy: 0.6808 - val_loss: 1.1013 - val_categorical_accuracy: 0.5857\n",
            "Epoch 63/200\n",
            "39/39 [==============================] - 5s 128ms/step - loss: 0.7205 - categorical_accuracy: 0.7082 - val_loss: 1.0281 - val_categorical_accuracy: 0.5857\n",
            "Epoch 64/200\n",
            "39/39 [==============================] - 5s 126ms/step - loss: 0.7837 - categorical_accuracy: 0.6623 - val_loss: 1.1626 - val_categorical_accuracy: 0.6143\n",
            "Epoch 65/200\n",
            "39/39 [==============================] - 5s 124ms/step - loss: 0.6087 - categorical_accuracy: 0.7729 - val_loss: 0.9986 - val_categorical_accuracy: 0.5571\n",
            "Epoch 66/200\n",
            "39/39 [==============================] - 5s 124ms/step - loss: 0.6269 - categorical_accuracy: 0.7518 - val_loss: 1.0547 - val_categorical_accuracy: 0.6000\n",
            "Epoch 67/200\n",
            "39/39 [==============================] - 5s 127ms/step - loss: 0.6789 - categorical_accuracy: 0.7587 - val_loss: 1.0955 - val_categorical_accuracy: 0.4714\n",
            "Epoch 68/200\n",
            "39/39 [==============================] - 5s 127ms/step - loss: 0.6467 - categorical_accuracy: 0.7356 - val_loss: 1.0462 - val_categorical_accuracy: 0.5571\n",
            "Epoch 69/200\n",
            "39/39 [==============================] - 5s 123ms/step - loss: 0.6577 - categorical_accuracy: 0.7246 - val_loss: 1.1242 - val_categorical_accuracy: 0.5571\n",
            "Epoch 70/200\n",
            "39/39 [==============================] - 5s 124ms/step - loss: 0.6088 - categorical_accuracy: 0.7614 - val_loss: 1.1454 - val_categorical_accuracy: 0.5571\n",
            "Epoch 71/200\n",
            "39/39 [==============================] - 5s 128ms/step - loss: 0.6891 - categorical_accuracy: 0.7045 - val_loss: 1.2619 - val_categorical_accuracy: 0.5429\n",
            "Epoch 72/200\n",
            "39/39 [==============================] - 5s 127ms/step - loss: 0.6289 - categorical_accuracy: 0.7400 - val_loss: 1.1714 - val_categorical_accuracy: 0.5286\n",
            "Epoch 73/200\n",
            "39/39 [==============================] - 5s 125ms/step - loss: 0.5819 - categorical_accuracy: 0.7744 - val_loss: 1.0232 - val_categorical_accuracy: 0.5857\n",
            "Epoch 74/200\n",
            "39/39 [==============================] - 5s 127ms/step - loss: 0.6309 - categorical_accuracy: 0.7494 - val_loss: 1.0671 - val_categorical_accuracy: 0.5714\n",
            "Epoch 75/200\n",
            "39/39 [==============================] - 5s 131ms/step - loss: 0.5865 - categorical_accuracy: 0.7533 - val_loss: 1.1071 - val_categorical_accuracy: 0.5714\n",
            "Epoch 76/200\n",
            "39/39 [==============================] - 5s 127ms/step - loss: 0.6079 - categorical_accuracy: 0.7435 - val_loss: 0.9651 - val_categorical_accuracy: 0.6000\n",
            "Epoch 77/200\n",
            "39/39 [==============================] - 5s 126ms/step - loss: 0.7031 - categorical_accuracy: 0.7091 - val_loss: 1.1440 - val_categorical_accuracy: 0.6000\n",
            "Epoch 78/200\n",
            "39/39 [==============================] - 5s 128ms/step - loss: 0.5878 - categorical_accuracy: 0.7564 - val_loss: 1.0923 - val_categorical_accuracy: 0.5571\n",
            "Epoch 79/200\n",
            "39/39 [==============================] - 5s 128ms/step - loss: 0.6306 - categorical_accuracy: 0.7313 - val_loss: 0.8628 - val_categorical_accuracy: 0.6000\n",
            "Epoch 80/200\n",
            "39/39 [==============================] - 5s 128ms/step - loss: 0.5557 - categorical_accuracy: 0.8000 - val_loss: 0.8551 - val_categorical_accuracy: 0.7000\n",
            "Epoch 81/200\n",
            "39/39 [==============================] - 5s 126ms/step - loss: 0.5694 - categorical_accuracy: 0.7740 - val_loss: 1.0483 - val_categorical_accuracy: 0.6000\n",
            "Epoch 82/200\n",
            "39/39 [==============================] - 5s 127ms/step - loss: 0.5448 - categorical_accuracy: 0.7763 - val_loss: 1.0566 - val_categorical_accuracy: 0.5000\n",
            "Epoch 83/200\n",
            "39/39 [==============================] - 5s 130ms/step - loss: 0.5450 - categorical_accuracy: 0.7723 - val_loss: 1.0661 - val_categorical_accuracy: 0.5857\n",
            "Epoch 84/200\n",
            "39/39 [==============================] - 5s 130ms/step - loss: 0.5553 - categorical_accuracy: 0.7615 - val_loss: 1.1238 - val_categorical_accuracy: 0.6571\n",
            "Epoch 85/200\n",
            "39/39 [==============================] - 5s 129ms/step - loss: 0.5253 - categorical_accuracy: 0.7654 - val_loss: 0.9203 - val_categorical_accuracy: 0.6000\n",
            "Epoch 86/200\n",
            "39/39 [==============================] - 5s 124ms/step - loss: 0.5624 - categorical_accuracy: 0.7838 - val_loss: 1.0797 - val_categorical_accuracy: 0.5857\n",
            "Epoch 87/200\n",
            "39/39 [==============================] - 5s 128ms/step - loss: 0.6191 - categorical_accuracy: 0.7234 - val_loss: 0.9919 - val_categorical_accuracy: 0.6143\n",
            "Epoch 88/200\n",
            "39/39 [==============================] - 5s 127ms/step - loss: 0.5642 - categorical_accuracy: 0.7908 - val_loss: 1.1638 - val_categorical_accuracy: 0.5857\n",
            "Epoch 89/200\n",
            "39/39 [==============================] - 5s 125ms/step - loss: 0.5801 - categorical_accuracy: 0.7722 - val_loss: 1.0018 - val_categorical_accuracy: 0.6571\n",
            "Epoch 90/200\n",
            "39/39 [==============================] - 5s 124ms/step - loss: 0.5701 - categorical_accuracy: 0.7669 - val_loss: 0.9208 - val_categorical_accuracy: 0.6429\n",
            "Epoch 91/200\n",
            "39/39 [==============================] - 5s 123ms/step - loss: 0.5882 - categorical_accuracy: 0.7611 - val_loss: 1.0786 - val_categorical_accuracy: 0.5857\n",
            "Epoch 92/200\n",
            "39/39 [==============================] - 5s 126ms/step - loss: 0.4544 - categorical_accuracy: 0.8447 - val_loss: 0.9278 - val_categorical_accuracy: 0.6714\n",
            "Epoch 93/200\n",
            "39/39 [==============================] - 5s 127ms/step - loss: 0.5316 - categorical_accuracy: 0.7909 - val_loss: 0.9011 - val_categorical_accuracy: 0.6000\n",
            "Epoch 94/200\n",
            "39/39 [==============================] - 5s 128ms/step - loss: 0.5667 - categorical_accuracy: 0.7578 - val_loss: 1.2333 - val_categorical_accuracy: 0.5000\n",
            "Epoch 95/200\n",
            "39/39 [==============================] - 5s 126ms/step - loss: 0.5507 - categorical_accuracy: 0.8002 - val_loss: 0.9744 - val_categorical_accuracy: 0.6571\n",
            "Epoch 96/200\n",
            "39/39 [==============================] - 5s 126ms/step - loss: 0.5462 - categorical_accuracy: 0.7674 - val_loss: 1.1203 - val_categorical_accuracy: 0.6143\n",
            "Epoch 97/200\n",
            "39/39 [==============================] - 5s 124ms/step - loss: 0.5216 - categorical_accuracy: 0.7801 - val_loss: 0.9687 - val_categorical_accuracy: 0.6286\n",
            "Epoch 98/200\n",
            "39/39 [==============================] - 5s 127ms/step - loss: 0.4757 - categorical_accuracy: 0.8124 - val_loss: 1.0870 - val_categorical_accuracy: 0.5571\n",
            "Epoch 99/200\n",
            "39/39 [==============================] - 5s 129ms/step - loss: 0.3964 - categorical_accuracy: 0.8366 - val_loss: 1.1258 - val_categorical_accuracy: 0.6143\n",
            "Epoch 100/200\n",
            "39/39 [==============================] - 5s 126ms/step - loss: 0.4264 - categorical_accuracy: 0.8208 - val_loss: 0.9997 - val_categorical_accuracy: 0.6000\n",
            "Epoch 101/200\n",
            "39/39 [==============================] - 5s 127ms/step - loss: 0.3807 - categorical_accuracy: 0.8458 - val_loss: 0.8952 - val_categorical_accuracy: 0.6429\n",
            "Epoch 102/200\n",
            "39/39 [==============================] - 5s 129ms/step - loss: 0.4113 - categorical_accuracy: 0.8420 - val_loss: 1.0299 - val_categorical_accuracy: 0.6429\n",
            "Epoch 103/200\n",
            "39/39 [==============================] - 5s 127ms/step - loss: 0.5640 - categorical_accuracy: 0.7827 - val_loss: 1.0066 - val_categorical_accuracy: 0.6000\n",
            "Epoch 104/200\n",
            "39/39 [==============================] - 5s 123ms/step - loss: 0.4768 - categorical_accuracy: 0.7898 - val_loss: 0.9570 - val_categorical_accuracy: 0.7000\n",
            "Epoch 105/200\n",
            "39/39 [==============================] - 5s 130ms/step - loss: 0.3964 - categorical_accuracy: 0.8700 - val_loss: 0.9553 - val_categorical_accuracy: 0.6714\n",
            "Epoch 106/200\n",
            "39/39 [==============================] - 5s 127ms/step - loss: 0.4125 - categorical_accuracy: 0.8478 - val_loss: 0.8921 - val_categorical_accuracy: 0.6286\n",
            "Epoch 107/200\n",
            "39/39 [==============================] - 5s 132ms/step - loss: 0.4138 - categorical_accuracy: 0.8364 - val_loss: 1.1441 - val_categorical_accuracy: 0.6286\n",
            "Epoch 108/200\n",
            "39/39 [==============================] - 5s 129ms/step - loss: 0.4117 - categorical_accuracy: 0.8266 - val_loss: 1.1174 - val_categorical_accuracy: 0.5429\n",
            "Epoch 109/200\n",
            "39/39 [==============================] - 5s 130ms/step - loss: 0.4192 - categorical_accuracy: 0.8404 - val_loss: 0.9940 - val_categorical_accuracy: 0.6714\n",
            "Epoch 110/200\n",
            "39/39 [==============================] - 5s 127ms/step - loss: 0.4180 - categorical_accuracy: 0.8264 - val_loss: 1.1612 - val_categorical_accuracy: 0.6143\n",
            "Epoch 111/200\n",
            "39/39 [==============================] - 5s 133ms/step - loss: 0.5089 - categorical_accuracy: 0.8181 - val_loss: 1.1995 - val_categorical_accuracy: 0.6286\n",
            "Epoch 112/200\n",
            "39/39 [==============================] - 5s 128ms/step - loss: 0.4023 - categorical_accuracy: 0.8258 - val_loss: 1.0008 - val_categorical_accuracy: 0.5714\n",
            "Epoch 113/200\n",
            "39/39 [==============================] - 5s 127ms/step - loss: 0.3917 - categorical_accuracy: 0.8511 - val_loss: 0.9359 - val_categorical_accuracy: 0.6143\n",
            "Epoch 114/200\n",
            "39/39 [==============================] - 5s 126ms/step - loss: 0.4150 - categorical_accuracy: 0.8312 - val_loss: 0.9099 - val_categorical_accuracy: 0.6143\n",
            "Epoch 115/200\n",
            "39/39 [==============================] - 5s 126ms/step - loss: 0.3966 - categorical_accuracy: 0.8367 - val_loss: 0.9802 - val_categorical_accuracy: 0.6286\n",
            "Epoch 116/200\n",
            "39/39 [==============================] - 5s 127ms/step - loss: 0.3481 - categorical_accuracy: 0.8599 - val_loss: 0.9345 - val_categorical_accuracy: 0.6714\n",
            "Epoch 117/200\n",
            "39/39 [==============================] - 5s 131ms/step - loss: 0.3863 - categorical_accuracy: 0.8634 - val_loss: 1.2057 - val_categorical_accuracy: 0.6429\n",
            "Epoch 118/200\n",
            "39/39 [==============================] - 5s 130ms/step - loss: 0.3997 - categorical_accuracy: 0.8461 - val_loss: 0.9511 - val_categorical_accuracy: 0.6571\n",
            "Epoch 119/200\n",
            "39/39 [==============================] - 5s 131ms/step - loss: 0.4078 - categorical_accuracy: 0.8448 - val_loss: 0.9182 - val_categorical_accuracy: 0.6000\n",
            "Epoch 120/200\n",
            "39/39 [==============================] - 5s 129ms/step - loss: 0.3338 - categorical_accuracy: 0.8609 - val_loss: 0.9611 - val_categorical_accuracy: 0.6857\n",
            "Epoch 121/200\n",
            "39/39 [==============================] - 5s 129ms/step - loss: 0.3488 - categorical_accuracy: 0.8572 - val_loss: 1.0102 - val_categorical_accuracy: 0.6286\n",
            "Epoch 122/200\n",
            "39/39 [==============================] - 5s 129ms/step - loss: 0.2964 - categorical_accuracy: 0.8843 - val_loss: 1.1014 - val_categorical_accuracy: 0.5571\n",
            "Epoch 123/200\n",
            "39/39 [==============================] - 5s 129ms/step - loss: 0.3541 - categorical_accuracy: 0.8753 - val_loss: 0.9814 - val_categorical_accuracy: 0.6429\n",
            "Epoch 124/200\n",
            "39/39 [==============================] - 5s 132ms/step - loss: 0.3037 - categorical_accuracy: 0.8813 - val_loss: 0.9853 - val_categorical_accuracy: 0.6714\n",
            "Epoch 125/200\n",
            "39/39 [==============================] - 5s 131ms/step - loss: 0.3592 - categorical_accuracy: 0.8396 - val_loss: 0.7931 - val_categorical_accuracy: 0.7143\n",
            "Epoch 126/200\n",
            "39/39 [==============================] - 5s 130ms/step - loss: 0.3461 - categorical_accuracy: 0.8642 - val_loss: 0.8859 - val_categorical_accuracy: 0.6571\n",
            "Epoch 127/200\n",
            "39/39 [==============================] - 5s 128ms/step - loss: 0.4598 - categorical_accuracy: 0.8407 - val_loss: 1.0733 - val_categorical_accuracy: 0.6000\n",
            "Epoch 128/200\n",
            "39/39 [==============================] - 5s 130ms/step - loss: 0.3067 - categorical_accuracy: 0.9035 - val_loss: 0.8529 - val_categorical_accuracy: 0.6571\n",
            "Epoch 129/200\n",
            "39/39 [==============================] - 5s 132ms/step - loss: 0.3168 - categorical_accuracy: 0.8937 - val_loss: 1.0380 - val_categorical_accuracy: 0.6571\n",
            "Epoch 130/200\n",
            "39/39 [==============================] - 5s 131ms/step - loss: 0.3386 - categorical_accuracy: 0.8740 - val_loss: 0.8453 - val_categorical_accuracy: 0.6714\n",
            "Epoch 131/200\n",
            "39/39 [==============================] - 5s 130ms/step - loss: 0.3328 - categorical_accuracy: 0.8649 - val_loss: 0.9619 - val_categorical_accuracy: 0.6143\n",
            "Epoch 132/200\n",
            "39/39 [==============================] - 5s 129ms/step - loss: 0.3014 - categorical_accuracy: 0.8707 - val_loss: 1.0754 - val_categorical_accuracy: 0.5857\n",
            "Epoch 133/200\n",
            "39/39 [==============================] - 5s 131ms/step - loss: 0.2751 - categorical_accuracy: 0.8976 - val_loss: 1.0474 - val_categorical_accuracy: 0.6000\n",
            "Epoch 134/200\n",
            "39/39 [==============================] - 5s 131ms/step - loss: 0.3020 - categorical_accuracy: 0.8844 - val_loss: 1.1287 - val_categorical_accuracy: 0.6000\n",
            "Epoch 135/200\n",
            "39/39 [==============================] - 5s 127ms/step - loss: 0.2788 - categorical_accuracy: 0.8936 - val_loss: 0.9849 - val_categorical_accuracy: 0.6571\n",
            "Epoch 136/200\n",
            "39/39 [==============================] - 5s 132ms/step - loss: 0.3366 - categorical_accuracy: 0.8701 - val_loss: 1.0296 - val_categorical_accuracy: 0.6143\n",
            "Epoch 137/200\n",
            "39/39 [==============================] - 5s 129ms/step - loss: 0.2602 - categorical_accuracy: 0.9014 - val_loss: 0.9017 - val_categorical_accuracy: 0.6714\n",
            "Epoch 138/200\n",
            "39/39 [==============================] - 5s 130ms/step - loss: 0.2471 - categorical_accuracy: 0.9126 - val_loss: 1.0960 - val_categorical_accuracy: 0.5714\n",
            "Epoch 139/200\n",
            "39/39 [==============================] - 5s 127ms/step - loss: 0.3092 - categorical_accuracy: 0.8924 - val_loss: 1.2080 - val_categorical_accuracy: 0.6571\n",
            "Epoch 140/200\n",
            "39/39 [==============================] - 5s 128ms/step - loss: 0.2522 - categorical_accuracy: 0.9118 - val_loss: 0.9657 - val_categorical_accuracy: 0.7143\n",
            "Epoch 141/200\n",
            "39/39 [==============================] - 5s 131ms/step - loss: 0.3390 - categorical_accuracy: 0.8604 - val_loss: 1.1300 - val_categorical_accuracy: 0.5857\n",
            "Epoch 142/200\n",
            "39/39 [==============================] - 5s 126ms/step - loss: 0.3067 - categorical_accuracy: 0.8660 - val_loss: 0.8442 - val_categorical_accuracy: 0.6714\n",
            "Epoch 143/200\n",
            "39/39 [==============================] - 5s 129ms/step - loss: 0.3540 - categorical_accuracy: 0.8589 - val_loss: 1.0316 - val_categorical_accuracy: 0.6714\n",
            "Epoch 144/200\n",
            "39/39 [==============================] - 5s 129ms/step - loss: 0.2737 - categorical_accuracy: 0.8898 - val_loss: 0.9076 - val_categorical_accuracy: 0.6857\n",
            "Epoch 145/200\n",
            "39/39 [==============================] - 5s 130ms/step - loss: 0.2526 - categorical_accuracy: 0.9095 - val_loss: 0.8658 - val_categorical_accuracy: 0.6857\n",
            "Epoch 146/200\n",
            "39/39 [==============================] - 5s 132ms/step - loss: 0.2782 - categorical_accuracy: 0.8992 - val_loss: 1.0875 - val_categorical_accuracy: 0.7000\n",
            "Epoch 147/200\n",
            "39/39 [==============================] - 5s 131ms/step - loss: 0.2842 - categorical_accuracy: 0.8948 - val_loss: 1.0057 - val_categorical_accuracy: 0.6143\n",
            "Epoch 148/200\n",
            "39/39 [==============================] - 5s 134ms/step - loss: 0.2984 - categorical_accuracy: 0.8799 - val_loss: 0.9466 - val_categorical_accuracy: 0.7000\n",
            "Epoch 149/200\n",
            "39/39 [==============================] - 5s 129ms/step - loss: 0.2627 - categorical_accuracy: 0.9104 - val_loss: 0.8832 - val_categorical_accuracy: 0.7000\n",
            "Epoch 150/200\n",
            "39/39 [==============================] - 5s 133ms/step - loss: 0.2719 - categorical_accuracy: 0.9038 - val_loss: 0.9781 - val_categorical_accuracy: 0.6714\n",
            "Epoch 151/200\n",
            "39/39 [==============================] - 5s 131ms/step - loss: 0.2099 - categorical_accuracy: 0.9270 - val_loss: 1.1254 - val_categorical_accuracy: 0.6857\n",
            "Epoch 152/200\n",
            "39/39 [==============================] - 5s 131ms/step - loss: 0.2271 - categorical_accuracy: 0.9161 - val_loss: 1.0078 - val_categorical_accuracy: 0.6429\n",
            "Epoch 153/200\n",
            "39/39 [==============================] - 5s 130ms/step - loss: 0.1996 - categorical_accuracy: 0.9325 - val_loss: 1.0836 - val_categorical_accuracy: 0.6429\n",
            "Epoch 154/200\n",
            "39/39 [==============================] - 5s 135ms/step - loss: 0.2204 - categorical_accuracy: 0.9343 - val_loss: 0.8708 - val_categorical_accuracy: 0.7429\n",
            "Epoch 155/200\n",
            "39/39 [==============================] - 5s 134ms/step - loss: 0.2118 - categorical_accuracy: 0.9205 - val_loss: 1.2688 - val_categorical_accuracy: 0.6143\n",
            "Epoch 156/200\n",
            "39/39 [==============================] - 5s 134ms/step - loss: 0.1918 - categorical_accuracy: 0.9217 - val_loss: 1.1339 - val_categorical_accuracy: 0.6714\n",
            "Epoch 157/200\n",
            "39/39 [==============================] - 5s 135ms/step - loss: 0.1720 - categorical_accuracy: 0.9513 - val_loss: 0.9978 - val_categorical_accuracy: 0.6857\n",
            "Epoch 158/200\n",
            "39/39 [==============================] - 5s 134ms/step - loss: 0.2117 - categorical_accuracy: 0.9035 - val_loss: 1.1135 - val_categorical_accuracy: 0.6429\n",
            "Epoch 159/200\n",
            "39/39 [==============================] - 5s 130ms/step - loss: 0.1861 - categorical_accuracy: 0.9116 - val_loss: 0.8923 - val_categorical_accuracy: 0.7000\n",
            "Epoch 160/200\n",
            "39/39 [==============================] - 5s 128ms/step - loss: 0.2004 - categorical_accuracy: 0.9260 - val_loss: 0.9115 - val_categorical_accuracy: 0.7143\n",
            "Epoch 161/200\n",
            "39/39 [==============================] - 5s 127ms/step - loss: 0.2097 - categorical_accuracy: 0.9213 - val_loss: 1.0095 - val_categorical_accuracy: 0.7000\n",
            "Epoch 162/200\n",
            "39/39 [==============================] - 5s 127ms/step - loss: 0.2450 - categorical_accuracy: 0.9002 - val_loss: 0.9681 - val_categorical_accuracy: 0.6857\n",
            "Epoch 163/200\n",
            "39/39 [==============================] - 5s 128ms/step - loss: 0.2906 - categorical_accuracy: 0.8728 - val_loss: 0.9297 - val_categorical_accuracy: 0.6429\n",
            "Epoch 164/200\n",
            "39/39 [==============================] - 5s 128ms/step - loss: 0.2371 - categorical_accuracy: 0.9136 - val_loss: 0.9200 - val_categorical_accuracy: 0.6857\n",
            "Epoch 165/200\n",
            "39/39 [==============================] - 5s 133ms/step - loss: 0.3177 - categorical_accuracy: 0.8948 - val_loss: 0.9844 - val_categorical_accuracy: 0.7000\n",
            "Epoch 166/200\n",
            "39/39 [==============================] - 5s 129ms/step - loss: 0.2686 - categorical_accuracy: 0.9087 - val_loss: 0.9735 - val_categorical_accuracy: 0.6571\n",
            "Epoch 167/200\n",
            "39/39 [==============================] - 5s 129ms/step - loss: 0.2346 - categorical_accuracy: 0.9287 - val_loss: 0.9210 - val_categorical_accuracy: 0.6571\n",
            "Epoch 168/200\n",
            "39/39 [==============================] - 5s 130ms/step - loss: 0.1717 - categorical_accuracy: 0.9321 - val_loss: 1.0204 - val_categorical_accuracy: 0.6571\n",
            "Epoch 169/200\n",
            "39/39 [==============================] - 5s 135ms/step - loss: 0.2090 - categorical_accuracy: 0.9197 - val_loss: 1.1171 - val_categorical_accuracy: 0.6429\n",
            "Epoch 170/200\n",
            "39/39 [==============================] - 5s 136ms/step - loss: 0.1992 - categorical_accuracy: 0.9323 - val_loss: 0.9341 - val_categorical_accuracy: 0.7000\n",
            "Epoch 171/200\n",
            "39/39 [==============================] - 5s 133ms/step - loss: 0.1536 - categorical_accuracy: 0.9319 - val_loss: 0.9152 - val_categorical_accuracy: 0.7143\n",
            "Epoch 172/200\n",
            "39/39 [==============================] - 5s 132ms/step - loss: 0.1451 - categorical_accuracy: 0.9597 - val_loss: 0.8945 - val_categorical_accuracy: 0.7000\n",
            "Epoch 173/200\n",
            "39/39 [==============================] - 5s 137ms/step - loss: 0.1842 - categorical_accuracy: 0.9352 - val_loss: 1.0078 - val_categorical_accuracy: 0.7000\n",
            "Epoch 174/200\n",
            "39/39 [==============================] - 5s 134ms/step - loss: 0.1783 - categorical_accuracy: 0.9286 - val_loss: 0.9382 - val_categorical_accuracy: 0.6857\n",
            "Epoch 175/200\n",
            "39/39 [==============================] - 5s 136ms/step - loss: 0.1984 - categorical_accuracy: 0.9291 - val_loss: 0.8262 - val_categorical_accuracy: 0.7429\n",
            "Epoch 176/200\n",
            "39/39 [==============================] - 5s 135ms/step - loss: 0.1453 - categorical_accuracy: 0.9414 - val_loss: 0.8460 - val_categorical_accuracy: 0.7143\n",
            "Epoch 177/200\n",
            "39/39 [==============================] - 5s 139ms/step - loss: 0.2446 - categorical_accuracy: 0.9059 - val_loss: 0.9424 - val_categorical_accuracy: 0.7000\n",
            "Epoch 178/200\n",
            "39/39 [==============================] - 5s 134ms/step - loss: 0.1420 - categorical_accuracy: 0.9481 - val_loss: 1.0351 - val_categorical_accuracy: 0.6714\n",
            "Epoch 179/200\n",
            "39/39 [==============================] - 5s 134ms/step - loss: 0.1774 - categorical_accuracy: 0.9208 - val_loss: 1.0202 - val_categorical_accuracy: 0.7286\n",
            "Epoch 180/200\n",
            "39/39 [==============================] - 5s 133ms/step - loss: 0.1997 - categorical_accuracy: 0.9243 - val_loss: 1.0995 - val_categorical_accuracy: 0.6714\n",
            "Epoch 181/200\n",
            "39/39 [==============================] - 5s 129ms/step - loss: 0.1536 - categorical_accuracy: 0.9459 - val_loss: 1.0028 - val_categorical_accuracy: 0.7143\n",
            "Epoch 182/200\n",
            "39/39 [==============================] - 5s 130ms/step - loss: 0.1713 - categorical_accuracy: 0.9370 - val_loss: 1.0374 - val_categorical_accuracy: 0.7000\n",
            "Epoch 183/200\n",
            "39/39 [==============================] - 5s 131ms/step - loss: 0.1770 - categorical_accuracy: 0.9149 - val_loss: 1.1782 - val_categorical_accuracy: 0.7000\n",
            "Epoch 184/200\n",
            "39/39 [==============================] - 5s 131ms/step - loss: 0.1635 - categorical_accuracy: 0.9412 - val_loss: 1.0470 - val_categorical_accuracy: 0.7143\n",
            "Epoch 185/200\n",
            "39/39 [==============================] - 5s 131ms/step - loss: 0.1890 - categorical_accuracy: 0.9406 - val_loss: 1.2000 - val_categorical_accuracy: 0.6571\n",
            "Epoch 186/200\n",
            "39/39 [==============================] - 5s 132ms/step - loss: 0.2058 - categorical_accuracy: 0.9206 - val_loss: 0.9718 - val_categorical_accuracy: 0.6857\n",
            "Epoch 187/200\n",
            "39/39 [==============================] - 5s 132ms/step - loss: 0.2039 - categorical_accuracy: 0.9174 - val_loss: 1.0789 - val_categorical_accuracy: 0.7000\n",
            "Epoch 188/200\n",
            "39/39 [==============================] - 5s 130ms/step - loss: 0.1969 - categorical_accuracy: 0.9185 - val_loss: 0.9459 - val_categorical_accuracy: 0.6714\n",
            "Epoch 189/200\n",
            "39/39 [==============================] - 5s 132ms/step - loss: 0.1950 - categorical_accuracy: 0.9257 - val_loss: 0.9055 - val_categorical_accuracy: 0.7286\n",
            "Epoch 190/200\n",
            "39/39 [==============================] - 5s 130ms/step - loss: 0.1982 - categorical_accuracy: 0.9354 - val_loss: 1.1365 - val_categorical_accuracy: 0.6857\n",
            "Epoch 191/200\n",
            "39/39 [==============================] - 5s 132ms/step - loss: 0.1436 - categorical_accuracy: 0.9374 - val_loss: 1.0518 - val_categorical_accuracy: 0.7143\n",
            "Epoch 192/200\n",
            "39/39 [==============================] - 5s 131ms/step - loss: 0.1366 - categorical_accuracy: 0.9668 - val_loss: 0.8924 - val_categorical_accuracy: 0.6571\n",
            "Epoch 193/200\n",
            "39/39 [==============================] - 5s 129ms/step - loss: 0.1596 - categorical_accuracy: 0.9389 - val_loss: 1.0356 - val_categorical_accuracy: 0.6857\n",
            "Epoch 194/200\n",
            "39/39 [==============================] - 5s 132ms/step - loss: 0.1742 - categorical_accuracy: 0.9330 - val_loss: 1.1620 - val_categorical_accuracy: 0.6714\n",
            "Epoch 195/200\n",
            "39/39 [==============================] - 5s 131ms/step - loss: 0.2173 - categorical_accuracy: 0.9190 - val_loss: 1.1071 - val_categorical_accuracy: 0.7143\n",
            "Epoch 196/200\n",
            "39/39 [==============================] - 5s 130ms/step - loss: 0.2047 - categorical_accuracy: 0.9406 - val_loss: 1.0722 - val_categorical_accuracy: 0.6714\n",
            "Epoch 197/200\n",
            "39/39 [==============================] - 5s 129ms/step - loss: 0.1886 - categorical_accuracy: 0.9288 - val_loss: 1.0771 - val_categorical_accuracy: 0.7000\n",
            "Epoch 198/200\n",
            "39/39 [==============================] - 5s 132ms/step - loss: 0.1285 - categorical_accuracy: 0.9558 - val_loss: 0.9622 - val_categorical_accuracy: 0.7143\n",
            "Epoch 199/200\n",
            "39/39 [==============================] - 5s 132ms/step - loss: 0.2345 - categorical_accuracy: 0.9156 - val_loss: 0.9697 - val_categorical_accuracy: 0.6429\n",
            "Epoch 200/200\n",
            "39/39 [==============================] - 5s 133ms/step - loss: 0.1834 - categorical_accuracy: 0.9299 - val_loss: 1.1571 - val_categorical_accuracy: 0.6429\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mx09k6qirna2"
      },
      "source": [
        "model.save('/content/drive/MyDrive/Colab Notebooks/SPEECH_EMOTION_Recognition/Nộp bài(chốt hạ)/model_saver/conv1D_mfcc13_ravdess.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L4jDC7cNsJL1"
      },
      "source": [
        "###test_result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ywGjCaH4sJMK",
        "outputId": "109fb496-2b1b-4bf6-f450-f0349ab6aff5"
      },
      "source": [
        "d = {0: 'happy',\n",
        "     1: 'sad',\n",
        "     2: 'angry',\n",
        "     3: 'fear'}\n",
        "Y_test_pred = np.argmax(model.predict(X_test), axis=-1)\n",
        "Y_test_pred = list(map(lambda x: d[x], Y_test_pred))\n",
        "y_test = np.argmax(y_test, axis=-1)\n",
        "y_test = list(map(lambda x: d[x], y_test))\n",
        "print(classification_report(y_test, Y_test_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f15d9d109e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.73      0.85      0.79        13\n",
            "        fear       0.75      0.57      0.65        21\n",
            "       happy       0.64      0.70      0.67        23\n",
            "         sad       0.76      0.80      0.78        20\n",
            "\n",
            "    accuracy                           0.71        77\n",
            "   macro avg       0.72      0.73      0.72        77\n",
            "weighted avg       0.72      0.71      0.71        77\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "id": "aGj4vva1sJMP",
        "outputId": "9cc5f76e-7422-40d9-cbab-96e2b607381b"
      },
      "source": [
        "import scikitplot as skplt\n",
        "\n",
        "skplt.metrics.plot_confusion_matrix(\n",
        "    y_test, \n",
        "    Y_test_pred,\n",
        "    figsize=(8,8))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f15e198a590>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gc-dIBQIsJMR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ccuTw71436-g"
      },
      "source": [
        "###test_result on best weghts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w_T_6Xll36-1",
        "outputId": "9aad8736-8e3d-4a54-95ff-23096d0f7edf"
      },
      "source": [
        "d = {0: 'happy',\n",
        "     1: 'sad',\n",
        "     2: 'angry',\n",
        "     3: 'fear'}\n",
        "\n",
        "# Define a simple sequential model\n",
        "def create_model():\n",
        "  model = Sequential(name='Audio_CNN_1D')\n",
        "\n",
        "  # LFLB1\n",
        "  model.add(Conv1D(filters=64, kernel_size=(3), strides=1, padding='same', data_format='channels_last',input_shape=input_shape))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation('elu'))\n",
        "  model.add(MaxPooling1D(pool_size=4, strides=4))\n",
        "  model.add(Dropout(0.5))\n",
        "\n",
        "  # LFLB2\n",
        "  model.add(Conv1D(filters=64, kernel_size=3, strides=1, padding='same'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation('elu'))\n",
        "  model.add(MaxPooling1D(pool_size=4, strides=4))\n",
        "  model.add(Dropout(0.25))\n",
        "\n",
        "  # LFLB3\n",
        "  model.add(Conv1D(filters=128, kernel_size=3, strides=1, padding='same'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation('elu'))\n",
        "  model.add(MaxPooling1D(pool_size=4, strides=4))\n",
        "  model.add(Dropout(0.25))\n",
        "\n",
        "  # LFLB4\n",
        "  model.add(Conv1D(filters=128, kernel_size=3, strides=1, padding='same'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation('elu'))\n",
        "  model.add(MaxPooling1D(pool_size=4, strides=4))\n",
        "  model.add(Dropout(0.25))\n",
        "\n",
        "  # LSTM\n",
        "  model.add(LSTM(units=num_lstm))\n",
        "\n",
        "  # FC\n",
        "  model.add(Dense(units=num_classes, activation='softmax'))\n",
        "\n",
        "  # Model compilation\n",
        "  opt= keras.optimizers.Adam(lr=0.01, beta_1=0.9,  beta_2=0.999, amsgrad=False)\n",
        "  model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
        "\n",
        "  return model\n",
        "\n",
        "# Create a basic model instance\n",
        "model = create_model()\n",
        "# Loads the weights\n",
        "model.load_weights('/content/Audio_1DCNN.h5')\n",
        "\n",
        "Y_test_pred = np.argmax(model.predict(X_test), axis=-1)\n",
        "Y_test_pred = list(map(lambda x: d[x], Y_test_pred))\n",
        "y_test = np.argmax(y_test, axis=-1)\n",
        "y_test = list(map(lambda x: d[x], y_test))\n",
        "print(classification_report(y_test, Y_test_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.69      0.69      0.69        13\n",
            "        fear       0.75      0.57      0.65        21\n",
            "       happy       0.55      0.70      0.62        23\n",
            "         sad       0.74      0.70      0.72        20\n",
            "\n",
            "    accuracy                           0.66        77\n",
            "   macro avg       0.68      0.66      0.67        77\n",
            "weighted avg       0.68      0.66      0.66        77\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "id": "hbvPnBa_36-5",
        "outputId": "a159ae89-40e5-4be2-c97d-318b7a68b96b"
      },
      "source": [
        "import scikitplot as skplt\n",
        "\n",
        "skplt.metrics.plot_confusion_matrix(\n",
        "    y_test, \n",
        "    Y_test_pred,\n",
        "    figsize=(8,8))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f15e1478110>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfcAAAHLCAYAAADVzdHxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdeVwV9f7H8dc5bCJESCIiKG1KmWkoinUxDSqXVNIWSy5a2lW74dZ1C43csiy1zOWaZZuhpWZimmmZP9NSr5VlLokLKimKiEsiChz4/WGeIjfEgYHx/fRxHsEs3/nMSc/nfL7z/c7YCgsLCxERERHLsJsdgIiIiBhLyV1ERMRilNxFREQsRsldRETEYpTcRURELEbJXURExGKU3EVEREw2duxYoqKiCA0NJSUlxbn89OnTvPDCC9x///20a9eO559/vljtuZZWoCIiIlI80dHRdOnShdjY2CLLX331VTw8PFi6dCk2m43MzMxitafkLiIiYrLw8PBzlmVnZ7NgwQJWrlyJzWYDoGrVqsVqT8ldRESkFBw/fpzjx4+fs9zHxwcfH59L7p+Wloavry+TJ09m3bp1eHl50bdv3/N+Efg7JXcREbnqZR3Lxu9aL0PbdHd3p2PHjhw7dqzI8vj4eHr37n3J/R0OB2lpadStW5fBgwfz888/06tXL7788ku8vb0vuq+Su4iIXPX8rvUi+skJ/HbwqCHtBQf4svzdZ0lOTsbhcBRZV5yqHSAwMBBXV1fatm0LQIMGDahSpQqpqancfvvtF91XyV1ERAT4LeM4ew8Yk9yxnZmMFhgYWOIm/Pz8iIiI4NtvvyUyMpLU1FQOHz5MSEjIpQ+vp8KJiIhA6APD2ZueZUhbtQL92LZ4eLG3Hz16NMuWLSMzM5MqVarg6+vL4sWLSUtLIyEhgaNHj+Lq6kq/fv1o3rz5JdtTchcREQFC244wNrkvesGQtkpCN7ERERGxGF1zFxERAbDZnNfKDWnLREruIiIi8EdyNygpm5zc1S0vIiJiMarcRURE4EyXvGHd8ubWzqrcRURELEaVu4iICFjqmruSu4iICKhbXkRERMovVe4iIiIAGNgtj6bCiYiIiIFUuYuIiIDuUCciImI5Fhotr255ERERi1HlLiIiApoKJyIiIuWXKncRERHQNXcRuTz5+fk899xzREREEBoayrp16wxpNyoqiqlTpxrSVnk3ZMgQnnjiCbPDEKkQVLnLVevIkSO89dZbLF++nP379+Pt7c2NN97II488Qtu2bXF1Ne6fx7Jly1i0aBHvv/8+NWvW5NprrzWk3Xnz5lGpUiVD2rqYdevW0aVLF9zc3Pjmm2/w8/NzrsvLy6N58+YcPnyYV155hZiYmGK1+f333xMbG8vy5csJDg6+5PZDhw6loKCgxOcgckkWuuau5C5XpfT0dDp37oyLiwt9+vShbt26uLq6smHDBmbMmEFoaCi33nqrYcfbvXs3AQEBNGzY0LA2gSJJtiz4+/uTnJzMk08+6Vz25ZdfluoXjLy8PNzc3LjmmmtK7RgigKXmuatbXq5KI0aMIDc3l08//ZT27dtz8803c/3119OhQwfmz59PSEgIcCaxjBs3jmbNmlGvXj3atGnDZ599VqSt0NBQkpKSGDhwIGFhYdx99928+eabzvVxcXFMnDiRtLQ0QkNDiYqKci4fOnRokbamTp3qXA+wfft2unfvTnh4OHfccQetW7dmwYIFzvV/75Y/ceIEiYmJNG3alHr16tGxY0dWr17tXP/bb78RGhrK559/Ts+ePWnQoAHR0dHMnz+/WO/bQw89xNy5c4ssmzNnDg899NA5277//vvExMQQFhbGP/7xD/r3709GRoYzjtjYWACio6MJDQ0lLi4O+LP7febMmURFRXH77bdz6tSpIt3yubm5PPjgg/z73/92Hu/UqVO0bduW//znP8U6FxErU3KXq87Ro0dZuXIlsbGx560G3dzcqFy5MgATJkxg7ty5JCQk8Nlnn9G+fXsGDhzImjVriuwzZcoUGjduTHJyMj179mTChAnObSZNmkS3bt0ICgpi9erVzJs3r9ixPvvss/j6+vLRRx/x2WefMWTIkIt26SckJLB69WpeffVVkpOTadiwIb169WLnzp1Fths/fjwxMTEsXLiQBx54gGHDhpGamnrJeB544AEOHjzI999/D8DevXtZv349Dz/88Hm3Hzx4MAsXLmTy5Mmkp6fz7LPPAhAYGOj8UjJ37lxWr17NpEmTnPtt3LiRtWvXMnXqVJKTk3FzcyvSrru7O6+99hpr1qzhww8/BGD06NGcPn2aESNGXPI8RM7LZgO7QS/doU6kbO3du5eCggJuvvnmi26Xk5PDzJkzee6552jdujUAvXr14pdffuG///0vd955p3PbNm3a8OijjwIQGxvLhx9+yHfffcedd96Jr68vlStXxsXFBX9//8uKdf/+/Tz55JPOWGvWrHnBbffs2cPSpUuZPn06zZo1A2DYsGH88MMPvP3227z00kvObf/5z3/Spk0bAPr27cvMmTNZt24dN9xww0Xj8fT0pF27dsydO5fw8HDmzJlDs2bNCAgIOGfbrl27On+uWbMmiYmJdOjQgYMHDxIQEOD8kuLn53fO+2K323nllVfw8vK6YCw33HADiYmJJCYmcvjwYRYsWMCsWbPw9va+6DmIXA1UuctVp7CwsFjb7dmzh7y8PBo3blxkeePGjdmxY0eRZbfcckuR36tVq0ZmZuaVBQp069aNYcOGERcXx6RJk9i8efMFtz0bU3h4eJHl4eHhF43XxcWF6667rtjxdurUiS+++IKsrCw+/fRT55eav1u3bh3du3enefPmhIWF0blzZwD27dt3yWPcdNNNF03sZ3Xo0IHo6GimTp1Knz59qF+/frHOQeS8zg6oM+plIiV3ueqEhIRgt9vPSXhX4u/dxjab7ZJfIs63TX5+fpHfn3nmGZYuXUqrVq3Yvn07nTp14rXXXjMl3rNuvfVWateuzbPPPouLiwvNmzc/Z5v9+/fTo0cPgoKCmDBhAp988gn//e9/gTPjGC7F09OzWLFkZ2ezZcsWXFxc2L17d7H2Ebmgs/PcjXqZSMldrjq+vr7cfffdJCUl8fvvv5+zPi8vj5MnTxISEoK7uzvr168vsn79+vXUrl37iuO47rrrnAPMztqyZcs529WsWZPY2FjeeOMN+vTpw0cffXTe9s7GdPZ6+Fnff/+9IfH+VadOnVizZg0PPfQQLi4u56z/5ZdfOHXqFAkJCTRq1Igbb7zxnJ4Bd3d3gCua3jZ8+HBcXV159913WbhwIZ9//nmJ2xKxEiV3uSq98MILuLq60rFjRz777DN27NjBnj17SE5O5qGHHmLPnj14enoSFxfHG2+8wZIlS0hNTWXatGksX76cXr16XXEMd911F2vWrGHJkiXs2bOH6dOnF0nM2dnZjBgxgjVr1pCWlsaWLVtYtWoVN91003nbq1WrFq1atWLEiBGsWrWKnTt3Mnr0aOeIeyN17NiRNWvWFBmt/lchISHYbDbeeecd0tLS+Oqrr5gyZUqRbWrUqIHdbmflypUcPnz4vF+0LmbBggUsXbqUCRMmEBERQb9+/UhMTOS3334r8XnJVc5C3fIaUCdXpRo1avDpp5/y1ltvMXnyZOdNbG666Sa6d+/urHT79++P3W5nzJgxHDlyhFq1avHqq68WGUxXUg8++CApKSmMHDmSvLw82rVrR1xcHMnJyQC4urpy/Phxhg4dyqFDh/D29iYiIoLBgwdfsM0XX3yRV155hYEDB3LixAnq1KnDtGnTLviFoKRcXFwuOsf+lltu4fnnn2f69OlMmzaN2267jYSEBP71r385t6latSrPPvss06dPZ8yYMYSHhzNz5sxiHX/Pnj2MHDmSQYMGOccPdO/enTVr1jBgwAA+/PBDQ29CJFLR2AqLe6FNRETEwkL/+V/2HjxuSFu1AnzY9uHThrRVEvpqKyIiApa6/ayuuYuIiFiMKncRERHQI19FRESk/FLlLiIiApa65q7kLiIiAoCRd5bTg2PKtec/30bWyUvfLlNKZsKD9cwO4aqwK+OE2SFYXjUfD7NDsDS7Dap4uV16QwGU3C8p62Qeh07kmh2GZekmC2Ujz6F3urQV6C2u+Gw2A7vlNaBOREREDKTKXUREBDQVTkRERMovVe4iIiKgqXAiIiKWY6Hkrm55ERERi1HlLiIiAhpQJyIiIuWXKncRERHQTWxEREQs52y3vFGvyzB27FiioqIIDQ0lJSXlnPWTJ0++4LrzUXIXERExWXR0NElJSQQFBZ2zbvPmzfz000/nXXch6pYXEREBwMCpcH/Uzunp6TgcjiJrfHx88PHxKbIsPDz8vK3k5uYycuRIxo8fT5cuXYp9dCV3ERGRUhIbG8u+ffuKLIuPj6d3797F2n/ixIm0b9+e4ODgyzqukruIiAiUylS4pKSk81buxbFhwwY2bdrEgAEDLvvwSu4iIiKAzWbDZlByP9tOYGBgidtYv349O3fuJDo6GoADBw7QvXt3XnrpJSIjIy+6r5K7iIhIOdSjRw969Ojh/D0qKopp06ZRp06dS+6r0fIiIiL8Wbkb9boco0eP5u677+bAgQM8+eSTPPDAA1d0LqrcRURETDZs2DCGDRt20W2+/vrrYren5C4iIgJg++NlVFsmUre8iIiIxahyFxERoXRGy5tFyV1ERISz09yNSu6GNFNi6pYXERGxGFXuIiIiWKtbXpW7iIiIxahyFxERAWwYWLmbPBdOyV1ERAQ0z11ERETKL1XuIiIiaECdiIiIlGOq3EVERAAMrNzNvouNkruIiAjqlhcREZFyTJW7iIgIqtxFRESkHFPlLiIiArqJjZQ/QddWIrFlbd7r3IA3Otalca1rzQ7JcrKysnj04Q5cd60XdW4K4aPZs8wOyXKe6/sU0Y1qc1fdINo1D2P+7PfNDslyZrw5lfuaNyW4qje9e3U3OxwpJarcLcBug4FRN/LltkxGLdtO3QBvBkffxODPfiX9+Gmzw7OMfn2ewd3dnT37DvLzTz/RMeYB6tdvQN3bbjM7NMvo/u//MOKVKbh7eJC6I4Xundpwy231qVs/zOzQLCMgMJD+A59jxfIvOZWTY3Y45YquuUu5EnRtJfwqu7F4SwaFhbD5wAm2ZWRz901+ZodmGdnZ2SyY/wkvDB+Ft7c3/4iM5IG27ZmVNNPs0Czl5tBbcffwAP74oMVG2p5Uk6OylrbtO9CmbQx+VfT58Hc2/kzwV/wy+Vwsm9zz8/PNDsFUNhvU9PU0OwzL2J6SgqurK7Xr1HEuu71BA7Zu2WxiVNb04tD+RNQJIOaeRlQNqE6zqPvNDkmkwjEluU+fPp17772XsLAw2rRpw5dffgnA/Pnzefzxxxk7diyNGzcmKiqKlStXOvdLS0sjNjaWsLAwnnjiCUaMGMGAAQMA+O233wgNDWXu3Lm0aNGCrl270qNHD2bOLFpZtWvXznk8q9h/7BTHTuXTvl4ALjaoX+Ma6gZ44+5q2e9uZe5E9gl8fHyKLLvW51p+//13kyKyrqEvvsZ3W/fz7rylRLdqh5u7h9khyVXCsKrdyDvdlZApn/41a9YkKSmJH374gfj4eAYOHEhGRgYAGzdu5IYbbmDt2rU89dRTDB06lMLCQgAGDBhA/fr1WbduHfHx8SQnJ5/T9vr16/n888+ZMWMGDz74IAsXLnSu+/XXX8nIyKB58+Zlc6JlxFEIr369i4bBPkzvVJ+2twWwZvdRsrJzzQ7NMry9vDl+/HiRZcd/P84111xjUkTW5uLiQsMmd3IwfT9zZr5tdjgiFY4pyb1169YEBARgt9tp06YNISEhbNy4EYAaNWrw6KOP4uLiQocOHTh06BCZmZns37+fX375hT59+uDu7k54eDhRUVHntN27d28qV65MpUqViI6OZvfu3ezevRuA5ORkWrdujbu7e1mebpnYeySH4V9sp/tHGxnz5Q6qXePOjsyTZodlGbXr1CE/P58d27c7l/3y88/cWleD6UqTw5HPb7rmLmXFZvDLRKYk9wULFhATE0N4eDjh4eFs376dI0eOAFC1alXndp6eZ64Znzx5koyMDK699lrnMoDAwMBz2q5evbrzZw8PD1q3bs3ChQspKChg0aJFxMTElNZpmapWFU/cXGy4u9hod1s1qni68X87DpsdlmV4eXkR06EjI0ckkp2dzXfffsuiz5LpHBtndmiWcTjzEEsWzuNk9gkcDgffrvyKJcnziPhHC7NDs5T8/HxOnTqFo8CBw+Hg1KlTV/0YpbOs1C1f5lPh9u3bx7Bhw3jvvfcICwvDxcWlWAnX39+fY8eOkZOT40zw6enp52z39ze0Q4cODBo0iEaNGuHp6UlYmDWn1Nx9kx9Rta/D1W5j68ETjFq2g/yCQrPDspSJk6bS81/dqFWjGn7XXcfEyf/VNDgD2Ww25s6cwYsJ/SkoKCAwqCaDXniZFve3MTs0S5nwyhjGvTza+fu8j2cxYMgwBiUkmhiVGK3Mk3tOTg42mw0/vzPTMD755BO2/6Wr80KCgoKoV68ekyZNol+/fmzevJkVK1Zwzz33XHS/sLAw7HY7L7/8Mu3btzfkHMqjD7/fx4ff7zM7DEvz8/Nj7icLzA7Dsvyuq8o7c5eYHYblDUpIVCK/AM1zvwI333wz3bp147HHHuOuu+4iJSWFhg0bFmvfcePG8dNPPxEREcHrr79OmzZtinX9PCYmhpSUFMt2yYuIiPyVKXeo69+/P/379z/vuo4dOxb5fdu2bc6fa9WqxaxZf97ys1+/ftx4440ABAcHF9n2r2rUqEHDhg2pWbPmlYYuIiJWZeS18qutcr8SGzduZO/evRQUFPDNN9+wfPly7r333ovuk5OTw6xZs+jUqVMZRSkiIhWRBtSZJDMzk969e3P06FGqV6/O8OHDqVu37gW3X7VqFb179+bOO++kbdu2ZRipiIiIeSpUco+Kijrv3PYLadasGT/99FMpRiQiIpahR76KiIhIeVWhKncREZHSYsPAqXAml+6q3EVERCxGlbuIiAjWuomNkruIiAhnpqYbl9wNaabE1C0vIiJiMarcRUREQFPhREREpPxS5S4iIoIG1ImIiFiOlZK7uuVFREQsRpW7iIgIqtxFRETEQGPHjiUqKorQ0FBSUlIAOHLkCP/6179o2bIl7dq1Iz4+nqysrGK1p+QuIiICYOSz3C+zco+OjiYpKYmgoKC/hGPjqaeeYunSpXz22WfUrFmTcePGFas9JXcREZGzbAa9LlN4eDiBgYFFlvn6+hIREeH8/Y477mD//v3Fak/X3EVEREpJeno6DoejyDIfHx98fHwuq52CggJmz55NVFRUsbZXchcREaF0BtTFxsayb9++Iuvi4+Pp3bv3ZbU3atQoKleuzD//+c9iba/kLiIiUkqSkpLOW7lfjrFjx7Jnzx6mTZuG3V68q+lK7iIiIpRO5f736+iXa8KECWzatInp06fj7u5e7P2U3EVEREw2evRoli1bRmZmJk8++SS+vr68/vrrvPnmm1x//fU89thjAAQHBzNlypRLtqfkLiIiwtnnuRvX1uUYNmwYw4YNO2f5tm3bSnR8JXcRERF0hzoREREpx1S5i4iIYG63vNFUuYuIiFiMKncRERHOVu5GXXM3pJkSU3IXERFB3fIiIiJSjqlyFxER4UyXvN2uqXAiIiJSDqlyFxERwVrX3JXcRURE0B3qREREpBxT5S4iIoK65a8qI1uFUlBodhTWdevAxWaHcFV4/vF6ZodgeS0qVTM7BEtztdu4ztvN7DAqDCV3ERERdM1dREREyjFV7iIiIlircldyFxERwVoD6tQtLyIiYjGq3EVERAAwrlseNKBOREREDKTKXUREBGtdc1dyFxERwVqj5dUtLyIiYjGq3EVERLBWt7wqdxEREYtR5S4iIoK1rrkruYuIiKBueRERESnHVLmLiIhwtnI3qlvekGZKTJW7iIiIxahyFxERQdfcRUREpBxT5S4iIgJY6alwSu4iIiKoW15ERETKMVXuIiIiWOsOdarcRURELEaVu4iICNa65q7kLiIigrrlRUREpBxT5S4iIoIqdxERESnHVLmLiIigAXUiIiKWo255ERERMczYsWOJiooiNDSUlJQU5/LU1FQ6depEy5Yt6dSpE7t37y5We0ruIiIifzjbNX+lr8sVHR1NUlISQUFBRZa/8MILdO7cmaVLl9K5c2cSExOL1Z6Su4iIiMnCw8MJDAwssuzw4cNs2bKFtm3bAtC2bVu2bNlCVlbWJdvTNXcRERFK55p7eno6DoejyDofHx98fHwu2UZ6ejoBAQG4uLgA4OLiQrVq1UhPT8fPz++i+yq5i4iIUDqj5WNjY9m3b1+RdfHx8fTu3duYA12AkruIiEgpSUpKOm/lXhyBgYEcPHgQh8OBi4sLDoeDjIyMc7rvz0fJXUREBLDbbNgNKt3PtlOcRHwh1113HbfeeiuLFi0iJiaGRYsWceutt16ySx6U3EVEREw3evRoli1bRmZmJk8++SS+vr4sXryY4cOHM2TIEKZOnYqPjw9jx44tVntK7hYw482pfDTrA7Zu3kSHhzsxadoMs0OyhC6RITzUJJjQwGv47Mf9DJy9EYA7Qnz5T+s61Au+FkdhIet2ZDH8080cOn7a5IitYd2yhXw2YyKHD+zn2uv86fb8OOqENTE7LMs4ffo0Lwzuy7ffrODYkSPUuv4GBgwbSYvolmaHZjoz71A3bNgwhg0bds7ym266iblz51728ct1ct+1axf9+/dn79699O/fny5dupgdUrkUEBhI/4HPsWL5l5zKyTE7HMs4eOw0k5ft4O5b/Knk9ues0Ws93Zi9Zi/f/JpJfkEBIx6qx6uP1eeJ6etNjNYaNq9bxbwpY+k1ehI33HYHxzIzzA7Jchz5+QTWCGb2gmXUCK7J/331BX2eiuPzlesJrhVidnhikHKd3N9++20iIiJITk42O5RyrW37DgD8/OMP7M/Zd4mtpbiW/nIAgPo1r6W6byXn8pW/Hiqy3Qerd/PRM3eWaWxWlfzWa7Tv3oebbm8IQJVq1U2OyHoqe3nRd9CfFWLU/W0IrnU9m37ecNUn9zOVu1FT4QxppsTK9U1s9u/fT+3atQ1ts7CwkIKCAkPblKtbkxv92H7gd7PDqPAKHA52b/2F348c5rmHmjOgbVOSXk0k99Qps0OztMyMg6Tu2k7tW241OxTT2WxgN+il5H4BXbp0Yd26dYwcOZKwsDB27drF2LFjadGiBXfddReJiYmc+uMf/bFjx+jZsydNmzalcePG9OzZkwMHDjjbiouL47XXXuOxxx6jQYMGpKWlmXVaYjG3BF5Dn/tr89JnW80OpcI7lpWJIz+P779ewuA35/LCh5+zN2Uzi96dZHZolpWXl0f/p7vR8dFYbqodanY4YqBym9w/+OADwsPDSUxMZMOGDXz00UekpqayYMECli1bRkZGBlOmTAGgoKCAjh07smLFClasWIGHhwcjR44s0l5ycjKjRo3ixx9/pEaNGmacklhMSNXKvNujCSMXbGH9riNmh1PhuXucufQR/WhXfKtW4xpfP+57/Ck2frfC5MisqaCggP880x03dzeGv/ya2eGUC2fvUGfUy0zlNrn/VWFhIXPmzCEhIQFfX1+8vb3p2bMnixcvBqBKlSq0bNkST09PvL29efrpp1m/vujgpg4dOlC7dm1cXV1xc3Mz4zTEQoKqePLh0xFM+nI7n36vcQ5G8PK5lirVAot8KJr9AWlVhYWFDOnXi8xDGUx9Z7Y+Ey2oXA+oOysrK4ucnBw6duzoXPbXa+c5OTm89NJLrFq1imPHjgGQnZ3tvKsPXNmNBMq7/Px88vPzcRQ4cDgcnDp1CldXV1xdK8T/3nLLxW7DxW7D/sd/3V3tOAoKqXqNO0n/juCDVXuY9d1es8O0lMi2j7B8zvvUa9ocF1c3vpw9gwb/iDY7LMt5fmAfdm7fxgdzF1PJ09PscMoNGwZOhTOmmRKrEJ/+VapUoVKlSixevJiAgIBz1r/zzjukpqYyZ84c/P392bp1Kw8++CCFhYXObaxcAUx4ZQzjXh7t/H3ex7MYMGQYgxKK92hAOb/4+26mX6s6zt87hAfz+hcpFAIhVb3o26o2fVv9OeCz3pClJkRpLW279+b3Y1kkPHIPbu4eNL63LW2ffMbssCxlX9peZn8wA3cPD5rWu8G5fPS4ScQ8/JiJkZnP9scfo9oyU4VI7na7nUceeYQxY8aQmJjIddddx8GDB0lJSaFZs2ZkZ2fj4eGBj48PR48eZfLkyWaHXKYGJSQqkZeCiUu3M3Hp9vOue+MCy+XKuLq6ETdoNHGDRl96YymRoJq12Jlx0uwwpJRViGvuAAMHDiQkJIRHH32Uhg0b8sQTT5CamgpA165dOX36NE2bNqVTp040a9bM5GhFRKSiMWoa3NmXmWyFf+27lnMcPpFHgd6hUtMkcZnZIVwVnn+8ntkhWF6LG6qZHYKludpt1Lqu0qU3vAJPzfqZjBO5hrRVzdudtzs3MKStkqgQ3fIiIiKlzcgpbGaP81JyFxERwdwHxxitwlxzFxERkeJR5S4iIsKZrnS7RbrlVbmLiIhYjCp3ERERdM1dREREyjFV7iIiImgqnIiIiOWoW15ERETKLVXuIiIigB3jpsLZy+tT4QYOHFisawavvPKKoQGJiIjIlblgcg8JCSnLOERERExl++NlVFtmumByj4+PL8s4REREzGXgaHmzR9QV+5r7t99+y+LFi8nKymLatGn88ssvnDhxgjvvvLM04xMREZHLVKzR8jNnzmT48OFcf/31rF+/HoBKlSoxceLEUg1ORESkrNhtxr5MPZfibPT+++/z7rvv0qNHD+z2M7vceOONpKamlmpwIiIicvmK1S2fnZ1NYGAg8Oddd/Lz83Fzcyu9yERERMrQmZvYGHWHOkOaKbFiVe6NGzdm+vTpRZZ98MEHRERElEpQIiIiZe3sHeqMepmpWJX7sGHD6NWrF3PnziU7O5uWLVvi5eXFm2++WdrxiYiIyGUqVnKvVq0an3zyCb/88gv79lcunlYAACAASURBVO0jMDCQ+vXrO6+/i4iIVHRWenBMsbNzQUEBeXl5ADgcDgoLC0stKBERESm5YlXuv/76K8888wy5ubkEBARw4MABPDw8mDJlCrfccktpxygiIlLqjJzCZvZUuGIl94SEBGJjY3nyySex2WwUFhby3nvvkZCQwPz580s7RhEREbkMxeqW3717N127dnVeQ7DZbHTp0oXdu3eXZmwiIiJl549r7ka8zB4uX6zk3rx5c77++usiy1asWEGLFi1KIyYREZEyZzP4ZaZiPfLV4XDQv39/6tWrR/Xq1Tlw4ACbNm0iOjq6zAIVERGR4in2I1/r1Knj/Pnmm28mMjKy9KISEREpY3Zs2A3qTrebXLvrka8iIiIWU+xHvubm5pKamsqRI0eKzHHXI19FRMQKjBwHVyFuP/v999/Tr18/cnNzOXHiBN7e3mRnZ1O9enWWL19e2jGKiIiUuqvuDnUvvfQSTz31FP/73//w8vLif//7H08//TSdO3cu7fhERETkMhV7nnuXLl2KLOvRowfvvfdeacQkIiJS5qz0VLhiJfdrrrmGEydOAODv78+OHTs4fvw4J0+eLNXgRERE5PIV65r7fffdx8qVK2nXrh0PPfQQXbp0wdXVlZYtW5Z2fCIiImXCZjNuKpzZ19yLldyHDh3q/Ll79+40aNCA7OxsmjVrVmqBiYiIlCWzR8uvWLGCiRMnUlhYSGFhIfHx8dx///0lOn6xp8L9VXh4eIkOJiIiIucqLCxk0KBBJCUlUadOHX799Vcef/xx7r33Xuz2Yj+d3emCyb1z587F6lZISkq67IOKiIiUN6UxFS49PR2Hw1FknY+PDz4+PufsY7fb+f333wH4/fffqVatWokSO1wkuT/yyCMlatBqsk87yC8ovPSGUiLJz95tdghXhYj2z5kdguVtXvaq2SFIORQbG8u+ffuKLIuPj6d3795FltlsNl5//XX+/e9/U7lyZbKzs5k+fXqJj3vB5N6hQ4cSNyoiIlLR2CnmFLJitgVnerfPV7n/XX5+Pm+++SZTp06lUaNG/PDDD/Tr14/Fixfj5eV12ccv0TV3ERERubTAwMBibbd161YyMjJo1KgRAI0aNcLT05OdO3dSv379yz6uUV9SREREKrSz19yNel2Os49T37VrFwA7d+7k8OHD1KpVq0TnospdRESEP7rlDZoKd7mVs7+/P8OHD6dv377OLwZjxozB19e3RMdXchcRESkH2rdvT/v27Q1pq1hfLnJzc3nttdeIjo52Xg9YvXo1H374oSFBiIiImM1mO1O5G/GqEPeWHzNmDCkpKYwbN87ZXVC7dm1mz55dqsGJiIjI5StWt/xXX33FsmXLqFy5snNCfUBAAAcPHizV4ERERMrKmdvPGnUTG0OaKbFiJXc3N7dz5ullZWWV+EK/iIhIeXO2S92otsxUrG75Vq1aMXjwYNLS0gDIyMhg5MiRPPDAA6UanIiIiFy+YiX3/v37ExwcTPv27Tl+/DgtW7akWrVqPPPMM6Udn4iISJk4+1Q4o15mKla3vLu7OwkJCSQkJJCVlUWVKlVMf1atiIiInF+xkvvZ7vizsrOznT/XrFnT2IhERERMYLfZsBtUuBrVTkkVK7nfd9992Gw2Cgv/fDra2cp969atpROZiIhIGbJh3D3Zze7bLlZy//XXX4v8fujQISZPnkx4eHipBCUiIiIlV6IvKf7+/gwdOpQJEyYYHY+IiIgprDSgrsQ9ELt27SInJ8fIWERERMQAxeqW79y5c5HR8Tk5OezYsUNT4URExDKuugF1jzzySJHfPT09ueWWW7j++utLIyYRERG5ApdM7g6Hg7Vr1zJq1Cjc3d3LIiYREZEyZ8O4a+XlfrS8i4sL3377rW5aIyIilnbV3Vu+a9euTJo0iby8vNKOR0RERK7QRSv3RYsW0bZtWz788EMyMzN599138fPzK1LF/9///V9pxygiIlLqbAYOqDO7t/uiyT0xMZG2bdvy6quvllU8IiIicoUumtzP3m62SZMmZRKMiIiIWYy8+YzZw9QumtwLCgpYu3ZtkXvK/92dd95peFAiIiJlzUoD6i6a3HNzcxk6dOgFk7vNZmP58uWlEpiIiIiUzEWTu6enp5K3iIhcFWx//DGqLTMZ9XQ7ERERKSeKNaBORETE6q6aa+4bNmwoqzhERERMZTMwuZs9Wl7d8iIiIhZTrKfCiYiIWJ3NZjPsznJm36FOlbuIiIjFqHIXERHhTLVr2IA6Y5qpsMcXERERg6lyFxER4Sq6t7yIiMjVwm7gI1+NaqfExzf16CIiImK4MknuUVFRfPfdd2VxqKvS6dOnGdKvF80ahlL/hmq0vSeC/1u+1OywLOe5vk8R3ag2d9UNol3zMObPft/skCq8Xp3uZnXSII6ue43pI/5ZZJ1nJTdef+5R0r5+mQPfvMqXM/qZFKW16PPiws7exMaIl7rl5Yo58vMJrBHM7AXLqBFck//76gv6PBXH5yvXE1wrxOzwLKP7v//DiFem4O7hQeqOFLp3asMtt9Wnbv0ws0OrsNIPHWPsW19w71234unhVmTdlGGP4+rqQthDo8k6lk2D0GCTorQWfV5cHZTcLaCylxd9Bw1z/h51fxuCa13Ppp836B+rgW4OvdX5s8125ulRaXtSldyvQPLXPwPQsG4tggJ8ncvrXB/AA81v5+ZWz/N79ikANmxNMyVGq9HnxYVZaUBdmV1z37p1K+3ataNRo0b069eP06dPc+zYMXr27EnTpk1p3LgxPXv25MCBA8594uLiGD9+PA8//DANGzbk6aef5ujRowD89ttvhIaG8vHHHxMZGUlkZCQzZswA4NChQzRo0IAjR44429q8eTNNmzYlLy+vrE7ZNJkZB0ndtZ3at9x66Y3lsrw4tD8RdQKIuacRVQOq0yzqfrNDsqTweiHsTT/C873akPb1y6yfk8CD0XeYHZYl6fPiT3Zshr7MPZcysmTJEt5++22WL1/Otm3bmD9/PgUFBXTs2JEVK1awYsUKPDw8GDlyZJH9FixYwJgxY1i9ejWurq6MHj26yPp169axbNkyZsyYwVtvvcV3332Hv78/TZo0YcmSJc7tkpOTeeCBB3BzK9r1ZzV5eXn0f7obHR+N5abaoWaHYzlDX3yN77bu5915S4lu1Q43dw+zQ7KkoGq+1Ktdg2MnTnHj/UPpP3YOb42MI/SGALNDsxR9XlhXmSX3uLg4AgIC8PX15Z577mHr1q1UqVKFli1b4unpibe3N08//TTr168vsl9MTAx16tShcuXK9O3bly+++AKHw+Fc/8wzz1C5cmVCQ0Pp2LEjixYtAqBDhw4sXLgQAIfDweLFi4mJiSmr0zVFQUEB/3mmO27ubgx/+TWzw7EsFxcXGja5k4Pp+5kz822zw7GkU6fzyM3L5+W3vyAv38HqH3awcn0K9zZVdWkUfV6c62y3vFEvM5XZNXd/f3/nz56enmRkZJCTk8NLL73EqlWrOHbsGADZ2dk4HA5cXFwACAwMdO5Xo0YN8vLyinS3/3V9UFAQKSkpAERHR/PCCy+QlpZGamoq3t7e1K9fv1TP0UyFhYUM6deLzEMZvDPrU8v3UJQHDkc+v+1JNTsMS/pl+75zlhWaEIdV6fPC+kyd5/7OO++QmprKnDlz+PHHH0lKSgLO/MU7Kz09vcjPbm5uVKlS5bzr9+/fT7Vq1QDw8PCgdevWLFy4kOTkZMtX7c8P7MPO7dt4a+Y8Knl6mh2O5RzOPMSShfM4mX0Ch8PBtyu/YknyPCL+0cLs0Co0Fxc7Hu6uuLjYcbH/+fPqH3eQln6Egd3ux8XFzp0NbqR5eG2+XLPV7JAtQZ8X52fUNLizL1PPxcyDZ2dn4+HhgY+PD0ePHmXy5MnnbLNw4UJ27NhBTk4OEydOpGXLls6qHmDq1Knk5OSwfft25s+fT5s2bZzrYmJi+PTTT/n6668tndz3pe1l9gcz2LJpI03r3cDt1/tz+/X+JM/7yOzQLMNmszF35gzuj7iVZrfXYsLoYQx64WVa3N/m0jvLBQ15qhVH173OwG7307ltE46ue50hT7UiP7+AR/q/SavI2zi46lWmJD7OU89/QMrug2aHXOHp8+LCzsxztxnyumq65c+na9euDBgwgKZNm1KtWjWefPJJvvrqqyLbxMTEMGTIEHbt2kWTJk0YPnx4kfVNmjThvvvuo7CwkG7duhEZGelc16hRI+x2O7fddhtBQUFlcUqmCKpZi50ZJ80Ow9L8rqvKO3OXXHpDuSwvvvk5L775+XnXbd11gBZdx5dxRNanz4urQ5kk96+//rrI771793b+PHPmzCLrHnvssSK/16pVi//85z8XbPuhhx6iU6dOF1xfvXp12rVrdznhiojIVciGgfPcjWmmxCx9E5uNGzeyZcsWpk6danYoIiIiF3X69GnGjBnDmjVr8PDw4I477mDUqFElasuyyX3w4MF89dVXDB06FG9vb7PDERGRcs7sp8K9+uqreHh4sHTpUmw2G5mZmSU+frlO7n/vsv+r4OBgtm3bdsH1Y8eOLY2QREREDJednc2CBQtYuXIltj++GFStWrXE7ZXr5C4iIlJWSuPe8unp6UVuvAbg4+ODj49PkWVpaWn4+voyefJk1q1bh5eXF3379iU8PLxEx1dyFxER4czccKPmh59tJzY2ln37it6UKT4+vsjAcjhzJ9W0tDTq1q3L4MGD+fnnn+nVqxdffvlliS4tK7mLiIiUkqSkpPNW7n8XGBiIq6srbdu2BaBBgwZUqVKF1NRUbr/99ss+rpK7iIgIgM3mvN5tRFtQ9BbpF+Pn50dERATffvstkZGRpKamcvjwYUJCSvYYXiV3ERGRcmDEiBEkJCQwduxYXF1deeWVV85b5ReHkruIiAh/3MTGwLYuV82aNS86S+xyKLmLiIhg/jx3I5n64BgRERExnip3ERERzO+WN5IqdxEREYtR5S4iIkLp3KHOLEruIiIigM3Aee6GzZcvIXXLi4iIWIwqdxEREc4MgjOq4tWAOhERETGUKncRERF0zV1ERETKMVXuIiIiWOsmNkruIiIigA0Du+VNTu/qlhcREbEYVe4iIiKcqXaNqnjNrpzNPr6IiIgYTJW7iIgI1poKp+QuIiKCtUbLq1teRETEYlS5i4iIABj4yFezS3dV7iIiIhajyl1ERISzU+GMKbnNrpyV3EVERDjTJW9Ut7zJg+VN/3IhIiIiBlPlLiIiwh/3ljeoW173lhcRERFDqXIXERHBWtfcldxFREQ4M1LeuNHy6pYXERERA6lyvwQvDxcKCs2OwrquqaS/gmVh+ZxRZodgebf1+NDsECytlr8326Y/XroH0R3qREREpLxS2SQiIoK1BtSpchcREbEYVe4iIiJY6yY2Su4iIiKA3XbmZVRbZlK3vIiIiMWochcREcFa3fKq3EVERCxGlbuIiAhn7jtj2FQ4Y5opMSV3ERER1C0vIiIi5ZgqdxEREc50yRs1hU13qBMRERFDqXIXERHBWtfcldxFRETQg2NERESkFEyePJnQ0FBSUlKuqB1V7iIiIvwxz93Ati7X5s2b+emnnwgKCrri46tyFxERMVlubi4jR45k+PDhhrSnyl1ERASw22zYDbpYfrad9PR0HA5HkXU+Pj74+PgUWTZx4kTat29PcHCwIcdXchcRESklsbGx7Nu3r8iy+Ph4evfu7fx9w4YNbNq0iQEDBhh2XCV3ERERSueae1JS0nkr979av349O3fuJDo6GoADBw7QvXt3XnrpJSIjI0t0fCV3ERERKJXsHhgYeMlNe/ToQY8ePZy/R0VFMW3aNOrUqVPiw2tAnYiIiMWochcREfmD2XeWA/j666+vuA1V7iIiIhajyl1ERARr3X5WyV1ERATz71BnJHXLi4iIWIwqdxEREbBU6a7KXURExGJUuYuIiHBmGpxxhbu5pbuSu4iICNYaLa9ueREREYtR5S4iIoKlxtOpchcREbEaVe4iIiJnmV1yG0SVu4iIiMWochcREUFT4URERCxHU+GkXJnx5lTua96U4Kre9O7V3exwLEvvc9lJ272Te+oFMmJAT7NDqfB6ta7L6lcf5Oicbkzv3fy82zz3aBg5n/6Le+rXKOPopLRcVck9Li6OuXPnmh2G4QICA+k/8Dkej3vC7FAsTe9z2Rk/YiC33B5mdhiWkH7kJGPnbuD95dvOu/6G6tfQ8a4bSc/KLuPIyiebQS+zXVXJ3aratu9Am7Yx+FXxMzsUS9P7XDa+WvQJ1/hcS/idd5sdiiUkr93NZ//bQ9bvp8+7/vV//YNhH/yP3PyCMo5MSpOSu4iUG9knjvP2Gy/T+7nRZodyVeh41w2cznew9Mc0s0MpH4wq28tB+V5hBtRNnz6dmTNncuLECapVq8bw4cPx8vLixRdfZOfOnVSqVIn777+fIUOG4O7uDsC3337LqFGjOHToEDExMRQWFpp8FiJyMW+9Poa2D/+TatWDzA7F8rwruTEitjEPDP/c7FDKDSuNlq8QlfuuXbtISkpi3rx5bNiwgRkzZhAUFITdbue5555j7dq1fPTRR6xZs4ZZs2YBkJWVRXx8PP369WPt2rXUqlWLH3/80eQzEZELSdnyC+u/W0mnJ542O5SrwrDHGjJr5Xb2HjphdihSCipE5e7i4kJubi47d+7Ez8+P4ODgc7YJDg6mU6dOrF+/nieeeIJvvvmG2rVr06pVKwC6du3KO++8U9ahi0gxbfjfag7sS6Nji/oA5JzMxuFwsHvHNt5d8H/mBmdBLeoHEXSdFz1a1QXA36cSHw6IZsKnGxn/6c8mR2cOK02FqxDJPSQkhISEBCZNmsSOHTuIjIxkyJAhnDx5kpdffplNmzaRk5ODw+HgtttuAyAjI4Pq1as727DZbAQGBpp1CqUqPz+f/Px8HAUOHA4Hp06dwtXVFVfXCvG/t8LQ+1y6Yjp15d4HOjp/nz1jMun79jJgxHgTo6r4XOw2XF3suNhtuNhteLi5kO8ooM0Li3Fz+bPzdvWrDzL43bW6/m4RFaJbHqBdu3bMnj2bFStWYLPZGDduHMOHD+fGG29k6dKl/Pjjj/Tv3995Xd3f358DBw449y8sLCQ9Pd2s8EvVhFfGUKuaD29MeJV5H8+iVjUfJrwyxuywLEfvc+mq5FmZ6/wDnC/Pyl64e1Siil9Vs0Or0IY8EsbROd0Y+NAddG5Rm6NzujHkkTCyfj/NwaM5zpejoJAjJ06TfSrf7JBNY6HxdBWjct+1axcHDx6kUaNGuLu74+HhQUFBAdnZ2Xh5eeHl5cXOnTuZPXs2fn5npik1b96ckSNHsmzZMqKiokhKSiIzM9PkMykdgxISGZSQaHYYlqf3uWx17zPE7BAs4cWPf+TFjy893uiWnh+VQTTlnIWe+VohKvfc3FzGjx9PREQEkZGRZGVl8eyzzzJ48GAWLVpEw4YNef7552nTpo1zHz8/PyZOnOjcb8+ePTRs2NDEsxARESkbtkLND7uowyfyKNA7JBXc9gMaEV3aogfNMzsES6vl78226Y+X6jFSDpwkz2HMB76bi4061Ssb0lZJVIjKXURERIqvQlxzFxERKW1Wmgqnyl1ERMRiVLmLiIhgqcHySu4iIiKApbK7uuVFREQsRpW7iIgIeiqciIiIlGOq3EVERAAMnApn9jV3JXcREREsNZ5O3fIiIiJWo8pdRETkLLNLboOochcREbEYVe4iIiJYayqckruIiAh6cIyIiIiUY6rcRURE0FQ4ERERKcdUuYuIiIClSncldxEREZMdOXKEQYMGsXfvXtzd3QkJCWHkyJH4+fmVqD11y4uIiHB2Kpxxfy7r2DYbTz31FEuXLuWzzz6jZs2ajBs3rsTnospdRESE0pkKl56ejsPhKLLOx8cHHx+fIst8fX2JiIhw/n7HHXcwe/bsEh9fyV1ERKSUxMbGsm/fviLL4uPj6d279wX3KSgoYPbs2URFRZX4uEruIiIilM54uqSkpPNW7hczatQoKleuzD//+c8SH1/JXUREpJQEBgZe1vZjx45lz549TJs2Dbu95MPilNxFRETA9KlwEyZMYNOmTUyfPh13d/crOrySu4iIyB/MeuDL9u3befPNN7n++ut57LHHAAgODmbKlCklak/JXURExGS1a9dm27ZthrWn5C4iIoKeCiciIiLlmCp3ERERTB9PZygldxEREdQtLyIiIuWYKncRERHA/M5046hyFxERsRhV7iIiIuiau4iIiJRjqtwvwW6dSzByFfNw1ff40lbL39vsECwt6DqvUj+GlabC2QoLCwtNjkFERMR0GcdzcRiUEV1sUM3nyh7+ciX0dV5ERMRi1C0vIiLCmSfCWaVbXpW7iIiIxahyFxERAWPLbZNLdyV3ERGRP5jdnW4UdcuLiIhYjCp3ERER/rhDnYFtmUmVu4iIiMWochcREUFT4UQsZ9euXcTExBAWFsYHH3xgdjgVWlRUFN99953ZYYgB4uLimDt3rtlhlB2bwS8TqXIXAd5++20iIiJITk42OxQRkSumyv0qlJ+fb3YI5c7+/fupXbu2oW0WFhZSUFBgaJsiUnosVLgruZc306dP59577yUsLIw2bdrw5ZdfAjB//nwef/xxxo4dS+PGjYmKimLlypXO/dLS0oiNjSUsLIwnnniCESNGMGDAAAB+++03QkNDmTt3Li1atKBr16706NGDmTNnFjl2u3btnMe7mnTp0oV169YxcuRIwsLC2LVrF2PHjqVFixbcddddJCYmcurUKQCOHTtGz549adq0KY0bN6Znz54cOHDA2VZcXByvvfYajz32GA0aNCAtLc2s0zLV1q1badeuHY0aNaJfv36cPn26WO/d+PHjefjhh2nYsCFPP/00R48eBf78O/zxxx8TGRlJZGQkM2bMAODQoUM0aNCAI0eOONvavHkzTZs2JS8vr2xPvByZPn06zZo1IywsjJYtW7JmzRo2btxIp06dCA8PJzIykpEjR5Kbm+vc59tvv6VVq1Y0atSIkSNHoueKVVxK7uVMzZo1SUpK4ocffiA+Pp6BAweSkZEBwMaNG7nhhhtYu3YtTz31FEOHDnX+4xswYAD169dn3bp1xMfHn7d7ef369Xz++efMmDGDBx98kIULFzrX/frrr2RkZNC8efOyOdFy5IMPPiA8PJzExEQ2bNjARx99RGpqKgsWLGDZsmVkZGQwZcoUAAoKCujYsSMrVqxgxYoVeHh4MHLkyCLtJScnM2rUKH788Udq1KhhximZbsmSJbz99tssX76cbdu2MX/+/GK9dwsWLGDMmDGsXr0aV1dXRo8eXWT9unXrWLZsGTNmzOCtt97iu+++w9/fnyZNmrBkyRLndsnJyTzwwAO4ubmVyfmWN7t27SIpKYl58+axYcMGZsyYQVBQEHa7neeee461a9fy0UcfsWbNGmbNmgVAVlYW8fHx9OvXj7Vr11KrVi1+/PFHk8+kbNlsxr7MpORezrRu3ZqAgADsdjtt2rQhJCSEjRs3AlCjRg0effRRXFxc6NChA4cOHSIzM5P9+/fzyy+/0KdPH9zd3QkPDycqKuqctnv37k3lypWpVKkS0dHR7N69m927dwNnPgxbt26Nu7t5jygsDwoLC5kzZw4JCQn4+vri7e1Nz549Wbx4MQBVqlShZcuWeHp64u3tzdNPP8369euLtNGhQwdq166Nq6vrVZtc4uLiCAgIwNfXl3vuuYetW7cW672LiYmhTp06VK5cmb59+/LFF1/gcDic65955hkqV65MaGgoHTt2ZNGiRcCZ9/zsl1WHw8HixYuJiYkpuxMuZ1xcXMjNzWXnzp3k5eURHBxMrVq1qFevHnfccQeurq4EBwfTqVMn5/+Db775htq1a9OqVSvc3Nzo2rUrVatWNflMpKQ0oK6cWbBgAe+++y779u0D4OTJkxw5cgQXF5ci/9A8PT2LrL/22mudywACAwNJT08v0nb16tWdP3t4eNC6dWsWLlxIfHw8ixYt4o033ijNU6sQsrKyyMnJoWPHjs5lf712npOTw0svvcSqVas4duwYANnZ2TgcDlxcXIAz7/3Vzt/f3/mzp6cnGRkZl/3e1ahRg7y8vCLd7X9dHxQUREpKCgDR0dG88MILpKWlkZqaire3N/Xr1y/VcyzPQkJCSEhIYNKkSezYsYPIyEiGDBnCyZMnefnll9m0aRM5OTk4HA5uu+02ADIyMop8Rthstqvu77KVpsIpuZcj+/btY9iwYbz33nuEhYXh4uJSrOrD39+fY8eOkZOT40zwf0/scOYf61916NCBQYMG0ahRIzw9PQkLCzPmRCqwKlWqUKlSJRYvXkxAQMA569955x1SU1OZM2cO/v7+bN26lQcffLDItcm/v89yRnHeu7/+vU1PT8fNzY0qVao4l6enp3PTTTcBZwZBVqtWDSj6ZfXstMarXbt27WjXrh0nTpwgMTGRcePGkZGRQd26dRk/fjze3t689957LF26FDjzOfLXMRCFhYXn/RyxMt2hTkpFTk4ONpsNPz8/AD755BO2b99+yf2CgoKoV68ekyZNIjc3lw0bNrBixYpL7hcWFobdbufll1+mffv2Vxy/Fdjtdh555BHGjBnD4cOHATh48CCrVq0CzlSaHh4e+Pj4cPToUSZPnmxmuBVKcd67hQsXsmPHDnJycpg4cSItW7Z0VvUAU6dOJScnh+3btzN//nzatGnjXBcTE8Onn37K119/fdUn9127drFmzRpyc3Nxd3fHw8MDu91OdnY2Xl5eeHl5sXPnTmbPnu3cp3nz5mzfvp1ly5aRn5/PBx98QGZmpolnIVdCyb0cufnmm+nWrRuPPfYYd911FykpKTRs2LBY+44bN46ffvqJiIgIXn/9ddq0aVOs6+cxMTGkpKRc9R+GfzVw4EBCQkJ49NFHadiwIU888QSpuhEQWAAACFtJREFUqakAdO3aldOnT9O0aVM6depEs2bNTI624ijOexcTE8OQIUP4xz/+QW5uLkOHDi2yvkmTJtx333088cQTdOvWjcjISOe6Ro0aYbfbue222wgKCir18ynPcnNzGT9+PBEREURGRpKVlcWzzz7L4MGDWbRoEQ0bNuT5558v8uXIz8+PiRMnOvfbs2dPsT9/pPyxFWqugyX169ePG2+8kT59+lx0uwULFvDxxx8X+QYvYoa4uDjat2/PI488cs663377jejoaDZv3oyr64WvJnbp0oV27dqdtw2RSzmW46DAoIxot8G1ni6X3rCUqHK3iI0bN7J3714KCgr45ptvWL58Offee+9F98nJyWHWrFl06tSpjKIUKT0bN25ky5YttG7d2uxQpIKy0lQ4DaiziMzMTHr37s3Ro0epXr06w4cPp27duhfcftWqVfTu3Zs777yTtm3blmGkIsYbPHgwX331FUOHDsXb29vscKTCMm60vNnULS8iIgIcP1WAURnRZgOfSuZ1jqtyFxERwdiudLO75XXNXURExGJUuYuIiGDsXeXMvnavyl2knBkyZAivvfYaAN9//z0tW7Ysk+OGhoayZ8+e866Li4tj7ty5xWonKiqK7777rkQxXMm+IoawwvNeUXIXKZGoqCjq169PWFgYd911F0OGDCE7O9vw44SHhztvD3oxZx8JLCICSu4iJTZt2jQ2bNjAp59+yqZNm/jvf/97zjb5+fkmRCYiJWEz+I+ZlNxFrlBAQADNmjVzPgcgNDSUpKQk7v//9u4vpOnvj+P405Ymo2QpOTYooSIQsjRmExtWkH+QYCjYwqBVF/7JBUEU5YXSosCLujHDC/MiIkoiBf+MllToRWhGmjC6SFZd+HEjoyT/rrXvhb/vh6Z+xfwpftn3/bjazufsHM65efE5+5zPyckhJycHgBcvXmC1WjGZTBw/fpz379+rv/d4PBQUFJCWlsb58+eZnp5Wr/X09JCVlaV+VxQFh8NBRkYGZrMZp9PJ0NAQ1dXV9Pf3k5aWhslkAmZfQVpTU8OhQ4fIzMykqqqKqakpta2GhgYsFgsWi4XHjx8vebyfP3/m5MmTmM1mzGYzFy5cYGxsLKzO4OAg+fn5pKenc+XKlbAxLTYXQoiVIeEuxP9JURS6urpITk5Wyzo7O2lqaqKjowOPx0NlZSVOp5Oenh5sNhtnz55lZmaGmZkZKioqsFqt9Pb2kpeXh9vtXrCfYDBIaWkpRqOR58+f09XVRX5+Pjt27ODq1aukpqby9u1b+vr6gNnzBrxeLy0tLbjdbvx+P3V1dcDs2d2NjY00Njbidrt59erVkscbCoUoLS2lu7sbl8vFyMgItbW1YXVaW1u5e/cuz549w+v1cufOHYBF50KItRZJb6iTcBdimSoqKjCZTBQXF5Oenk5ZWZl6raSkBJ1OR2xsLI8ePcJms7F37140Gg0FBQVER0fT39/PwMAAgUAAu91OdHQ0eXl5pKSkLNjfu3fv8Pv9XLp0Ca1Wy4YNG9S79LlCoRBNTU1UVlai0+nYuHEjpaWltLe3A+ByuSgsLGTXrl1otVocDseSx52UlMSBAweIiYkhPj6e06dP8/r167A6J06cwGAwoNPpKC8vV/tdbC6EECtHtsIJsUx1dXVkZmYueM1gMKifh4eHaWlp4f79+2pZIBDA7/cTFRWFXq8POwPeaDQu2KaiKBiNxkUPTvnb169fmZycpLCwUC0LhUL8+vULAL/fz+7du9Vrf3KK2pcvX7h+/Tp9fX2Mj48TCoWIi4sLq/P7+I1GI36/H1h8LoRYa5G0FU7CXYhV8HtYGwwGysrKKC8vn1evt7cXn89HKBRSfzM8PMzWrVvn1TUYDCiKws+fP+cFfNScNcDNmzcTGxtLe3s7er1+XluJiYkoiqJ+Hx4eXvLYbt26RVRUFK2treh0Ojo7O3E6nWF15radmJiojuGf5kKINbfWibyCZFleiFVWVFTEw4cPGRgYIBQKMTExwcuXL/nx4wepqamsX7+ee/fuEQgEcLvdDA4OLtjOnj172LJlCzdv3mRiYoLp6WnevHkDQEJCAj6fT/3vet26dRQVFXHjxg1GR0cB8Pl8dHd3A5CXl0dzczMfPnxgcnKS27dvL3k84+PjaLVaNm3ahM/no6GhYV6dBw8eMDIywrdv36ivr1fPDV9sLoT4r/N6vdhsNnJzc7HZbHz8+HHZbUm4C7HKUlJSuHbtGk6nk/T0dHJycnjy5AkAMTEx1NbW0tzczP79++no6CA7O3vBdjQaDfX19Xz69InDhw+TlZWFy+UCICMjg507d2KxWDCbzQBcvHiRpKQkjh07xr59+zh16hRerxeAgwcPYrfbsdvtZGdnk5GRseTxOBwOPB4PJpOJkpISdUfA744ePcqZM2c4cuQI27ZtU+/UF5sLIdbaWm+Fq66upri4mKdPn1JcXExVVdXyxyKnwgkhhBAwFYCVCsQoIDZ66fVHR0fJzc2lp6cHjUZDMBjEbDbjdruJj4//4/7lP3chhBCC/21hW+E2FUUhGAyGlcXFxc17CFVRFPR6PRqNBphdqfv72RgJdyGEEGKZNqxwIk5NTWG1Wvn+/XtYucPh4Ny5cyvb2RwS7kIIIcQqmJmZWfCZkrl37TC7k8Tn8xEMBtVleb/fH7at9E9IuAshhBCrYKHl93+SkJBAcnIybW1tWK1W2traSE5OXtaSPMgDdUIIIcS/wtDQEJcvX2ZsbIy4uDhqamrYvn37stqScBdCCCEijOxzF0IIISKMhLsQQggRYSTchRBCiAgj4S6EEEJEGAl3IYQQIsJIuAshhBARRsJdCCGEiDAS7kIIIUSE+QsNlkuhwdyxsAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 576x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQ3MyEHt36-7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0zRQZ1nG8Lxk"
      },
      "source": [
        "# mfcc_26 + conv1D:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDzhXx0B8LyC"
      },
      "source": [
        "audio_duration = 3\n",
        "sampling_rate = 22050\n",
        "input_length = sampling_rate * audio_duration"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lw2cG43e8LyD"
      },
      "source": [
        "features = []\n",
        "labels = []\n",
        "for i in range(len(Ravdess_DF['Paths'])):\n",
        "  if ((Ravdess_DF['Emotion'][i] == '03') | (Ravdess_DF['Emotion'][i] == '04') | \n",
        "      (Ravdess_DF['Emotion'][i] == '05') | (Ravdess_DF['Emotion'][i] == '06')):\n",
        "    signal, sr = librosa.load(Ravdess_DF['Paths'][i])\n",
        "\n",
        "    if len(signal) > input_length:\n",
        "      signal = signal[0:input_length]\n",
        "    elif  input_length > len(signal):\n",
        "      max_offset = input_length - len(signal)  \n",
        "      signal = np.pad(signal, (0, max_offset), \"constant\")\n",
        "\n",
        "    mfcc = librosa.feature.mfcc(y=signal, sr=sr, n_mfcc=26).T\n",
        "    mfcc = mfcc.reshape(-1,1)\n",
        "    features.append(mfcc)\n",
        "\n",
        "    if Ravdess_DF['Emotion'][i] == '03':\n",
        "      labels.append(0)\n",
        "    elif Ravdess_DF['Emotion'][i] == '04':\n",
        "      labels.append(1)\n",
        "    elif Ravdess_DF['Emotion'][i] == '05':\n",
        "      labels.append(2)\n",
        "    elif Ravdess_DF['Emotion'][i] == '06':\n",
        "      labels.append(3)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lD55rhfH8LyE"
      },
      "source": [
        "X = features\n",
        "y = labels\n",
        "\n",
        "y = np.array(y)\n",
        "y = to_categorical(y)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=0)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=0)\n",
        "\n",
        "X_train = np.array(X_train)\n",
        "X_test = np.array(X_test)\n",
        "X_val = np.array(X_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TuVcTkxv8LyE",
        "outputId": "48dfaf35-8f7b-4fac-b804-e26218b2bad6"
      },
      "source": [
        "X_train.shape,X_test.shape,y_train.shape,y_test.shape\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((621, 3380, 1), (77, 3380, 1), (621, 4), (77, 4))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HhVEPOyx8LyG"
      },
      "source": [
        "\n",
        "# CNN I/P Config\n",
        "num_classes = 4\n",
        "input_shape = X_train.shape[1:]\n",
        "learning_rate = 0.0001\n",
        "decay = 1e-6\n",
        "momentum = 0.9\n",
        "\n",
        "#LSTM Configuration\n",
        "num_lstm = 256"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WKPKoL-88LyH",
        "outputId": "a737e0db-5e20-4375-c288-ca13a854eada"
      },
      "source": [
        "model = Sequential(name='Audio_CNN_1D')\n",
        "\n",
        "# LFLB1\n",
        "model.add(Conv1D(filters=64, kernel_size=(3), strides=1, padding='same', data_format='channels_last',input_shape=input_shape))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('elu'))\n",
        "model.add(MaxPooling1D(pool_size=4, strides=4))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "# LFLB2\n",
        "model.add(Conv1D(filters=64, kernel_size=3, strides=1, padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('elu'))\n",
        "model.add(MaxPooling1D(pool_size=4, strides=4))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# LFLB3\n",
        "model.add(Conv1D(filters=128, kernel_size=3, strides=1, padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('elu'))\n",
        "model.add(MaxPooling1D(pool_size=4, strides=4))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# LFLB4\n",
        "model.add(Conv1D(filters=128, kernel_size=3, strides=1, padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('elu'))\n",
        "model.add(MaxPooling1D(pool_size=4, strides=4))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# LSTM\n",
        "model.add(LSTM(units=num_lstm))\n",
        "\n",
        "# FC\n",
        "model.add(Dense(units=num_classes, activation='softmax'))\n",
        "\n",
        "# Model compilation\n",
        "opt= keras.optimizers.Adam(lr=0.01, beta_1=0.9,  beta_2=0.999, amsgrad=False)\n",
        "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
        "\n",
        "model.summary()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"Audio_CNN_1D\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_16 (Conv1D)           (None, 3380, 64)          256       \n",
            "_________________________________________________________________\n",
            "batch_normalization_16 (Batc (None, 3380, 64)          256       \n",
            "_________________________________________________________________\n",
            "activation_16 (Activation)   (None, 3380, 64)          0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_16 (MaxPooling (None, 845, 64)           0         \n",
            "_________________________________________________________________\n",
            "dropout_16 (Dropout)         (None, 845, 64)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_17 (Conv1D)           (None, 845, 64)           12352     \n",
            "_________________________________________________________________\n",
            "batch_normalization_17 (Batc (None, 845, 64)           256       \n",
            "_________________________________________________________________\n",
            "activation_17 (Activation)   (None, 845, 64)           0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_17 (MaxPooling (None, 211, 64)           0         \n",
            "_________________________________________________________________\n",
            "dropout_17 (Dropout)         (None, 211, 64)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_18 (Conv1D)           (None, 211, 128)          24704     \n",
            "_________________________________________________________________\n",
            "batch_normalization_18 (Batc (None, 211, 128)          512       \n",
            "_________________________________________________________________\n",
            "activation_18 (Activation)   (None, 211, 128)          0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_18 (MaxPooling (None, 52, 128)           0         \n",
            "_________________________________________________________________\n",
            "dropout_18 (Dropout)         (None, 52, 128)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_19 (Conv1D)           (None, 52, 128)           49280     \n",
            "_________________________________________________________________\n",
            "batch_normalization_19 (Batc (None, 52, 128)           512       \n",
            "_________________________________________________________________\n",
            "activation_19 (Activation)   (None, 52, 128)           0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_19 (MaxPooling (None, 13, 128)           0         \n",
            "_________________________________________________________________\n",
            "dropout_19 (Dropout)         (None, 13, 128)           0         \n",
            "_________________________________________________________________\n",
            "lstm_4 (LSTM)                (None, 256)               394240    \n",
            "_________________________________________________________________\n",
            "dense_20 (Dense)             (None, 4)                 1028      \n",
            "=================================================================\n",
            "Total params: 483,396\n",
            "Trainable params: 482,628\n",
            "Non-trainable params: 768\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aWs3a8Ok8LyI",
        "outputId": "30d733f8-ddde-4bac-f7ae-3b16d2797d72"
      },
      "source": [
        "#Train Config\n",
        "\n",
        "batch_size = 16\n",
        "num_epochs = 200\n",
        "\n",
        "# Model Training\n",
        "lr_reduce = ReduceLROnPlateau(monitor='val_loss', factor=0.9, patience=20, min_lr=0.000001)\n",
        "# Please change the model name accordingly.\n",
        "mcp_save = ModelCheckpoint('/content/Audio_1DCNN.h5', save_best_only=True, monitor='val_categorical_accuracy', mode='max')\n",
        "cnnhistory=model.fit(X_train, y_train, batch_size=batch_size, epochs=num_epochs,validation_data=(X_val, y_val), callbacks=[mcp_save, lr_reduce])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "39/39 [==============================] - 15s 274ms/step - loss: 1.9676 - categorical_accuracy: 0.3488 - val_loss: 1.6166 - val_categorical_accuracy: 0.1857\n",
            "Epoch 2/200\n",
            "39/39 [==============================] - 10s 245ms/step - loss: 1.2756 - categorical_accuracy: 0.4107 - val_loss: 1.5244 - val_categorical_accuracy: 0.1857\n",
            "Epoch 3/200\n",
            "39/39 [==============================] - 9s 240ms/step - loss: 1.2569 - categorical_accuracy: 0.4111 - val_loss: 1.7697 - val_categorical_accuracy: 0.1857\n",
            "Epoch 4/200\n",
            "39/39 [==============================] - 9s 239ms/step - loss: 1.2512 - categorical_accuracy: 0.4100 - val_loss: 2.0437 - val_categorical_accuracy: 0.1857\n",
            "Epoch 5/200\n",
            "39/39 [==============================] - 9s 242ms/step - loss: 1.1861 - categorical_accuracy: 0.4686 - val_loss: 1.9157 - val_categorical_accuracy: 0.1857\n",
            "Epoch 6/200\n",
            "39/39 [==============================] - 9s 243ms/step - loss: 1.2061 - categorical_accuracy: 0.4108 - val_loss: 1.9692 - val_categorical_accuracy: 0.2857\n",
            "Epoch 7/200\n",
            "39/39 [==============================] - 10s 250ms/step - loss: 1.2207 - categorical_accuracy: 0.4266 - val_loss: 1.7344 - val_categorical_accuracy: 0.2857\n",
            "Epoch 8/200\n",
            "39/39 [==============================] - 10s 248ms/step - loss: 1.1861 - categorical_accuracy: 0.4689 - val_loss: 1.6430 - val_categorical_accuracy: 0.2857\n",
            "Epoch 9/200\n",
            "39/39 [==============================] - 10s 248ms/step - loss: 1.1913 - categorical_accuracy: 0.4317 - val_loss: 1.6735 - val_categorical_accuracy: 0.3000\n",
            "Epoch 10/200\n",
            "39/39 [==============================] - 10s 244ms/step - loss: 1.1542 - categorical_accuracy: 0.4600 - val_loss: 1.5753 - val_categorical_accuracy: 0.3286\n",
            "Epoch 11/200\n",
            "39/39 [==============================] - 10s 248ms/step - loss: 1.2268 - categorical_accuracy: 0.4358 - val_loss: 1.4850 - val_categorical_accuracy: 0.3286\n",
            "Epoch 12/200\n",
            "39/39 [==============================] - 10s 248ms/step - loss: 1.1578 - categorical_accuracy: 0.5014 - val_loss: 1.2429 - val_categorical_accuracy: 0.4571\n",
            "Epoch 13/200\n",
            "39/39 [==============================] - 10s 245ms/step - loss: 1.2251 - categorical_accuracy: 0.4474 - val_loss: 1.2576 - val_categorical_accuracy: 0.4000\n",
            "Epoch 14/200\n",
            "39/39 [==============================] - 9s 241ms/step - loss: 1.2080 - categorical_accuracy: 0.4798 - val_loss: 1.5778 - val_categorical_accuracy: 0.2714\n",
            "Epoch 15/200\n",
            "39/39 [==============================] - 9s 243ms/step - loss: 1.1260 - categorical_accuracy: 0.5095 - val_loss: 1.6094 - val_categorical_accuracy: 0.3286\n",
            "Epoch 16/200\n",
            "39/39 [==============================] - 10s 246ms/step - loss: 1.1737 - categorical_accuracy: 0.4827 - val_loss: 1.5025 - val_categorical_accuracy: 0.3714\n",
            "Epoch 17/200\n",
            "39/39 [==============================] - 10s 245ms/step - loss: 1.1090 - categorical_accuracy: 0.5090 - val_loss: 1.4233 - val_categorical_accuracy: 0.3571\n",
            "Epoch 18/200\n",
            "39/39 [==============================] - 10s 244ms/step - loss: 1.1174 - categorical_accuracy: 0.5306 - val_loss: 1.2931 - val_categorical_accuracy: 0.3857\n",
            "Epoch 19/200\n",
            "39/39 [==============================] - 10s 245ms/step - loss: 1.1196 - categorical_accuracy: 0.4796 - val_loss: 1.6469 - val_categorical_accuracy: 0.3000\n",
            "Epoch 20/200\n",
            "39/39 [==============================] - 10s 246ms/step - loss: 1.1433 - categorical_accuracy: 0.4682 - val_loss: 1.2466 - val_categorical_accuracy: 0.4571\n",
            "Epoch 21/200\n",
            "39/39 [==============================] - 10s 248ms/step - loss: 1.0817 - categorical_accuracy: 0.5242 - val_loss: 1.4994 - val_categorical_accuracy: 0.3714\n",
            "Epoch 22/200\n",
            "39/39 [==============================] - 10s 249ms/step - loss: 1.1179 - categorical_accuracy: 0.4797 - val_loss: 1.5562 - val_categorical_accuracy: 0.3714\n",
            "Epoch 23/200\n",
            "39/39 [==============================] - 10s 244ms/step - loss: 1.0985 - categorical_accuracy: 0.4999 - val_loss: 1.2065 - val_categorical_accuracy: 0.4857\n",
            "Epoch 24/200\n",
            "39/39 [==============================] - 10s 247ms/step - loss: 1.0103 - categorical_accuracy: 0.5565 - val_loss: 1.2936 - val_categorical_accuracy: 0.4286\n",
            "Epoch 25/200\n",
            "39/39 [==============================] - 9s 243ms/step - loss: 1.1016 - categorical_accuracy: 0.5056 - val_loss: 1.1225 - val_categorical_accuracy: 0.5143\n",
            "Epoch 26/200\n",
            "39/39 [==============================] - 10s 250ms/step - loss: 1.0447 - categorical_accuracy: 0.5367 - val_loss: 1.3264 - val_categorical_accuracy: 0.3571\n",
            "Epoch 27/200\n",
            "39/39 [==============================] - 9s 242ms/step - loss: 1.0818 - categorical_accuracy: 0.5390 - val_loss: 1.2703 - val_categorical_accuracy: 0.4571\n",
            "Epoch 28/200\n",
            "39/39 [==============================] - 10s 246ms/step - loss: 1.1078 - categorical_accuracy: 0.5013 - val_loss: 1.2664 - val_categorical_accuracy: 0.4571\n",
            "Epoch 29/200\n",
            "39/39 [==============================] - 10s 247ms/step - loss: 1.0509 - categorical_accuracy: 0.5179 - val_loss: 1.1930 - val_categorical_accuracy: 0.4714\n",
            "Epoch 30/200\n",
            "39/39 [==============================] - 10s 247ms/step - loss: 1.0378 - categorical_accuracy: 0.5328 - val_loss: 1.1490 - val_categorical_accuracy: 0.5000\n",
            "Epoch 31/200\n",
            "39/39 [==============================] - 10s 249ms/step - loss: 1.0165 - categorical_accuracy: 0.5485 - val_loss: 1.2972 - val_categorical_accuracy: 0.5286\n",
            "Epoch 32/200\n",
            "39/39 [==============================] - 10s 248ms/step - loss: 1.0794 - categorical_accuracy: 0.5091 - val_loss: 1.1308 - val_categorical_accuracy: 0.5286\n",
            "Epoch 33/200\n",
            "39/39 [==============================] - 10s 249ms/step - loss: 1.0041 - categorical_accuracy: 0.5418 - val_loss: 1.1112 - val_categorical_accuracy: 0.4857\n",
            "Epoch 34/200\n",
            "39/39 [==============================] - 10s 250ms/step - loss: 1.0208 - categorical_accuracy: 0.5592 - val_loss: 1.2858 - val_categorical_accuracy: 0.4571\n",
            "Epoch 35/200\n",
            "39/39 [==============================] - 10s 252ms/step - loss: 0.9960 - categorical_accuracy: 0.5818 - val_loss: 1.4112 - val_categorical_accuracy: 0.4286\n",
            "Epoch 36/200\n",
            "39/39 [==============================] - 10s 249ms/step - loss: 0.9867 - categorical_accuracy: 0.5848 - val_loss: 1.3979 - val_categorical_accuracy: 0.3714\n",
            "Epoch 37/200\n",
            "39/39 [==============================] - 10s 251ms/step - loss: 1.0554 - categorical_accuracy: 0.5407 - val_loss: 1.2975 - val_categorical_accuracy: 0.4143\n",
            "Epoch 38/200\n",
            "39/39 [==============================] - 10s 249ms/step - loss: 1.0402 - categorical_accuracy: 0.5619 - val_loss: 1.2270 - val_categorical_accuracy: 0.4571\n",
            "Epoch 39/200\n",
            "39/39 [==============================] - 10s 245ms/step - loss: 1.0087 - categorical_accuracy: 0.5600 - val_loss: 1.2597 - val_categorical_accuracy: 0.4857\n",
            "Epoch 40/200\n",
            "39/39 [==============================] - 10s 246ms/step - loss: 0.9697 - categorical_accuracy: 0.5906 - val_loss: 1.2413 - val_categorical_accuracy: 0.4714\n",
            "Epoch 41/200\n",
            "39/39 [==============================] - 10s 246ms/step - loss: 1.0674 - categorical_accuracy: 0.5219 - val_loss: 1.2062 - val_categorical_accuracy: 0.4429\n",
            "Epoch 42/200\n",
            "39/39 [==============================] - 10s 244ms/step - loss: 1.0413 - categorical_accuracy: 0.5645 - val_loss: 1.3574 - val_categorical_accuracy: 0.4857\n",
            "Epoch 43/200\n",
            "39/39 [==============================] - 10s 246ms/step - loss: 1.0103 - categorical_accuracy: 0.5419 - val_loss: 1.1836 - val_categorical_accuracy: 0.4714\n",
            "Epoch 44/200\n",
            "39/39 [==============================] - 10s 245ms/step - loss: 1.0191 - categorical_accuracy: 0.5238 - val_loss: 1.1162 - val_categorical_accuracy: 0.5143\n",
            "Epoch 45/200\n",
            "39/39 [==============================] - 10s 244ms/step - loss: 0.9770 - categorical_accuracy: 0.5890 - val_loss: 1.2452 - val_categorical_accuracy: 0.4857\n",
            "Epoch 46/200\n",
            "39/39 [==============================] - 10s 249ms/step - loss: 1.0196 - categorical_accuracy: 0.5480 - val_loss: 1.2323 - val_categorical_accuracy: 0.4429\n",
            "Epoch 47/200\n",
            "39/39 [==============================] - 10s 245ms/step - loss: 0.9522 - categorical_accuracy: 0.5836 - val_loss: 1.0854 - val_categorical_accuracy: 0.5000\n",
            "Epoch 48/200\n",
            "39/39 [==============================] - 10s 247ms/step - loss: 0.9763 - categorical_accuracy: 0.5753 - val_loss: 1.0888 - val_categorical_accuracy: 0.4714\n",
            "Epoch 49/200\n",
            "39/39 [==============================] - 10s 245ms/step - loss: 1.0073 - categorical_accuracy: 0.5414 - val_loss: 1.0950 - val_categorical_accuracy: 0.5571\n",
            "Epoch 50/200\n",
            "39/39 [==============================] - 10s 248ms/step - loss: 0.9966 - categorical_accuracy: 0.5494 - val_loss: 1.1714 - val_categorical_accuracy: 0.4857\n",
            "Epoch 51/200\n",
            "39/39 [==============================] - 10s 248ms/step - loss: 0.9213 - categorical_accuracy: 0.6051 - val_loss: 1.1661 - val_categorical_accuracy: 0.4857\n",
            "Epoch 52/200\n",
            "39/39 [==============================] - 10s 249ms/step - loss: 0.9301 - categorical_accuracy: 0.6109 - val_loss: 1.2344 - val_categorical_accuracy: 0.4857\n",
            "Epoch 53/200\n",
            "39/39 [==============================] - 10s 250ms/step - loss: 0.9805 - categorical_accuracy: 0.5433 - val_loss: 1.1479 - val_categorical_accuracy: 0.5143\n",
            "Epoch 54/200\n",
            "39/39 [==============================] - 10s 245ms/step - loss: 0.9626 - categorical_accuracy: 0.5948 - val_loss: 1.1073 - val_categorical_accuracy: 0.5143\n",
            "Epoch 55/200\n",
            "39/39 [==============================] - 10s 247ms/step - loss: 0.9476 - categorical_accuracy: 0.6034 - val_loss: 1.2305 - val_categorical_accuracy: 0.4143\n",
            "Epoch 56/200\n",
            "39/39 [==============================] - 10s 249ms/step - loss: 0.9865 - categorical_accuracy: 0.5870 - val_loss: 1.1037 - val_categorical_accuracy: 0.5000\n",
            "Epoch 57/200\n",
            "39/39 [==============================] - 10s 255ms/step - loss: 1.0294 - categorical_accuracy: 0.5531 - val_loss: 1.6284 - val_categorical_accuracy: 0.3429\n",
            "Epoch 58/200\n",
            "39/39 [==============================] - 10s 256ms/step - loss: 0.9660 - categorical_accuracy: 0.5846 - val_loss: 1.1344 - val_categorical_accuracy: 0.3714\n",
            "Epoch 59/200\n",
            "39/39 [==============================] - 10s 254ms/step - loss: 1.0022 - categorical_accuracy: 0.5689 - val_loss: 1.2367 - val_categorical_accuracy: 0.5000\n",
            "Epoch 60/200\n",
            "39/39 [==============================] - 10s 248ms/step - loss: 0.9519 - categorical_accuracy: 0.5915 - val_loss: 1.1922 - val_categorical_accuracy: 0.5000\n",
            "Epoch 61/200\n",
            "39/39 [==============================] - 10s 247ms/step - loss: 0.9121 - categorical_accuracy: 0.5846 - val_loss: 1.2645 - val_categorical_accuracy: 0.4286\n",
            "Epoch 62/200\n",
            "39/39 [==============================] - 10s 251ms/step - loss: 0.9240 - categorical_accuracy: 0.6029 - val_loss: 1.2145 - val_categorical_accuracy: 0.5286\n",
            "Epoch 63/200\n",
            "39/39 [==============================] - 10s 250ms/step - loss: 0.9286 - categorical_accuracy: 0.6199 - val_loss: 1.1547 - val_categorical_accuracy: 0.5571\n",
            "Epoch 64/200\n",
            "39/39 [==============================] - 10s 257ms/step - loss: 0.9568 - categorical_accuracy: 0.6194 - val_loss: 1.1706 - val_categorical_accuracy: 0.5571\n",
            "Epoch 65/200\n",
            "39/39 [==============================] - 10s 255ms/step - loss: 0.9162 - categorical_accuracy: 0.6056 - val_loss: 1.2943 - val_categorical_accuracy: 0.4429\n",
            "Epoch 66/200\n",
            "39/39 [==============================] - 10s 256ms/step - loss: 1.0052 - categorical_accuracy: 0.5713 - val_loss: 1.1796 - val_categorical_accuracy: 0.5429\n",
            "Epoch 67/200\n",
            "39/39 [==============================] - 10s 251ms/step - loss: 0.9054 - categorical_accuracy: 0.5997 - val_loss: 1.0876 - val_categorical_accuracy: 0.5286\n",
            "Epoch 68/200\n",
            "39/39 [==============================] - 10s 253ms/step - loss: 0.8775 - categorical_accuracy: 0.6369 - val_loss: 1.1040 - val_categorical_accuracy: 0.4857\n",
            "Epoch 69/200\n",
            "39/39 [==============================] - 10s 256ms/step - loss: 0.8724 - categorical_accuracy: 0.6363 - val_loss: 1.0902 - val_categorical_accuracy: 0.5714\n",
            "Epoch 70/200\n",
            "39/39 [==============================] - 10s 255ms/step - loss: 0.8822 - categorical_accuracy: 0.6221 - val_loss: 1.1905 - val_categorical_accuracy: 0.5571\n",
            "Epoch 71/200\n",
            "39/39 [==============================] - 10s 256ms/step - loss: 0.8808 - categorical_accuracy: 0.6385 - val_loss: 1.0770 - val_categorical_accuracy: 0.5286\n",
            "Epoch 72/200\n",
            "39/39 [==============================] - 10s 253ms/step - loss: 0.8152 - categorical_accuracy: 0.6522 - val_loss: 1.1088 - val_categorical_accuracy: 0.5000\n",
            "Epoch 73/200\n",
            "39/39 [==============================] - 10s 253ms/step - loss: 0.8635 - categorical_accuracy: 0.6250 - val_loss: 1.0219 - val_categorical_accuracy: 0.5429\n",
            "Epoch 74/200\n",
            "39/39 [==============================] - 10s 256ms/step - loss: 0.8732 - categorical_accuracy: 0.6103 - val_loss: 1.3102 - val_categorical_accuracy: 0.4857\n",
            "Epoch 75/200\n",
            "39/39 [==============================] - 10s 255ms/step - loss: 0.9109 - categorical_accuracy: 0.6011 - val_loss: 1.2489 - val_categorical_accuracy: 0.4571\n",
            "Epoch 76/200\n",
            "39/39 [==============================] - 10s 254ms/step - loss: 0.8255 - categorical_accuracy: 0.6243 - val_loss: 1.3237 - val_categorical_accuracy: 0.5286\n",
            "Epoch 77/200\n",
            "39/39 [==============================] - 10s 253ms/step - loss: 0.8792 - categorical_accuracy: 0.6291 - val_loss: 1.1630 - val_categorical_accuracy: 0.5857\n",
            "Epoch 78/200\n",
            "39/39 [==============================] - 10s 257ms/step - loss: 0.8833 - categorical_accuracy: 0.6047 - val_loss: 1.0787 - val_categorical_accuracy: 0.5857\n",
            "Epoch 79/200\n",
            "39/39 [==============================] - 10s 252ms/step - loss: 0.7861 - categorical_accuracy: 0.6636 - val_loss: 1.1968 - val_categorical_accuracy: 0.5857\n",
            "Epoch 80/200\n",
            "39/39 [==============================] - 10s 254ms/step - loss: 0.8675 - categorical_accuracy: 0.6453 - val_loss: 1.2362 - val_categorical_accuracy: 0.4571\n",
            "Epoch 81/200\n",
            "39/39 [==============================] - 10s 254ms/step - loss: 0.8018 - categorical_accuracy: 0.6424 - val_loss: 1.1064 - val_categorical_accuracy: 0.5000\n",
            "Epoch 82/200\n",
            "39/39 [==============================] - 10s 255ms/step - loss: 0.8667 - categorical_accuracy: 0.6372 - val_loss: 1.1807 - val_categorical_accuracy: 0.5714\n",
            "Epoch 83/200\n",
            "39/39 [==============================] - 10s 257ms/step - loss: 0.7924 - categorical_accuracy: 0.6627 - val_loss: 1.1203 - val_categorical_accuracy: 0.4571\n",
            "Epoch 84/200\n",
            "39/39 [==============================] - 10s 257ms/step - loss: 0.8215 - categorical_accuracy: 0.6667 - val_loss: 1.1742 - val_categorical_accuracy: 0.5143\n",
            "Epoch 85/200\n",
            "39/39 [==============================] - 10s 255ms/step - loss: 0.8778 - categorical_accuracy: 0.6000 - val_loss: 1.0524 - val_categorical_accuracy: 0.5714\n",
            "Epoch 86/200\n",
            "39/39 [==============================] - 10s 256ms/step - loss: 0.7432 - categorical_accuracy: 0.6934 - val_loss: 1.0557 - val_categorical_accuracy: 0.6000\n",
            "Epoch 87/200\n",
            "39/39 [==============================] - 10s 258ms/step - loss: 0.8047 - categorical_accuracy: 0.6810 - val_loss: 1.0520 - val_categorical_accuracy: 0.5857\n",
            "Epoch 88/200\n",
            "39/39 [==============================] - 10s 256ms/step - loss: 0.8019 - categorical_accuracy: 0.6672 - val_loss: 1.2560 - val_categorical_accuracy: 0.4714\n",
            "Epoch 89/200\n",
            "39/39 [==============================] - 10s 260ms/step - loss: 0.8102 - categorical_accuracy: 0.6652 - val_loss: 1.0136 - val_categorical_accuracy: 0.6286\n",
            "Epoch 90/200\n",
            "39/39 [==============================] - 10s 256ms/step - loss: 0.7955 - categorical_accuracy: 0.6540 - val_loss: 1.4419 - val_categorical_accuracy: 0.4286\n",
            "Epoch 91/200\n",
            "39/39 [==============================] - 10s 260ms/step - loss: 0.7863 - categorical_accuracy: 0.6743 - val_loss: 1.3078 - val_categorical_accuracy: 0.4714\n",
            "Epoch 92/200\n",
            "39/39 [==============================] - 10s 250ms/step - loss: 0.7789 - categorical_accuracy: 0.6546 - val_loss: 1.1657 - val_categorical_accuracy: 0.5143\n",
            "Epoch 93/200\n",
            "39/39 [==============================] - 10s 254ms/step - loss: 0.8161 - categorical_accuracy: 0.6657 - val_loss: 1.2739 - val_categorical_accuracy: 0.5286\n",
            "Epoch 94/200\n",
            "39/39 [==============================] - 10s 251ms/step - loss: 0.8055 - categorical_accuracy: 0.6767 - val_loss: 1.0857 - val_categorical_accuracy: 0.6143\n",
            "Epoch 95/200\n",
            "39/39 [==============================] - 10s 255ms/step - loss: 0.7881 - categorical_accuracy: 0.6815 - val_loss: 1.1455 - val_categorical_accuracy: 0.5000\n",
            "Epoch 96/200\n",
            "39/39 [==============================] - 10s 254ms/step - loss: 0.7670 - categorical_accuracy: 0.6574 - val_loss: 1.0689 - val_categorical_accuracy: 0.5286\n",
            "Epoch 97/200\n",
            "39/39 [==============================] - 10s 257ms/step - loss: 0.7251 - categorical_accuracy: 0.6861 - val_loss: 1.2460 - val_categorical_accuracy: 0.5000\n",
            "Epoch 98/200\n",
            "39/39 [==============================] - 10s 255ms/step - loss: 0.7520 - categorical_accuracy: 0.6826 - val_loss: 1.2787 - val_categorical_accuracy: 0.4857\n",
            "Epoch 99/200\n",
            "39/39 [==============================] - 10s 255ms/step - loss: 0.7506 - categorical_accuracy: 0.6733 - val_loss: 1.2018 - val_categorical_accuracy: 0.5286\n",
            "Epoch 100/200\n",
            "39/39 [==============================] - 10s 255ms/step - loss: 0.7526 - categorical_accuracy: 0.6898 - val_loss: 1.3450 - val_categorical_accuracy: 0.4143\n",
            "Epoch 101/200\n",
            "39/39 [==============================] - 10s 255ms/step - loss: 0.7442 - categorical_accuracy: 0.6896 - val_loss: 1.2383 - val_categorical_accuracy: 0.5000\n",
            "Epoch 102/200\n",
            "39/39 [==============================] - 10s 250ms/step - loss: 0.7541 - categorical_accuracy: 0.6927 - val_loss: 1.0469 - val_categorical_accuracy: 0.5714\n",
            "Epoch 103/200\n",
            "39/39 [==============================] - 10s 254ms/step - loss: 0.7264 - categorical_accuracy: 0.7074 - val_loss: 1.3907 - val_categorical_accuracy: 0.4714\n",
            "Epoch 104/200\n",
            "39/39 [==============================] - 10s 253ms/step - loss: 0.7183 - categorical_accuracy: 0.6942 - val_loss: 1.1365 - val_categorical_accuracy: 0.5571\n",
            "Epoch 105/200\n",
            "39/39 [==============================] - 10s 258ms/step - loss: 0.8286 - categorical_accuracy: 0.6584 - val_loss: 1.2442 - val_categorical_accuracy: 0.5000\n",
            "Epoch 106/200\n",
            "39/39 [==============================] - 10s 254ms/step - loss: 0.7266 - categorical_accuracy: 0.6861 - val_loss: 1.1161 - val_categorical_accuracy: 0.5429\n",
            "Epoch 107/200\n",
            "39/39 [==============================] - 10s 254ms/step - loss: 0.6840 - categorical_accuracy: 0.7304 - val_loss: 1.2014 - val_categorical_accuracy: 0.5286\n",
            "Epoch 108/200\n",
            "39/39 [==============================] - 10s 252ms/step - loss: 0.6959 - categorical_accuracy: 0.7052 - val_loss: 1.1629 - val_categorical_accuracy: 0.5429\n",
            "Epoch 109/200\n",
            "39/39 [==============================] - 10s 251ms/step - loss: 0.7716 - categorical_accuracy: 0.6704 - val_loss: 1.1607 - val_categorical_accuracy: 0.5143\n",
            "Epoch 110/200\n",
            "39/39 [==============================] - 10s 251ms/step - loss: 0.8049 - categorical_accuracy: 0.6694 - val_loss: 1.1751 - val_categorical_accuracy: 0.5429\n",
            "Epoch 111/200\n",
            "39/39 [==============================] - 10s 249ms/step - loss: 0.7346 - categorical_accuracy: 0.7214 - val_loss: 1.3962 - val_categorical_accuracy: 0.4429\n",
            "Epoch 112/200\n",
            "39/39 [==============================] - 10s 249ms/step - loss: 0.7038 - categorical_accuracy: 0.6990 - val_loss: 1.2583 - val_categorical_accuracy: 0.4571\n",
            "Epoch 113/200\n",
            "39/39 [==============================] - 10s 250ms/step - loss: 0.6657 - categorical_accuracy: 0.7365 - val_loss: 1.3420 - val_categorical_accuracy: 0.4429\n",
            "Epoch 114/200\n",
            "39/39 [==============================] - 10s 252ms/step - loss: 0.6298 - categorical_accuracy: 0.7377 - val_loss: 1.4829 - val_categorical_accuracy: 0.4143\n",
            "Epoch 115/200\n",
            "39/39 [==============================] - 10s 257ms/step - loss: 0.6544 - categorical_accuracy: 0.7321 - val_loss: 1.3590 - val_categorical_accuracy: 0.4857\n",
            "Epoch 116/200\n",
            "39/39 [==============================] - 10s 249ms/step - loss: 0.7797 - categorical_accuracy: 0.6972 - val_loss: 1.0291 - val_categorical_accuracy: 0.5143\n",
            "Epoch 117/200\n",
            "39/39 [==============================] - 10s 255ms/step - loss: 0.6777 - categorical_accuracy: 0.7175 - val_loss: 1.1015 - val_categorical_accuracy: 0.5000\n",
            "Epoch 118/200\n",
            "39/39 [==============================] - 10s 253ms/step - loss: 0.6996 - categorical_accuracy: 0.7118 - val_loss: 1.0796 - val_categorical_accuracy: 0.4857\n",
            "Epoch 119/200\n",
            "39/39 [==============================] - 10s 256ms/step - loss: 0.6456 - categorical_accuracy: 0.7122 - val_loss: 1.0843 - val_categorical_accuracy: 0.4714\n",
            "Epoch 120/200\n",
            "39/39 [==============================] - 10s 253ms/step - loss: 0.6806 - categorical_accuracy: 0.7030 - val_loss: 1.1090 - val_categorical_accuracy: 0.5714\n",
            "Epoch 121/200\n",
            "39/39 [==============================] - 10s 256ms/step - loss: 0.5882 - categorical_accuracy: 0.7829 - val_loss: 1.1435 - val_categorical_accuracy: 0.5429\n",
            "Epoch 122/200\n",
            "39/39 [==============================] - 10s 249ms/step - loss: 0.6884 - categorical_accuracy: 0.7189 - val_loss: 1.3141 - val_categorical_accuracy: 0.4571\n",
            "Epoch 123/200\n",
            "39/39 [==============================] - 10s 246ms/step - loss: 0.5944 - categorical_accuracy: 0.7656 - val_loss: 1.3328 - val_categorical_accuracy: 0.5000\n",
            "Epoch 124/200\n",
            "39/39 [==============================] - 10s 252ms/step - loss: 0.5822 - categorical_accuracy: 0.7721 - val_loss: 1.3883 - val_categorical_accuracy: 0.4571\n",
            "Epoch 125/200\n",
            "39/39 [==============================] - 10s 250ms/step - loss: 0.6410 - categorical_accuracy: 0.7385 - val_loss: 1.4726 - val_categorical_accuracy: 0.4429\n",
            "Epoch 126/200\n",
            "39/39 [==============================] - 10s 252ms/step - loss: 0.6167 - categorical_accuracy: 0.7648 - val_loss: 1.2334 - val_categorical_accuracy: 0.5571\n",
            "Epoch 127/200\n",
            "39/39 [==============================] - 10s 253ms/step - loss: 0.6121 - categorical_accuracy: 0.7432 - val_loss: 1.3692 - val_categorical_accuracy: 0.4571\n",
            "Epoch 128/200\n",
            "39/39 [==============================] - 10s 253ms/step - loss: 0.7085 - categorical_accuracy: 0.7101 - val_loss: 1.1506 - val_categorical_accuracy: 0.4429\n",
            "Epoch 129/200\n",
            "39/39 [==============================] - 10s 254ms/step - loss: 0.6563 - categorical_accuracy: 0.7188 - val_loss: 1.1358 - val_categorical_accuracy: 0.5571\n",
            "Epoch 130/200\n",
            "39/39 [==============================] - 10s 255ms/step - loss: 0.6227 - categorical_accuracy: 0.7554 - val_loss: 1.0995 - val_categorical_accuracy: 0.5286\n",
            "Epoch 131/200\n",
            "39/39 [==============================] - 10s 252ms/step - loss: 0.6016 - categorical_accuracy: 0.7859 - val_loss: 1.1040 - val_categorical_accuracy: 0.5000\n",
            "Epoch 132/200\n",
            "39/39 [==============================] - 10s 256ms/step - loss: 0.5545 - categorical_accuracy: 0.7546 - val_loss: 1.2194 - val_categorical_accuracy: 0.5143\n",
            "Epoch 133/200\n",
            "39/39 [==============================] - 10s 251ms/step - loss: 0.6063 - categorical_accuracy: 0.7681 - val_loss: 1.3369 - val_categorical_accuracy: 0.4857\n",
            "Epoch 134/200\n",
            "39/39 [==============================] - 10s 252ms/step - loss: 0.5588 - categorical_accuracy: 0.7716 - val_loss: 1.2503 - val_categorical_accuracy: 0.5429\n",
            "Epoch 135/200\n",
            "39/39 [==============================] - 10s 253ms/step - loss: 0.6320 - categorical_accuracy: 0.7482 - val_loss: 1.1928 - val_categorical_accuracy: 0.4286\n",
            "Epoch 136/200\n",
            "39/39 [==============================] - 10s 256ms/step - loss: 0.6438 - categorical_accuracy: 0.7369 - val_loss: 1.2839 - val_categorical_accuracy: 0.5143\n",
            "Epoch 137/200\n",
            "39/39 [==============================] - 10s 249ms/step - loss: 0.5893 - categorical_accuracy: 0.7525 - val_loss: 1.3958 - val_categorical_accuracy: 0.4143\n",
            "Epoch 138/200\n",
            "39/39 [==============================] - 10s 247ms/step - loss: 0.5646 - categorical_accuracy: 0.7565 - val_loss: 1.2540 - val_categorical_accuracy: 0.5143\n",
            "Epoch 139/200\n",
            "39/39 [==============================] - 10s 250ms/step - loss: 0.6397 - categorical_accuracy: 0.7576 - val_loss: 1.3795 - val_categorical_accuracy: 0.5000\n",
            "Epoch 140/200\n",
            "39/39 [==============================] - 10s 250ms/step - loss: 0.6946 - categorical_accuracy: 0.7293 - val_loss: 1.2156 - val_categorical_accuracy: 0.5286\n",
            "Epoch 141/200\n",
            "39/39 [==============================] - 10s 251ms/step - loss: 0.6184 - categorical_accuracy: 0.7524 - val_loss: 1.1620 - val_categorical_accuracy: 0.5143\n",
            "Epoch 142/200\n",
            "39/39 [==============================] - 10s 252ms/step - loss: 0.5890 - categorical_accuracy: 0.7532 - val_loss: 1.0509 - val_categorical_accuracy: 0.5571\n",
            "Epoch 143/200\n",
            "39/39 [==============================] - 10s 253ms/step - loss: 0.5184 - categorical_accuracy: 0.8116 - val_loss: 1.1963 - val_categorical_accuracy: 0.5000\n",
            "Epoch 144/200\n",
            "39/39 [==============================] - 10s 248ms/step - loss: 0.5273 - categorical_accuracy: 0.7924 - val_loss: 1.1963 - val_categorical_accuracy: 0.4714\n",
            "Epoch 145/200\n",
            "39/39 [==============================] - 10s 255ms/step - loss: 0.6212 - categorical_accuracy: 0.7414 - val_loss: 1.1847 - val_categorical_accuracy: 0.5857\n",
            "Epoch 146/200\n",
            "39/39 [==============================] - 10s 249ms/step - loss: 0.5294 - categorical_accuracy: 0.7959 - val_loss: 1.2648 - val_categorical_accuracy: 0.5857\n",
            "Epoch 147/200\n",
            "39/39 [==============================] - 10s 253ms/step - loss: 0.6189 - categorical_accuracy: 0.7484 - val_loss: 1.1581 - val_categorical_accuracy: 0.5143\n",
            "Epoch 148/200\n",
            "39/39 [==============================] - 10s 251ms/step - loss: 0.5326 - categorical_accuracy: 0.7801 - val_loss: 1.2905 - val_categorical_accuracy: 0.5714\n",
            "Epoch 149/200\n",
            "39/39 [==============================] - 10s 253ms/step - loss: 0.5212 - categorical_accuracy: 0.8007 - val_loss: 1.4013 - val_categorical_accuracy: 0.4714\n",
            "Epoch 150/200\n",
            "39/39 [==============================] - 10s 248ms/step - loss: 0.5281 - categorical_accuracy: 0.7842 - val_loss: 1.3691 - val_categorical_accuracy: 0.5000\n",
            "Epoch 151/200\n",
            "39/39 [==============================] - 10s 253ms/step - loss: 0.5819 - categorical_accuracy: 0.7966 - val_loss: 1.4082 - val_categorical_accuracy: 0.5286\n",
            "Epoch 152/200\n",
            "39/39 [==============================] - 10s 244ms/step - loss: 0.5051 - categorical_accuracy: 0.8047 - val_loss: 1.7159 - val_categorical_accuracy: 0.4143\n",
            "Epoch 153/200\n",
            "39/39 [==============================] - 10s 247ms/step - loss: 0.4592 - categorical_accuracy: 0.8174 - val_loss: 1.2504 - val_categorical_accuracy: 0.5429\n",
            "Epoch 154/200\n",
            "39/39 [==============================] - 10s 249ms/step - loss: 0.5054 - categorical_accuracy: 0.8056 - val_loss: 1.1599 - val_categorical_accuracy: 0.5714\n",
            "Epoch 155/200\n",
            "39/39 [==============================] - 9s 243ms/step - loss: 0.5466 - categorical_accuracy: 0.7989 - val_loss: 1.3359 - val_categorical_accuracy: 0.5714\n",
            "Epoch 156/200\n",
            "39/39 [==============================] - 10s 244ms/step - loss: 0.4583 - categorical_accuracy: 0.8218 - val_loss: 1.2554 - val_categorical_accuracy: 0.6000\n",
            "Epoch 157/200\n",
            "39/39 [==============================] - 10s 250ms/step - loss: 0.4871 - categorical_accuracy: 0.8072 - val_loss: 1.1672 - val_categorical_accuracy: 0.6000\n",
            "Epoch 158/200\n",
            "39/39 [==============================] - 10s 249ms/step - loss: 0.5285 - categorical_accuracy: 0.7988 - val_loss: 1.2600 - val_categorical_accuracy: 0.6143\n",
            "Epoch 159/200\n",
            "39/39 [==============================] - 10s 246ms/step - loss: 0.4275 - categorical_accuracy: 0.8286 - val_loss: 1.2667 - val_categorical_accuracy: 0.5000\n",
            "Epoch 160/200\n",
            "39/39 [==============================] - 9s 243ms/step - loss: 0.3702 - categorical_accuracy: 0.8745 - val_loss: 1.3202 - val_categorical_accuracy: 0.5714\n",
            "Epoch 161/200\n",
            "39/39 [==============================] - 10s 250ms/step - loss: 0.5046 - categorical_accuracy: 0.8010 - val_loss: 1.1136 - val_categorical_accuracy: 0.6143\n",
            "Epoch 162/200\n",
            "39/39 [==============================] - 10s 250ms/step - loss: 0.4870 - categorical_accuracy: 0.8241 - val_loss: 1.3296 - val_categorical_accuracy: 0.5857\n",
            "Epoch 163/200\n",
            "39/39 [==============================] - 10s 252ms/step - loss: 0.4323 - categorical_accuracy: 0.8324 - val_loss: 1.3260 - val_categorical_accuracy: 0.5714\n",
            "Epoch 164/200\n",
            "39/39 [==============================] - 10s 250ms/step - loss: 0.4915 - categorical_accuracy: 0.8120 - val_loss: 1.1616 - val_categorical_accuracy: 0.6143\n",
            "Epoch 165/200\n",
            "39/39 [==============================] - 10s 252ms/step - loss: 0.4147 - categorical_accuracy: 0.8612 - val_loss: 1.1720 - val_categorical_accuracy: 0.6000\n",
            "Epoch 166/200\n",
            "39/39 [==============================] - 10s 251ms/step - loss: 0.4964 - categorical_accuracy: 0.7929 - val_loss: 1.0353 - val_categorical_accuracy: 0.6714\n",
            "Epoch 167/200\n",
            "39/39 [==============================] - 10s 251ms/step - loss: 0.4424 - categorical_accuracy: 0.8063 - val_loss: 1.2917 - val_categorical_accuracy: 0.5143\n",
            "Epoch 168/200\n",
            "39/39 [==============================] - 10s 250ms/step - loss: 0.4379 - categorical_accuracy: 0.8317 - val_loss: 1.3870 - val_categorical_accuracy: 0.5571\n",
            "Epoch 169/200\n",
            "39/39 [==============================] - 10s 245ms/step - loss: 0.3818 - categorical_accuracy: 0.8569 - val_loss: 1.2897 - val_categorical_accuracy: 0.6000\n",
            "Epoch 170/200\n",
            "39/39 [==============================] - 9s 243ms/step - loss: 0.3938 - categorical_accuracy: 0.8558 - val_loss: 1.4474 - val_categorical_accuracy: 0.5000\n",
            "Epoch 171/200\n",
            "39/39 [==============================] - 10s 245ms/step - loss: 0.4541 - categorical_accuracy: 0.7987 - val_loss: 1.3715 - val_categorical_accuracy: 0.5429\n",
            "Epoch 172/200\n",
            "39/39 [==============================] - 10s 249ms/step - loss: 0.4168 - categorical_accuracy: 0.8580 - val_loss: 1.1725 - val_categorical_accuracy: 0.5857\n",
            "Epoch 173/200\n",
            "39/39 [==============================] - 10s 249ms/step - loss: 0.3928 - categorical_accuracy: 0.8466 - val_loss: 1.1330 - val_categorical_accuracy: 0.5857\n",
            "Epoch 174/200\n",
            "39/39 [==============================] - 10s 252ms/step - loss: 0.3986 - categorical_accuracy: 0.8404 - val_loss: 1.2554 - val_categorical_accuracy: 0.5857\n",
            "Epoch 175/200\n",
            "39/39 [==============================] - 10s 254ms/step - loss: 0.4291 - categorical_accuracy: 0.8290 - val_loss: 1.2170 - val_categorical_accuracy: 0.6143\n",
            "Epoch 176/200\n",
            "39/39 [==============================] - 10s 254ms/step - loss: 0.3371 - categorical_accuracy: 0.8714 - val_loss: 1.2940 - val_categorical_accuracy: 0.6429\n",
            "Epoch 177/200\n",
            "39/39 [==============================] - 10s 252ms/step - loss: 0.3637 - categorical_accuracy: 0.8664 - val_loss: 1.3367 - val_categorical_accuracy: 0.5571\n",
            "Epoch 178/200\n",
            "39/39 [==============================] - 10s 253ms/step - loss: 0.3695 - categorical_accuracy: 0.8563 - val_loss: 1.2494 - val_categorical_accuracy: 0.5571\n",
            "Epoch 179/200\n",
            "39/39 [==============================] - 10s 247ms/step - loss: 0.3164 - categorical_accuracy: 0.8786 - val_loss: 1.2593 - val_categorical_accuracy: 0.5714\n",
            "Epoch 180/200\n",
            "39/39 [==============================] - 9s 243ms/step - loss: 0.3266 - categorical_accuracy: 0.8709 - val_loss: 1.0901 - val_categorical_accuracy: 0.5857\n",
            "Epoch 181/200\n",
            "39/39 [==============================] - 9s 243ms/step - loss: 0.4363 - categorical_accuracy: 0.8308 - val_loss: 1.3049 - val_categorical_accuracy: 0.5286\n",
            "Epoch 182/200\n",
            "39/39 [==============================] - 10s 247ms/step - loss: 0.4037 - categorical_accuracy: 0.8622 - val_loss: 1.3526 - val_categorical_accuracy: 0.5429\n",
            "Epoch 183/200\n",
            "39/39 [==============================] - 10s 245ms/step - loss: 0.4102 - categorical_accuracy: 0.8383 - val_loss: 1.1847 - val_categorical_accuracy: 0.5286\n",
            "Epoch 184/200\n",
            "39/39 [==============================] - 10s 248ms/step - loss: 0.4748 - categorical_accuracy: 0.8074 - val_loss: 1.3070 - val_categorical_accuracy: 0.5286\n",
            "Epoch 185/200\n",
            "39/39 [==============================] - 10s 247ms/step - loss: 0.4205 - categorical_accuracy: 0.8319 - val_loss: 1.3756 - val_categorical_accuracy: 0.6143\n",
            "Epoch 186/200\n",
            "39/39 [==============================] - 10s 252ms/step - loss: 0.3395 - categorical_accuracy: 0.8741 - val_loss: 1.3480 - val_categorical_accuracy: 0.5000\n",
            "Epoch 187/200\n",
            "39/39 [==============================] - 10s 248ms/step - loss: 0.3732 - categorical_accuracy: 0.8560 - val_loss: 1.3065 - val_categorical_accuracy: 0.5571\n",
            "Epoch 188/200\n",
            "39/39 [==============================] - 10s 253ms/step - loss: 0.3629 - categorical_accuracy: 0.8633 - val_loss: 1.1897 - val_categorical_accuracy: 0.6143\n",
            "Epoch 189/200\n",
            "39/39 [==============================] - 10s 248ms/step - loss: 0.3452 - categorical_accuracy: 0.8761 - val_loss: 1.4068 - val_categorical_accuracy: 0.5714\n",
            "Epoch 190/200\n",
            "39/39 [==============================] - 10s 248ms/step - loss: 0.3492 - categorical_accuracy: 0.8682 - val_loss: 1.2685 - val_categorical_accuracy: 0.5429\n",
            "Epoch 191/200\n",
            "39/39 [==============================] - 10s 252ms/step - loss: 0.3217 - categorical_accuracy: 0.8818 - val_loss: 1.2796 - val_categorical_accuracy: 0.5714\n",
            "Epoch 192/200\n",
            "39/39 [==============================] - 10s 253ms/step - loss: 0.4786 - categorical_accuracy: 0.8140 - val_loss: 1.5872 - val_categorical_accuracy: 0.4857\n",
            "Epoch 193/200\n",
            "39/39 [==============================] - 10s 250ms/step - loss: 0.3063 - categorical_accuracy: 0.8979 - val_loss: 1.2348 - val_categorical_accuracy: 0.5857\n",
            "Epoch 194/200\n",
            "39/39 [==============================] - 10s 248ms/step - loss: 0.2882 - categorical_accuracy: 0.9032 - val_loss: 1.1123 - val_categorical_accuracy: 0.6286\n",
            "Epoch 195/200\n",
            "39/39 [==============================] - 10s 253ms/step - loss: 0.2363 - categorical_accuracy: 0.9239 - val_loss: 1.4260 - val_categorical_accuracy: 0.4857\n",
            "Epoch 196/200\n",
            "39/39 [==============================] - 10s 251ms/step - loss: 0.3208 - categorical_accuracy: 0.8662 - val_loss: 1.2316 - val_categorical_accuracy: 0.6286\n",
            "Epoch 197/200\n",
            "39/39 [==============================] - 10s 257ms/step - loss: 0.3602 - categorical_accuracy: 0.8616 - val_loss: 1.3717 - val_categorical_accuracy: 0.6143\n",
            "Epoch 198/200\n",
            "39/39 [==============================] - 10s 255ms/step - loss: 0.4019 - categorical_accuracy: 0.8538 - val_loss: 1.3105 - val_categorical_accuracy: 0.6143\n",
            "Epoch 199/200\n",
            "39/39 [==============================] - 10s 254ms/step - loss: 0.2697 - categorical_accuracy: 0.8977 - val_loss: 1.3314 - val_categorical_accuracy: 0.6143\n",
            "Epoch 200/200\n",
            "39/39 [==============================] - 10s 257ms/step - loss: 0.2806 - categorical_accuracy: 0.8920 - val_loss: 1.2532 - val_categorical_accuracy: 0.6000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FSQMRrtt8LyK"
      },
      "source": [
        "model.save('/content/drive/MyDrive/Colab Notebooks/SPEECH_EMOTION_Recognition/Nộp bài(chốt hạ)/model_saver/conv1D_mfcc26_ravdess.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "soL_83cb8LyL"
      },
      "source": [
        "###test_result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HeaUupku8LyM",
        "outputId": "111524d6-83d7-4533-9bd2-b1158df1dbda"
      },
      "source": [
        "d = {0: 'happy',\n",
        "     1: 'sad',\n",
        "     2: 'angry',\n",
        "     3: 'fear'}\n",
        "Y_test_pred = np.argmax(model.predict(X_test), axis=-1)\n",
        "Y_test_pred = list(map(lambda x: d[x], Y_test_pred))\n",
        "y_test = np.argmax(y_test, axis=-1)\n",
        "y_test = list(map(lambda x: d[x], y_test))\n",
        "print(classification_report(y_test, Y_test_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.69      0.85      0.76        13\n",
            "        fear       0.65      0.52      0.58        21\n",
            "       happy       0.71      0.52      0.60        23\n",
            "         sad       0.63      0.85      0.72        20\n",
            "\n",
            "    accuracy                           0.66        77\n",
            "   macro avg       0.67      0.69      0.67        77\n",
            "weighted avg       0.67      0.66      0.65        77\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "id": "0I7Pgkx58LyN",
        "outputId": "ef7e1e36-cd81-4bc8-a87b-eb60730d7eca"
      },
      "source": [
        "import scikitplot as skplt\n",
        "\n",
        "skplt.metrics.plot_confusion_matrix(\n",
        "    y_test, \n",
        "    Y_test_pred,\n",
        "    figsize=(8,8))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f15e13fbc50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xHBdsNOD8LyO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bP7WeLYGFjiN"
      },
      "source": [
        "# mfcc_39 + conv1D:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ec0Ae5XpFjid"
      },
      "source": [
        "audio_duration = 3\n",
        "sampling_rate = 22050\n",
        "input_length = sampling_rate * audio_duration"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4qTM8becFjih"
      },
      "source": [
        "features = []\n",
        "labels = []\n",
        "for i in range(len(Ravdess_DF['Paths'])):\n",
        "  if ((Ravdess_DF['Emotion'][i] == '03') | (Ravdess_DF['Emotion'][i] == '04') | \n",
        "      (Ravdess_DF['Emotion'][i] == '05') | (Ravdess_DF['Emotion'][i] == '06')):\n",
        "    signal, sr = librosa.load(Ravdess_DF['Paths'][i])\n",
        "\n",
        "    if len(signal) > input_length:\n",
        "      signal = signal[0:input_length]\n",
        "    elif  input_length > len(signal):\n",
        "      max_offset = input_length - len(signal)  \n",
        "      signal = np.pad(signal, (0, max_offset), \"constant\")\n",
        "\n",
        "    mfcc = librosa.feature.mfcc(y=signal, sr=sr, n_mfcc=39).T\n",
        "    mfcc = mfcc.reshape(-1,1)\n",
        "    features.append(mfcc)\n",
        "\n",
        "    if Ravdess_DF['Emotion'][i] == '03':\n",
        "      labels.append(0)\n",
        "    elif Ravdess_DF['Emotion'][i] == '04':\n",
        "      labels.append(1)\n",
        "    elif Ravdess_DF['Emotion'][i] == '05':\n",
        "      labels.append(2)\n",
        "    elif Ravdess_DF['Emotion'][i] == '06':\n",
        "      labels.append(3)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5tuBVX8Fjij"
      },
      "source": [
        "X = features\n",
        "y = labels\n",
        "\n",
        "y = np.array(y)\n",
        "y = to_categorical(y)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=0)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=0)\n",
        "\n",
        "X_train = np.array(X_train)\n",
        "X_test = np.array(X_test)\n",
        "X_val = np.array(X_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LYYHZi0bFjik",
        "outputId": "000534b2-1594-4c2f-9148-ab26a70bdef8"
      },
      "source": [
        "X_train.shape,X_test.shape,y_train.shape,y_test.shape\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((621, 5070, 1), (77, 5070, 1), (621, 4), (77, 4))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J0QVBmj5Fjio"
      },
      "source": [
        "\n",
        "# CNN I/P Config\n",
        "num_classes = 4\n",
        "input_shape = X_train.shape[1:]\n",
        "learning_rate = 0.0001\n",
        "decay = 1e-6\n",
        "momentum = 0.9\n",
        "\n",
        "#LSTM Configuration\n",
        "num_lstm = 256"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WQO_wHDrFjiq",
        "outputId": "cb14e00e-81a9-44c2-a4d4-da3aa8e947a2"
      },
      "source": [
        "model = Sequential(name='Audio_CNN_1D')\n",
        "\n",
        "# LFLB1\n",
        "model.add(Conv1D(filters=64, kernel_size=(3), strides=1, padding='same', data_format='channels_last',input_shape=input_shape))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('elu'))\n",
        "model.add(MaxPooling1D(pool_size=4, strides=4))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "# LFLB2\n",
        "model.add(Conv1D(filters=64, kernel_size=3, strides=1, padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('elu'))\n",
        "model.add(MaxPooling1D(pool_size=4, strides=4))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# LFLB3\n",
        "model.add(Conv1D(filters=128, kernel_size=3, strides=1, padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('elu'))\n",
        "model.add(MaxPooling1D(pool_size=4, strides=4))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# LFLB4\n",
        "model.add(Conv1D(filters=128, kernel_size=3, strides=1, padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('elu'))\n",
        "model.add(MaxPooling1D(pool_size=4, strides=4))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# LSTM\n",
        "model.add(LSTM(units=num_lstm))\n",
        "\n",
        "# FC\n",
        "model.add(Dense(units=num_classes, activation='softmax'))\n",
        "\n",
        "# Model compilation\n",
        "opt= keras.optimizers.Adam(lr=0.01, beta_1=0.9,  beta_2=0.999, amsgrad=False)\n",
        "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
        "\n",
        "model.summary()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"Audio_CNN_1D\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 5070, 64)          256       \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 5070, 64)          256       \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 5070, 64)          0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D) (None, 1267, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 1267, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 1267, 64)          12352     \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 1267, 64)          256       \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 1267, 64)          0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1 (None, 316, 64)           0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 316, 64)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 316, 128)          24704     \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 316, 128)          512       \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 316, 128)          0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_2 (MaxPooling1 (None, 79, 128)           0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 79, 128)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 79, 128)           49280     \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 79, 128)           512       \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 79, 128)           0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_3 (MaxPooling1 (None, 19, 128)           0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 19, 128)           0         \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 256)               394240    \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 4)                 1028      \n",
            "=================================================================\n",
            "Total params: 483,396\n",
            "Trainable params: 482,628\n",
            "Non-trainable params: 768\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ukLsW0C4Fjir",
        "outputId": "a24da6c9-b9ac-4822-ce20-82d2d4b2c06c"
      },
      "source": [
        "#Train Config\n",
        "\n",
        "batch_size = 16\n",
        "num_epochs = 200\n",
        "\n",
        "# Model Training\n",
        "lr_reduce = ReduceLROnPlateau(monitor='val_loss', factor=0.9, patience=20, min_lr=0.000001)\n",
        "# Please change the model name accordingly.\n",
        "mcp_save = ModelCheckpoint('/content/Audio_1DCNN.h5', save_best_only=True, monitor='val_categorical_accuracy', mode='max')\n",
        "cnnhistory=model.fit(X_train, y_train, batch_size=batch_size, epochs=num_epochs,validation_data=(X_val, y_val), callbacks=[mcp_save, lr_reduce])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "39/39 [==============================] - 53s 59ms/step - loss: 1.7661 - categorical_accuracy: 0.2848 - val_loss: 1.8292 - val_categorical_accuracy: 0.1857\n",
            "Epoch 2/200\n",
            "39/39 [==============================] - 1s 15ms/step - loss: 1.2470 - categorical_accuracy: 0.4363 - val_loss: 1.7030 - val_categorical_accuracy: 0.1857\n",
            "Epoch 3/200\n",
            "39/39 [==============================] - 1s 15ms/step - loss: 1.2459 - categorical_accuracy: 0.4695 - val_loss: 1.4212 - val_categorical_accuracy: 0.1857\n",
            "Epoch 4/200\n",
            "39/39 [==============================] - 1s 15ms/step - loss: 1.2839 - categorical_accuracy: 0.4119 - val_loss: 1.5534 - val_categorical_accuracy: 0.2143\n",
            "Epoch 5/200\n",
            "39/39 [==============================] - 1s 15ms/step - loss: 1.2580 - categorical_accuracy: 0.4143 - val_loss: 1.7295 - val_categorical_accuracy: 0.1857\n",
            "Epoch 6/200\n",
            "39/39 [==============================] - 1s 16ms/step - loss: 1.2649 - categorical_accuracy: 0.3794 - val_loss: 1.9163 - val_categorical_accuracy: 0.2286\n",
            "Epoch 7/200\n",
            "39/39 [==============================] - 1s 15ms/step - loss: 1.2131 - categorical_accuracy: 0.4529 - val_loss: 1.5225 - val_categorical_accuracy: 0.2714\n",
            "Epoch 8/200\n",
            "39/39 [==============================] - 1s 15ms/step - loss: 1.2392 - categorical_accuracy: 0.4202 - val_loss: 2.0248 - val_categorical_accuracy: 0.2286\n",
            "Epoch 9/200\n",
            "39/39 [==============================] - 1s 16ms/step - loss: 1.1970 - categorical_accuracy: 0.4755 - val_loss: 1.8047 - val_categorical_accuracy: 0.1857\n",
            "Epoch 10/200\n",
            "39/39 [==============================] - 1s 15ms/step - loss: 1.1973 - categorical_accuracy: 0.4773 - val_loss: 1.8260 - val_categorical_accuracy: 0.2000\n",
            "Epoch 11/200\n",
            "39/39 [==============================] - 1s 16ms/step - loss: 1.1768 - categorical_accuracy: 0.4620 - val_loss: 1.9132 - val_categorical_accuracy: 0.2143\n",
            "Epoch 12/200\n",
            "39/39 [==============================] - 1s 16ms/step - loss: 1.2096 - categorical_accuracy: 0.4266 - val_loss: 1.6810 - val_categorical_accuracy: 0.2286\n",
            "Epoch 13/200\n",
            "39/39 [==============================] - 1s 15ms/step - loss: 1.1897 - categorical_accuracy: 0.4592 - val_loss: 1.7114 - val_categorical_accuracy: 0.2714\n",
            "Epoch 14/200\n",
            "39/39 [==============================] - 1s 16ms/step - loss: 1.1670 - categorical_accuracy: 0.4987 - val_loss: 1.6565 - val_categorical_accuracy: 0.3286\n",
            "Epoch 15/200\n",
            "39/39 [==============================] - 1s 15ms/step - loss: 1.1500 - categorical_accuracy: 0.4960 - val_loss: 1.3209 - val_categorical_accuracy: 0.4000\n",
            "Epoch 16/200\n",
            "39/39 [==============================] - 1s 15ms/step - loss: 1.1456 - categorical_accuracy: 0.4951 - val_loss: 1.3249 - val_categorical_accuracy: 0.4000\n",
            "Epoch 17/200\n",
            "39/39 [==============================] - 1s 15ms/step - loss: 1.1583 - categorical_accuracy: 0.4971 - val_loss: 1.4714 - val_categorical_accuracy: 0.3714\n",
            "Epoch 18/200\n",
            "39/39 [==============================] - 1s 16ms/step - loss: 1.1195 - categorical_accuracy: 0.5164 - val_loss: 1.2814 - val_categorical_accuracy: 0.4571\n",
            "Epoch 19/200\n",
            "39/39 [==============================] - 1s 16ms/step - loss: 1.1273 - categorical_accuracy: 0.5306 - val_loss: 1.3286 - val_categorical_accuracy: 0.3714\n",
            "Epoch 20/200\n",
            "39/39 [==============================] - 1s 15ms/step - loss: 1.0900 - categorical_accuracy: 0.5283 - val_loss: 1.1728 - val_categorical_accuracy: 0.4286\n",
            "Epoch 21/200\n",
            "39/39 [==============================] - 1s 15ms/step - loss: 1.1163 - categorical_accuracy: 0.5140 - val_loss: 1.2534 - val_categorical_accuracy: 0.4286\n",
            "Epoch 22/200\n",
            "39/39 [==============================] - 1s 15ms/step - loss: 1.1379 - categorical_accuracy: 0.4713 - val_loss: 1.2141 - val_categorical_accuracy: 0.4714\n",
            "Epoch 23/200\n",
            "39/39 [==============================] - 1s 15ms/step - loss: 1.1160 - categorical_accuracy: 0.4991 - val_loss: 1.3153 - val_categorical_accuracy: 0.4286\n",
            "Epoch 24/200\n",
            "39/39 [==============================] - 1s 16ms/step - loss: 1.1408 - categorical_accuracy: 0.4693 - val_loss: 1.1686 - val_categorical_accuracy: 0.5000\n",
            "Epoch 25/200\n",
            "39/39 [==============================] - 1s 16ms/step - loss: 1.0849 - categorical_accuracy: 0.5030 - val_loss: 1.1925 - val_categorical_accuracy: 0.4571\n",
            "Epoch 26/200\n",
            "39/39 [==============================] - 1s 15ms/step - loss: 1.0294 - categorical_accuracy: 0.5409 - val_loss: 1.2741 - val_categorical_accuracy: 0.3429\n",
            "Epoch 27/200\n",
            "39/39 [==============================] - 1s 16ms/step - loss: 1.0352 - categorical_accuracy: 0.5241 - val_loss: 1.2348 - val_categorical_accuracy: 0.4714\n",
            "Epoch 28/200\n",
            "39/39 [==============================] - 1s 15ms/step - loss: 1.1121 - categorical_accuracy: 0.4926 - val_loss: 1.1456 - val_categorical_accuracy: 0.4286\n",
            "Epoch 29/200\n",
            "39/39 [==============================] - 1s 15ms/step - loss: 1.0948 - categorical_accuracy: 0.4874 - val_loss: 1.2229 - val_categorical_accuracy: 0.4143\n",
            "Epoch 30/200\n",
            "39/39 [==============================] - 1s 15ms/step - loss: 1.0491 - categorical_accuracy: 0.5593 - val_loss: 1.3804 - val_categorical_accuracy: 0.3286\n",
            "Epoch 31/200\n",
            "39/39 [==============================] - 1s 15ms/step - loss: 0.9808 - categorical_accuracy: 0.5909 - val_loss: 1.0799 - val_categorical_accuracy: 0.5000\n",
            "Epoch 32/200\n",
            "39/39 [==============================] - 1s 16ms/step - loss: 1.1245 - categorical_accuracy: 0.5014 - val_loss: 1.2106 - val_categorical_accuracy: 0.4429\n",
            "Epoch 33/200\n",
            "39/39 [==============================] - 1s 15ms/step - loss: 1.0462 - categorical_accuracy: 0.5638 - val_loss: 1.3995 - val_categorical_accuracy: 0.4286\n",
            "Epoch 34/200\n",
            "39/39 [==============================] - 1s 15ms/step - loss: 1.1687 - categorical_accuracy: 0.5239 - val_loss: 1.3040 - val_categorical_accuracy: 0.4429\n",
            "Epoch 35/200\n",
            "39/39 [==============================] - 1s 16ms/step - loss: 1.0765 - categorical_accuracy: 0.4833 - val_loss: 1.2479 - val_categorical_accuracy: 0.4571\n",
            "Epoch 36/200\n",
            "39/39 [==============================] - 1s 15ms/step - loss: 1.0492 - categorical_accuracy: 0.5535 - val_loss: 1.1691 - val_categorical_accuracy: 0.4857\n",
            "Epoch 37/200\n",
            "39/39 [==============================] - 1s 16ms/step - loss: 1.0428 - categorical_accuracy: 0.5731 - val_loss: 1.3521 - val_categorical_accuracy: 0.4143\n",
            "Epoch 38/200\n",
            "39/39 [==============================] - 1s 15ms/step - loss: 0.9426 - categorical_accuracy: 0.5940 - val_loss: 1.2425 - val_categorical_accuracy: 0.4286\n",
            "Epoch 39/200\n",
            "39/39 [==============================] - 1s 15ms/step - loss: 0.9414 - categorical_accuracy: 0.5815 - val_loss: 1.2405 - val_categorical_accuracy: 0.4429\n",
            "Epoch 40/200\n",
            "39/39 [==============================] - 1s 15ms/step - loss: 0.9724 - categorical_accuracy: 0.5662 - val_loss: 1.1367 - val_categorical_accuracy: 0.4857\n",
            "Epoch 41/200\n",
            "39/39 [==============================] - 1s 15ms/step - loss: 1.0169 - categorical_accuracy: 0.5523 - val_loss: 1.1739 - val_categorical_accuracy: 0.4429\n",
            "Epoch 42/200\n",
            "39/39 [==============================] - 1s 16ms/step - loss: 0.9912 - categorical_accuracy: 0.5615 - val_loss: 1.2597 - val_categorical_accuracy: 0.4571\n",
            "Epoch 43/200\n",
            "39/39 [==============================] - 1s 15ms/step - loss: 0.9319 - categorical_accuracy: 0.6001 - val_loss: 1.1712 - val_categorical_accuracy: 0.5143\n",
            "Epoch 44/200\n",
            "39/39 [==============================] - 1s 15ms/step - loss: 0.9534 - categorical_accuracy: 0.5668 - val_loss: 1.0861 - val_categorical_accuracy: 0.5000\n",
            "Epoch 45/200\n",
            "39/39 [==============================] - 1s 15ms/step - loss: 0.9752 - categorical_accuracy: 0.5718 - val_loss: 1.1652 - val_categorical_accuracy: 0.4429\n",
            "Epoch 46/200\n",
            "39/39 [==============================] - 1s 16ms/step - loss: 0.8941 - categorical_accuracy: 0.6044 - val_loss: 1.1237 - val_categorical_accuracy: 0.5000\n",
            "Epoch 47/200\n",
            "39/39 [==============================] - 1s 15ms/step - loss: 0.9453 - categorical_accuracy: 0.6222 - val_loss: 1.3149 - val_categorical_accuracy: 0.4286\n",
            "Epoch 48/200\n",
            "39/39 [==============================] - 1s 15ms/step - loss: 1.0686 - categorical_accuracy: 0.5671 - val_loss: 1.1363 - val_categorical_accuracy: 0.4714\n",
            "Epoch 49/200\n",
            "39/39 [==============================] - 1s 15ms/step - loss: 1.0086 - categorical_accuracy: 0.5441 - val_loss: 1.3520 - val_categorical_accuracy: 0.4714\n",
            "Epoch 50/200\n",
            "39/39 [==============================] - 1s 16ms/step - loss: 0.9406 - categorical_accuracy: 0.6258 - val_loss: 1.2377 - val_categorical_accuracy: 0.4714\n",
            "Epoch 51/200\n",
            "39/39 [==============================] - 1s 15ms/step - loss: 0.9261 - categorical_accuracy: 0.5925 - val_loss: 1.1115 - val_categorical_accuracy: 0.5429\n",
            "Epoch 52/200\n",
            "39/39 [==============================] - 1s 15ms/step - loss: 0.9606 - categorical_accuracy: 0.5928 - val_loss: 1.1242 - val_categorical_accuracy: 0.4857\n",
            "Epoch 53/200\n",
            "39/39 [==============================] - 1s 16ms/step - loss: 0.9397 - categorical_accuracy: 0.5766 - val_loss: 1.1516 - val_categorical_accuracy: 0.5000\n",
            "Epoch 54/200\n",
            "39/39 [==============================] - 1s 15ms/step - loss: 0.9727 - categorical_accuracy: 0.6111 - val_loss: 1.1067 - val_categorical_accuracy: 0.5143\n",
            "Epoch 55/200\n",
            "39/39 [==============================] - 1s 15ms/step - loss: 0.8786 - categorical_accuracy: 0.6366 - val_loss: 1.0898 - val_categorical_accuracy: 0.4571\n",
            "Epoch 56/200\n",
            "39/39 [==============================] - 1s 16ms/step - loss: 0.9101 - categorical_accuracy: 0.6214 - val_loss: 1.3530 - val_categorical_accuracy: 0.4714\n",
            "Epoch 57/200\n",
            "39/39 [==============================] - 1s 15ms/step - loss: 0.8953 - categorical_accuracy: 0.6041 - val_loss: 1.2514 - val_categorical_accuracy: 0.4857\n",
            "Epoch 58/200\n",
            "39/39 [==============================] - 1s 15ms/step - loss: 0.8892 - categorical_accuracy: 0.6293 - val_loss: 1.3138 - val_categorical_accuracy: 0.4714\n",
            "Epoch 59/200\n",
            "39/39 [==============================] - 1s 15ms/step - loss: 0.8964 - categorical_accuracy: 0.6193 - val_loss: 1.2570 - val_categorical_accuracy: 0.4429\n",
            "Epoch 60/200\n",
            "39/39 [==============================] - 1s 15ms/step - loss: 0.8836 - categorical_accuracy: 0.5981 - val_loss: 1.1811 - val_categorical_accuracy: 0.5143\n",
            "Epoch 61/200\n",
            "39/39 [==============================] - 1s 15ms/step - loss: 0.8630 - categorical_accuracy: 0.6123 - val_loss: 1.1724 - val_categorical_accuracy: 0.5429\n",
            "Epoch 62/200\n",
            "39/39 [==============================] - 1s 16ms/step - loss: 0.9091 - categorical_accuracy: 0.6062 - val_loss: 1.0799 - val_categorical_accuracy: 0.5571\n",
            "Epoch 63/200\n",
            "39/39 [==============================] - 1s 15ms/step - loss: 0.8937 - categorical_accuracy: 0.5954 - val_loss: 1.3196 - val_categorical_accuracy: 0.3714\n",
            "Epoch 64/200\n",
            "39/39 [==============================] - 1s 15ms/step - loss: 0.8531 - categorical_accuracy: 0.6472 - val_loss: 1.2567 - val_categorical_accuracy: 0.4714\n",
            "Epoch 65/200\n",
            "39/39 [==============================] - 1s 16ms/step - loss: 0.7619 - categorical_accuracy: 0.6897 - val_loss: 1.3113 - val_categorical_accuracy: 0.3857\n",
            "Epoch 66/200\n",
            "39/39 [==============================] - 1s 16ms/step - loss: 0.8777 - categorical_accuracy: 0.6368 - val_loss: 1.2408 - val_categorical_accuracy: 0.5000\n",
            "Epoch 67/200\n",
            "39/39 [==============================] - 1s 15ms/step - loss: 0.8636 - categorical_accuracy: 0.6653 - val_loss: 1.3694 - val_categorical_accuracy: 0.4429\n",
            "Epoch 68/200\n",
            "39/39 [==============================] - 1s 17ms/step - loss: 0.8613 - categorical_accuracy: 0.6378 - val_loss: 1.2792 - val_categorical_accuracy: 0.5714\n",
            "Epoch 69/200\n",
            "39/39 [==============================] - 1s 15ms/step - loss: 0.7703 - categorical_accuracy: 0.6949 - val_loss: 1.1702 - val_categorical_accuracy: 0.5571\n",
            "Epoch 70/200\n",
            "39/39 [==============================] - 1s 16ms/step - loss: 0.8224 - categorical_accuracy: 0.6666 - val_loss: 1.4004 - val_categorical_accuracy: 0.3571\n",
            "Epoch 71/200\n",
            "39/39 [==============================] - 1s 16ms/step - loss: 0.8451 - categorical_accuracy: 0.6487 - val_loss: 1.2499 - val_categorical_accuracy: 0.5143\n",
            "Epoch 72/200\n",
            "39/39 [==============================] - 1s 16ms/step - loss: 0.7906 - categorical_accuracy: 0.6974 - val_loss: 1.2722 - val_categorical_accuracy: 0.4286\n",
            "Epoch 73/200\n",
            "39/39 [==============================] - 1s 16ms/step - loss: 0.7381 - categorical_accuracy: 0.7034 - val_loss: 1.3257 - val_categorical_accuracy: 0.5429\n",
            "Epoch 74/200\n",
            "39/39 [==============================] - 1s 16ms/step - loss: 0.8461 - categorical_accuracy: 0.6468 - val_loss: 1.1226 - val_categorical_accuracy: 0.4714\n",
            "Epoch 75/200\n",
            "39/39 [==============================] - 1s 16ms/step - loss: 0.8293 - categorical_accuracy: 0.6085 - val_loss: 1.1055 - val_categorical_accuracy: 0.5143\n",
            "Epoch 76/200\n",
            "39/39 [==============================] - 1s 16ms/step - loss: 0.8722 - categorical_accuracy: 0.6304 - val_loss: 1.2195 - val_categorical_accuracy: 0.4714\n",
            "Epoch 77/200\n",
            "39/39 [==============================] - 1s 15ms/step - loss: 0.8088 - categorical_accuracy: 0.6342 - val_loss: 1.2036 - val_categorical_accuracy: 0.6143\n",
            "Epoch 78/200\n",
            "39/39 [==============================] - 1s 15ms/step - loss: 0.7647 - categorical_accuracy: 0.6816 - val_loss: 1.1030 - val_categorical_accuracy: 0.6000\n",
            "Epoch 79/200\n",
            "39/39 [==============================] - 1s 15ms/step - loss: 0.8200 - categorical_accuracy: 0.6720 - val_loss: 1.1451 - val_categorical_accuracy: 0.5286\n",
            "Epoch 80/200\n",
            "39/39 [==============================] - 1s 16ms/step - loss: 0.7330 - categorical_accuracy: 0.6751 - val_loss: 1.2006 - val_categorical_accuracy: 0.5286\n",
            "Epoch 81/200\n",
            "39/39 [==============================] - 1s 15ms/step - loss: 0.7945 - categorical_accuracy: 0.6590 - val_loss: 1.1278 - val_categorical_accuracy: 0.5571\n",
            "Epoch 82/200\n",
            "39/39 [==============================] - 1s 16ms/step - loss: 0.6803 - categorical_accuracy: 0.6959 - val_loss: 1.1489 - val_categorical_accuracy: 0.5286\n",
            "Epoch 83/200\n",
            "39/39 [==============================] - 1s 15ms/step - loss: 0.7127 - categorical_accuracy: 0.6830 - val_loss: 1.1327 - val_categorical_accuracy: 0.5857\n",
            "Epoch 84/200\n",
            "39/39 [==============================] - 1s 16ms/step - loss: 0.7546 - categorical_accuracy: 0.6626 - val_loss: 1.2306 - val_categorical_accuracy: 0.5286\n",
            "Epoch 85/200\n",
            "39/39 [==============================] - 1s 15ms/step - loss: 0.7619 - categorical_accuracy: 0.6909 - val_loss: 1.0426 - val_categorical_accuracy: 0.6000\n",
            "Epoch 86/200\n",
            "39/39 [==============================] - 1s 15ms/step - loss: 0.7326 - categorical_accuracy: 0.6967 - val_loss: 1.1253 - val_categorical_accuracy: 0.5714\n",
            "Epoch 87/200\n",
            "39/39 [==============================] - 1s 16ms/step - loss: 0.6980 - categorical_accuracy: 0.7144 - val_loss: 1.5398 - val_categorical_accuracy: 0.3571\n",
            "Epoch 88/200\n",
            "39/39 [==============================] - 1s 15ms/step - loss: 0.6737 - categorical_accuracy: 0.7275 - val_loss: 1.3345 - val_categorical_accuracy: 0.5000\n",
            "Epoch 89/200\n",
            "39/39 [==============================] - 1s 15ms/step - loss: 0.7179 - categorical_accuracy: 0.7111 - val_loss: 1.4971 - val_categorical_accuracy: 0.5000\n",
            "Epoch 90/200\n",
            "39/39 [==============================] - 1s 16ms/step - loss: 0.7469 - categorical_accuracy: 0.6820 - val_loss: 1.2539 - val_categorical_accuracy: 0.5143\n",
            "Epoch 91/200\n",
            "39/39 [==============================] - 1s 16ms/step - loss: 0.7856 - categorical_accuracy: 0.6543 - val_loss: 1.1134 - val_categorical_accuracy: 0.5143\n",
            "Epoch 92/200\n",
            "39/39 [==============================] - 1s 16ms/step - loss: 0.7398 - categorical_accuracy: 0.6635 - val_loss: 1.1339 - val_categorical_accuracy: 0.5429\n",
            "Epoch 93/200\n",
            "39/39 [==============================] - 1s 16ms/step - loss: 0.7670 - categorical_accuracy: 0.6537 - val_loss: 1.2167 - val_categorical_accuracy: 0.5286\n",
            "Epoch 94/200\n",
            "39/39 [==============================] - 1s 15ms/step - loss: 0.6882 - categorical_accuracy: 0.6988 - val_loss: 1.1346 - val_categorical_accuracy: 0.5429\n",
            "Epoch 95/200\n",
            "39/39 [==============================] - 1s 16ms/step - loss: 0.7148 - categorical_accuracy: 0.6843 - val_loss: 1.1977 - val_categorical_accuracy: 0.4143\n",
            "Epoch 96/200\n",
            "39/39 [==============================] - 1s 16ms/step - loss: 0.6928 - categorical_accuracy: 0.7261 - val_loss: 1.3558 - val_categorical_accuracy: 0.4429\n",
            "Epoch 97/200\n",
            "39/39 [==============================] - 1s 16ms/step - loss: 0.7321 - categorical_accuracy: 0.7048 - val_loss: 1.1611 - val_categorical_accuracy: 0.5143\n",
            "Epoch 98/200\n",
            "39/39 [==============================] - 1s 15ms/step - loss: 0.6952 - categorical_accuracy: 0.7004 - val_loss: 1.0857 - val_categorical_accuracy: 0.4714\n",
            "Epoch 99/200\n",
            "39/39 [==============================] - 1s 15ms/step - loss: 0.7051 - categorical_accuracy: 0.7051 - val_loss: 1.1150 - val_categorical_accuracy: 0.5286\n",
            "Epoch 100/200\n",
            "39/39 [==============================] - 1s 15ms/step - loss: 0.7075 - categorical_accuracy: 0.7191 - val_loss: 1.1781 - val_categorical_accuracy: 0.5571\n",
            "Epoch 101/200\n",
            "39/39 [==============================] - 1s 16ms/step - loss: 0.7137 - categorical_accuracy: 0.6897 - val_loss: 1.2577 - val_categorical_accuracy: 0.6000\n",
            "Epoch 102/200\n",
            "39/39 [==============================] - 1s 16ms/step - loss: 0.6823 - categorical_accuracy: 0.7226 - val_loss: 1.2825 - val_categorical_accuracy: 0.5000\n",
            "Epoch 103/200\n",
            "39/39 [==============================] - 1s 15ms/step - loss: 0.7448 - categorical_accuracy: 0.6822 - val_loss: 1.1887 - val_categorical_accuracy: 0.4571\n",
            "Epoch 104/200\n",
            "39/39 [==============================] - 1s 16ms/step - loss: 0.6809 - categorical_accuracy: 0.7147 - val_loss: 1.1720 - val_categorical_accuracy: 0.5286\n",
            "Epoch 105/200\n",
            "39/39 [==============================] - 1s 16ms/step - loss: 0.6814 - categorical_accuracy: 0.7461 - val_loss: 1.3109 - val_categorical_accuracy: 0.5571\n",
            "Epoch 106/200\n",
            "39/39 [==============================] - 1s 16ms/step - loss: 0.6749 - categorical_accuracy: 0.7190 - val_loss: 1.1550 - val_categorical_accuracy: 0.5429\n",
            "Epoch 107/200\n",
            "39/39 [==============================] - 1s 15ms/step - loss: 0.6335 - categorical_accuracy: 0.7312 - val_loss: 1.2976 - val_categorical_accuracy: 0.6000\n",
            "Epoch 108/200\n",
            "39/39 [==============================] - 1s 15ms/step - loss: 0.6716 - categorical_accuracy: 0.7151 - val_loss: 1.1386 - val_categorical_accuracy: 0.5429\n",
            "Epoch 109/200\n",
            "39/39 [==============================] - 1s 16ms/step - loss: 0.7337 - categorical_accuracy: 0.7076 - val_loss: 1.0730 - val_categorical_accuracy: 0.5714\n",
            "Epoch 110/200\n",
            "39/39 [==============================] - 1s 16ms/step - loss: 0.6858 - categorical_accuracy: 0.7110 - val_loss: 1.2268 - val_categorical_accuracy: 0.5857\n",
            "Epoch 111/200\n",
            "39/39 [==============================] - 1s 16ms/step - loss: 0.6968 - categorical_accuracy: 0.7038 - val_loss: 1.3015 - val_categorical_accuracy: 0.5000\n",
            "Epoch 112/200\n",
            "39/39 [==============================] - 1s 16ms/step - loss: 0.7011 - categorical_accuracy: 0.7084 - val_loss: 1.3722 - val_categorical_accuracy: 0.4286\n",
            "Epoch 113/200\n",
            "39/39 [==============================] - 1s 16ms/step - loss: 0.7498 - categorical_accuracy: 0.6964 - val_loss: 1.7400 - val_categorical_accuracy: 0.4143\n",
            "Epoch 114/200\n",
            "39/39 [==============================] - 1s 15ms/step - loss: 0.6286 - categorical_accuracy: 0.7441 - val_loss: 1.3192 - val_categorical_accuracy: 0.5143\n",
            "Epoch 115/200\n",
            "39/39 [==============================] - 1s 16ms/step - loss: 0.6896 - categorical_accuracy: 0.7009 - val_loss: 1.4245 - val_categorical_accuracy: 0.4571\n",
            "Epoch 116/200\n",
            "39/39 [==============================] - 1s 16ms/step - loss: 0.7217 - categorical_accuracy: 0.7009 - val_loss: 1.2832 - val_categorical_accuracy: 0.4571\n",
            "Epoch 117/200\n",
            "39/39 [==============================] - 1s 15ms/step - loss: 0.6448 - categorical_accuracy: 0.7243 - val_loss: 1.2484 - val_categorical_accuracy: 0.5714\n",
            "Epoch 118/200\n",
            "39/39 [==============================] - 1s 16ms/step - loss: 0.5812 - categorical_accuracy: 0.7390 - val_loss: 1.1770 - val_categorical_accuracy: 0.5143\n",
            "Epoch 119/200\n",
            "39/39 [==============================] - 1s 16ms/step - loss: 0.7414 - categorical_accuracy: 0.6991 - val_loss: 1.2196 - val_categorical_accuracy: 0.5571\n",
            "Epoch 120/200\n",
            "39/39 [==============================] - 1s 16ms/step - loss: 0.5846 - categorical_accuracy: 0.7547 - val_loss: 1.2222 - val_categorical_accuracy: 0.4857\n",
            "Epoch 121/200\n",
            "39/39 [==============================] - 1s 16ms/step - loss: 0.6040 - categorical_accuracy: 0.7405 - val_loss: 1.2066 - val_categorical_accuracy: 0.5429\n",
            "Epoch 122/200\n",
            "39/39 [==============================] - 1s 15ms/step - loss: 0.5579 - categorical_accuracy: 0.7649 - val_loss: 1.2548 - val_categorical_accuracy: 0.5286\n",
            "Epoch 123/200\n",
            "39/39 [==============================] - 1s 17ms/step - loss: 0.6514 - categorical_accuracy: 0.7439 - val_loss: 1.2849 - val_categorical_accuracy: 0.5571\n",
            "Epoch 124/200\n",
            "39/39 [==============================] - 1s 17ms/step - loss: 0.6833 - categorical_accuracy: 0.7138 - val_loss: 1.3146 - val_categorical_accuracy: 0.5571\n",
            "Epoch 125/200\n",
            "39/39 [==============================] - 1s 16ms/step - loss: 0.6502 - categorical_accuracy: 0.7656 - val_loss: 1.1955 - val_categorical_accuracy: 0.6000\n",
            "Epoch 126/200\n",
            "39/39 [==============================] - 1s 16ms/step - loss: 0.5768 - categorical_accuracy: 0.7603 - val_loss: 1.2200 - val_categorical_accuracy: 0.6143\n",
            "Epoch 127/200\n",
            "39/39 [==============================] - 1s 15ms/step - loss: 0.6510 - categorical_accuracy: 0.7161 - val_loss: 1.2845 - val_categorical_accuracy: 0.5429\n",
            "Epoch 128/200\n",
            "39/39 [==============================] - 1s 16ms/step - loss: 0.5981 - categorical_accuracy: 0.7606 - val_loss: 1.3402 - val_categorical_accuracy: 0.6143\n",
            "Epoch 129/200\n",
            "39/39 [==============================] - 1s 17ms/step - loss: 0.5222 - categorical_accuracy: 0.7718 - val_loss: 1.3099 - val_categorical_accuracy: 0.5571\n",
            "Epoch 130/200\n",
            "39/39 [==============================] - 1s 16ms/step - loss: 0.6010 - categorical_accuracy: 0.7453 - val_loss: 1.2841 - val_categorical_accuracy: 0.5429\n",
            "Epoch 131/200\n",
            "39/39 [==============================] - 1s 15ms/step - loss: 0.5106 - categorical_accuracy: 0.7920 - val_loss: 1.1292 - val_categorical_accuracy: 0.5143\n",
            "Epoch 132/200\n",
            "39/39 [==============================] - 1s 16ms/step - loss: 0.5917 - categorical_accuracy: 0.7666 - val_loss: 1.3223 - val_categorical_accuracy: 0.5714\n",
            "Epoch 133/200\n",
            "39/39 [==============================] - 1s 16ms/step - loss: 0.5807 - categorical_accuracy: 0.7478 - val_loss: 1.1790 - val_categorical_accuracy: 0.5429\n",
            "Epoch 134/200\n",
            "39/39 [==============================] - 1s 16ms/step - loss: 0.5629 - categorical_accuracy: 0.7554 - val_loss: 1.3553 - val_categorical_accuracy: 0.5571\n",
            "Epoch 135/200\n",
            "39/39 [==============================] - 1s 17ms/step - loss: 0.4713 - categorical_accuracy: 0.8005 - val_loss: 1.2710 - val_categorical_accuracy: 0.5857\n",
            "Epoch 136/200\n",
            "39/39 [==============================] - 1s 16ms/step - loss: 0.4525 - categorical_accuracy: 0.8463 - val_loss: 1.2344 - val_categorical_accuracy: 0.5714\n",
            "Epoch 137/200\n",
            "39/39 [==============================] - 1s 17ms/step - loss: 0.5307 - categorical_accuracy: 0.8133 - val_loss: 1.4003 - val_categorical_accuracy: 0.5286\n",
            "Epoch 138/200\n",
            "39/39 [==============================] - 1s 15ms/step - loss: 0.4737 - categorical_accuracy: 0.8086 - val_loss: 1.3908 - val_categorical_accuracy: 0.5286\n",
            "Epoch 139/200\n",
            "39/39 [==============================] - 1s 16ms/step - loss: 0.5773 - categorical_accuracy: 0.7784 - val_loss: 1.4332 - val_categorical_accuracy: 0.4857\n",
            "Epoch 140/200\n",
            "39/39 [==============================] - 1s 16ms/step - loss: 0.5576 - categorical_accuracy: 0.7643 - val_loss: 1.0429 - val_categorical_accuracy: 0.6429\n",
            "Epoch 141/200\n",
            "39/39 [==============================] - 1s 16ms/step - loss: 0.5852 - categorical_accuracy: 0.7556 - val_loss: 1.1601 - val_categorical_accuracy: 0.6143\n",
            "Epoch 142/200\n",
            "39/39 [==============================] - 1s 16ms/step - loss: 0.4822 - categorical_accuracy: 0.8087 - val_loss: 1.2693 - val_categorical_accuracy: 0.5714\n",
            "Epoch 143/200\n",
            "39/39 [==============================] - 1s 16ms/step - loss: 0.5215 - categorical_accuracy: 0.7986 - val_loss: 1.3072 - val_categorical_accuracy: 0.5857\n",
            "Epoch 144/200\n",
            "39/39 [==============================] - 1s 17ms/step - loss: 0.4103 - categorical_accuracy: 0.8333 - val_loss: 1.2929 - val_categorical_accuracy: 0.5857\n",
            "Epoch 145/200\n",
            "39/39 [==============================] - 1s 16ms/step - loss: 0.4475 - categorical_accuracy: 0.8447 - val_loss: 1.2373 - val_categorical_accuracy: 0.5143\n",
            "Epoch 146/200\n",
            "39/39 [==============================] - 1s 15ms/step - loss: 0.4923 - categorical_accuracy: 0.7916 - val_loss: 1.3031 - val_categorical_accuracy: 0.6000\n",
            "Epoch 147/200\n",
            "39/39 [==============================] - 1s 16ms/step - loss: 0.4787 - categorical_accuracy: 0.8170 - val_loss: 1.4372 - val_categorical_accuracy: 0.5286\n",
            "Epoch 148/200\n",
            "39/39 [==============================] - 1s 16ms/step - loss: 0.4683 - categorical_accuracy: 0.8118 - val_loss: 1.4871 - val_categorical_accuracy: 0.5286\n",
            "Epoch 149/200\n",
            "39/39 [==============================] - 1s 16ms/step - loss: 0.4907 - categorical_accuracy: 0.8078 - val_loss: 1.3898 - val_categorical_accuracy: 0.5429\n",
            "Epoch 150/200\n",
            "39/39 [==============================] - 1s 16ms/step - loss: 0.4867 - categorical_accuracy: 0.7822 - val_loss: 1.4266 - val_categorical_accuracy: 0.5143\n",
            "Epoch 151/200\n",
            "39/39 [==============================] - 1s 16ms/step - loss: 0.4961 - categorical_accuracy: 0.8126 - val_loss: 1.2305 - val_categorical_accuracy: 0.6000\n",
            "Epoch 152/200\n",
            "39/39 [==============================] - 1s 17ms/step - loss: 0.4708 - categorical_accuracy: 0.8187 - val_loss: 1.2165 - val_categorical_accuracy: 0.5286\n",
            "Epoch 153/200\n",
            "39/39 [==============================] - 1s 15ms/step - loss: 0.4616 - categorical_accuracy: 0.8277 - val_loss: 1.2328 - val_categorical_accuracy: 0.5714\n",
            "Epoch 154/200\n",
            "39/39 [==============================] - 1s 17ms/step - loss: 0.3872 - categorical_accuracy: 0.8321 - val_loss: 1.3409 - val_categorical_accuracy: 0.5143\n",
            "Epoch 155/200\n",
            "39/39 [==============================] - 1s 16ms/step - loss: 0.4274 - categorical_accuracy: 0.8248 - val_loss: 1.2535 - val_categorical_accuracy: 0.5429\n",
            "Epoch 156/200\n",
            "39/39 [==============================] - 1s 16ms/step - loss: 0.4133 - categorical_accuracy: 0.8463 - val_loss: 1.5196 - val_categorical_accuracy: 0.5429\n",
            "Epoch 157/200\n",
            "39/39 [==============================] - 1s 16ms/step - loss: 0.5220 - categorical_accuracy: 0.7942 - val_loss: 1.8876 - val_categorical_accuracy: 0.4429\n",
            "Epoch 158/200\n",
            "39/39 [==============================] - 1s 16ms/step - loss: 0.4588 - categorical_accuracy: 0.8245 - val_loss: 1.4657 - val_categorical_accuracy: 0.5571\n",
            "Epoch 159/200\n",
            "39/39 [==============================] - 1s 16ms/step - loss: 0.4406 - categorical_accuracy: 0.8289 - val_loss: 1.2848 - val_categorical_accuracy: 0.5286\n",
            "Epoch 160/200\n",
            "39/39 [==============================] - 1s 16ms/step - loss: 0.4404 - categorical_accuracy: 0.8565 - val_loss: 1.3207 - val_categorical_accuracy: 0.5429\n",
            "Epoch 161/200\n",
            "39/39 [==============================] - 1s 16ms/step - loss: 0.4371 - categorical_accuracy: 0.8283 - val_loss: 1.2187 - val_categorical_accuracy: 0.5571\n",
            "Epoch 162/200\n",
            "39/39 [==============================] - 1s 16ms/step - loss: 0.3816 - categorical_accuracy: 0.8605 - val_loss: 1.3830 - val_categorical_accuracy: 0.5286\n",
            "Epoch 163/200\n",
            "39/39 [==============================] - 1s 16ms/step - loss: 0.4830 - categorical_accuracy: 0.8198 - val_loss: 1.2734 - val_categorical_accuracy: 0.5286\n",
            "Epoch 164/200\n",
            "39/39 [==============================] - 1s 17ms/step - loss: 0.4189 - categorical_accuracy: 0.8468 - val_loss: 1.5683 - val_categorical_accuracy: 0.4286\n",
            "Epoch 165/200\n",
            "39/39 [==============================] - 1s 16ms/step - loss: 0.4316 - categorical_accuracy: 0.8224 - val_loss: 1.4579 - val_categorical_accuracy: 0.5429\n",
            "Epoch 166/200\n",
            "39/39 [==============================] - 1s 17ms/step - loss: 0.4337 - categorical_accuracy: 0.8421 - val_loss: 1.3532 - val_categorical_accuracy: 0.5571\n",
            "Epoch 167/200\n",
            "39/39 [==============================] - 1s 17ms/step - loss: 0.3914 - categorical_accuracy: 0.8522 - val_loss: 1.4290 - val_categorical_accuracy: 0.5429\n",
            "Epoch 168/200\n",
            "39/39 [==============================] - 1s 16ms/step - loss: 0.3704 - categorical_accuracy: 0.8621 - val_loss: 1.3445 - val_categorical_accuracy: 0.5286\n",
            "Epoch 169/200\n",
            "39/39 [==============================] - 1s 16ms/step - loss: 0.3393 - categorical_accuracy: 0.8610 - val_loss: 1.3502 - val_categorical_accuracy: 0.5714\n",
            "Epoch 170/200\n",
            "39/39 [==============================] - 1s 15ms/step - loss: 0.3589 - categorical_accuracy: 0.8530 - val_loss: 1.4313 - val_categorical_accuracy: 0.5429\n",
            "Epoch 171/200\n",
            "39/39 [==============================] - 1s 16ms/step - loss: 0.3870 - categorical_accuracy: 0.8653 - val_loss: 1.3757 - val_categorical_accuracy: 0.5857\n",
            "Epoch 172/200\n",
            "39/39 [==============================] - 1s 16ms/step - loss: 0.3625 - categorical_accuracy: 0.8527 - val_loss: 1.5739 - val_categorical_accuracy: 0.5143\n",
            "Epoch 173/200\n",
            "39/39 [==============================] - 1s 16ms/step - loss: 0.3489 - categorical_accuracy: 0.8417 - val_loss: 1.5023 - val_categorical_accuracy: 0.5429\n",
            "Epoch 174/200\n",
            "39/39 [==============================] - 1s 16ms/step - loss: 0.3699 - categorical_accuracy: 0.8644 - val_loss: 1.3757 - val_categorical_accuracy: 0.5714\n",
            "Epoch 175/200\n",
            "39/39 [==============================] - 1s 16ms/step - loss: 0.3822 - categorical_accuracy: 0.8626 - val_loss: 1.2995 - val_categorical_accuracy: 0.5857\n",
            "Epoch 176/200\n",
            "39/39 [==============================] - 1s 16ms/step - loss: 0.3764 - categorical_accuracy: 0.8655 - val_loss: 1.4065 - val_categorical_accuracy: 0.5429\n",
            "Epoch 177/200\n",
            "39/39 [==============================] - 1s 16ms/step - loss: 0.3190 - categorical_accuracy: 0.8923 - val_loss: 1.4408 - val_categorical_accuracy: 0.5714\n",
            "Epoch 178/200\n",
            "39/39 [==============================] - 1s 16ms/step - loss: 0.3338 - categorical_accuracy: 0.8588 - val_loss: 1.4316 - val_categorical_accuracy: 0.5429\n",
            "Epoch 179/200\n",
            "39/39 [==============================] - 1s 16ms/step - loss: 0.3135 - categorical_accuracy: 0.8940 - val_loss: 1.3341 - val_categorical_accuracy: 0.5714\n",
            "Epoch 180/200\n",
            "39/39 [==============================] - 1s 17ms/step - loss: 0.4066 - categorical_accuracy: 0.8449 - val_loss: 1.1668 - val_categorical_accuracy: 0.6000\n",
            "Epoch 181/200\n",
            "39/39 [==============================] - 1s 16ms/step - loss: 0.3807 - categorical_accuracy: 0.8475 - val_loss: 1.3385 - val_categorical_accuracy: 0.5571\n",
            "Epoch 182/200\n",
            "39/39 [==============================] - 1s 16ms/step - loss: 0.3078 - categorical_accuracy: 0.8931 - val_loss: 1.3702 - val_categorical_accuracy: 0.5143\n",
            "Epoch 183/200\n",
            "39/39 [==============================] - 1s 17ms/step - loss: 0.3403 - categorical_accuracy: 0.8655 - val_loss: 1.2770 - val_categorical_accuracy: 0.5429\n",
            "Epoch 184/200\n",
            "39/39 [==============================] - 1s 17ms/step - loss: 0.3370 - categorical_accuracy: 0.8760 - val_loss: 1.2015 - val_categorical_accuracy: 0.5714\n",
            "Epoch 185/200\n",
            "39/39 [==============================] - 1s 17ms/step - loss: 0.3198 - categorical_accuracy: 0.8634 - val_loss: 1.5784 - val_categorical_accuracy: 0.5143\n",
            "Epoch 186/200\n",
            "39/39 [==============================] - 1s 16ms/step - loss: 0.2848 - categorical_accuracy: 0.8921 - val_loss: 1.2160 - val_categorical_accuracy: 0.5571\n",
            "Epoch 187/200\n",
            "39/39 [==============================] - 1s 16ms/step - loss: 0.3278 - categorical_accuracy: 0.8787 - val_loss: 1.3686 - val_categorical_accuracy: 0.5571\n",
            "Epoch 188/200\n",
            "39/39 [==============================] - 1s 17ms/step - loss: 0.3308 - categorical_accuracy: 0.8862 - val_loss: 1.5454 - val_categorical_accuracy: 0.5571\n",
            "Epoch 189/200\n",
            "39/39 [==============================] - 1s 16ms/step - loss: 0.3570 - categorical_accuracy: 0.8776 - val_loss: 1.4936 - val_categorical_accuracy: 0.5286\n",
            "Epoch 190/200\n",
            "39/39 [==============================] - 1s 16ms/step - loss: 0.2622 - categorical_accuracy: 0.9048 - val_loss: 1.5520 - val_categorical_accuracy: 0.5857\n",
            "Epoch 191/200\n",
            "39/39 [==============================] - 1s 15ms/step - loss: 0.2814 - categorical_accuracy: 0.9017 - val_loss: 1.4408 - val_categorical_accuracy: 0.5286\n",
            "Epoch 192/200\n",
            "39/39 [==============================] - 1s 16ms/step - loss: 0.2576 - categorical_accuracy: 0.9057 - val_loss: 1.4549 - val_categorical_accuracy: 0.5143\n",
            "Epoch 193/200\n",
            "39/39 [==============================] - 1s 17ms/step - loss: 0.2913 - categorical_accuracy: 0.8974 - val_loss: 1.5249 - val_categorical_accuracy: 0.5714\n",
            "Epoch 194/200\n",
            "39/39 [==============================] - 1s 16ms/step - loss: 0.2956 - categorical_accuracy: 0.8799 - val_loss: 1.2813 - val_categorical_accuracy: 0.5714\n",
            "Epoch 195/200\n",
            "39/39 [==============================] - 1s 16ms/step - loss: 0.2867 - categorical_accuracy: 0.8937 - val_loss: 1.6183 - val_categorical_accuracy: 0.5286\n",
            "Epoch 196/200\n",
            "39/39 [==============================] - 1s 16ms/step - loss: 0.3276 - categorical_accuracy: 0.8720 - val_loss: 1.7198 - val_categorical_accuracy: 0.5429\n",
            "Epoch 197/200\n",
            "39/39 [==============================] - 1s 17ms/step - loss: 0.2756 - categorical_accuracy: 0.9163 - val_loss: 1.5941 - val_categorical_accuracy: 0.5857\n",
            "Epoch 198/200\n",
            "39/39 [==============================] - 1s 16ms/step - loss: 0.2418 - categorical_accuracy: 0.9114 - val_loss: 1.6062 - val_categorical_accuracy: 0.5429\n",
            "Epoch 199/200\n",
            "39/39 [==============================] - 1s 15ms/step - loss: 0.2939 - categorical_accuracy: 0.8659 - val_loss: 1.5792 - val_categorical_accuracy: 0.5143\n",
            "Epoch 200/200\n",
            "39/39 [==============================] - 1s 16ms/step - loss: 0.3296 - categorical_accuracy: 0.8598 - val_loss: 1.3081 - val_categorical_accuracy: 0.5714\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HvyjmqkBFjit"
      },
      "source": [
        "model.save('/content/drive/MyDrive/Colab Notebooks/SPEECH_EMOTION_Recognition/Nộp bài(chốt hạ)/model_saver/conv1D_mfcc39_ravdess.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pskOhf2FFjiv"
      },
      "source": [
        "###test_result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0KNK4XtRFjiw",
        "outputId": "e289be21-baf8-4486-a0db-ba04bfe8f3cf"
      },
      "source": [
        "d = {0: 'happy',\n",
        "     1: 'sad',\n",
        "     2: 'angry',\n",
        "     3: 'fear'}\n",
        "Y_test_pred = np.argmax(model.predict(X_test), axis=-1)\n",
        "Y_test_pred = list(map(lambda x: d[x], Y_test_pred))\n",
        "y_test = np.argmax(y_test, axis=-1)\n",
        "y_test = list(map(lambda x: d[x], y_test))\n",
        "print(classification_report(y_test, Y_test_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.75      0.69      0.72        13\n",
            "        fear       0.58      0.67      0.62        21\n",
            "       happy       0.65      0.48      0.55        23\n",
            "         sad       0.67      0.80      0.73        20\n",
            "\n",
            "    accuracy                           0.65        77\n",
            "   macro avg       0.66      0.66      0.65        77\n",
            "weighted avg       0.65      0.65      0.64        77\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "id": "QdWuqzrMFjiw",
        "outputId": "af677e2f-6dba-4c88-f837-0207f2f7db56"
      },
      "source": [
        "import scikitplot as skplt\n",
        "\n",
        "skplt.metrics.plot_confusion_matrix(\n",
        "    y_test, \n",
        "    Y_test_pred,\n",
        "    figsize=(8,8))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fda8e3e5410>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dV7-VjwtFjix"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8JPwepBQ2ndF"
      },
      "source": [
        "# mfcc_13 + conv2D:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wmPx3AB62ndc"
      },
      "source": [
        "audio_duration = 3\n",
        "sampling_rate = 22050\n",
        "input_length = sampling_rate * audio_duration"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hwf1Uquo2ndd"
      },
      "source": [
        "features = []\n",
        "labels = []\n",
        "for i in range(len(Ravdess_DF['Paths'])):\n",
        "  if ((Ravdess_DF['Emotion'][i] == '03') | (Ravdess_DF['Emotion'][i] == '04') | \n",
        "      (Ravdess_DF['Emotion'][i] == '05') | (Ravdess_DF['Emotion'][i] == '06')):\n",
        "    signal, sr = librosa.load(Ravdess_DF['Paths'][i])\n",
        "\n",
        "    if len(signal) > input_length:\n",
        "      signal = signal[0:input_length]\n",
        "    elif  input_length > len(signal):\n",
        "      max_offset = input_length - len(signal)  \n",
        "      signal = np.pad(signal, (0, max_offset), \"constant\")\n",
        "\n",
        "    mfcc = librosa.feature.mfcc(y=signal, sr=sr, n_mfcc=13).T\n",
        "    mfcc = np.expand_dims(mfcc, axis=-1)\n",
        "    features.append(mfcc)\n",
        "\n",
        "    if Ravdess_DF['Emotion'][i] == '03':\n",
        "      labels.append(0)\n",
        "    elif Ravdess_DF['Emotion'][i] == '04':\n",
        "      labels.append(1)\n",
        "    elif Ravdess_DF['Emotion'][i] == '05':\n",
        "      labels.append(2)\n",
        "    elif Ravdess_DF['Emotion'][i] == '06':\n",
        "      labels.append(3)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahakomyG2nde"
      },
      "source": [
        "X = features\n",
        "y = labels\n",
        "\n",
        "y = np.array(y)\n",
        "y = to_categorical(y)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=0)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=0)\n",
        "\n",
        "X_train = np.array(X_train)\n",
        "X_test = np.array(X_test)\n",
        "X_val = np.array(X_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xaP08C9C2nde",
        "outputId": "b3c40b82-b395-4f52-b2b7-1ebe436e03a6"
      },
      "source": [
        "X_train.shape,X_test.shape,y_train.shape,y_test.shape\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((621, 130, 13, 1), (77, 130, 13, 1), (621, 4), (77, 4))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UsHxeSsK2ndf"
      },
      "source": [
        "# CNN I/P Config\n",
        "num_classes = 4\n",
        "input_shape = X_train.shape[1:]\n",
        "learning_rate = 0.0001\n",
        "decay = 1e-6\n",
        "momentum = 0.9"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0RqouXuA2ndg",
        "outputId": "4d1a26ef-6d90-4678-d3ea-a2bf419e48ba"
      },
      "source": [
        "model = Sequential(name='Audio_CNN_2D')\n",
        "\n",
        "# LFLB1\n",
        "model.add(Conv2D(filters=64, kernel_size=(3,3), strides=(1,1), padding='same',input_shape=input_shape))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Conv2D(filters=64, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(4,4), strides=(4,4)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(units=num_classes, activation='softmax'))\n",
        "\n",
        "# Model compilation\n",
        "opt = optimizers.SGD(lr=learning_rate, decay=decay, momentum=momentum, nesterov=True)\n",
        "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"Audio_CNN_2D\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 130, 13, 64)       640       \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 130, 13, 64)       256       \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 130, 13, 64)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 65, 6, 64)         0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 65, 6, 64)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 65, 6, 64)         36928     \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 65, 6, 64)         256       \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 65, 6, 64)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 16, 1, 64)         0         \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 16, 1, 64)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 4)                 4100      \n",
            "=================================================================\n",
            "Total params: 42,180\n",
            "Trainable params: 41,924\n",
            "Non-trainable params: 256\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2_85mCVM2ndg",
        "outputId": "3eb1699a-e397-463a-a45c-245406684e59"
      },
      "source": [
        "#Train Config\n",
        "\n",
        "batch_size = 16\n",
        "num_epochs = 200\n",
        "\n",
        "# Model Training\n",
        "lr_reduce = ReduceLROnPlateau(monitor='val_loss', factor=0.9, patience=20, min_lr=0.000001)\n",
        "# Please change the model name accordingly.\n",
        "mcp_save = ModelCheckpoint('/content/Modelfull_2_1.h5', save_best_only=True, monitor='val_categorical_accuracy', mode='max')\n",
        "cnnhistory=model.fit(X_train, y_train, batch_size=batch_size, epochs=num_epochs,validation_data=(X_val, y_val), callbacks=[mcp_save, lr_reduce])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "39/39 [==============================] - 3s 20ms/step - loss: 2.7719 - categorical_accuracy: 0.2917 - val_loss: 2.0664 - val_categorical_accuracy: 0.2571\n",
            "Epoch 2/200\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 2.2485 - categorical_accuracy: 0.3436 - val_loss: 1.5513 - val_categorical_accuracy: 0.2714\n",
            "Epoch 3/200\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 2.2768 - categorical_accuracy: 0.3220 - val_loss: 1.4574 - val_categorical_accuracy: 0.3429\n",
            "Epoch 4/200\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 2.0994 - categorical_accuracy: 0.3549 - val_loss: 1.3980 - val_categorical_accuracy: 0.3000\n",
            "Epoch 5/200\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 2.0014 - categorical_accuracy: 0.3190 - val_loss: 1.3988 - val_categorical_accuracy: 0.3143\n",
            "Epoch 6/200\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 1.9409 - categorical_accuracy: 0.3190 - val_loss: 1.3968 - val_categorical_accuracy: 0.3857\n",
            "Epoch 7/200\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 1.8557 - categorical_accuracy: 0.3388 - val_loss: 1.3392 - val_categorical_accuracy: 0.3571\n",
            "Epoch 8/200\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 1.7042 - categorical_accuracy: 0.4048 - val_loss: 1.3010 - val_categorical_accuracy: 0.3571\n",
            "Epoch 9/200\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 1.7437 - categorical_accuracy: 0.3651 - val_loss: 1.2902 - val_categorical_accuracy: 0.3714\n",
            "Epoch 10/200\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 1.7569 - categorical_accuracy: 0.3599 - val_loss: 1.3302 - val_categorical_accuracy: 0.3429\n",
            "Epoch 11/200\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 1.6210 - categorical_accuracy: 0.4359 - val_loss: 1.3553 - val_categorical_accuracy: 0.3571\n",
            "Epoch 12/200\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 1.6370 - categorical_accuracy: 0.3961 - val_loss: 1.2206 - val_categorical_accuracy: 0.4000\n",
            "Epoch 13/200\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 1.7102 - categorical_accuracy: 0.3441 - val_loss: 1.2844 - val_categorical_accuracy: 0.4000\n",
            "Epoch 14/200\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 1.6482 - categorical_accuracy: 0.3392 - val_loss: 1.3302 - val_categorical_accuracy: 0.3857\n",
            "Epoch 15/200\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 1.5343 - categorical_accuracy: 0.4177 - val_loss: 1.3567 - val_categorical_accuracy: 0.4000\n",
            "Epoch 16/200\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 1.4440 - categorical_accuracy: 0.4272 - val_loss: 1.3620 - val_categorical_accuracy: 0.3857\n",
            "Epoch 17/200\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 1.5549 - categorical_accuracy: 0.4041 - val_loss: 1.2629 - val_categorical_accuracy: 0.4000\n",
            "Epoch 18/200\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 1.5105 - categorical_accuracy: 0.3952 - val_loss: 1.2167 - val_categorical_accuracy: 0.4000\n",
            "Epoch 19/200\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 1.4695 - categorical_accuracy: 0.3851 - val_loss: 1.2104 - val_categorical_accuracy: 0.3857\n",
            "Epoch 20/200\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 1.4718 - categorical_accuracy: 0.4149 - val_loss: 1.2133 - val_categorical_accuracy: 0.4429\n",
            "Epoch 21/200\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 1.3892 - categorical_accuracy: 0.4635 - val_loss: 1.1871 - val_categorical_accuracy: 0.4000\n",
            "Epoch 22/200\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 1.4501 - categorical_accuracy: 0.3823 - val_loss: 1.2001 - val_categorical_accuracy: 0.4857\n",
            "Epoch 23/200\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 1.4244 - categorical_accuracy: 0.4035 - val_loss: 1.2221 - val_categorical_accuracy: 0.4000\n",
            "Epoch 24/200\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 1.3171 - categorical_accuracy: 0.4844 - val_loss: 1.1538 - val_categorical_accuracy: 0.4857\n",
            "Epoch 25/200\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 1.3855 - categorical_accuracy: 0.4103 - val_loss: 1.1884 - val_categorical_accuracy: 0.4000\n",
            "Epoch 26/200\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 1.4059 - categorical_accuracy: 0.4210 - val_loss: 1.1990 - val_categorical_accuracy: 0.4286\n",
            "Epoch 27/200\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 1.3538 - categorical_accuracy: 0.4553 - val_loss: 1.1769 - val_categorical_accuracy: 0.4429\n",
            "Epoch 28/200\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 1.4243 - categorical_accuracy: 0.3808 - val_loss: 1.1662 - val_categorical_accuracy: 0.4571\n",
            "Epoch 29/200\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 1.3143 - categorical_accuracy: 0.4585 - val_loss: 1.1633 - val_categorical_accuracy: 0.4286\n",
            "Epoch 30/200\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 1.4118 - categorical_accuracy: 0.4250 - val_loss: 1.1664 - val_categorical_accuracy: 0.4429\n",
            "Epoch 31/200\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 1.3163 - categorical_accuracy: 0.4513 - val_loss: 1.1618 - val_categorical_accuracy: 0.4571\n",
            "Epoch 32/200\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 1.3050 - categorical_accuracy: 0.4468 - val_loss: 1.1800 - val_categorical_accuracy: 0.4286\n",
            "Epoch 33/200\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 1.2976 - categorical_accuracy: 0.4554 - val_loss: 1.1864 - val_categorical_accuracy: 0.4429\n",
            "Epoch 34/200\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 1.3169 - categorical_accuracy: 0.4541 - val_loss: 1.1605 - val_categorical_accuracy: 0.4286\n",
            "Epoch 35/200\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 1.2816 - categorical_accuracy: 0.4566 - val_loss: 1.1605 - val_categorical_accuracy: 0.4714\n",
            "Epoch 36/200\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 1.2729 - categorical_accuracy: 0.4438 - val_loss: 1.1265 - val_categorical_accuracy: 0.5000\n",
            "Epoch 37/200\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 1.2929 - categorical_accuracy: 0.4458 - val_loss: 1.1352 - val_categorical_accuracy: 0.4857\n",
            "Epoch 38/200\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 1.3086 - categorical_accuracy: 0.4288 - val_loss: 1.1385 - val_categorical_accuracy: 0.4571\n",
            "Epoch 39/200\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 1.2454 - categorical_accuracy: 0.4643 - val_loss: 1.1372 - val_categorical_accuracy: 0.4857\n",
            "Epoch 40/200\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 1.2575 - categorical_accuracy: 0.4734 - val_loss: 1.1521 - val_categorical_accuracy: 0.4714\n",
            "Epoch 41/200\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 1.3338 - categorical_accuracy: 0.4214 - val_loss: 1.1469 - val_categorical_accuracy: 0.4857\n",
            "Epoch 42/200\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 1.2233 - categorical_accuracy: 0.4561 - val_loss: 1.1317 - val_categorical_accuracy: 0.4571\n",
            "Epoch 43/200\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 1.1750 - categorical_accuracy: 0.5017 - val_loss: 1.1526 - val_categorical_accuracy: 0.4857\n",
            "Epoch 44/200\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 1.2768 - categorical_accuracy: 0.4663 - val_loss: 1.1323 - val_categorical_accuracy: 0.4857\n",
            "Epoch 45/200\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 1.3392 - categorical_accuracy: 0.4222 - val_loss: 1.1221 - val_categorical_accuracy: 0.5286\n",
            "Epoch 46/200\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 1.2029 - categorical_accuracy: 0.4407 - val_loss: 1.0934 - val_categorical_accuracy: 0.5429\n",
            "Epoch 47/200\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 1.2025 - categorical_accuracy: 0.4901 - val_loss: 1.0960 - val_categorical_accuracy: 0.5429\n",
            "Epoch 48/200\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 1.3394 - categorical_accuracy: 0.4776 - val_loss: 1.1064 - val_categorical_accuracy: 0.4857\n",
            "Epoch 49/200\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 1.2365 - categorical_accuracy: 0.4520 - val_loss: 1.1455 - val_categorical_accuracy: 0.4857\n",
            "Epoch 50/200\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 1.2642 - categorical_accuracy: 0.4427 - val_loss: 1.1087 - val_categorical_accuracy: 0.5000\n",
            "Epoch 51/200\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 1.1861 - categorical_accuracy: 0.4863 - val_loss: 1.0969 - val_categorical_accuracy: 0.5000\n",
            "Epoch 52/200\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 1.2643 - categorical_accuracy: 0.4896 - val_loss: 1.1097 - val_categorical_accuracy: 0.4857\n",
            "Epoch 53/200\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 1.2589 - categorical_accuracy: 0.4555 - val_loss: 1.1019 - val_categorical_accuracy: 0.5429\n",
            "Epoch 54/200\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 1.2135 - categorical_accuracy: 0.4803 - val_loss: 1.1363 - val_categorical_accuracy: 0.5000\n",
            "Epoch 55/200\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 1.1541 - categorical_accuracy: 0.5078 - val_loss: 1.0923 - val_categorical_accuracy: 0.5571\n",
            "Epoch 56/200\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 1.2538 - categorical_accuracy: 0.4664 - val_loss: 1.1038 - val_categorical_accuracy: 0.5000\n",
            "Epoch 57/200\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 1.1635 - categorical_accuracy: 0.5284 - val_loss: 1.1074 - val_categorical_accuracy: 0.4857\n",
            "Epoch 58/200\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 1.1722 - categorical_accuracy: 0.4717 - val_loss: 1.1159 - val_categorical_accuracy: 0.5000\n",
            "Epoch 59/200\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 1.2468 - categorical_accuracy: 0.4958 - val_loss: 1.0735 - val_categorical_accuracy: 0.5000\n",
            "Epoch 60/200\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 1.2217 - categorical_accuracy: 0.4704 - val_loss: 1.1009 - val_categorical_accuracy: 0.5143\n",
            "Epoch 61/200\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 1.2436 - categorical_accuracy: 0.4787 - val_loss: 1.0749 - val_categorical_accuracy: 0.5286\n",
            "Epoch 62/200\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 1.1850 - categorical_accuracy: 0.5169 - val_loss: 1.0918 - val_categorical_accuracy: 0.5000\n",
            "Epoch 63/200\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 1.2054 - categorical_accuracy: 0.5042 - val_loss: 1.1235 - val_categorical_accuracy: 0.4714\n",
            "Epoch 64/200\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 1.1396 - categorical_accuracy: 0.5375 - val_loss: 1.0789 - val_categorical_accuracy: 0.5571\n",
            "Epoch 65/200\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 1.1762 - categorical_accuracy: 0.5027 - val_loss: 1.1291 - val_categorical_accuracy: 0.4714\n",
            "Epoch 66/200\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 1.1793 - categorical_accuracy: 0.4890 - val_loss: 1.1119 - val_categorical_accuracy: 0.5143\n",
            "Epoch 67/200\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 1.2219 - categorical_accuracy: 0.4759 - val_loss: 1.0868 - val_categorical_accuracy: 0.5000\n",
            "Epoch 68/200\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 1.1872 - categorical_accuracy: 0.4866 - val_loss: 1.0800 - val_categorical_accuracy: 0.5286\n",
            "Epoch 69/200\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 1.2076 - categorical_accuracy: 0.5019 - val_loss: 1.0695 - val_categorical_accuracy: 0.5714\n",
            "Epoch 70/200\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 1.1568 - categorical_accuracy: 0.5071 - val_loss: 1.0861 - val_categorical_accuracy: 0.4857\n",
            "Epoch 71/200\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 1.1693 - categorical_accuracy: 0.5037 - val_loss: 1.0731 - val_categorical_accuracy: 0.5286\n",
            "Epoch 72/200\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 1.1589 - categorical_accuracy: 0.4757 - val_loss: 1.1162 - val_categorical_accuracy: 0.4429\n",
            "Epoch 73/200\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 1.2365 - categorical_accuracy: 0.4584 - val_loss: 1.0754 - val_categorical_accuracy: 0.5143\n",
            "Epoch 74/200\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 1.1442 - categorical_accuracy: 0.5171 - val_loss: 1.0871 - val_categorical_accuracy: 0.5000\n",
            "Epoch 75/200\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 1.2171 - categorical_accuracy: 0.4891 - val_loss: 1.0730 - val_categorical_accuracy: 0.5286\n",
            "Epoch 76/200\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 1.1013 - categorical_accuracy: 0.5082 - val_loss: 1.0669 - val_categorical_accuracy: 0.5571\n",
            "Epoch 77/200\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 1.1881 - categorical_accuracy: 0.4460 - val_loss: 1.0526 - val_categorical_accuracy: 0.5429\n",
            "Epoch 78/200\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 1.1836 - categorical_accuracy: 0.4873 - val_loss: 1.0730 - val_categorical_accuracy: 0.5429\n",
            "Epoch 79/200\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 1.1459 - categorical_accuracy: 0.5312 - val_loss: 1.0535 - val_categorical_accuracy: 0.5429\n",
            "Epoch 80/200\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 1.1348 - categorical_accuracy: 0.5153 - val_loss: 1.0976 - val_categorical_accuracy: 0.4571\n",
            "Epoch 81/200\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 1.1383 - categorical_accuracy: 0.4923 - val_loss: 1.0528 - val_categorical_accuracy: 0.5143\n",
            "Epoch 82/200\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 1.1695 - categorical_accuracy: 0.5008 - val_loss: 1.0468 - val_categorical_accuracy: 0.5857\n",
            "Epoch 83/200\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 1.1512 - categorical_accuracy: 0.4810 - val_loss: 1.0531 - val_categorical_accuracy: 0.5571\n",
            "Epoch 84/200\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 1.0892 - categorical_accuracy: 0.5294 - val_loss: 1.0340 - val_categorical_accuracy: 0.5714\n",
            "Epoch 85/200\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 1.0635 - categorical_accuracy: 0.5493 - val_loss: 1.0581 - val_categorical_accuracy: 0.5286\n",
            "Epoch 86/200\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 1.1651 - categorical_accuracy: 0.5398 - val_loss: 1.0408 - val_categorical_accuracy: 0.5429\n",
            "Epoch 87/200\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 1.0931 - categorical_accuracy: 0.5392 - val_loss: 1.0625 - val_categorical_accuracy: 0.5143\n",
            "Epoch 88/200\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 1.0654 - categorical_accuracy: 0.5561 - val_loss: 1.0817 - val_categorical_accuracy: 0.5286\n",
            "Epoch 89/200\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 1.1052 - categorical_accuracy: 0.5153 - val_loss: 1.0326 - val_categorical_accuracy: 0.5714\n",
            "Epoch 90/200\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 1.1149 - categorical_accuracy: 0.5252 - val_loss: 1.0510 - val_categorical_accuracy: 0.5571\n",
            "Epoch 91/200\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 1.1281 - categorical_accuracy: 0.5211 - val_loss: 1.0432 - val_categorical_accuracy: 0.5857\n",
            "Epoch 92/200\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 1.0909 - categorical_accuracy: 0.5330 - val_loss: 1.0445 - val_categorical_accuracy: 0.5857\n",
            "Epoch 93/200\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 1.1003 - categorical_accuracy: 0.5241 - val_loss: 1.0452 - val_categorical_accuracy: 0.5286\n",
            "Epoch 94/200\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 1.1038 - categorical_accuracy: 0.5364 - val_loss: 1.0191 - val_categorical_accuracy: 0.5714\n",
            "Epoch 95/200\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 1.0671 - categorical_accuracy: 0.5283 - val_loss: 1.0145 - val_categorical_accuracy: 0.6000\n",
            "Epoch 96/200\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 1.0690 - categorical_accuracy: 0.5089 - val_loss: 1.0367 - val_categorical_accuracy: 0.5571\n",
            "Epoch 97/200\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 1.1062 - categorical_accuracy: 0.5335 - val_loss: 1.0394 - val_categorical_accuracy: 0.5571\n",
            "Epoch 98/200\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 1.0782 - categorical_accuracy: 0.5118 - val_loss: 1.0205 - val_categorical_accuracy: 0.6143\n",
            "Epoch 99/200\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 1.0539 - categorical_accuracy: 0.5520 - val_loss: 1.0080 - val_categorical_accuracy: 0.6000\n",
            "Epoch 100/200\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 1.1012 - categorical_accuracy: 0.5224 - val_loss: 1.0303 - val_categorical_accuracy: 0.5857\n",
            "Epoch 101/200\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 1.1497 - categorical_accuracy: 0.5046 - val_loss: 1.0494 - val_categorical_accuracy: 0.5286\n",
            "Epoch 102/200\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 1.1259 - categorical_accuracy: 0.4849 - val_loss: 1.0123 - val_categorical_accuracy: 0.6000\n",
            "Epoch 103/200\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 1.0897 - categorical_accuracy: 0.5373 - val_loss: 1.0186 - val_categorical_accuracy: 0.6000\n",
            "Epoch 104/200\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 1.0925 - categorical_accuracy: 0.5345 - val_loss: 1.0040 - val_categorical_accuracy: 0.6000\n",
            "Epoch 105/200\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 1.0926 - categorical_accuracy: 0.5194 - val_loss: 0.9999 - val_categorical_accuracy: 0.6286\n",
            "Epoch 106/200\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 1.1271 - categorical_accuracy: 0.5331 - val_loss: 0.9924 - val_categorical_accuracy: 0.6000\n",
            "Epoch 107/200\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 1.0961 - categorical_accuracy: 0.5140 - val_loss: 0.9921 - val_categorical_accuracy: 0.6286\n",
            "Epoch 108/200\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 1.0578 - categorical_accuracy: 0.5535 - val_loss: 1.0077 - val_categorical_accuracy: 0.5857\n",
            "Epoch 109/200\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 1.0826 - categorical_accuracy: 0.5415 - val_loss: 0.9891 - val_categorical_accuracy: 0.6429\n",
            "Epoch 110/200\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 1.1138 - categorical_accuracy: 0.5119 - val_loss: 1.0094 - val_categorical_accuracy: 0.6143\n",
            "Epoch 111/200\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 1.0607 - categorical_accuracy: 0.5243 - val_loss: 1.0212 - val_categorical_accuracy: 0.5714\n",
            "Epoch 112/200\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 1.0832 - categorical_accuracy: 0.5561 - val_loss: 1.0201 - val_categorical_accuracy: 0.5857\n",
            "Epoch 113/200\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 1.0606 - categorical_accuracy: 0.5428 - val_loss: 0.9939 - val_categorical_accuracy: 0.6000\n",
            "Epoch 114/200\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 1.0874 - categorical_accuracy: 0.5304 - val_loss: 1.0056 - val_categorical_accuracy: 0.5857\n",
            "Epoch 115/200\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 1.0745 - categorical_accuracy: 0.5321 - val_loss: 1.0066 - val_categorical_accuracy: 0.6143\n",
            "Epoch 116/200\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 1.0734 - categorical_accuracy: 0.5335 - val_loss: 1.0123 - val_categorical_accuracy: 0.6286\n",
            "Epoch 117/200\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 1.1774 - categorical_accuracy: 0.5210 - val_loss: 0.9942 - val_categorical_accuracy: 0.6143\n",
            "Epoch 118/200\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 1.0205 - categorical_accuracy: 0.5596 - val_loss: 1.0180 - val_categorical_accuracy: 0.5714\n",
            "Epoch 119/200\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 1.1066 - categorical_accuracy: 0.5237 - val_loss: 0.9892 - val_categorical_accuracy: 0.6571\n",
            "Epoch 120/200\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 1.1382 - categorical_accuracy: 0.5132 - val_loss: 0.9735 - val_categorical_accuracy: 0.6429\n",
            "Epoch 121/200\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 0.9855 - categorical_accuracy: 0.5629 - val_loss: 0.9857 - val_categorical_accuracy: 0.6286\n",
            "Epoch 122/200\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 1.0314 - categorical_accuracy: 0.5580 - val_loss: 1.0080 - val_categorical_accuracy: 0.6143\n",
            "Epoch 123/200\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 1.1378 - categorical_accuracy: 0.5441 - val_loss: 0.9824 - val_categorical_accuracy: 0.5857\n",
            "Epoch 124/200\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 1.0422 - categorical_accuracy: 0.5486 - val_loss: 0.9652 - val_categorical_accuracy: 0.6714\n",
            "Epoch 125/200\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 1.1124 - categorical_accuracy: 0.5100 - val_loss: 0.9744 - val_categorical_accuracy: 0.6286\n",
            "Epoch 126/200\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 1.0326 - categorical_accuracy: 0.5750 - val_loss: 0.9578 - val_categorical_accuracy: 0.6571\n",
            "Epoch 127/200\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 1.0243 - categorical_accuracy: 0.5717 - val_loss: 0.9739 - val_categorical_accuracy: 0.7000\n",
            "Epoch 128/200\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 1.0886 - categorical_accuracy: 0.5603 - val_loss: 0.9600 - val_categorical_accuracy: 0.6286\n",
            "Epoch 129/200\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 1.0117 - categorical_accuracy: 0.5783 - val_loss: 1.0083 - val_categorical_accuracy: 0.6143\n",
            "Epoch 130/200\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.9879 - categorical_accuracy: 0.6088 - val_loss: 0.9638 - val_categorical_accuracy: 0.6429\n",
            "Epoch 131/200\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 1.0347 - categorical_accuracy: 0.5531 - val_loss: 0.9719 - val_categorical_accuracy: 0.7143\n",
            "Epoch 132/200\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 1.0022 - categorical_accuracy: 0.5865 - val_loss: 0.9641 - val_categorical_accuracy: 0.6429\n",
            "Epoch 133/200\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 1.0423 - categorical_accuracy: 0.5646 - val_loss: 0.9559 - val_categorical_accuracy: 0.6429\n",
            "Epoch 134/200\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 1.0343 - categorical_accuracy: 0.5443 - val_loss: 0.9677 - val_categorical_accuracy: 0.6286\n",
            "Epoch 135/200\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 1.0413 - categorical_accuracy: 0.5594 - val_loss: 0.9644 - val_categorical_accuracy: 0.6571\n",
            "Epoch 136/200\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 1.0631 - categorical_accuracy: 0.5565 - val_loss: 0.9585 - val_categorical_accuracy: 0.6286\n",
            "Epoch 137/200\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.9478 - categorical_accuracy: 0.5954 - val_loss: 0.9638 - val_categorical_accuracy: 0.7143\n",
            "Epoch 138/200\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 1.0260 - categorical_accuracy: 0.5599 - val_loss: 0.9677 - val_categorical_accuracy: 0.6571\n",
            "Epoch 139/200\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 1.0532 - categorical_accuracy: 0.5742 - val_loss: 0.9600 - val_categorical_accuracy: 0.6429\n",
            "Epoch 140/200\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 1.0337 - categorical_accuracy: 0.5352 - val_loss: 0.9550 - val_categorical_accuracy: 0.7143\n",
            "Epoch 141/200\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 1.0493 - categorical_accuracy: 0.5685 - val_loss: 0.9452 - val_categorical_accuracy: 0.6571\n",
            "Epoch 142/200\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 1.0365 - categorical_accuracy: 0.5598 - val_loss: 0.9509 - val_categorical_accuracy: 0.6429\n",
            "Epoch 143/200\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.9821 - categorical_accuracy: 0.5885 - val_loss: 0.9751 - val_categorical_accuracy: 0.6143\n",
            "Epoch 144/200\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.9862 - categorical_accuracy: 0.5940 - val_loss: 0.9537 - val_categorical_accuracy: 0.6571\n",
            "Epoch 145/200\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 1.0399 - categorical_accuracy: 0.5589 - val_loss: 0.9650 - val_categorical_accuracy: 0.6429\n",
            "Epoch 146/200\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 1.1077 - categorical_accuracy: 0.5477 - val_loss: 0.9445 - val_categorical_accuracy: 0.6143\n",
            "Epoch 147/200\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 1.0278 - categorical_accuracy: 0.5563 - val_loss: 0.9419 - val_categorical_accuracy: 0.6714\n",
            "Epoch 148/200\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 1.0556 - categorical_accuracy: 0.5313 - val_loss: 0.9595 - val_categorical_accuracy: 0.6429\n",
            "Epoch 149/200\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 1.0265 - categorical_accuracy: 0.5883 - val_loss: 0.9762 - val_categorical_accuracy: 0.6000\n",
            "Epoch 150/200\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 1.1360 - categorical_accuracy: 0.5089 - val_loss: 0.9374 - val_categorical_accuracy: 0.6714\n",
            "Epoch 151/200\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 1.0237 - categorical_accuracy: 0.5520 - val_loss: 0.9418 - val_categorical_accuracy: 0.6714\n",
            "Epoch 152/200\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.9740 - categorical_accuracy: 0.5808 - val_loss: 0.9374 - val_categorical_accuracy: 0.6429\n",
            "Epoch 153/200\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.9872 - categorical_accuracy: 0.5901 - val_loss: 0.9368 - val_categorical_accuracy: 0.7286\n",
            "Epoch 154/200\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 1.0810 - categorical_accuracy: 0.5627 - val_loss: 0.9342 - val_categorical_accuracy: 0.6571\n",
            "Epoch 155/200\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 1.0935 - categorical_accuracy: 0.5251 - val_loss: 0.9482 - val_categorical_accuracy: 0.6286\n",
            "Epoch 156/200\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.9370 - categorical_accuracy: 0.6082 - val_loss: 0.9295 - val_categorical_accuracy: 0.6857\n",
            "Epoch 157/200\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 1.0076 - categorical_accuracy: 0.5857 - val_loss: 0.9461 - val_categorical_accuracy: 0.6714\n",
            "Epoch 158/200\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 1.0728 - categorical_accuracy: 0.5455 - val_loss: 0.9359 - val_categorical_accuracy: 0.6714\n",
            "Epoch 159/200\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 1.0222 - categorical_accuracy: 0.5562 - val_loss: 0.9259 - val_categorical_accuracy: 0.6571\n",
            "Epoch 160/200\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 1.0241 - categorical_accuracy: 0.5548 - val_loss: 0.9280 - val_categorical_accuracy: 0.6714\n",
            "Epoch 161/200\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 1.0811 - categorical_accuracy: 0.5499 - val_loss: 0.9483 - val_categorical_accuracy: 0.6571\n",
            "Epoch 162/200\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 1.0741 - categorical_accuracy: 0.5434 - val_loss: 0.9254 - val_categorical_accuracy: 0.6714\n",
            "Epoch 163/200\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.9781 - categorical_accuracy: 0.5954 - val_loss: 0.9289 - val_categorical_accuracy: 0.7000\n",
            "Epoch 164/200\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.9709 - categorical_accuracy: 0.5592 - val_loss: 0.9204 - val_categorical_accuracy: 0.7000\n",
            "Epoch 165/200\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.9847 - categorical_accuracy: 0.5780 - val_loss: 0.9240 - val_categorical_accuracy: 0.7000\n",
            "Epoch 166/200\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.9446 - categorical_accuracy: 0.6120 - val_loss: 0.9266 - val_categorical_accuracy: 0.6714\n",
            "Epoch 167/200\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.9289 - categorical_accuracy: 0.6001 - val_loss: 0.9252 - val_categorical_accuracy: 0.7000\n",
            "Epoch 168/200\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.9544 - categorical_accuracy: 0.5988 - val_loss: 0.9258 - val_categorical_accuracy: 0.7000\n",
            "Epoch 169/200\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.9685 - categorical_accuracy: 0.5725 - val_loss: 0.9118 - val_categorical_accuracy: 0.6429\n",
            "Epoch 170/200\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.9941 - categorical_accuracy: 0.5829 - val_loss: 0.9335 - val_categorical_accuracy: 0.6857\n",
            "Epoch 171/200\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 1.0033 - categorical_accuracy: 0.5842 - val_loss: 0.9224 - val_categorical_accuracy: 0.7286\n",
            "Epoch 172/200\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 0.9972 - categorical_accuracy: 0.5599 - val_loss: 0.9286 - val_categorical_accuracy: 0.6857\n",
            "Epoch 173/200\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.9927 - categorical_accuracy: 0.5451 - val_loss: 0.9096 - val_categorical_accuracy: 0.7143\n",
            "Epoch 174/200\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.9524 - categorical_accuracy: 0.6342 - val_loss: 0.9127 - val_categorical_accuracy: 0.6429\n",
            "Epoch 175/200\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 1.0607 - categorical_accuracy: 0.5311 - val_loss: 0.9441 - val_categorical_accuracy: 0.6571\n",
            "Epoch 176/200\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.9956 - categorical_accuracy: 0.5839 - val_loss: 0.9199 - val_categorical_accuracy: 0.6571\n",
            "Epoch 177/200\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 1.0095 - categorical_accuracy: 0.5830 - val_loss: 0.9051 - val_categorical_accuracy: 0.6571\n",
            "Epoch 178/200\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.9546 - categorical_accuracy: 0.6093 - val_loss: 0.9242 - val_categorical_accuracy: 0.7286\n",
            "Epoch 179/200\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.9778 - categorical_accuracy: 0.6123 - val_loss: 0.9180 - val_categorical_accuracy: 0.7000\n",
            "Epoch 180/200\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.9660 - categorical_accuracy: 0.6278 - val_loss: 0.9663 - val_categorical_accuracy: 0.6000\n",
            "Epoch 181/200\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.9570 - categorical_accuracy: 0.5820 - val_loss: 0.9439 - val_categorical_accuracy: 0.6571\n",
            "Epoch 182/200\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 0.9655 - categorical_accuracy: 0.5968 - val_loss: 0.8954 - val_categorical_accuracy: 0.6857\n",
            "Epoch 183/200\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.9331 - categorical_accuracy: 0.6069 - val_loss: 0.8955 - val_categorical_accuracy: 0.6714\n",
            "Epoch 184/200\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 1.0158 - categorical_accuracy: 0.5918 - val_loss: 0.9228 - val_categorical_accuracy: 0.6714\n",
            "Epoch 185/200\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.9694 - categorical_accuracy: 0.5308 - val_loss: 0.9462 - val_categorical_accuracy: 0.6571\n",
            "Epoch 186/200\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.9719 - categorical_accuracy: 0.6022 - val_loss: 0.9292 - val_categorical_accuracy: 0.7000\n",
            "Epoch 187/200\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.9499 - categorical_accuracy: 0.6238 - val_loss: 0.8991 - val_categorical_accuracy: 0.7143\n",
            "Epoch 188/200\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.9336 - categorical_accuracy: 0.5948 - val_loss: 0.8926 - val_categorical_accuracy: 0.7000\n",
            "Epoch 189/200\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.9045 - categorical_accuracy: 0.6099 - val_loss: 0.8963 - val_categorical_accuracy: 0.6714\n",
            "Epoch 190/200\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.8391 - categorical_accuracy: 0.6606 - val_loss: 0.9087 - val_categorical_accuracy: 0.7143\n",
            "Epoch 191/200\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.9632 - categorical_accuracy: 0.6221 - val_loss: 0.9027 - val_categorical_accuracy: 0.7000\n",
            "Epoch 192/200\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.9950 - categorical_accuracy: 0.5770 - val_loss: 0.9017 - val_categorical_accuracy: 0.6857\n",
            "Epoch 193/200\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.9565 - categorical_accuracy: 0.5582 - val_loss: 0.8838 - val_categorical_accuracy: 0.6857\n",
            "Epoch 194/200\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.9273 - categorical_accuracy: 0.6051 - val_loss: 0.8938 - val_categorical_accuracy: 0.6857\n",
            "Epoch 195/200\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.9496 - categorical_accuracy: 0.6045 - val_loss: 0.8743 - val_categorical_accuracy: 0.6714\n",
            "Epoch 196/200\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.9286 - categorical_accuracy: 0.6256 - val_loss: 0.9042 - val_categorical_accuracy: 0.6857\n",
            "Epoch 197/200\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.9326 - categorical_accuracy: 0.5924 - val_loss: 0.8871 - val_categorical_accuracy: 0.6571\n",
            "Epoch 198/200\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.9547 - categorical_accuracy: 0.5977 - val_loss: 0.8968 - val_categorical_accuracy: 0.7143\n",
            "Epoch 199/200\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.9833 - categorical_accuracy: 0.5818 - val_loss: 0.8816 - val_categorical_accuracy: 0.7000\n",
            "Epoch 200/200\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.9318 - categorical_accuracy: 0.6341 - val_loss: 0.8777 - val_categorical_accuracy: 0.6857\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "phONxCpg2ndh"
      },
      "source": [
        "model.save('/content/drive/MyDrive/Colab Notebooks/SPEECH_EMOTION_Recognition/Nộp bài(chốt hạ)/model_saver/conv2D_mfcc13_ravdess.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HjbGkNOG2ndi"
      },
      "source": [
        "###test_result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a80Gcu9H2ndi",
        "outputId": "b4e0e558-d89e-4dd5-bec8-1cd4f6059965"
      },
      "source": [
        "d = {0: 'happy',\n",
        "     1: 'sad',\n",
        "     2: 'angry',\n",
        "     3: 'fear'}\n",
        "Y_test_pred = np.argmax(model.predict(X_test), axis=-1)\n",
        "Y_test_pred = list(map(lambda x: d[x], Y_test_pred))\n",
        "y_test = np.argmax(y_test, axis=-1)\n",
        "y_test = list(map(lambda x: d[x], y_test))\n",
        "print(classification_report(y_test, Y_test_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.60      0.92      0.73        13\n",
            "        fear       0.65      0.52      0.58        21\n",
            "       happy       0.56      0.61      0.58        23\n",
            "         sad       0.80      0.60      0.69        20\n",
            "\n",
            "    accuracy                           0.64        77\n",
            "   macro avg       0.65      0.66      0.64        77\n",
            "weighted avg       0.65      0.64      0.63        77\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "id": "9Y0mQ9rM2ndj",
        "outputId": "879ad5db-5f52-4902-e45c-a7bd1ef19baf"
      },
      "source": [
        "import scikitplot as skplt\n",
        "\n",
        "skplt.metrics.plot_confusion_matrix(\n",
        "    y_test, \n",
        "    Y_test_pred,\n",
        "    figsize=(8,8))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fda6e3c9550>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNZony_t2ndk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4C8Zhxb9HjOz"
      },
      "source": [
        "# mfcc_26 + conv2D:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2X5MDnhHjPT"
      },
      "source": [
        "audio_duration = 3\n",
        "sampling_rate = 22050\n",
        "input_length = sampling_rate * audio_duration"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Epr1t2XbHjPU"
      },
      "source": [
        "features = []\n",
        "labels = []\n",
        "for i in range(len(Ravdess_DF['Paths'])):\n",
        "  if ((Ravdess_DF['Emotion'][i] == '03') | (Ravdess_DF['Emotion'][i] == '04') | \n",
        "      (Ravdess_DF['Emotion'][i] == '05') | (Ravdess_DF['Emotion'][i] == '06')):\n",
        "    signal, sr = librosa.load(Ravdess_DF['Paths'][i])\n",
        "\n",
        "    if len(signal) > input_length:\n",
        "      signal = signal[0:input_length]\n",
        "    elif  input_length > len(signal):\n",
        "      max_offset = input_length - len(signal)  \n",
        "      signal = np.pad(signal, (0, max_offset), \"constant\")\n",
        "\n",
        "    mfcc = librosa.feature.mfcc(y=signal, sr=sr, n_mfcc=26).T\n",
        "    mfcc = np.expand_dims(mfcc, axis=-1)\n",
        "    features.append(mfcc)\n",
        "\n",
        "    if Ravdess_DF['Emotion'][i] == '03':\n",
        "      labels.append(0)\n",
        "    elif Ravdess_DF['Emotion'][i] == '04':\n",
        "      labels.append(1)\n",
        "    elif Ravdess_DF['Emotion'][i] == '05':\n",
        "      labels.append(2)\n",
        "    elif Ravdess_DF['Emotion'][i] == '06':\n",
        "      labels.append(3)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqcj3jBmHjPV"
      },
      "source": [
        "X = features\n",
        "y = labels\n",
        "\n",
        "y = np.array(y)\n",
        "y = to_categorical(y)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=0)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=0)\n",
        "\n",
        "X_train = np.array(X_train)\n",
        "X_test = np.array(X_test)\n",
        "X_val = np.array(X_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KRdDgHoRHjPW",
        "outputId": "19f8157d-6f3b-4488-c53f-41e526ccea2a"
      },
      "source": [
        "X_train.shape,X_test.shape,y_train.shape,y_test.shape\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((621, 130, 26, 1), (77, 130, 26, 1), (621, 4), (77, 4))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sxujyYqGHjPY"
      },
      "source": [
        "# CNN I/P Config\n",
        "num_classes = 4\n",
        "input_shape = X_train.shape[1:]\n",
        "learning_rate = 0.0001\n",
        "decay = 1e-6\n",
        "momentum = 0.9"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "teCyFWEfHjPY",
        "outputId": "0dfa46c8-7688-4daa-e69a-bce6a210f20d"
      },
      "source": [
        "model = Sequential(name='Audio_CNN_2D')\n",
        "\n",
        "# LFLB1\n",
        "model.add(Conv2D(filters=64, kernel_size=(3,3), strides=(1,1), padding='same',input_shape=input_shape))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Conv2D(filters=64, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(4,4), strides=(4,4)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(units=num_classes, activation='softmax'))\n",
        "\n",
        "# Model compilation\n",
        "opt = optimizers.SGD(lr=learning_rate, decay=decay, momentum=momentum, nesterov=True)\n",
        "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"Audio_CNN_2D\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_2 (Conv2D)            (None, 130, 26, 64)       640       \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 130, 26, 64)       256       \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 130, 26, 64)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 65, 13, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 65, 13, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 65, 13, 64)        36928     \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 65, 13, 64)        256       \n",
            "_________________________________________________________________\n",
            "activation_7 (Activation)    (None, 65, 13, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 16, 3, 64)         0         \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 16, 3, 64)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 3072)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 4)                 12292     \n",
            "=================================================================\n",
            "Total params: 50,372\n",
            "Trainable params: 50,116\n",
            "Non-trainable params: 256\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sV4p0gKtHjPZ",
        "outputId": "16523f81-8e27-401a-a699-8d300be22c5d"
      },
      "source": [
        "#Train Config\n",
        "\n",
        "batch_size = 16\n",
        "num_epochs = 200\n",
        "\n",
        "# Model Training\n",
        "lr_reduce = ReduceLROnPlateau(monitor='val_loss', factor=0.9, patience=20, min_lr=0.000001)\n",
        "# Please change the model name accordingly.\n",
        "mcp_save = ModelCheckpoint('/content/Modelfull_2_1.h5', save_best_only=True, monitor='val_categorical_accuracy', mode='max')\n",
        "cnnhistory=model.fit(X_train, y_train, batch_size=batch_size, epochs=num_epochs,validation_data=(X_val, y_val), callbacks=[mcp_save, lr_reduce])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "39/39 [==============================] - 2s 23ms/step - loss: 2.8076 - categorical_accuracy: 0.1992 - val_loss: 2.1010 - val_categorical_accuracy: 0.2857\n",
            "Epoch 2/200\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 2.3760 - categorical_accuracy: 0.2491 - val_loss: 1.5884 - val_categorical_accuracy: 0.3571\n",
            "Epoch 3/200\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 2.2413 - categorical_accuracy: 0.2967 - val_loss: 1.6176 - val_categorical_accuracy: 0.2286\n",
            "Epoch 4/200\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 1.9773 - categorical_accuracy: 0.3331 - val_loss: 1.4811 - val_categorical_accuracy: 0.3714\n",
            "Epoch 5/200\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 1.7594 - categorical_accuracy: 0.3317 - val_loss: 1.5699 - val_categorical_accuracy: 0.3429\n",
            "Epoch 6/200\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 1.6477 - categorical_accuracy: 0.4146 - val_loss: 1.3922 - val_categorical_accuracy: 0.4571\n",
            "Epoch 7/200\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 1.6122 - categorical_accuracy: 0.3978 - val_loss: 1.4127 - val_categorical_accuracy: 0.4286\n",
            "Epoch 8/200\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 1.6591 - categorical_accuracy: 0.3665 - val_loss: 1.6094 - val_categorical_accuracy: 0.2714\n",
            "Epoch 9/200\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 1.4467 - categorical_accuracy: 0.4327 - val_loss: 1.4982 - val_categorical_accuracy: 0.2857\n",
            "Epoch 10/200\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 1.5045 - categorical_accuracy: 0.3882 - val_loss: 1.4146 - val_categorical_accuracy: 0.3857\n",
            "Epoch 11/200\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 1.5002 - categorical_accuracy: 0.3732 - val_loss: 1.2062 - val_categorical_accuracy: 0.5000\n",
            "Epoch 12/200\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 1.4148 - categorical_accuracy: 0.4043 - val_loss: 1.2072 - val_categorical_accuracy: 0.5286\n",
            "Epoch 13/200\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 1.4806 - categorical_accuracy: 0.4044 - val_loss: 1.2115 - val_categorical_accuracy: 0.4857\n",
            "Epoch 14/200\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 1.3690 - categorical_accuracy: 0.4178 - val_loss: 1.2573 - val_categorical_accuracy: 0.3714\n",
            "Epoch 15/200\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 1.3880 - categorical_accuracy: 0.4400 - val_loss: 1.2008 - val_categorical_accuracy: 0.5143\n",
            "Epoch 16/200\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 1.4062 - categorical_accuracy: 0.4156 - val_loss: 1.1998 - val_categorical_accuracy: 0.4857\n",
            "Epoch 17/200\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 1.3611 - categorical_accuracy: 0.4341 - val_loss: 1.2083 - val_categorical_accuracy: 0.4429\n",
            "Epoch 18/200\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 1.3504 - categorical_accuracy: 0.4544 - val_loss: 1.2120 - val_categorical_accuracy: 0.4857\n",
            "Epoch 19/200\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 1.2815 - categorical_accuracy: 0.4693 - val_loss: 1.1904 - val_categorical_accuracy: 0.5429\n",
            "Epoch 20/200\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 1.3362 - categorical_accuracy: 0.4333 - val_loss: 1.1447 - val_categorical_accuracy: 0.5429\n",
            "Epoch 21/200\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 1.2796 - categorical_accuracy: 0.4658 - val_loss: 1.1502 - val_categorical_accuracy: 0.5143\n",
            "Epoch 22/200\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 1.3726 - categorical_accuracy: 0.4563 - val_loss: 1.2189 - val_categorical_accuracy: 0.4857\n",
            "Epoch 23/200\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 1.3894 - categorical_accuracy: 0.4417 - val_loss: 1.1472 - val_categorical_accuracy: 0.5857\n",
            "Epoch 24/200\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 1.2902 - categorical_accuracy: 0.4425 - val_loss: 1.1597 - val_categorical_accuracy: 0.5286\n",
            "Epoch 25/200\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 1.2146 - categorical_accuracy: 0.4911 - val_loss: 1.1784 - val_categorical_accuracy: 0.4714\n",
            "Epoch 26/200\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 1.2851 - categorical_accuracy: 0.4246 - val_loss: 1.1589 - val_categorical_accuracy: 0.4714\n",
            "Epoch 27/200\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 1.2032 - categorical_accuracy: 0.4617 - val_loss: 1.1530 - val_categorical_accuracy: 0.5143\n",
            "Epoch 28/200\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 1.2256 - categorical_accuracy: 0.4661 - val_loss: 1.1526 - val_categorical_accuracy: 0.4286\n",
            "Epoch 29/200\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 1.2116 - categorical_accuracy: 0.4744 - val_loss: 1.1297 - val_categorical_accuracy: 0.5571\n",
            "Epoch 30/200\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 1.2612 - categorical_accuracy: 0.4485 - val_loss: 1.1209 - val_categorical_accuracy: 0.6000\n",
            "Epoch 31/200\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 1.2376 - categorical_accuracy: 0.4800 - val_loss: 1.1429 - val_categorical_accuracy: 0.5000\n",
            "Epoch 32/200\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 1.1772 - categorical_accuracy: 0.5124 - val_loss: 1.1376 - val_categorical_accuracy: 0.4571\n",
            "Epoch 33/200\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 1.1947 - categorical_accuracy: 0.4827 - val_loss: 1.1417 - val_categorical_accuracy: 0.4571\n",
            "Epoch 34/200\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 1.2402 - categorical_accuracy: 0.4658 - val_loss: 1.2138 - val_categorical_accuracy: 0.4286\n",
            "Epoch 35/200\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 1.1633 - categorical_accuracy: 0.5382 - val_loss: 1.1560 - val_categorical_accuracy: 0.5143\n",
            "Epoch 36/200\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 1.1926 - categorical_accuracy: 0.5093 - val_loss: 1.1351 - val_categorical_accuracy: 0.4429\n",
            "Epoch 37/200\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 1.1430 - categorical_accuracy: 0.4939 - val_loss: 1.1133 - val_categorical_accuracy: 0.5714\n",
            "Epoch 38/200\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 1.1416 - categorical_accuracy: 0.5307 - val_loss: 1.1783 - val_categorical_accuracy: 0.4429\n",
            "Epoch 39/200\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 1.2345 - categorical_accuracy: 0.4833 - val_loss: 1.1139 - val_categorical_accuracy: 0.4429\n",
            "Epoch 40/200\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 1.1764 - categorical_accuracy: 0.4980 - val_loss: 1.0983 - val_categorical_accuracy: 0.5857\n",
            "Epoch 41/200\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 1.1166 - categorical_accuracy: 0.4764 - val_loss: 1.1035 - val_categorical_accuracy: 0.5429\n",
            "Epoch 42/200\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 1.1864 - categorical_accuracy: 0.4985 - val_loss: 1.1117 - val_categorical_accuracy: 0.5571\n",
            "Epoch 43/200\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 1.1862 - categorical_accuracy: 0.4896 - val_loss: 1.1031 - val_categorical_accuracy: 0.5286\n",
            "Epoch 44/200\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 1.1490 - categorical_accuracy: 0.4889 - val_loss: 1.0936 - val_categorical_accuracy: 0.5429\n",
            "Epoch 45/200\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 1.0372 - categorical_accuracy: 0.5481 - val_loss: 1.1018 - val_categorical_accuracy: 0.4571\n",
            "Epoch 46/200\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 1.1144 - categorical_accuracy: 0.5027 - val_loss: 1.1064 - val_categorical_accuracy: 0.4857\n",
            "Epoch 47/200\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 1.1111 - categorical_accuracy: 0.5252 - val_loss: 1.0792 - val_categorical_accuracy: 0.6143\n",
            "Epoch 48/200\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 1.1299 - categorical_accuracy: 0.4731 - val_loss: 1.0855 - val_categorical_accuracy: 0.5286\n",
            "Epoch 49/200\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 1.1540 - categorical_accuracy: 0.5034 - val_loss: 1.0852 - val_categorical_accuracy: 0.5143\n",
            "Epoch 50/200\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 1.1368 - categorical_accuracy: 0.5449 - val_loss: 1.0842 - val_categorical_accuracy: 0.5429\n",
            "Epoch 51/200\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 1.0954 - categorical_accuracy: 0.5404 - val_loss: 1.0837 - val_categorical_accuracy: 0.5286\n",
            "Epoch 52/200\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 1.1461 - categorical_accuracy: 0.5121 - val_loss: 1.0773 - val_categorical_accuracy: 0.5571\n",
            "Epoch 53/200\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 1.0933 - categorical_accuracy: 0.5154 - val_loss: 1.0672 - val_categorical_accuracy: 0.5286\n",
            "Epoch 54/200\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 1.0702 - categorical_accuracy: 0.5558 - val_loss: 1.0796 - val_categorical_accuracy: 0.6000\n",
            "Epoch 55/200\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 1.1575 - categorical_accuracy: 0.5158 - val_loss: 1.0859 - val_categorical_accuracy: 0.5714\n",
            "Epoch 56/200\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 1.0932 - categorical_accuracy: 0.5778 - val_loss: 1.0595 - val_categorical_accuracy: 0.5714\n",
            "Epoch 57/200\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 1.0918 - categorical_accuracy: 0.5463 - val_loss: 1.0719 - val_categorical_accuracy: 0.5571\n",
            "Epoch 58/200\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 1.0360 - categorical_accuracy: 0.5635 - val_loss: 1.0654 - val_categorical_accuracy: 0.5429\n",
            "Epoch 59/200\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 1.1177 - categorical_accuracy: 0.5436 - val_loss: 1.0406 - val_categorical_accuracy: 0.6143\n",
            "Epoch 60/200\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 1.0797 - categorical_accuracy: 0.5170 - val_loss: 1.0644 - val_categorical_accuracy: 0.5000\n",
            "Epoch 61/200\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 1.0797 - categorical_accuracy: 0.5483 - val_loss: 1.0489 - val_categorical_accuracy: 0.5571\n",
            "Epoch 62/200\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 1.0417 - categorical_accuracy: 0.5846 - val_loss: 1.0338 - val_categorical_accuracy: 0.6143\n",
            "Epoch 63/200\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 1.1260 - categorical_accuracy: 0.5033 - val_loss: 1.0518 - val_categorical_accuracy: 0.5714\n",
            "Epoch 64/200\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 1.0861 - categorical_accuracy: 0.5454 - val_loss: 1.0455 - val_categorical_accuracy: 0.5857\n",
            "Epoch 65/200\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 1.1391 - categorical_accuracy: 0.5095 - val_loss: 1.0638 - val_categorical_accuracy: 0.5857\n",
            "Epoch 66/200\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 1.1387 - categorical_accuracy: 0.5327 - val_loss: 1.0317 - val_categorical_accuracy: 0.5714\n",
            "Epoch 67/200\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 1.0083 - categorical_accuracy: 0.5524 - val_loss: 1.0180 - val_categorical_accuracy: 0.6286\n",
            "Epoch 68/200\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 1.0316 - categorical_accuracy: 0.5422 - val_loss: 1.0177 - val_categorical_accuracy: 0.6571\n",
            "Epoch 69/200\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 1.0800 - categorical_accuracy: 0.5438 - val_loss: 1.0283 - val_categorical_accuracy: 0.5286\n",
            "Epoch 70/200\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.9972 - categorical_accuracy: 0.5727 - val_loss: 1.0213 - val_categorical_accuracy: 0.5857\n",
            "Epoch 71/200\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 1.0882 - categorical_accuracy: 0.5234 - val_loss: 1.0118 - val_categorical_accuracy: 0.5714\n",
            "Epoch 72/200\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 1.0247 - categorical_accuracy: 0.5614 - val_loss: 1.0002 - val_categorical_accuracy: 0.6143\n",
            "Epoch 73/200\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.9948 - categorical_accuracy: 0.6088 - val_loss: 1.0299 - val_categorical_accuracy: 0.5286\n",
            "Epoch 74/200\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 1.0843 - categorical_accuracy: 0.5572 - val_loss: 1.0009 - val_categorical_accuracy: 0.6000\n",
            "Epoch 75/200\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 1.0500 - categorical_accuracy: 0.5890 - val_loss: 1.0126 - val_categorical_accuracy: 0.5714\n",
            "Epoch 76/200\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 1.0485 - categorical_accuracy: 0.5578 - val_loss: 0.9980 - val_categorical_accuracy: 0.6286\n",
            "Epoch 77/200\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 1.0369 - categorical_accuracy: 0.5737 - val_loss: 1.0119 - val_categorical_accuracy: 0.5714\n",
            "Epoch 78/200\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.9920 - categorical_accuracy: 0.5745 - val_loss: 0.9900 - val_categorical_accuracy: 0.6143\n",
            "Epoch 79/200\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 1.0277 - categorical_accuracy: 0.5707 - val_loss: 0.9852 - val_categorical_accuracy: 0.6571\n",
            "Epoch 80/200\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 1.0308 - categorical_accuracy: 0.5798 - val_loss: 1.0065 - val_categorical_accuracy: 0.5429\n",
            "Epoch 81/200\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.9842 - categorical_accuracy: 0.5890 - val_loss: 0.9839 - val_categorical_accuracy: 0.6286\n",
            "Epoch 82/200\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 1.0327 - categorical_accuracy: 0.5593 - val_loss: 0.9874 - val_categorical_accuracy: 0.6286\n",
            "Epoch 83/200\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 1.0427 - categorical_accuracy: 0.5635 - val_loss: 0.9870 - val_categorical_accuracy: 0.6143\n",
            "Epoch 84/200\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 1.0374 - categorical_accuracy: 0.5666 - val_loss: 0.9782 - val_categorical_accuracy: 0.6571\n",
            "Epoch 85/200\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 1.0015 - categorical_accuracy: 0.6001 - val_loss: 0.9726 - val_categorical_accuracy: 0.6714\n",
            "Epoch 86/200\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.9786 - categorical_accuracy: 0.5984 - val_loss: 0.9785 - val_categorical_accuracy: 0.6429\n",
            "Epoch 87/200\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 1.0220 - categorical_accuracy: 0.5685 - val_loss: 1.0315 - val_categorical_accuracy: 0.5286\n",
            "Epoch 88/200\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 1.0244 - categorical_accuracy: 0.5620 - val_loss: 0.9728 - val_categorical_accuracy: 0.6429\n",
            "Epoch 89/200\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.9993 - categorical_accuracy: 0.5932 - val_loss: 0.9858 - val_categorical_accuracy: 0.6429\n",
            "Epoch 90/200\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 1.0644 - categorical_accuracy: 0.5666 - val_loss: 0.9614 - val_categorical_accuracy: 0.6429\n",
            "Epoch 91/200\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.9660 - categorical_accuracy: 0.5814 - val_loss: 0.9827 - val_categorical_accuracy: 0.5429\n",
            "Epoch 92/200\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 1.0064 - categorical_accuracy: 0.5785 - val_loss: 0.9686 - val_categorical_accuracy: 0.6143\n",
            "Epoch 93/200\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.9658 - categorical_accuracy: 0.5957 - val_loss: 0.9976 - val_categorical_accuracy: 0.5857\n",
            "Epoch 94/200\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 1.0168 - categorical_accuracy: 0.5637 - val_loss: 0.9573 - val_categorical_accuracy: 0.6286\n",
            "Epoch 95/200\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.9945 - categorical_accuracy: 0.5692 - val_loss: 0.9653 - val_categorical_accuracy: 0.6857\n",
            "Epoch 96/200\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.9817 - categorical_accuracy: 0.5909 - val_loss: 0.9527 - val_categorical_accuracy: 0.6429\n",
            "Epoch 97/200\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.8824 - categorical_accuracy: 0.6551 - val_loss: 0.9604 - val_categorical_accuracy: 0.6571\n",
            "Epoch 98/200\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 1.0010 - categorical_accuracy: 0.6082 - val_loss: 0.9555 - val_categorical_accuracy: 0.6714\n",
            "Epoch 99/200\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 1.0054 - categorical_accuracy: 0.5726 - val_loss: 0.9430 - val_categorical_accuracy: 0.6143\n",
            "Epoch 100/200\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 1.0629 - categorical_accuracy: 0.5471 - val_loss: 0.9560 - val_categorical_accuracy: 0.6143\n",
            "Epoch 101/200\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 1.0188 - categorical_accuracy: 0.5846 - val_loss: 0.9376 - val_categorical_accuracy: 0.6429\n",
            "Epoch 102/200\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.9416 - categorical_accuracy: 0.6161 - val_loss: 0.9560 - val_categorical_accuracy: 0.6571\n",
            "Epoch 103/200\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.9592 - categorical_accuracy: 0.5963 - val_loss: 0.9370 - val_categorical_accuracy: 0.6571\n",
            "Epoch 104/200\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.9960 - categorical_accuracy: 0.5807 - val_loss: 0.9254 - val_categorical_accuracy: 0.6857\n",
            "Epoch 105/200\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 1.0011 - categorical_accuracy: 0.5763 - val_loss: 0.9472 - val_categorical_accuracy: 0.6571\n",
            "Epoch 106/200\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 1.0813 - categorical_accuracy: 0.5557 - val_loss: 0.9698 - val_categorical_accuracy: 0.5857\n",
            "Epoch 107/200\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.9838 - categorical_accuracy: 0.5719 - val_loss: 0.9329 - val_categorical_accuracy: 0.7143\n",
            "Epoch 108/200\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.9298 - categorical_accuracy: 0.6235 - val_loss: 0.9568 - val_categorical_accuracy: 0.5714\n",
            "Epoch 109/200\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 1.0414 - categorical_accuracy: 0.5432 - val_loss: 0.9425 - val_categorical_accuracy: 0.6714\n",
            "Epoch 110/200\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.9850 - categorical_accuracy: 0.5720 - val_loss: 0.9170 - val_categorical_accuracy: 0.6857\n",
            "Epoch 111/200\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.9348 - categorical_accuracy: 0.6303 - val_loss: 0.9162 - val_categorical_accuracy: 0.6571\n",
            "Epoch 112/200\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.9076 - categorical_accuracy: 0.6247 - val_loss: 0.9439 - val_categorical_accuracy: 0.6143\n",
            "Epoch 113/200\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.9658 - categorical_accuracy: 0.6228 - val_loss: 0.9336 - val_categorical_accuracy: 0.6429\n",
            "Epoch 114/200\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.9962 - categorical_accuracy: 0.5907 - val_loss: 0.9522 - val_categorical_accuracy: 0.6000\n",
            "Epoch 115/200\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.9735 - categorical_accuracy: 0.6033 - val_loss: 0.9274 - val_categorical_accuracy: 0.6571\n",
            "Epoch 116/200\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.9257 - categorical_accuracy: 0.6350 - val_loss: 0.9677 - val_categorical_accuracy: 0.5714\n",
            "Epoch 117/200\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.9298 - categorical_accuracy: 0.6410 - val_loss: 0.9197 - val_categorical_accuracy: 0.6286\n",
            "Epoch 118/200\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.9833 - categorical_accuracy: 0.5894 - val_loss: 0.9104 - val_categorical_accuracy: 0.6857\n",
            "Epoch 119/200\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.9809 - categorical_accuracy: 0.5664 - val_loss: 0.9168 - val_categorical_accuracy: 0.6714\n",
            "Epoch 120/200\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.9857 - categorical_accuracy: 0.5999 - val_loss: 0.9384 - val_categorical_accuracy: 0.6143\n",
            "Epoch 121/200\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.9938 - categorical_accuracy: 0.5821 - val_loss: 0.9024 - val_categorical_accuracy: 0.6286\n",
            "Epoch 122/200\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.9213 - categorical_accuracy: 0.6375 - val_loss: 0.9061 - val_categorical_accuracy: 0.6429\n",
            "Epoch 123/200\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.9778 - categorical_accuracy: 0.5889 - val_loss: 0.9088 - val_categorical_accuracy: 0.6571\n",
            "Epoch 124/200\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.9348 - categorical_accuracy: 0.5874 - val_loss: 0.9204 - val_categorical_accuracy: 0.6571\n",
            "Epoch 125/200\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.9766 - categorical_accuracy: 0.5877 - val_loss: 0.9470 - val_categorical_accuracy: 0.6143\n",
            "Epoch 126/200\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.9866 - categorical_accuracy: 0.6212 - val_loss: 0.9064 - val_categorical_accuracy: 0.6571\n",
            "Epoch 127/200\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.9243 - categorical_accuracy: 0.6232 - val_loss: 0.8978 - val_categorical_accuracy: 0.6714\n",
            "Epoch 128/200\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.9107 - categorical_accuracy: 0.6284 - val_loss: 0.8880 - val_categorical_accuracy: 0.6571\n",
            "Epoch 129/200\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.8943 - categorical_accuracy: 0.6446 - val_loss: 0.9048 - val_categorical_accuracy: 0.6571\n",
            "Epoch 130/200\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.8496 - categorical_accuracy: 0.6615 - val_loss: 0.9452 - val_categorical_accuracy: 0.6286\n",
            "Epoch 131/200\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.8983 - categorical_accuracy: 0.6500 - val_loss: 0.8879 - val_categorical_accuracy: 0.6714\n",
            "Epoch 132/200\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.9296 - categorical_accuracy: 0.6022 - val_loss: 0.9191 - val_categorical_accuracy: 0.6286\n",
            "Epoch 133/200\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.9395 - categorical_accuracy: 0.6164 - val_loss: 0.8798 - val_categorical_accuracy: 0.6714\n",
            "Epoch 134/200\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.9136 - categorical_accuracy: 0.6361 - val_loss: 0.8781 - val_categorical_accuracy: 0.6857\n",
            "Epoch 135/200\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.9492 - categorical_accuracy: 0.5747 - val_loss: 0.9110 - val_categorical_accuracy: 0.6429\n",
            "Epoch 136/200\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.8879 - categorical_accuracy: 0.6351 - val_loss: 0.9158 - val_categorical_accuracy: 0.6286\n",
            "Epoch 137/200\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.8782 - categorical_accuracy: 0.6474 - val_loss: 0.9153 - val_categorical_accuracy: 0.6571\n",
            "Epoch 138/200\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.9226 - categorical_accuracy: 0.6100 - val_loss: 0.8855 - val_categorical_accuracy: 0.6714\n",
            "Epoch 139/200\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.8707 - categorical_accuracy: 0.6219 - val_loss: 0.9035 - val_categorical_accuracy: 0.6571\n",
            "Epoch 140/200\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.9228 - categorical_accuracy: 0.6576 - val_loss: 0.9041 - val_categorical_accuracy: 0.6571\n",
            "Epoch 141/200\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.9141 - categorical_accuracy: 0.6269 - val_loss: 0.8779 - val_categorical_accuracy: 0.6429\n",
            "Epoch 142/200\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.8415 - categorical_accuracy: 0.6434 - val_loss: 0.8838 - val_categorical_accuracy: 0.6714\n",
            "Epoch 143/200\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.8801 - categorical_accuracy: 0.6490 - val_loss: 0.8904 - val_categorical_accuracy: 0.6429\n",
            "Epoch 144/200\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.9551 - categorical_accuracy: 0.5921 - val_loss: 0.8943 - val_categorical_accuracy: 0.6571\n",
            "Epoch 145/200\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.8645 - categorical_accuracy: 0.6590 - val_loss: 0.9110 - val_categorical_accuracy: 0.6429\n",
            "Epoch 146/200\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.9144 - categorical_accuracy: 0.6477 - val_loss: 0.8638 - val_categorical_accuracy: 0.6429\n",
            "Epoch 147/200\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.8375 - categorical_accuracy: 0.6662 - val_loss: 0.8643 - val_categorical_accuracy: 0.6857\n",
            "Epoch 148/200\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.8517 - categorical_accuracy: 0.6712 - val_loss: 0.8809 - val_categorical_accuracy: 0.6571\n",
            "Epoch 149/200\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.8790 - categorical_accuracy: 0.6544 - val_loss: 0.8739 - val_categorical_accuracy: 0.6571\n",
            "Epoch 150/200\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.8940 - categorical_accuracy: 0.6155 - val_loss: 0.9373 - val_categorical_accuracy: 0.6143\n",
            "Epoch 151/200\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.8638 - categorical_accuracy: 0.6651 - val_loss: 0.8655 - val_categorical_accuracy: 0.6857\n",
            "Epoch 152/200\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.8559 - categorical_accuracy: 0.6637 - val_loss: 0.8762 - val_categorical_accuracy: 0.6429\n",
            "Epoch 153/200\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.8793 - categorical_accuracy: 0.6591 - val_loss: 0.8661 - val_categorical_accuracy: 0.6571\n",
            "Epoch 154/200\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.8881 - categorical_accuracy: 0.6237 - val_loss: 0.9009 - val_categorical_accuracy: 0.6571\n",
            "Epoch 155/200\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.9022 - categorical_accuracy: 0.6365 - val_loss: 0.8627 - val_categorical_accuracy: 0.6714\n",
            "Epoch 156/200\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.8550 - categorical_accuracy: 0.6234 - val_loss: 0.8709 - val_categorical_accuracy: 0.6571\n",
            "Epoch 157/200\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.8314 - categorical_accuracy: 0.6388 - val_loss: 0.8518 - val_categorical_accuracy: 0.6429\n",
            "Epoch 158/200\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.8829 - categorical_accuracy: 0.6282 - val_loss: 0.8771 - val_categorical_accuracy: 0.6571\n",
            "Epoch 159/200\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.7932 - categorical_accuracy: 0.6657 - val_loss: 0.8914 - val_categorical_accuracy: 0.6571\n",
            "Epoch 160/200\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.8856 - categorical_accuracy: 0.6370 - val_loss: 0.9261 - val_categorical_accuracy: 0.6000\n",
            "Epoch 161/200\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.8727 - categorical_accuracy: 0.6344 - val_loss: 0.8716 - val_categorical_accuracy: 0.6571\n",
            "Epoch 162/200\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.8704 - categorical_accuracy: 0.6165 - val_loss: 0.8461 - val_categorical_accuracy: 0.6714\n",
            "Epoch 163/200\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.8369 - categorical_accuracy: 0.6525 - val_loss: 0.8392 - val_categorical_accuracy: 0.6714\n",
            "Epoch 164/200\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.8733 - categorical_accuracy: 0.6528 - val_loss: 0.8906 - val_categorical_accuracy: 0.6429\n",
            "Epoch 165/200\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.7881 - categorical_accuracy: 0.6781 - val_loss: 0.8663 - val_categorical_accuracy: 0.6857\n",
            "Epoch 166/200\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.8569 - categorical_accuracy: 0.6357 - val_loss: 0.8913 - val_categorical_accuracy: 0.6429\n",
            "Epoch 167/200\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.8323 - categorical_accuracy: 0.6375 - val_loss: 0.8503 - val_categorical_accuracy: 0.6429\n",
            "Epoch 168/200\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.8211 - categorical_accuracy: 0.6665 - val_loss: 0.8516 - val_categorical_accuracy: 0.6571\n",
            "Epoch 169/200\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.9095 - categorical_accuracy: 0.6278 - val_loss: 0.8438 - val_categorical_accuracy: 0.6286\n",
            "Epoch 170/200\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.8516 - categorical_accuracy: 0.6438 - val_loss: 0.8494 - val_categorical_accuracy: 0.6571\n",
            "Epoch 171/200\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.8046 - categorical_accuracy: 0.6696 - val_loss: 0.9146 - val_categorical_accuracy: 0.6000\n",
            "Epoch 172/200\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.8566 - categorical_accuracy: 0.6826 - val_loss: 0.8430 - val_categorical_accuracy: 0.6429\n",
            "Epoch 173/200\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.8652 - categorical_accuracy: 0.6588 - val_loss: 0.8895 - val_categorical_accuracy: 0.6571\n",
            "Epoch 174/200\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.8605 - categorical_accuracy: 0.6461 - val_loss: 0.8615 - val_categorical_accuracy: 0.6571\n",
            "Epoch 175/200\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.7464 - categorical_accuracy: 0.7149 - val_loss: 0.8609 - val_categorical_accuracy: 0.6429\n",
            "Epoch 176/200\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.8135 - categorical_accuracy: 0.6730 - val_loss: 0.8343 - val_categorical_accuracy: 0.6571\n",
            "Epoch 177/200\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.8289 - categorical_accuracy: 0.6502 - val_loss: 0.8792 - val_categorical_accuracy: 0.6429\n",
            "Epoch 178/200\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.8460 - categorical_accuracy: 0.6494 - val_loss: 0.8691 - val_categorical_accuracy: 0.6429\n",
            "Epoch 179/200\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.8161 - categorical_accuracy: 0.6430 - val_loss: 0.8449 - val_categorical_accuracy: 0.6429\n",
            "Epoch 180/200\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.7815 - categorical_accuracy: 0.6837 - val_loss: 0.8621 - val_categorical_accuracy: 0.6571\n",
            "Epoch 181/200\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.7942 - categorical_accuracy: 0.6792 - val_loss: 0.8667 - val_categorical_accuracy: 0.6429\n",
            "Epoch 182/200\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.8110 - categorical_accuracy: 0.6799 - val_loss: 0.8582 - val_categorical_accuracy: 0.6429\n",
            "Epoch 183/200\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.8725 - categorical_accuracy: 0.6415 - val_loss: 0.8635 - val_categorical_accuracy: 0.6429\n",
            "Epoch 184/200\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.8323 - categorical_accuracy: 0.6619 - val_loss: 0.8525 - val_categorical_accuracy: 0.6286\n",
            "Epoch 185/200\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.8723 - categorical_accuracy: 0.6357 - val_loss: 0.8262 - val_categorical_accuracy: 0.6429\n",
            "Epoch 186/200\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.8456 - categorical_accuracy: 0.6605 - val_loss: 0.8611 - val_categorical_accuracy: 0.6714\n",
            "Epoch 187/200\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.7606 - categorical_accuracy: 0.6941 - val_loss: 0.8463 - val_categorical_accuracy: 0.6714\n",
            "Epoch 188/200\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.7772 - categorical_accuracy: 0.6854 - val_loss: 0.8558 - val_categorical_accuracy: 0.6714\n",
            "Epoch 189/200\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.7536 - categorical_accuracy: 0.7019 - val_loss: 0.8513 - val_categorical_accuracy: 0.6286\n",
            "Epoch 190/200\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.7752 - categorical_accuracy: 0.7105 - val_loss: 0.8139 - val_categorical_accuracy: 0.6286\n",
            "Epoch 191/200\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.8790 - categorical_accuracy: 0.6523 - val_loss: 0.8339 - val_categorical_accuracy: 0.6286\n",
            "Epoch 192/200\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.8150 - categorical_accuracy: 0.6517 - val_loss: 0.8067 - val_categorical_accuracy: 0.6571\n",
            "Epoch 193/200\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.8160 - categorical_accuracy: 0.6547 - val_loss: 0.8742 - val_categorical_accuracy: 0.6286\n",
            "Epoch 194/200\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.8544 - categorical_accuracy: 0.6785 - val_loss: 0.8193 - val_categorical_accuracy: 0.6571\n",
            "Epoch 195/200\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.8132 - categorical_accuracy: 0.6532 - val_loss: 0.8488 - val_categorical_accuracy: 0.6286\n",
            "Epoch 196/200\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.7846 - categorical_accuracy: 0.6674 - val_loss: 0.8934 - val_categorical_accuracy: 0.6286\n",
            "Epoch 197/200\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.8038 - categorical_accuracy: 0.6972 - val_loss: 0.8279 - val_categorical_accuracy: 0.6571\n",
            "Epoch 198/200\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.6871 - categorical_accuracy: 0.7145 - val_loss: 0.8398 - val_categorical_accuracy: 0.6571\n",
            "Epoch 199/200\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.7787 - categorical_accuracy: 0.7063 - val_loss: 0.7945 - val_categorical_accuracy: 0.6429\n",
            "Epoch 200/200\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.8245 - categorical_accuracy: 0.6453 - val_loss: 0.8271 - val_categorical_accuracy: 0.6571\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4NFXIyYQHjPa"
      },
      "source": [
        "model.save('/content/drive/MyDrive/Colab Notebooks/SPEECH_EMOTION_Recognition/Nộp bài(chốt hạ)/model_saver/conv2D_mfcc26_ravdess.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67QFbETrHjPa"
      },
      "source": [
        "###test_result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IqmyX7AIHjPb",
        "outputId": "76bb936f-7ae5-4bb4-beed-91827d841c4e"
      },
      "source": [
        "d = {0: 'happy',\n",
        "     1: 'sad',\n",
        "     2: 'angry',\n",
        "     3: 'fear'}\n",
        "Y_test_pred = np.argmax(model.predict(X_test), axis=-1)\n",
        "Y_test_pred = list(map(lambda x: d[x], Y_test_pred))\n",
        "y_test = np.argmax(y_test, axis=-1)\n",
        "y_test = list(map(lambda x: d[x], y_test))\n",
        "print(classification_report(y_test, Y_test_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.79      0.85      0.81        13\n",
            "        fear       0.64      0.33      0.44        21\n",
            "       happy       0.51      0.78      0.62        23\n",
            "         sad       0.76      0.65      0.70        20\n",
            "\n",
            "    accuracy                           0.64        77\n",
            "   macro avg       0.68      0.65      0.64        77\n",
            "weighted avg       0.66      0.64      0.62        77\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "id": "6HEu3PFcHjPb",
        "outputId": "25ca6540-2f2f-4de2-8afa-2225617940ed"
      },
      "source": [
        "import scikitplot as skplt\n",
        "\n",
        "skplt.metrics.plot_confusion_matrix(\n",
        "    y_test, \n",
        "    Y_test_pred,\n",
        "    figsize=(8,8))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fd8f659dc90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Up_pIk62HjPc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UbMzp6IWHwqK"
      },
      "source": [
        "# mfcc_39 + conv2D:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZOBaWP6HwqM"
      },
      "source": [
        "audio_duration = 3\n",
        "sampling_rate = 22050\n",
        "input_length = sampling_rate * audio_duration"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jPHXywBOHwqN"
      },
      "source": [
        "features = []\n",
        "labels = []\n",
        "for i in range(len(Ravdess_DF['Paths'])):\n",
        "  if ((Ravdess_DF['Emotion'][i] == '03') | (Ravdess_DF['Emotion'][i] == '04') | \n",
        "      (Ravdess_DF['Emotion'][i] == '05') | (Ravdess_DF['Emotion'][i] == '06')):\n",
        "    signal, sr = librosa.load(Ravdess_DF['Paths'][i])\n",
        "\n",
        "    if len(signal) > input_length:\n",
        "      signal = signal[0:input_length]\n",
        "    elif  input_length > len(signal):\n",
        "      max_offset = input_length - len(signal)  \n",
        "      signal = np.pad(signal, (0, max_offset), \"constant\")\n",
        "\n",
        "    mfcc = librosa.feature.mfcc(y=signal, sr=sr, n_mfcc=39).T\n",
        "    mfcc = np.expand_dims(mfcc, axis=-1)\n",
        "    features.append(mfcc)\n",
        "\n",
        "    if Ravdess_DF['Emotion'][i] == '03':\n",
        "      labels.append(0)\n",
        "    elif Ravdess_DF['Emotion'][i] == '04':\n",
        "      labels.append(1)\n",
        "    elif Ravdess_DF['Emotion'][i] == '05':\n",
        "      labels.append(2)\n",
        "    elif Ravdess_DF['Emotion'][i] == '06':\n",
        "      labels.append(3)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFJEaX4aHwqO"
      },
      "source": [
        "X = features\n",
        "y = labels\n",
        "\n",
        "y = np.array(y)\n",
        "y = to_categorical(y)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=0)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=0)\n",
        "\n",
        "X_train = np.array(X_train)\n",
        "X_test = np.array(X_test)\n",
        "X_val = np.array(X_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UUrSXDbtHwqP",
        "outputId": "db621adf-589c-45f5-920c-30e82a600d3e"
      },
      "source": [
        "X_train.shape,X_test.shape,y_train.shape,y_test.shape\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((621, 130, 39, 1), (77, 130, 39, 1), (621, 4), (77, 4))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4TlcX2V2HwqQ"
      },
      "source": [
        "# CNN I/P Config\n",
        "num_classes = 4\n",
        "input_shape = X_train.shape[1:]\n",
        "learning_rate = 0.0001\n",
        "decay = 1e-6\n",
        "momentum = 0.9"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8u_qzXt-HwqR",
        "outputId": "660c2c05-26c2-418d-96e0-728936a604c5"
      },
      "source": [
        "model = Sequential(name='Audio_CNN_2D')\n",
        "\n",
        "# LFLB1\n",
        "model.add(Conv2D(filters=64, kernel_size=(3,3), strides=(1,1), padding='same',input_shape=input_shape))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Conv2D(filters=64, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(4,4), strides=(4,4)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(units=num_classes, activation='softmax'))\n",
        "\n",
        "# Model compilation\n",
        "opt = optimizers.SGD(lr=learning_rate, decay=decay, momentum=momentum, nesterov=True)\n",
        "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"Audio_CNN_2D\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_6 (Conv2D)            (None, 130, 39, 64)       640       \n",
            "_________________________________________________________________\n",
            "batch_normalization_10 (Batc (None, 130, 39, 64)       256       \n",
            "_________________________________________________________________\n",
            "activation_10 (Activation)   (None, 130, 39, 64)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 65, 19, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 65, 19, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 65, 19, 64)        36928     \n",
            "_________________________________________________________________\n",
            "batch_normalization_11 (Batc (None, 65, 19, 64)        256       \n",
            "_________________________________________________________________\n",
            "activation_11 (Activation)   (None, 65, 19, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 16, 4, 64)         0         \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 16, 4, 64)         0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 4)                 16388     \n",
            "=================================================================\n",
            "Total params: 54,468\n",
            "Trainable params: 54,212\n",
            "Non-trainable params: 256\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HYylC2Z1HwqS",
        "outputId": "e909dd87-53ff-46d7-bfd9-c3044ac563e1"
      },
      "source": [
        "#Train Config\n",
        "\n",
        "batch_size = 16\n",
        "num_epochs = 200\n",
        "\n",
        "# Model Training\n",
        "lr_reduce = ReduceLROnPlateau(monitor='val_loss', factor=0.9, patience=20, min_lr=0.000001)\n",
        "# Please change the model name accordingly.\n",
        "mcp_save = ModelCheckpoint('/content/Modelfull_2_1.h5', save_best_only=True, monitor='val_categorical_accuracy', mode='max')\n",
        "cnnhistory=model.fit(X_train, y_train, batch_size=batch_size, epochs=num_epochs,validation_data=(X_val, y_val), callbacks=[mcp_save, lr_reduce])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "39/39 [==============================] - 2s 18ms/step - loss: 2.7248 - categorical_accuracy: 0.2233 - val_loss: 2.6544 - val_categorical_accuracy: 0.2143\n",
            "Epoch 2/200\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 2.3506 - categorical_accuracy: 0.2743 - val_loss: 2.2641 - val_categorical_accuracy: 0.2000\n",
            "Epoch 3/200\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 1.9715 - categorical_accuracy: 0.3386 - val_loss: 1.7578 - val_categorical_accuracy: 0.2286\n",
            "Epoch 4/200\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 1.9496 - categorical_accuracy: 0.3397 - val_loss: 1.5218 - val_categorical_accuracy: 0.3286\n",
            "Epoch 5/200\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 1.7655 - categorical_accuracy: 0.3853 - val_loss: 1.4678 - val_categorical_accuracy: 0.3571\n",
            "Epoch 6/200\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 1.7080 - categorical_accuracy: 0.4155 - val_loss: 1.5234 - val_categorical_accuracy: 0.3000\n",
            "Epoch 7/200\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 1.6356 - categorical_accuracy: 0.3693 - val_loss: 1.3612 - val_categorical_accuracy: 0.3571\n",
            "Epoch 8/200\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 1.5768 - categorical_accuracy: 0.4142 - val_loss: 1.3343 - val_categorical_accuracy: 0.4000\n",
            "Epoch 9/200\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 1.4596 - categorical_accuracy: 0.4524 - val_loss: 1.3371 - val_categorical_accuracy: 0.3429\n",
            "Epoch 10/200\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 1.5262 - categorical_accuracy: 0.4136 - val_loss: 1.5190 - val_categorical_accuracy: 0.3000\n",
            "Epoch 11/200\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 1.5661 - categorical_accuracy: 0.4139 - val_loss: 1.4348 - val_categorical_accuracy: 0.3571\n",
            "Epoch 12/200\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 1.4703 - categorical_accuracy: 0.4286 - val_loss: 1.3710 - val_categorical_accuracy: 0.3571\n",
            "Epoch 13/200\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 1.5271 - categorical_accuracy: 0.3929 - val_loss: 1.2877 - val_categorical_accuracy: 0.4714\n",
            "Epoch 14/200\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 1.4516 - categorical_accuracy: 0.3939 - val_loss: 1.4736 - val_categorical_accuracy: 0.3857\n",
            "Epoch 15/200\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 1.3663 - categorical_accuracy: 0.4542 - val_loss: 1.3263 - val_categorical_accuracy: 0.3857\n",
            "Epoch 16/200\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 1.3711 - categorical_accuracy: 0.4304 - val_loss: 1.2889 - val_categorical_accuracy: 0.4714\n",
            "Epoch 17/200\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 1.2860 - categorical_accuracy: 0.4509 - val_loss: 1.2077 - val_categorical_accuracy: 0.4000\n",
            "Epoch 18/200\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 1.2284 - categorical_accuracy: 0.4928 - val_loss: 1.1699 - val_categorical_accuracy: 0.4857\n",
            "Epoch 19/200\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 1.2966 - categorical_accuracy: 0.4665 - val_loss: 1.2498 - val_categorical_accuracy: 0.5000\n",
            "Epoch 20/200\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 1.2454 - categorical_accuracy: 0.4731 - val_loss: 1.1820 - val_categorical_accuracy: 0.5000\n",
            "Epoch 21/200\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 1.2551 - categorical_accuracy: 0.4738 - val_loss: 1.2517 - val_categorical_accuracy: 0.3143\n",
            "Epoch 22/200\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 1.2632 - categorical_accuracy: 0.4943 - val_loss: 1.1474 - val_categorical_accuracy: 0.5286\n",
            "Epoch 23/200\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 1.2028 - categorical_accuracy: 0.4812 - val_loss: 1.2106 - val_categorical_accuracy: 0.4143\n",
            "Epoch 24/200\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 1.2669 - categorical_accuracy: 0.4577 - val_loss: 1.2354 - val_categorical_accuracy: 0.3857\n",
            "Epoch 25/200\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 1.1726 - categorical_accuracy: 0.5139 - val_loss: 1.2161 - val_categorical_accuracy: 0.5286\n",
            "Epoch 26/200\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 1.2419 - categorical_accuracy: 0.5189 - val_loss: 1.1447 - val_categorical_accuracy: 0.5000\n",
            "Epoch 27/200\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 1.1151 - categorical_accuracy: 0.5181 - val_loss: 1.2379 - val_categorical_accuracy: 0.3714\n",
            "Epoch 28/200\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 1.1616 - categorical_accuracy: 0.5314 - val_loss: 1.1500 - val_categorical_accuracy: 0.5571\n",
            "Epoch 29/200\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 1.1831 - categorical_accuracy: 0.5281 - val_loss: 1.1622 - val_categorical_accuracy: 0.4000\n",
            "Epoch 30/200\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 1.1661 - categorical_accuracy: 0.4769 - val_loss: 1.1134 - val_categorical_accuracy: 0.5571\n",
            "Epoch 31/200\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 1.1682 - categorical_accuracy: 0.5049 - val_loss: 1.1843 - val_categorical_accuracy: 0.4143\n",
            "Epoch 32/200\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 1.1954 - categorical_accuracy: 0.4990 - val_loss: 1.1997 - val_categorical_accuracy: 0.4714\n",
            "Epoch 33/200\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 1.1787 - categorical_accuracy: 0.5084 - val_loss: 1.2030 - val_categorical_accuracy: 0.4286\n",
            "Epoch 34/200\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 1.1640 - categorical_accuracy: 0.5192 - val_loss: 1.1588 - val_categorical_accuracy: 0.4143\n",
            "Epoch 35/200\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 1.1325 - categorical_accuracy: 0.5461 - val_loss: 1.2239 - val_categorical_accuracy: 0.3714\n",
            "Epoch 36/200\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 1.1513 - categorical_accuracy: 0.5101 - val_loss: 1.1619 - val_categorical_accuracy: 0.4429\n",
            "Epoch 37/200\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 1.1171 - categorical_accuracy: 0.4984 - val_loss: 1.1039 - val_categorical_accuracy: 0.5429\n",
            "Epoch 38/200\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 1.0429 - categorical_accuracy: 0.5518 - val_loss: 1.1347 - val_categorical_accuracy: 0.5286\n",
            "Epoch 39/200\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 1.0646 - categorical_accuracy: 0.5628 - val_loss: 1.1329 - val_categorical_accuracy: 0.5000\n",
            "Epoch 40/200\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 1.1302 - categorical_accuracy: 0.4971 - val_loss: 1.0842 - val_categorical_accuracy: 0.5429\n",
            "Epoch 41/200\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 1.0374 - categorical_accuracy: 0.5482 - val_loss: 1.1297 - val_categorical_accuracy: 0.5286\n",
            "Epoch 42/200\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 1.2137 - categorical_accuracy: 0.4843 - val_loss: 1.2317 - val_categorical_accuracy: 0.4286\n",
            "Epoch 43/200\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 1.1629 - categorical_accuracy: 0.5081 - val_loss: 1.1338 - val_categorical_accuracy: 0.5286\n",
            "Epoch 44/200\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 1.1538 - categorical_accuracy: 0.5132 - val_loss: 1.1839 - val_categorical_accuracy: 0.4143\n",
            "Epoch 45/200\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 1.1078 - categorical_accuracy: 0.5391 - val_loss: 1.1887 - val_categorical_accuracy: 0.4286\n",
            "Epoch 46/200\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 1.0276 - categorical_accuracy: 0.5688 - val_loss: 1.1636 - val_categorical_accuracy: 0.4429\n",
            "Epoch 47/200\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 1.0149 - categorical_accuracy: 0.5829 - val_loss: 1.1202 - val_categorical_accuracy: 0.5571\n",
            "Epoch 48/200\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 1.0580 - categorical_accuracy: 0.5414 - val_loss: 1.0765 - val_categorical_accuracy: 0.5857\n",
            "Epoch 49/200\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 1.0959 - categorical_accuracy: 0.5307 - val_loss: 1.0997 - val_categorical_accuracy: 0.5571\n",
            "Epoch 50/200\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 1.1097 - categorical_accuracy: 0.5050 - val_loss: 1.1053 - val_categorical_accuracy: 0.5000\n",
            "Epoch 51/200\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 1.0871 - categorical_accuracy: 0.5634 - val_loss: 1.0897 - val_categorical_accuracy: 0.5143\n",
            "Epoch 52/200\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 1.1197 - categorical_accuracy: 0.5343 - val_loss: 1.1329 - val_categorical_accuracy: 0.5143\n",
            "Epoch 53/200\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 1.0725 - categorical_accuracy: 0.5380 - val_loss: 1.1196 - val_categorical_accuracy: 0.5286\n",
            "Epoch 54/200\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 1.0174 - categorical_accuracy: 0.5519 - val_loss: 1.0980 - val_categorical_accuracy: 0.4857\n",
            "Epoch 55/200\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 1.0248 - categorical_accuracy: 0.5635 - val_loss: 1.1162 - val_categorical_accuracy: 0.4714\n",
            "Epoch 56/200\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 1.0875 - categorical_accuracy: 0.5395 - val_loss: 1.1517 - val_categorical_accuracy: 0.4429\n",
            "Epoch 57/200\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 1.0068 - categorical_accuracy: 0.5726 - val_loss: 1.0617 - val_categorical_accuracy: 0.6286\n",
            "Epoch 58/200\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 1.0595 - categorical_accuracy: 0.5733 - val_loss: 1.0894 - val_categorical_accuracy: 0.4571\n",
            "Epoch 59/200\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 1.1191 - categorical_accuracy: 0.5132 - val_loss: 1.0837 - val_categorical_accuracy: 0.5571\n",
            "Epoch 60/200\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.9952 - categorical_accuracy: 0.5773 - val_loss: 1.0719 - val_categorical_accuracy: 0.5857\n",
            "Epoch 61/200\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 1.0003 - categorical_accuracy: 0.5907 - val_loss: 1.0707 - val_categorical_accuracy: 0.5286\n",
            "Epoch 62/200\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.9671 - categorical_accuracy: 0.5956 - val_loss: 1.1230 - val_categorical_accuracy: 0.4857\n",
            "Epoch 63/200\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 1.0730 - categorical_accuracy: 0.5660 - val_loss: 1.0396 - val_categorical_accuracy: 0.5714\n",
            "Epoch 64/200\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 1.0171 - categorical_accuracy: 0.6044 - val_loss: 1.1223 - val_categorical_accuracy: 0.4714\n",
            "Epoch 65/200\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.9875 - categorical_accuracy: 0.5745 - val_loss: 0.9968 - val_categorical_accuracy: 0.6429\n",
            "Epoch 66/200\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.9794 - categorical_accuracy: 0.5898 - val_loss: 1.0407 - val_categorical_accuracy: 0.5857\n",
            "Epoch 67/200\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 1.0526 - categorical_accuracy: 0.5667 - val_loss: 1.0232 - val_categorical_accuracy: 0.6000\n",
            "Epoch 68/200\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.9751 - categorical_accuracy: 0.5895 - val_loss: 1.0362 - val_categorical_accuracy: 0.4714\n",
            "Epoch 69/200\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.9776 - categorical_accuracy: 0.6130 - val_loss: 0.9886 - val_categorical_accuracy: 0.6286\n",
            "Epoch 70/200\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.9836 - categorical_accuracy: 0.5767 - val_loss: 1.0042 - val_categorical_accuracy: 0.6000\n",
            "Epoch 71/200\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.9591 - categorical_accuracy: 0.6263 - val_loss: 1.0067 - val_categorical_accuracy: 0.6000\n",
            "Epoch 72/200\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.9567 - categorical_accuracy: 0.6039 - val_loss: 1.0480 - val_categorical_accuracy: 0.5714\n",
            "Epoch 73/200\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 1.0574 - categorical_accuracy: 0.5275 - val_loss: 1.0296 - val_categorical_accuracy: 0.5286\n",
            "Epoch 74/200\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.9719 - categorical_accuracy: 0.6080 - val_loss: 0.9646 - val_categorical_accuracy: 0.6571\n",
            "Epoch 75/200\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 1.0605 - categorical_accuracy: 0.5508 - val_loss: 0.9608 - val_categorical_accuracy: 0.6571\n",
            "Epoch 76/200\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.9403 - categorical_accuracy: 0.6040 - val_loss: 0.9557 - val_categorical_accuracy: 0.6857\n",
            "Epoch 77/200\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.9601 - categorical_accuracy: 0.5916 - val_loss: 0.9987 - val_categorical_accuracy: 0.6143\n",
            "Epoch 78/200\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.9722 - categorical_accuracy: 0.5918 - val_loss: 0.9623 - val_categorical_accuracy: 0.6429\n",
            "Epoch 79/200\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 1.0090 - categorical_accuracy: 0.5817 - val_loss: 1.0523 - val_categorical_accuracy: 0.5714\n",
            "Epoch 80/200\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.9884 - categorical_accuracy: 0.5623 - val_loss: 0.9666 - val_categorical_accuracy: 0.6429\n",
            "Epoch 81/200\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.9565 - categorical_accuracy: 0.6111 - val_loss: 0.9708 - val_categorical_accuracy: 0.6429\n",
            "Epoch 82/200\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.9223 - categorical_accuracy: 0.5996 - val_loss: 0.9580 - val_categorical_accuracy: 0.6571\n",
            "Epoch 83/200\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.9286 - categorical_accuracy: 0.6201 - val_loss: 0.9763 - val_categorical_accuracy: 0.6286\n",
            "Epoch 84/200\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.9867 - categorical_accuracy: 0.5759 - val_loss: 0.9735 - val_categorical_accuracy: 0.6000\n",
            "Epoch 85/200\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 1.0119 - categorical_accuracy: 0.5990 - val_loss: 0.9388 - val_categorical_accuracy: 0.6143\n",
            "Epoch 86/200\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.8897 - categorical_accuracy: 0.6511 - val_loss: 0.9995 - val_categorical_accuracy: 0.6429\n",
            "Epoch 87/200\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.9537 - categorical_accuracy: 0.6132 - val_loss: 0.9848 - val_categorical_accuracy: 0.5571\n",
            "Epoch 88/200\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.9763 - categorical_accuracy: 0.5913 - val_loss: 0.9473 - val_categorical_accuracy: 0.6286\n",
            "Epoch 89/200\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.9450 - categorical_accuracy: 0.6209 - val_loss: 0.9268 - val_categorical_accuracy: 0.6286\n",
            "Epoch 90/200\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.9082 - categorical_accuracy: 0.6280 - val_loss: 0.9780 - val_categorical_accuracy: 0.6571\n",
            "Epoch 91/200\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.9119 - categorical_accuracy: 0.6478 - val_loss: 0.9602 - val_categorical_accuracy: 0.6714\n",
            "Epoch 92/200\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.8892 - categorical_accuracy: 0.6309 - val_loss: 0.9444 - val_categorical_accuracy: 0.6429\n",
            "Epoch 93/200\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.8943 - categorical_accuracy: 0.6563 - val_loss: 0.9627 - val_categorical_accuracy: 0.6571\n",
            "Epoch 94/200\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.8685 - categorical_accuracy: 0.6715 - val_loss: 0.9496 - val_categorical_accuracy: 0.6143\n",
            "Epoch 95/200\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.9116 - categorical_accuracy: 0.6219 - val_loss: 0.9192 - val_categorical_accuracy: 0.6714\n",
            "Epoch 96/200\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.9425 - categorical_accuracy: 0.6098 - val_loss: 0.9187 - val_categorical_accuracy: 0.6571\n",
            "Epoch 97/200\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.9053 - categorical_accuracy: 0.6387 - val_loss: 0.9841 - val_categorical_accuracy: 0.5571\n",
            "Epoch 98/200\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.8684 - categorical_accuracy: 0.6167 - val_loss: 0.8816 - val_categorical_accuracy: 0.6571\n",
            "Epoch 99/200\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.8823 - categorical_accuracy: 0.6354 - val_loss: 0.9917 - val_categorical_accuracy: 0.5714\n",
            "Epoch 100/200\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.8824 - categorical_accuracy: 0.6505 - val_loss: 0.9725 - val_categorical_accuracy: 0.6000\n",
            "Epoch 101/200\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.8999 - categorical_accuracy: 0.6179 - val_loss: 0.9778 - val_categorical_accuracy: 0.6286\n",
            "Epoch 102/200\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.8901 - categorical_accuracy: 0.6338 - val_loss: 0.9467 - val_categorical_accuracy: 0.6286\n",
            "Epoch 103/200\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.9564 - categorical_accuracy: 0.6377 - val_loss: 0.9507 - val_categorical_accuracy: 0.6429\n",
            "Epoch 104/200\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.8125 - categorical_accuracy: 0.6874 - val_loss: 0.8970 - val_categorical_accuracy: 0.6714\n",
            "Epoch 105/200\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.8584 - categorical_accuracy: 0.6740 - val_loss: 0.9564 - val_categorical_accuracy: 0.6143\n",
            "Epoch 106/200\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.8286 - categorical_accuracy: 0.6607 - val_loss: 0.8645 - val_categorical_accuracy: 0.6857\n",
            "Epoch 107/200\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.8840 - categorical_accuracy: 0.6380 - val_loss: 0.9488 - val_categorical_accuracy: 0.5857\n",
            "Epoch 108/200\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.8858 - categorical_accuracy: 0.6615 - val_loss: 0.9300 - val_categorical_accuracy: 0.6000\n",
            "Epoch 109/200\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.8983 - categorical_accuracy: 0.6315 - val_loss: 0.8818 - val_categorical_accuracy: 0.6714\n",
            "Epoch 110/200\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.8852 - categorical_accuracy: 0.6389 - val_loss: 0.9308 - val_categorical_accuracy: 0.6286\n",
            "Epoch 111/200\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.8931 - categorical_accuracy: 0.6254 - val_loss: 0.8707 - val_categorical_accuracy: 0.6714\n",
            "Epoch 112/200\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.8485 - categorical_accuracy: 0.6530 - val_loss: 0.8883 - val_categorical_accuracy: 0.6571\n",
            "Epoch 113/200\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.8913 - categorical_accuracy: 0.6689 - val_loss: 1.0327 - val_categorical_accuracy: 0.5286\n",
            "Epoch 114/200\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.8539 - categorical_accuracy: 0.6530 - val_loss: 0.8499 - val_categorical_accuracy: 0.7000\n",
            "Epoch 115/200\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.8691 - categorical_accuracy: 0.6305 - val_loss: 0.9203 - val_categorical_accuracy: 0.6429\n",
            "Epoch 116/200\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.8451 - categorical_accuracy: 0.6617 - val_loss: 0.8560 - val_categorical_accuracy: 0.7000\n",
            "Epoch 117/200\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.8403 - categorical_accuracy: 0.6360 - val_loss: 0.8567 - val_categorical_accuracy: 0.6714\n",
            "Epoch 118/200\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.8116 - categorical_accuracy: 0.6867 - val_loss: 0.8755 - val_categorical_accuracy: 0.6714\n",
            "Epoch 119/200\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.8355 - categorical_accuracy: 0.6708 - val_loss: 0.9353 - val_categorical_accuracy: 0.6429\n",
            "Epoch 120/200\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.8895 - categorical_accuracy: 0.6070 - val_loss: 0.8971 - val_categorical_accuracy: 0.6429\n",
            "Epoch 121/200\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.7955 - categorical_accuracy: 0.6934 - val_loss: 0.8536 - val_categorical_accuracy: 0.6571\n",
            "Epoch 122/200\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.8267 - categorical_accuracy: 0.6500 - val_loss: 0.8728 - val_categorical_accuracy: 0.6714\n",
            "Epoch 123/200\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.8750 - categorical_accuracy: 0.6126 - val_loss: 0.9004 - val_categorical_accuracy: 0.6143\n",
            "Epoch 124/200\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.8328 - categorical_accuracy: 0.6694 - val_loss: 0.8681 - val_categorical_accuracy: 0.6714\n",
            "Epoch 125/200\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.8296 - categorical_accuracy: 0.6717 - val_loss: 0.8690 - val_categorical_accuracy: 0.6714\n",
            "Epoch 126/200\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.8664 - categorical_accuracy: 0.6516 - val_loss: 0.9005 - val_categorical_accuracy: 0.6429\n",
            "Epoch 127/200\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.8669 - categorical_accuracy: 0.6497 - val_loss: 0.8497 - val_categorical_accuracy: 0.7000\n",
            "Epoch 128/200\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.9030 - categorical_accuracy: 0.6276 - val_loss: 0.8963 - val_categorical_accuracy: 0.6429\n",
            "Epoch 129/200\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.8435 - categorical_accuracy: 0.6669 - val_loss: 0.9664 - val_categorical_accuracy: 0.6429\n",
            "Epoch 130/200\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.7332 - categorical_accuracy: 0.6897 - val_loss: 0.8065 - val_categorical_accuracy: 0.6857\n",
            "Epoch 131/200\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.8695 - categorical_accuracy: 0.6667 - val_loss: 0.8827 - val_categorical_accuracy: 0.6429\n",
            "Epoch 132/200\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.7832 - categorical_accuracy: 0.7052 - val_loss: 0.9298 - val_categorical_accuracy: 0.6286\n",
            "Epoch 133/200\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.7984 - categorical_accuracy: 0.6850 - val_loss: 0.8490 - val_categorical_accuracy: 0.6571\n",
            "Epoch 134/200\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.7782 - categorical_accuracy: 0.6832 - val_loss: 0.8309 - val_categorical_accuracy: 0.6714\n",
            "Epoch 135/200\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.8015 - categorical_accuracy: 0.7146 - val_loss: 0.8823 - val_categorical_accuracy: 0.6571\n",
            "Epoch 136/200\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.8698 - categorical_accuracy: 0.6444 - val_loss: 0.8547 - val_categorical_accuracy: 0.6857\n",
            "Epoch 137/200\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.7747 - categorical_accuracy: 0.7127 - val_loss: 0.8521 - val_categorical_accuracy: 0.6857\n",
            "Epoch 138/200\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.8243 - categorical_accuracy: 0.6608 - val_loss: 0.8558 - val_categorical_accuracy: 0.6571\n",
            "Epoch 139/200\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.7847 - categorical_accuracy: 0.6815 - val_loss: 0.8283 - val_categorical_accuracy: 0.6857\n",
            "Epoch 140/200\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.8348 - categorical_accuracy: 0.6640 - val_loss: 0.8528 - val_categorical_accuracy: 0.6857\n",
            "Epoch 141/200\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.7746 - categorical_accuracy: 0.6839 - val_loss: 0.9002 - val_categorical_accuracy: 0.6429\n",
            "Epoch 142/200\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.7857 - categorical_accuracy: 0.6933 - val_loss: 0.8331 - val_categorical_accuracy: 0.6714\n",
            "Epoch 143/200\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.7842 - categorical_accuracy: 0.6887 - val_loss: 0.9330 - val_categorical_accuracy: 0.6000\n",
            "Epoch 144/200\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.7819 - categorical_accuracy: 0.6663 - val_loss: 0.8036 - val_categorical_accuracy: 0.7000\n",
            "Epoch 145/200\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.7039 - categorical_accuracy: 0.7021 - val_loss: 0.8439 - val_categorical_accuracy: 0.6857\n",
            "Epoch 146/200\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.8017 - categorical_accuracy: 0.6956 - val_loss: 0.8336 - val_categorical_accuracy: 0.6857\n",
            "Epoch 147/200\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.7543 - categorical_accuracy: 0.7065 - val_loss: 0.8477 - val_categorical_accuracy: 0.6286\n",
            "Epoch 148/200\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.8044 - categorical_accuracy: 0.7017 - val_loss: 0.7827 - val_categorical_accuracy: 0.7143\n",
            "Epoch 149/200\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.7888 - categorical_accuracy: 0.6943 - val_loss: 0.8352 - val_categorical_accuracy: 0.6429\n",
            "Epoch 150/200\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.8306 - categorical_accuracy: 0.6491 - val_loss: 0.8547 - val_categorical_accuracy: 0.6714\n",
            "Epoch 151/200\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.7406 - categorical_accuracy: 0.7224 - val_loss: 0.8246 - val_categorical_accuracy: 0.6429\n",
            "Epoch 152/200\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.7545 - categorical_accuracy: 0.7093 - val_loss: 0.8037 - val_categorical_accuracy: 0.6714\n",
            "Epoch 153/200\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.7813 - categorical_accuracy: 0.6938 - val_loss: 0.7785 - val_categorical_accuracy: 0.7429\n",
            "Epoch 154/200\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.7561 - categorical_accuracy: 0.7239 - val_loss: 0.8336 - val_categorical_accuracy: 0.6714\n",
            "Epoch 155/200\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.8395 - categorical_accuracy: 0.6906 - val_loss: 0.9324 - val_categorical_accuracy: 0.6143\n",
            "Epoch 156/200\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.7312 - categorical_accuracy: 0.7030 - val_loss: 0.9355 - val_categorical_accuracy: 0.5714\n",
            "Epoch 157/200\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.7784 - categorical_accuracy: 0.6957 - val_loss: 0.8080 - val_categorical_accuracy: 0.6714\n",
            "Epoch 158/200\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.8012 - categorical_accuracy: 0.6773 - val_loss: 0.8400 - val_categorical_accuracy: 0.6143\n",
            "Epoch 159/200\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.7085 - categorical_accuracy: 0.7263 - val_loss: 0.8248 - val_categorical_accuracy: 0.6714\n",
            "Epoch 160/200\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.6642 - categorical_accuracy: 0.7247 - val_loss: 0.7591 - val_categorical_accuracy: 0.7571\n",
            "Epoch 161/200\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.7858 - categorical_accuracy: 0.6864 - val_loss: 0.8010 - val_categorical_accuracy: 0.7143\n",
            "Epoch 162/200\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.8195 - categorical_accuracy: 0.6899 - val_loss: 0.8028 - val_categorical_accuracy: 0.6286\n",
            "Epoch 163/200\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.7485 - categorical_accuracy: 0.7033 - val_loss: 0.8213 - val_categorical_accuracy: 0.6857\n",
            "Epoch 164/200\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.7570 - categorical_accuracy: 0.7006 - val_loss: 0.7778 - val_categorical_accuracy: 0.7429\n",
            "Epoch 165/200\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.7134 - categorical_accuracy: 0.7179 - val_loss: 0.8677 - val_categorical_accuracy: 0.6429\n",
            "Epoch 166/200\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.7091 - categorical_accuracy: 0.7231 - val_loss: 0.7537 - val_categorical_accuracy: 0.7429\n",
            "Epoch 167/200\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.7588 - categorical_accuracy: 0.7078 - val_loss: 0.8090 - val_categorical_accuracy: 0.6714\n",
            "Epoch 168/200\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.7229 - categorical_accuracy: 0.7175 - val_loss: 0.7859 - val_categorical_accuracy: 0.7286\n",
            "Epoch 169/200\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.7499 - categorical_accuracy: 0.7208 - val_loss: 0.7884 - val_categorical_accuracy: 0.7000\n",
            "Epoch 170/200\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.7251 - categorical_accuracy: 0.7308 - val_loss: 0.8711 - val_categorical_accuracy: 0.6571\n",
            "Epoch 171/200\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.7383 - categorical_accuracy: 0.7103 - val_loss: 0.8124 - val_categorical_accuracy: 0.6714\n",
            "Epoch 172/200\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.7677 - categorical_accuracy: 0.6748 - val_loss: 0.7889 - val_categorical_accuracy: 0.6857\n",
            "Epoch 173/200\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.7595 - categorical_accuracy: 0.7030 - val_loss: 0.8054 - val_categorical_accuracy: 0.6857\n",
            "Epoch 174/200\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.7212 - categorical_accuracy: 0.7202 - val_loss: 0.7932 - val_categorical_accuracy: 0.6714\n",
            "Epoch 175/200\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.7558 - categorical_accuracy: 0.6805 - val_loss: 0.8402 - val_categorical_accuracy: 0.6571\n",
            "Epoch 176/200\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.7020 - categorical_accuracy: 0.7110 - val_loss: 0.8805 - val_categorical_accuracy: 0.6857\n",
            "Epoch 177/200\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.7106 - categorical_accuracy: 0.7329 - val_loss: 0.7891 - val_categorical_accuracy: 0.6714\n",
            "Epoch 178/200\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.7352 - categorical_accuracy: 0.7114 - val_loss: 0.7894 - val_categorical_accuracy: 0.6714\n",
            "Epoch 179/200\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.7510 - categorical_accuracy: 0.6927 - val_loss: 0.8018 - val_categorical_accuracy: 0.6857\n",
            "Epoch 180/200\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.7217 - categorical_accuracy: 0.7074 - val_loss: 0.8316 - val_categorical_accuracy: 0.6571\n",
            "Epoch 181/200\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.7279 - categorical_accuracy: 0.7224 - val_loss: 0.8284 - val_categorical_accuracy: 0.6857\n",
            "Epoch 182/200\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.6683 - categorical_accuracy: 0.7388 - val_loss: 0.8578 - val_categorical_accuracy: 0.6714\n",
            "Epoch 183/200\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.7471 - categorical_accuracy: 0.7243 - val_loss: 0.8308 - val_categorical_accuracy: 0.6857\n",
            "Epoch 184/200\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.6422 - categorical_accuracy: 0.7459 - val_loss: 0.7647 - val_categorical_accuracy: 0.7429\n",
            "Epoch 185/200\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.6488 - categorical_accuracy: 0.7473 - val_loss: 0.8323 - val_categorical_accuracy: 0.6857\n",
            "Epoch 186/200\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.7467 - categorical_accuracy: 0.7243 - val_loss: 0.8406 - val_categorical_accuracy: 0.6429\n",
            "Epoch 187/200\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.6889 - categorical_accuracy: 0.7522 - val_loss: 0.8275 - val_categorical_accuracy: 0.6857\n",
            "Epoch 188/200\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.7141 - categorical_accuracy: 0.7304 - val_loss: 0.8635 - val_categorical_accuracy: 0.6571\n",
            "Epoch 189/200\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.7648 - categorical_accuracy: 0.6636 - val_loss: 0.8122 - val_categorical_accuracy: 0.6714\n",
            "Epoch 190/200\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.6628 - categorical_accuracy: 0.7248 - val_loss: 0.8055 - val_categorical_accuracy: 0.6714\n",
            "Epoch 191/200\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.7332 - categorical_accuracy: 0.6935 - val_loss: 0.7847 - val_categorical_accuracy: 0.6857\n",
            "Epoch 192/200\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.7041 - categorical_accuracy: 0.7366 - val_loss: 0.8670 - val_categorical_accuracy: 0.6286\n",
            "Epoch 193/200\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.8264 - categorical_accuracy: 0.6777 - val_loss: 0.8865 - val_categorical_accuracy: 0.6714\n",
            "Epoch 194/200\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.6882 - categorical_accuracy: 0.7237 - val_loss: 0.8279 - val_categorical_accuracy: 0.6571\n",
            "Epoch 195/200\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.6642 - categorical_accuracy: 0.7598 - val_loss: 0.7905 - val_categorical_accuracy: 0.7000\n",
            "Epoch 196/200\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.6361 - categorical_accuracy: 0.7533 - val_loss: 0.8656 - val_categorical_accuracy: 0.6571\n",
            "Epoch 197/200\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.6666 - categorical_accuracy: 0.7380 - val_loss: 0.8549 - val_categorical_accuracy: 0.6714\n",
            "Epoch 198/200\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.6739 - categorical_accuracy: 0.7395 - val_loss: 0.7980 - val_categorical_accuracy: 0.6714\n",
            "Epoch 199/200\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.6937 - categorical_accuracy: 0.7065 - val_loss: 0.7989 - val_categorical_accuracy: 0.7000\n",
            "Epoch 200/200\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.7013 - categorical_accuracy: 0.7290 - val_loss: 0.7673 - val_categorical_accuracy: 0.7143\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-SbAEGgyHwqT"
      },
      "source": [
        "model.save('/content/drive/MyDrive/Colab Notebooks/SPEECH_EMOTION_Recognition/Nộp bài(chốt hạ)/model_saver/conv2D_mfcc39_ravdess.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9kR9EefiHwqU"
      },
      "source": [
        "###test_result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JrG2BmU8HwqV",
        "outputId": "8d8f4d3c-ded1-4fb3-9722-269420da7cff"
      },
      "source": [
        "d = {0: 'happy',\n",
        "     1: 'sad',\n",
        "     2: 'angry',\n",
        "     3: 'fear'}\n",
        "Y_test_pred = np.argmax(model.predict(X_test), axis=-1)\n",
        "Y_test_pred = list(map(lambda x: d[x], Y_test_pred))\n",
        "y_test = np.argmax(y_test, axis=-1)\n",
        "y_test = list(map(lambda x: d[x], y_test))\n",
        "print(classification_report(y_test, Y_test_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd8f6542d40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.69      0.85      0.76        13\n",
            "        fear       0.92      0.52      0.67        21\n",
            "       happy       0.74      0.61      0.67        23\n",
            "         sad       0.63      0.95      0.76        20\n",
            "\n",
            "    accuracy                           0.71        77\n",
            "   macro avg       0.74      0.73      0.71        77\n",
            "weighted avg       0.75      0.71      0.71        77\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "id": "K4AMC_WvHwqW",
        "outputId": "dd2efd86-6b7f-43c7-ef77-461db99d5b83"
      },
      "source": [
        "import scikitplot as skplt\n",
        "\n",
        "skplt.metrics.plot_confusion_matrix(\n",
        "    y_test, \n",
        "    Y_test_pred,\n",
        "    figsize=(8,8))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fd8f6e7db90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKZ4QWu4HwqX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_7YOAt2TIKPI"
      },
      "source": [
        "# Mel Spectrogram + basic model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xr3mQSInIQ84"
      },
      "source": [
        "audio_duration = 3\n",
        "sampling_rate = 44100\n",
        "input_length = sampling_rate * audio_duration\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_mWyb8nIYyb",
        "outputId": "4762d9fb-0e8a-4264-f697-25350b90b9ef"
      },
      "source": [
        "features = []\n",
        "labels = []\n",
        "for i in range(len(Ravdess_DF['Paths'])):\n",
        "  if ((Ravdess_DF['Emotion'][i] == '03') | (Ravdess_DF['Emotion'][i] == '04') | \n",
        "      (Ravdess_DF['Emotion'][i] == '05') | (Ravdess_DF['Emotion'][i] == '06')):\n",
        "    signal, sample_rate = librosa.load(Ravdess_DF['Paths'][i], res_type='kaiser_fast',sr=22050*2)\n",
        "    signal,index = librosa.effects.trim(signal,top_db = 25)\n",
        "    signal = scipy.signal.wiener(signal)\n",
        "\n",
        "    if len(signal) > input_length:\n",
        "      signal = signal[0:input_length]\n",
        "    elif  input_length > len(signal):\n",
        "      max_offset = input_length - len(signal)  \n",
        "      signal = np.pad(signal, (0, max_offset), \"constant\")\n",
        "\n",
        "    melspec = librosa.feature.melspectrogram(signal, sr=sample_rate, n_mels=128,n_fft=2048,hop_length=512)   \n",
        "    melspec = np.mean(melspec, axis=0)\n",
        "    features.append(melspec)\n",
        "\n",
        "    if Ravdess_DF['Emotion'][i] == '03':\n",
        "      labels.append(0)\n",
        "    elif Ravdess_DF['Emotion'][i] == '04':\n",
        "      labels.append(1)\n",
        "    elif Ravdess_DF['Emotion'][i] == '05':\n",
        "      labels.append(2)\n",
        "    elif Ravdess_DF['Emotion'][i] == '06':\n",
        "      labels.append(3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/scipy/signal/signaltools.py:1456: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  res *= (1 - noise / lVar)\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/signal/signaltools.py:1456: RuntimeWarning: invalid value encountered in multiply\n",
            "  res *= (1 - noise / lVar)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6yk6fzByIY1W"
      },
      "source": [
        "X = features\n",
        "y = labels\n",
        "\n",
        "y = np.array(y)\n",
        "y = to_categorical(y)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=0)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=0)\n",
        "\n",
        "X_train = np.array(X_train)\n",
        "X_test = np.array(X_test)\n",
        "X_val = np.array(X_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aowUl_16N8b3",
        "outputId": "cba6edf0-ae84-4db8-e070-8bcff4e7c5c4"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(621, 259)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TgEIFTMtNvym"
      },
      "source": [
        "## basic models:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-i-abjOsNvzH",
        "outputId": "0908cb10-de9c-4220-c5ae-7ad2e6960393"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(259, input_shape=(259, ), activation = 'relu'))\n",
        "#model.add(Dropout(0.1))\n",
        "model.add(Dense(128, activation = 'relu'))\n",
        "#model.add(Dropout(0.25))\n",
        "model.add(Dense(128, activation = 'relu'))\n",
        "#model.add(Dropout(0.2))\n",
        "model.add(Dense(4, activation = 'softmax'))\n",
        "\n",
        "optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
        "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer=optimizer)\n",
        "early_stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=100, verbose=1, mode='auto')\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_21 (Dense)             (None, 259)               67340     \n",
            "_________________________________________________________________\n",
            "dense_22 (Dense)             (None, 128)               33280     \n",
            "_________________________________________________________________\n",
            "dense_23 (Dense)             (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dense_24 (Dense)             (None, 4)                 516       \n",
            "=================================================================\n",
            "Total params: 117,648\n",
            "Trainable params: 117,648\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Q3G-i0jNvzI",
        "outputId": "3c866f41-08b6-4055-e12c-30c6945f1e95"
      },
      "source": [
        "history = model.fit(X_train, y_train, batch_size=64, epochs=200, \n",
        "                    validation_data=(X_val, y_val))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "10/10 [==============================] - 1s 35ms/step - loss: 1.3433 - accuracy: 0.3353 - val_loss: 1.2123 - val_accuracy: 0.5000\n",
            "Epoch 2/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2082 - accuracy: 0.5057 - val_loss: 1.2295 - val_accuracy: 0.3857\n",
            "Epoch 3/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1362 - accuracy: 0.5164 - val_loss: 1.1985 - val_accuracy: 0.3714\n",
            "Epoch 4/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0913 - accuracy: 0.5188 - val_loss: 1.1887 - val_accuracy: 0.4000\n",
            "Epoch 5/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.0251 - accuracy: 0.5992 - val_loss: 1.1652 - val_accuracy: 0.4286\n",
            "Epoch 6/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.9752 - accuracy: 0.6090 - val_loss: 1.1568 - val_accuracy: 0.4143\n",
            "Epoch 7/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.9318 - accuracy: 0.6123 - val_loss: 1.1591 - val_accuracy: 0.4286\n",
            "Epoch 8/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9257 - accuracy: 0.5983 - val_loss: 1.1778 - val_accuracy: 0.4286\n",
            "Epoch 9/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8856 - accuracy: 0.6281 - val_loss: 1.1869 - val_accuracy: 0.4714\n",
            "Epoch 10/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.8236 - accuracy: 0.6532 - val_loss: 1.2351 - val_accuracy: 0.4714\n",
            "Epoch 11/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.8577 - accuracy: 0.6442 - val_loss: 1.2408 - val_accuracy: 0.4571\n",
            "Epoch 12/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7876 - accuracy: 0.6806 - val_loss: 1.2150 - val_accuracy: 0.4571\n",
            "Epoch 13/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8132 - accuracy: 0.6711 - val_loss: 1.2539 - val_accuracy: 0.5000\n",
            "Epoch 14/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7808 - accuracy: 0.6789 - val_loss: 1.2408 - val_accuracy: 0.4857\n",
            "Epoch 15/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7512 - accuracy: 0.6933 - val_loss: 1.2603 - val_accuracy: 0.5000\n",
            "Epoch 16/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7256 - accuracy: 0.6991 - val_loss: 1.3219 - val_accuracy: 0.5000\n",
            "Epoch 17/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7365 - accuracy: 0.6978 - val_loss: 1.3635 - val_accuracy: 0.4857\n",
            "Epoch 18/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6919 - accuracy: 0.7298 - val_loss: 1.3596 - val_accuracy: 0.5143\n",
            "Epoch 19/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6399 - accuracy: 0.7472 - val_loss: 1.4639 - val_accuracy: 0.4714\n",
            "Epoch 20/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6016 - accuracy: 0.7620 - val_loss: 1.4769 - val_accuracy: 0.5143\n",
            "Epoch 21/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.5808 - accuracy: 0.7768 - val_loss: 1.5437 - val_accuracy: 0.5143\n",
            "Epoch 22/200\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.6273 - accuracy: 0.7625 - val_loss: 1.6611 - val_accuracy: 0.4857\n",
            "Epoch 23/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6813 - accuracy: 0.7492 - val_loss: 1.4577 - val_accuracy: 0.5857\n",
            "Epoch 24/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6161 - accuracy: 0.7582 - val_loss: 1.5600 - val_accuracy: 0.4714\n",
            "Epoch 25/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.5873 - accuracy: 0.7777 - val_loss: 1.4252 - val_accuracy: 0.6000\n",
            "Epoch 26/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6185 - accuracy: 0.7815 - val_loss: 1.6753 - val_accuracy: 0.4857\n",
            "Epoch 27/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.5783 - accuracy: 0.7975 - val_loss: 1.6684 - val_accuracy: 0.5571\n",
            "Epoch 28/200\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.5410 - accuracy: 0.8020 - val_loss: 1.5994 - val_accuracy: 0.4857\n",
            "Epoch 29/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.5551 - accuracy: 0.7955 - val_loss: 1.6170 - val_accuracy: 0.5571\n",
            "Epoch 30/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.5085 - accuracy: 0.7957 - val_loss: 1.7329 - val_accuracy: 0.4857\n",
            "Epoch 31/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.4981 - accuracy: 0.8375 - val_loss: 1.7301 - val_accuracy: 0.5714\n",
            "Epoch 32/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.4476 - accuracy: 0.8485 - val_loss: 1.8671 - val_accuracy: 0.5429\n",
            "Epoch 33/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.4337 - accuracy: 0.8549 - val_loss: 1.9375 - val_accuracy: 0.5571\n",
            "Epoch 34/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.4267 - accuracy: 0.8738 - val_loss: 1.9890 - val_accuracy: 0.5857\n",
            "Epoch 35/200\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.4299 - accuracy: 0.8586 - val_loss: 2.0502 - val_accuracy: 0.6000\n",
            "Epoch 36/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.4287 - accuracy: 0.8632 - val_loss: 2.1272 - val_accuracy: 0.5714\n",
            "Epoch 37/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.3733 - accuracy: 0.8954 - val_loss: 2.2676 - val_accuracy: 0.5571\n",
            "Epoch 38/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.3510 - accuracy: 0.8924 - val_loss: 2.3291 - val_accuracy: 0.5714\n",
            "Epoch 39/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.3648 - accuracy: 0.8826 - val_loss: 2.4786 - val_accuracy: 0.5429\n",
            "Epoch 40/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.3352 - accuracy: 0.8963 - val_loss: 2.5383 - val_accuracy: 0.5571\n",
            "Epoch 41/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.3693 - accuracy: 0.8795 - val_loss: 2.5316 - val_accuracy: 0.5429\n",
            "Epoch 42/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.3373 - accuracy: 0.8849 - val_loss: 2.7592 - val_accuracy: 0.5571\n",
            "Epoch 43/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.3025 - accuracy: 0.9192 - val_loss: 2.8579 - val_accuracy: 0.5286\n",
            "Epoch 44/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.3077 - accuracy: 0.9094 - val_loss: 2.8139 - val_accuracy: 0.5571\n",
            "Epoch 45/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.2887 - accuracy: 0.9105 - val_loss: 2.9303 - val_accuracy: 0.5429\n",
            "Epoch 46/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.2913 - accuracy: 0.9169 - val_loss: 3.0556 - val_accuracy: 0.5571\n",
            "Epoch 47/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.2676 - accuracy: 0.9202 - val_loss: 3.1701 - val_accuracy: 0.5286\n",
            "Epoch 48/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.2630 - accuracy: 0.9248 - val_loss: 2.9594 - val_accuracy: 0.6286\n",
            "Epoch 49/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.4015 - accuracy: 0.8891 - val_loss: 3.0114 - val_accuracy: 0.5571\n",
            "Epoch 50/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.5525 - accuracy: 0.8290 - val_loss: 2.7266 - val_accuracy: 0.4714\n",
            "Epoch 51/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.5757 - accuracy: 0.8096 - val_loss: 2.3435 - val_accuracy: 0.5714\n",
            "Epoch 52/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.4275 - accuracy: 0.8502 - val_loss: 2.5618 - val_accuracy: 0.5714\n",
            "Epoch 53/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.3883 - accuracy: 0.8723 - val_loss: 2.7499 - val_accuracy: 0.5429\n",
            "Epoch 54/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.4211 - accuracy: 0.8633 - val_loss: 2.5938 - val_accuracy: 0.5857\n",
            "Epoch 55/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.3554 - accuracy: 0.8884 - val_loss: 2.8176 - val_accuracy: 0.5714\n",
            "Epoch 56/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.3078 - accuracy: 0.9042 - val_loss: 2.9971 - val_accuracy: 0.5429\n",
            "Epoch 57/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.2828 - accuracy: 0.9083 - val_loss: 2.9338 - val_accuracy: 0.5286\n",
            "Epoch 58/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.2529 - accuracy: 0.9364 - val_loss: 3.0719 - val_accuracy: 0.5714\n",
            "Epoch 59/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.2261 - accuracy: 0.9390 - val_loss: 3.0842 - val_accuracy: 0.5571\n",
            "Epoch 60/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.2112 - accuracy: 0.9316 - val_loss: 3.2971 - val_accuracy: 0.6143\n",
            "Epoch 61/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.2430 - accuracy: 0.9344 - val_loss: 3.3409 - val_accuracy: 0.6000\n",
            "Epoch 62/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.2370 - accuracy: 0.9254 - val_loss: 3.4745 - val_accuracy: 0.6000\n",
            "Epoch 63/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.2286 - accuracy: 0.9354 - val_loss: 3.4377 - val_accuracy: 0.5286\n",
            "Epoch 64/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.2096 - accuracy: 0.9348 - val_loss: 3.5837 - val_accuracy: 0.5714\n",
            "Epoch 65/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1893 - accuracy: 0.9462 - val_loss: 3.6422 - val_accuracy: 0.5857\n",
            "Epoch 66/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.1876 - accuracy: 0.9420 - val_loss: 3.7534 - val_accuracy: 0.5857\n",
            "Epoch 67/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1731 - accuracy: 0.9425 - val_loss: 3.7372 - val_accuracy: 0.5571\n",
            "Epoch 68/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.1826 - accuracy: 0.9468 - val_loss: 3.8246 - val_accuracy: 0.5857\n",
            "Epoch 69/200\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1564 - accuracy: 0.9622 - val_loss: 3.8337 - val_accuracy: 0.5714\n",
            "Epoch 70/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1648 - accuracy: 0.9503 - val_loss: 3.9361 - val_accuracy: 0.6000\n",
            "Epoch 71/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1696 - accuracy: 0.9493 - val_loss: 4.0256 - val_accuracy: 0.6143\n",
            "Epoch 72/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1729 - accuracy: 0.9526 - val_loss: 4.0562 - val_accuracy: 0.6000\n",
            "Epoch 73/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1389 - accuracy: 0.9622 - val_loss: 4.1776 - val_accuracy: 0.5857\n",
            "Epoch 74/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1405 - accuracy: 0.9571 - val_loss: 4.1852 - val_accuracy: 0.6000\n",
            "Epoch 75/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1492 - accuracy: 0.9478 - val_loss: 4.2598 - val_accuracy: 0.6000\n",
            "Epoch 76/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1110 - accuracy: 0.9730 - val_loss: 4.3599 - val_accuracy: 0.5714\n",
            "Epoch 77/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.1533 - accuracy: 0.9595 - val_loss: 4.4153 - val_accuracy: 0.6143\n",
            "Epoch 78/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1259 - accuracy: 0.9683 - val_loss: 4.6465 - val_accuracy: 0.5857\n",
            "Epoch 79/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1313 - accuracy: 0.9628 - val_loss: 4.6099 - val_accuracy: 0.5714\n",
            "Epoch 80/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1257 - accuracy: 0.9593 - val_loss: 4.6047 - val_accuracy: 0.6143\n",
            "Epoch 81/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1327 - accuracy: 0.9548 - val_loss: 4.8213 - val_accuracy: 0.5429\n",
            "Epoch 82/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1355 - accuracy: 0.9635 - val_loss: 4.7774 - val_accuracy: 0.5857\n",
            "Epoch 83/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.1134 - accuracy: 0.9586 - val_loss: 4.9513 - val_accuracy: 0.5571\n",
            "Epoch 84/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.1224 - accuracy: 0.9660 - val_loss: 4.9147 - val_accuracy: 0.6000\n",
            "Epoch 85/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0955 - accuracy: 0.9786 - val_loss: 5.0711 - val_accuracy: 0.5714\n",
            "Epoch 86/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1128 - accuracy: 0.9675 - val_loss: 5.0053 - val_accuracy: 0.5857\n",
            "Epoch 87/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1219 - accuracy: 0.9583 - val_loss: 5.1400 - val_accuracy: 0.5714\n",
            "Epoch 88/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1342 - accuracy: 0.9637 - val_loss: 5.4290 - val_accuracy: 0.5429\n",
            "Epoch 89/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1090 - accuracy: 0.9692 - val_loss: 5.3752 - val_accuracy: 0.5857\n",
            "Epoch 90/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1097 - accuracy: 0.9637 - val_loss: 5.3814 - val_accuracy: 0.6000\n",
            "Epoch 91/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0965 - accuracy: 0.9729 - val_loss: 5.4927 - val_accuracy: 0.5857\n",
            "Epoch 92/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0954 - accuracy: 0.9749 - val_loss: 5.5197 - val_accuracy: 0.5857\n",
            "Epoch 93/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0961 - accuracy: 0.9749 - val_loss: 5.5643 - val_accuracy: 0.6000\n",
            "Epoch 94/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0911 - accuracy: 0.9727 - val_loss: 5.6503 - val_accuracy: 0.5429\n",
            "Epoch 95/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0985 - accuracy: 0.9728 - val_loss: 5.6286 - val_accuracy: 0.5857\n",
            "Epoch 96/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0838 - accuracy: 0.9806 - val_loss: 5.8450 - val_accuracy: 0.5429\n",
            "Epoch 97/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0843 - accuracy: 0.9795 - val_loss: 5.7101 - val_accuracy: 0.5857\n",
            "Epoch 98/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0932 - accuracy: 0.9721 - val_loss: 6.0021 - val_accuracy: 0.5429\n",
            "Epoch 99/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0807 - accuracy: 0.9798 - val_loss: 6.0370 - val_accuracy: 0.5571\n",
            "Epoch 100/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0850 - accuracy: 0.9755 - val_loss: 6.1265 - val_accuracy: 0.5857\n",
            "Epoch 101/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0836 - accuracy: 0.9730 - val_loss: 6.1478 - val_accuracy: 0.5143\n",
            "Epoch 102/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0860 - accuracy: 0.9725 - val_loss: 6.0767 - val_accuracy: 0.5571\n",
            "Epoch 103/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.9739 - val_loss: 6.4162 - val_accuracy: 0.5429\n",
            "Epoch 104/200\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0664 - accuracy: 0.9843 - val_loss: 6.3570 - val_accuracy: 0.5714\n",
            "Epoch 105/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0795 - accuracy: 0.9746 - val_loss: 6.5177 - val_accuracy: 0.5429\n",
            "Epoch 106/200\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0729 - accuracy: 0.9782 - val_loss: 6.4131 - val_accuracy: 0.5429\n",
            "Epoch 107/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0735 - accuracy: 0.9770 - val_loss: 6.3030 - val_accuracy: 0.5714\n",
            "Epoch 108/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0659 - accuracy: 0.9872 - val_loss: 6.3798 - val_accuracy: 0.5857\n",
            "Epoch 109/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0611 - accuracy: 0.9891 - val_loss: 6.6201 - val_accuracy: 0.5714\n",
            "Epoch 110/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0655 - accuracy: 0.9869 - val_loss: 6.6756 - val_accuracy: 0.5571\n",
            "Epoch 111/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0643 - accuracy: 0.9846 - val_loss: 6.7386 - val_accuracy: 0.5571\n",
            "Epoch 112/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0732 - accuracy: 0.9837 - val_loss: 6.9282 - val_accuracy: 0.5571\n",
            "Epoch 113/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0678 - accuracy: 0.9789 - val_loss: 6.8644 - val_accuracy: 0.5857\n",
            "Epoch 114/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0624 - accuracy: 0.9799 - val_loss: 7.0206 - val_accuracy: 0.5286\n",
            "Epoch 115/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0658 - accuracy: 0.9787 - val_loss: 7.0002 - val_accuracy: 0.5714\n",
            "Epoch 116/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0570 - accuracy: 0.9865 - val_loss: 6.9918 - val_accuracy: 0.5286\n",
            "Epoch 117/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0532 - accuracy: 0.9856 - val_loss: 7.0801 - val_accuracy: 0.5714\n",
            "Epoch 118/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0626 - accuracy: 0.9843 - val_loss: 7.4889 - val_accuracy: 0.5286\n",
            "Epoch 119/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0766 - accuracy: 0.9735 - val_loss: 7.2863 - val_accuracy: 0.5714\n",
            "Epoch 120/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0586 - accuracy: 0.9800 - val_loss: 7.2831 - val_accuracy: 0.5714\n",
            "Epoch 121/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0452 - accuracy: 0.9906 - val_loss: 7.3913 - val_accuracy: 0.5857\n",
            "Epoch 122/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0470 - accuracy: 0.9892 - val_loss: 7.4696 - val_accuracy: 0.5714\n",
            "Epoch 123/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0568 - accuracy: 0.9855 - val_loss: 7.6675 - val_accuracy: 0.5714\n",
            "Epoch 124/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0550 - accuracy: 0.9840 - val_loss: 7.6748 - val_accuracy: 0.5571\n",
            "Epoch 125/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0567 - accuracy: 0.9900 - val_loss: 7.8951 - val_accuracy: 0.5571\n",
            "Epoch 126/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0677 - accuracy: 0.9773 - val_loss: 7.9509 - val_accuracy: 0.5429\n",
            "Epoch 127/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0695 - accuracy: 0.9786 - val_loss: 7.6361 - val_accuracy: 0.5714\n",
            "Epoch 128/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0473 - accuracy: 0.9837 - val_loss: 7.8614 - val_accuracy: 0.5429\n",
            "Epoch 129/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0490 - accuracy: 0.9838 - val_loss: 7.8051 - val_accuracy: 0.5571\n",
            "Epoch 130/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0493 - accuracy: 0.9863 - val_loss: 7.9621 - val_accuracy: 0.5143\n",
            "Epoch 131/200\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0395 - accuracy: 0.9922 - val_loss: 7.8739 - val_accuracy: 0.5714\n",
            "Epoch 132/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0529 - accuracy: 0.9815 - val_loss: 8.2243 - val_accuracy: 0.5286\n",
            "Epoch 133/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0479 - accuracy: 0.9850 - val_loss: 7.8954 - val_accuracy: 0.5429\n",
            "Epoch 134/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0485 - accuracy: 0.9868 - val_loss: 8.0778 - val_accuracy: 0.5571\n",
            "Epoch 135/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0516 - accuracy: 0.9880 - val_loss: 8.0175 - val_accuracy: 0.5571\n",
            "Epoch 136/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0612 - accuracy: 0.9839 - val_loss: 8.5153 - val_accuracy: 0.5143\n",
            "Epoch 137/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0708 - accuracy: 0.9691 - val_loss: 8.3040 - val_accuracy: 0.5714\n",
            "Epoch 138/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0618 - accuracy: 0.9764 - val_loss: 8.4548 - val_accuracy: 0.5286\n",
            "Epoch 139/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0408 - accuracy: 0.9860 - val_loss: 8.3886 - val_accuracy: 0.5571\n",
            "Epoch 140/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.5725 - accuracy: 0.9336 - val_loss: 5.8945 - val_accuracy: 0.5714\n",
            "Epoch 141/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.6123 - accuracy: 0.8042 - val_loss: 4.9181 - val_accuracy: 0.5429\n",
            "Epoch 142/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.0582 - accuracy: 0.7949 - val_loss: 4.7292 - val_accuracy: 0.4857\n",
            "Epoch 143/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0173 - accuracy: 0.7842 - val_loss: 3.0153 - val_accuracy: 0.5286\n",
            "Epoch 144/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.4506 - accuracy: 0.8295 - val_loss: 2.5458 - val_accuracy: 0.5714\n",
            "Epoch 145/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.3369 - accuracy: 0.8887 - val_loss: 2.7980 - val_accuracy: 0.5429\n",
            "Epoch 146/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.2810 - accuracy: 0.9229 - val_loss: 3.0868 - val_accuracy: 0.5000\n",
            "Epoch 147/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.2069 - accuracy: 0.9555 - val_loss: 3.3656 - val_accuracy: 0.5143\n",
            "Epoch 148/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1580 - accuracy: 0.9600 - val_loss: 3.6753 - val_accuracy: 0.5714\n",
            "Epoch 149/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1362 - accuracy: 0.9682 - val_loss: 3.8722 - val_accuracy: 0.5571\n",
            "Epoch 150/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1184 - accuracy: 0.9711 - val_loss: 3.9672 - val_accuracy: 0.5571\n",
            "Epoch 151/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1068 - accuracy: 0.9775 - val_loss: 3.8527 - val_accuracy: 0.5571\n",
            "Epoch 152/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1041 - accuracy: 0.9762 - val_loss: 3.8011 - val_accuracy: 0.5714\n",
            "Epoch 153/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0991 - accuracy: 0.9701 - val_loss: 3.8334 - val_accuracy: 0.5429\n",
            "Epoch 154/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0777 - accuracy: 0.9795 - val_loss: 4.0817 - val_accuracy: 0.5429\n",
            "Epoch 155/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0711 - accuracy: 0.9831 - val_loss: 4.1888 - val_accuracy: 0.5571\n",
            "Epoch 156/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0683 - accuracy: 0.9843 - val_loss: 4.2615 - val_accuracy: 0.5429\n",
            "Epoch 157/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0658 - accuracy: 0.9858 - val_loss: 4.3916 - val_accuracy: 0.5714\n",
            "Epoch 158/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0556 - accuracy: 0.9886 - val_loss: 4.4242 - val_accuracy: 0.5714\n",
            "Epoch 159/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0577 - accuracy: 0.9895 - val_loss: 4.5274 - val_accuracy: 0.5714\n",
            "Epoch 160/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0573 - accuracy: 0.9920 - val_loss: 4.5825 - val_accuracy: 0.5571\n",
            "Epoch 161/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0516 - accuracy: 0.9862 - val_loss: 4.7246 - val_accuracy: 0.5714\n",
            "Epoch 162/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0592 - accuracy: 0.9855 - val_loss: 4.6990 - val_accuracy: 0.5429\n",
            "Epoch 163/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0561 - accuracy: 0.9807 - val_loss: 4.8455 - val_accuracy: 0.5714\n",
            "Epoch 164/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0502 - accuracy: 0.9875 - val_loss: 4.9697 - val_accuracy: 0.5714\n",
            "Epoch 165/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0476 - accuracy: 0.9885 - val_loss: 4.9213 - val_accuracy: 0.5286\n",
            "Epoch 166/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0554 - accuracy: 0.9844 - val_loss: 5.0001 - val_accuracy: 0.5571\n",
            "Epoch 167/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0511 - accuracy: 0.9893 - val_loss: 5.1141 - val_accuracy: 0.5714\n",
            "Epoch 168/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0521 - accuracy: 0.9830 - val_loss: 5.1853 - val_accuracy: 0.5571\n",
            "Epoch 169/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0421 - accuracy: 0.9881 - val_loss: 5.3092 - val_accuracy: 0.5571\n",
            "Epoch 170/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0451 - accuracy: 0.9838 - val_loss: 5.3683 - val_accuracy: 0.5571\n",
            "Epoch 171/200\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0493 - accuracy: 0.9827 - val_loss: 5.4586 - val_accuracy: 0.5571\n",
            "Epoch 172/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0406 - accuracy: 0.9899 - val_loss: 5.5248 - val_accuracy: 0.5429\n",
            "Epoch 173/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0441 - accuracy: 0.9928 - val_loss: 5.6290 - val_accuracy: 0.5714\n",
            "Epoch 174/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0345 - accuracy: 0.9917 - val_loss: 5.7404 - val_accuracy: 0.5714\n",
            "Epoch 175/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0470 - accuracy: 0.9839 - val_loss: 5.7517 - val_accuracy: 0.5714\n",
            "Epoch 176/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0325 - accuracy: 0.9915 - val_loss: 5.7591 - val_accuracy: 0.5571\n",
            "Epoch 177/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0390 - accuracy: 0.9896 - val_loss: 5.8985 - val_accuracy: 0.5714\n",
            "Epoch 178/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0350 - accuracy: 0.9903 - val_loss: 5.8658 - val_accuracy: 0.5429\n",
            "Epoch 179/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0395 - accuracy: 0.9943 - val_loss: 6.0108 - val_accuracy: 0.5714\n",
            "Epoch 180/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0434 - accuracy: 0.9844 - val_loss: 6.0743 - val_accuracy: 0.5714\n",
            "Epoch 181/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0350 - accuracy: 0.9914 - val_loss: 6.0873 - val_accuracy: 0.5571\n",
            "Epoch 182/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0346 - accuracy: 0.9903 - val_loss: 6.1317 - val_accuracy: 0.5571\n",
            "Epoch 183/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0447 - accuracy: 0.9847 - val_loss: 6.2985 - val_accuracy: 0.5571\n",
            "Epoch 184/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0400 - accuracy: 0.9893 - val_loss: 6.2259 - val_accuracy: 0.5429\n",
            "Epoch 185/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0363 - accuracy: 0.9882 - val_loss: 6.3537 - val_accuracy: 0.5714\n",
            "Epoch 186/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0363 - accuracy: 0.9878 - val_loss: 6.4211 - val_accuracy: 0.5714\n",
            "Epoch 187/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0352 - accuracy: 0.9892 - val_loss: 6.3499 - val_accuracy: 0.5286\n",
            "Epoch 188/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0420 - accuracy: 0.9889 - val_loss: 6.4167 - val_accuracy: 0.5571\n",
            "Epoch 189/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0276 - accuracy: 0.9956 - val_loss: 6.4167 - val_accuracy: 0.5286\n",
            "Epoch 190/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0383 - accuracy: 0.9898 - val_loss: 6.6000 - val_accuracy: 0.5714\n",
            "Epoch 191/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0287 - accuracy: 0.9935 - val_loss: 6.5936 - val_accuracy: 0.5714\n",
            "Epoch 192/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0413 - accuracy: 0.9861 - val_loss: 6.5787 - val_accuracy: 0.5571\n",
            "Epoch 193/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0379 - accuracy: 0.9889 - val_loss: 6.7536 - val_accuracy: 0.5714\n",
            "Epoch 194/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0397 - accuracy: 0.9839 - val_loss: 6.6949 - val_accuracy: 0.5714\n",
            "Epoch 195/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0275 - accuracy: 0.9957 - val_loss: 6.6515 - val_accuracy: 0.5286\n",
            "Epoch 196/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0472 - accuracy: 0.9779 - val_loss: 6.8938 - val_accuracy: 0.5571\n",
            "Epoch 197/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0352 - accuracy: 0.9934 - val_loss: 6.8021 - val_accuracy: 0.5714\n",
            "Epoch 198/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0355 - accuracy: 0.9896 - val_loss: 6.8133 - val_accuracy: 0.5714\n",
            "Epoch 199/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0286 - accuracy: 0.9923 - val_loss: 6.8796 - val_accuracy: 0.5714\n",
            "Epoch 200/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0371 - accuracy: 0.9854 - val_loss: 6.8266 - val_accuracy: 0.5571\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OcxSAMrpWwn6"
      },
      "source": [
        "model.save('/content/drive/MyDrive/Colab Notebooks/SPEECH_EMOTION_Recognition/Nộp bài(chốt hạ)/model_saver/basic_melspec_ravdess.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JY0Ki_DJNvzK"
      },
      "source": [
        "###test_result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_syQ5_c5NvzL",
        "outputId": "0f61766e-0a76-4628-e7b6-65b0e183ec8d"
      },
      "source": [
        "d = {0: 'happy',\n",
        "     1: 'sad',\n",
        "     2: 'angry',\n",
        "     3: 'fear'}\n",
        "Y_test_pred = np.argmax(model.predict(X_test), axis=-1)\n",
        "Y_test_pred = list(map(lambda x: d[x], Y_test_pred))\n",
        "y_test = np.argmax(y_test, axis=-1)\n",
        "y_test = list(map(lambda x: d[x], y_test))\n",
        "print(classification_report(y_test, Y_test_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.60      0.69      0.64        13\n",
            "        fear       0.38      0.38      0.38        21\n",
            "       happy       0.33      0.30      0.32        23\n",
            "         sad       0.60      0.60      0.60        20\n",
            "\n",
            "    accuracy                           0.47        77\n",
            "   macro avg       0.48      0.49      0.49        77\n",
            "weighted avg       0.46      0.47      0.46        77\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "cFY-fvMRNvzL",
        "outputId": "93fede2e-225a-44b2-8075-4b6ac4a15b82"
      },
      "source": [
        "import scikitplot as skplt\n",
        "\n",
        "skplt.metrics.plot_confusion_matrix(\n",
        "    y_test, \n",
        "    Y_test_pred,\n",
        "    figsize=(8,8))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fda6e176710>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lcNft7CpLrUW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xoFUigALIY4T"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jNEbmeonPxXR"
      },
      "source": [
        "# Mel Spectrogram + conv1D"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j8K-0mOcPxXm"
      },
      "source": [
        "audio_duration = 3\n",
        "sampling_rate = 44100\n",
        "input_length = sampling_rate * audio_duration\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eKTGQBGrPxXo",
        "outputId": "58b95b48-e332-4ded-df17-b1de4a94367d"
      },
      "source": [
        "features = []\n",
        "labels = []\n",
        "for i in range(len(Ravdess_DF['Paths'])):\n",
        "  if ((Ravdess_DF['Emotion'][i] == '03') | (Ravdess_DF['Emotion'][i] == '04') | \n",
        "      (Ravdess_DF['Emotion'][i] == '05') | (Ravdess_DF['Emotion'][i] == '06')):\n",
        "    signal, sample_rate = librosa.load(Ravdess_DF['Paths'][i], res_type='kaiser_fast',sr=22050*2)\n",
        "    signal,index = librosa.effects.trim(signal,top_db = 25)\n",
        "    signal = scipy.signal.wiener(signal)\n",
        "\n",
        "    if len(signal) > input_length:\n",
        "      signal = signal[0:input_length]\n",
        "    elif  input_length > len(signal):\n",
        "      max_offset = input_length - len(signal)  \n",
        "      signal = np.pad(signal, (0, max_offset), \"constant\")\n",
        "\n",
        "    melspec = librosa.feature.melspectrogram(signal, sr=sample_rate, n_mels=128,n_fft=2048,hop_length=512)   \n",
        "    melspec = melspec.reshape(-1,1)\n",
        "    features.append(melspec)\n",
        "\n",
        "    if Ravdess_DF['Emotion'][i] == '03':\n",
        "      labels.append(0)\n",
        "    elif Ravdess_DF['Emotion'][i] == '04':\n",
        "      labels.append(1)\n",
        "    elif Ravdess_DF['Emotion'][i] == '05':\n",
        "      labels.append(2)\n",
        "    elif Ravdess_DF['Emotion'][i] == '06':\n",
        "      labels.append(3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/scipy/signal/signaltools.py:1456: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  res *= (1 - noise / lVar)\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/signal/signaltools.py:1456: RuntimeWarning: invalid value encountered in multiply\n",
            "  res *= (1 - noise / lVar)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1inUhrfPxXp"
      },
      "source": [
        "X = features\n",
        "y = labels\n",
        "\n",
        "y = np.array(y)\n",
        "y = to_categorical(y)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=0)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=0)\n",
        "\n",
        "X_train = np.array(X_train)\n",
        "X_test = np.array(X_test)\n",
        "X_val = np.array(X_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75dgiNuHPxXq",
        "outputId": "3d7076c6-3e39-4996-9789-74d3a01a87f6"
      },
      "source": [
        "X_train.shape,X_test.shape,y_train.shape,y_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((621, 33152, 1), (77, 33152, 1), (621, 4), (77, 4))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oh_OiXY_Yg4_"
      },
      "source": [
        "### conv1D"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0YU2uUSwQXSk"
      },
      "source": [
        "\n",
        "# CNN I/P Config\n",
        "num_classes = 4\n",
        "input_shape = X_train.shape[1:]\n",
        "learning_rate = 0.0001\n",
        "decay = 1e-6\n",
        "momentum = 0.9\n",
        "\n",
        "#LSTM Configuration\n",
        "num_lstm = 256"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SqfS1FIXQYZc",
        "outputId": "17e8c250-b15e-4b0b-a5c8-9de3a9cd6959"
      },
      "source": [
        "model = Sequential(name='Audio_CNN_1D')\n",
        "\n",
        "# LFLB1\n",
        "model.add(Conv1D(filters=64, kernel_size=(3), strides=1, padding='same', data_format='channels_last',input_shape=input_shape))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('elu'))\n",
        "model.add(MaxPooling1D(pool_size=4, strides=4))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "# LFLB2\n",
        "model.add(Conv1D(filters=64, kernel_size=3, strides=1, padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('elu'))\n",
        "model.add(MaxPooling1D(pool_size=4, strides=4))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# LFLB3\n",
        "model.add(Conv1D(filters=128, kernel_size=3, strides=1, padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('elu'))\n",
        "model.add(MaxPooling1D(pool_size=4, strides=4))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# LFLB4\n",
        "model.add(Conv1D(filters=128, kernel_size=3, strides=1, padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('elu'))\n",
        "model.add(MaxPooling1D(pool_size=4, strides=4))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# LSTM\n",
        "model.add(LSTM(units=num_lstm))\n",
        "\n",
        "# FC\n",
        "model.add(Dense(units=num_classes, activation='softmax'))\n",
        "\n",
        "# Model compilation\n",
        "opt= keras.optimizers.Adam(lr=0.01, beta_1=0.9,  beta_2=0.999, amsgrad=False)\n",
        "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
        "\n",
        "model.summary()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"Audio_CNN_1D\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 33152, 64)         256       \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 33152, 64)         256       \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 33152, 64)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D) (None, 8288, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 8288, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 8288, 64)          12352     \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 8288, 64)          256       \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 8288, 64)          0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1 (None, 2072, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 2072, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 2072, 128)         24704     \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 2072, 128)         512       \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 2072, 128)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_2 (MaxPooling1 (None, 518, 128)          0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 518, 128)          0         \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 518, 128)          49280     \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 518, 128)          512       \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 518, 128)          0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_3 (MaxPooling1 (None, 129, 128)          0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 129, 128)          0         \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 256)               394240    \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 4)                 1028      \n",
            "=================================================================\n",
            "Total params: 483,396\n",
            "Trainable params: 482,628\n",
            "Non-trainable params: 768\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "StwxbTydQegU",
        "outputId": "4099e704-883b-440f-a717-47db8e950d1f"
      },
      "source": [
        "#Train Config\n",
        "\n",
        "batch_size = 16\n",
        "num_epochs = 200\n",
        "\n",
        "# Model Training\n",
        "lr_reduce = ReduceLROnPlateau(monitor='val_loss', factor=0.9, patience=20, min_lr=0.000001)\n",
        "# Please change the model name accordingly.\n",
        "mcp_save = ModelCheckpoint('/content/Audio_1DCNN.h5', save_best_only=True, monitor='val_categorical_accuracy', mode='max')\n",
        "cnnhistory=model.fit(X_train, y_train, batch_size=batch_size, epochs=num_epochs,validation_data=(X_val, y_val), callbacks=[mcp_save, lr_reduce])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "39/39 [==============================] - 54s 106ms/step - loss: 1.4787 - categorical_accuracy: 0.2359 - val_loss: 1.3743 - val_categorical_accuracy: 0.2571\n",
            "Epoch 2/200\n",
            "39/39 [==============================] - 3s 74ms/step - loss: 1.4794 - categorical_accuracy: 0.2432 - val_loss: 1.4252 - val_categorical_accuracy: 0.2286\n",
            "Epoch 3/200\n",
            "39/39 [==============================] - 3s 74ms/step - loss: 1.4068 - categorical_accuracy: 0.2697 - val_loss: 1.3865 - val_categorical_accuracy: 0.2143\n",
            "Epoch 4/200\n",
            "39/39 [==============================] - 3s 74ms/step - loss: 1.3898 - categorical_accuracy: 0.2677 - val_loss: 1.3695 - val_categorical_accuracy: 0.3143\n",
            "Epoch 5/200\n",
            "39/39 [==============================] - 3s 74ms/step - loss: 1.3950 - categorical_accuracy: 0.2629 - val_loss: 1.3826 - val_categorical_accuracy: 0.2143\n",
            "Epoch 6/200\n",
            "39/39 [==============================] - 3s 74ms/step - loss: 1.3835 - categorical_accuracy: 0.2722 - val_loss: 1.3546 - val_categorical_accuracy: 0.3143\n",
            "Epoch 7/200\n",
            "39/39 [==============================] - 3s 74ms/step - loss: 1.3315 - categorical_accuracy: 0.3809 - val_loss: 1.3877 - val_categorical_accuracy: 0.2429\n",
            "Epoch 8/200\n",
            "39/39 [==============================] - 3s 74ms/step - loss: 1.3712 - categorical_accuracy: 0.2704 - val_loss: 1.3839 - val_categorical_accuracy: 0.2857\n",
            "Epoch 9/200\n",
            "39/39 [==============================] - 3s 75ms/step - loss: 1.4074 - categorical_accuracy: 0.2137 - val_loss: 1.4227 - val_categorical_accuracy: 0.1857\n",
            "Epoch 10/200\n",
            "39/39 [==============================] - 3s 75ms/step - loss: 1.3954 - categorical_accuracy: 0.2199 - val_loss: 1.3968 - val_categorical_accuracy: 0.1857\n",
            "Epoch 11/200\n",
            "39/39 [==============================] - 3s 75ms/step - loss: 1.3942 - categorical_accuracy: 0.2381 - val_loss: 1.3926 - val_categorical_accuracy: 0.1857\n",
            "Epoch 12/200\n",
            "39/39 [==============================] - 3s 74ms/step - loss: 1.3981 - categorical_accuracy: 0.1967 - val_loss: 1.4174 - val_categorical_accuracy: 0.2143\n",
            "Epoch 13/200\n",
            "39/39 [==============================] - 3s 75ms/step - loss: 1.4009 - categorical_accuracy: 0.2124 - val_loss: 1.3922 - val_categorical_accuracy: 0.1857\n",
            "Epoch 14/200\n",
            "39/39 [==============================] - 3s 75ms/step - loss: 1.3922 - categorical_accuracy: 0.2412 - val_loss: 1.3867 - val_categorical_accuracy: 0.1857\n",
            "Epoch 15/200\n",
            "39/39 [==============================] - 3s 75ms/step - loss: 1.3914 - categorical_accuracy: 0.2384 - val_loss: 1.3897 - val_categorical_accuracy: 0.2143\n",
            "Epoch 16/200\n",
            "39/39 [==============================] - 3s 75ms/step - loss: 1.3912 - categorical_accuracy: 0.2653 - val_loss: 1.4079 - val_categorical_accuracy: 0.1857\n",
            "Epoch 17/200\n",
            "39/39 [==============================] - 3s 74ms/step - loss: 1.3985 - categorical_accuracy: 0.2496 - val_loss: 1.3994 - val_categorical_accuracy: 0.2857\n",
            "Epoch 18/200\n",
            "39/39 [==============================] - 3s 75ms/step - loss: 1.3972 - categorical_accuracy: 0.2415 - val_loss: 1.3940 - val_categorical_accuracy: 0.1857\n",
            "Epoch 19/200\n",
            "39/39 [==============================] - 3s 75ms/step - loss: 1.3887 - categorical_accuracy: 0.2200 - val_loss: 1.3796 - val_categorical_accuracy: 0.3143\n",
            "Epoch 20/200\n",
            "39/39 [==============================] - 3s 75ms/step - loss: 1.3943 - categorical_accuracy: 0.2178 - val_loss: 1.3854 - val_categorical_accuracy: 0.3143\n",
            "Epoch 21/200\n",
            "39/39 [==============================] - 3s 75ms/step - loss: 1.3855 - categorical_accuracy: 0.2797 - val_loss: 1.3843 - val_categorical_accuracy: 0.3143\n",
            "Epoch 22/200\n",
            "39/39 [==============================] - 3s 75ms/step - loss: 1.3974 - categorical_accuracy: 0.2393 - val_loss: 1.3875 - val_categorical_accuracy: 0.3143\n",
            "Epoch 23/200\n",
            "39/39 [==============================] - 3s 75ms/step - loss: 1.3825 - categorical_accuracy: 0.2989 - val_loss: 1.3858 - val_categorical_accuracy: 0.2143\n",
            "Epoch 24/200\n",
            "39/39 [==============================] - 3s 75ms/step - loss: 1.3891 - categorical_accuracy: 0.2598 - val_loss: 1.3804 - val_categorical_accuracy: 0.3143\n",
            "Epoch 25/200\n",
            "39/39 [==============================] - 3s 75ms/step - loss: 1.3871 - categorical_accuracy: 0.2637 - val_loss: 1.3820 - val_categorical_accuracy: 0.3143\n",
            "Epoch 26/200\n",
            "39/39 [==============================] - 3s 75ms/step - loss: 1.3922 - categorical_accuracy: 0.2337 - val_loss: 1.3772 - val_categorical_accuracy: 0.3143\n",
            "Epoch 27/200\n",
            "39/39 [==============================] - 3s 76ms/step - loss: 1.3871 - categorical_accuracy: 0.2655 - val_loss: 1.3901 - val_categorical_accuracy: 0.3143\n",
            "Epoch 28/200\n",
            "39/39 [==============================] - 3s 75ms/step - loss: 1.3915 - categorical_accuracy: 0.2252 - val_loss: 1.3887 - val_categorical_accuracy: 0.3143\n",
            "Epoch 29/200\n",
            "39/39 [==============================] - 3s 75ms/step - loss: 1.3873 - categorical_accuracy: 0.2875 - val_loss: 1.3928 - val_categorical_accuracy: 0.2143\n",
            "Epoch 30/200\n",
            "39/39 [==============================] - 3s 75ms/step - loss: 1.3549 - categorical_accuracy: 0.2867 - val_loss: 1.3548 - val_categorical_accuracy: 0.3000\n",
            "Epoch 31/200\n",
            "39/39 [==============================] - 3s 77ms/step - loss: 1.3489 - categorical_accuracy: 0.2886 - val_loss: 1.3722 - val_categorical_accuracy: 0.3429\n",
            "Epoch 32/200\n",
            "39/39 [==============================] - 3s 75ms/step - loss: 1.2632 - categorical_accuracy: 0.4030 - val_loss: 1.3475 - val_categorical_accuracy: 0.3571\n",
            "Epoch 33/200\n",
            "39/39 [==============================] - 3s 76ms/step - loss: 1.2524 - categorical_accuracy: 0.4457 - val_loss: 1.3071 - val_categorical_accuracy: 0.3429\n",
            "Epoch 34/200\n",
            "39/39 [==============================] - 3s 75ms/step - loss: 1.2811 - categorical_accuracy: 0.3712 - val_loss: 1.3137 - val_categorical_accuracy: 0.3429\n",
            "Epoch 35/200\n",
            "39/39 [==============================] - 3s 76ms/step - loss: 1.2667 - categorical_accuracy: 0.3858 - val_loss: 1.3992 - val_categorical_accuracy: 0.3286\n",
            "Epoch 36/200\n",
            "39/39 [==============================] - 3s 76ms/step - loss: 1.2634 - categorical_accuracy: 0.4162 - val_loss: 1.2548 - val_categorical_accuracy: 0.3857\n",
            "Epoch 37/200\n",
            "39/39 [==============================] - 3s 76ms/step - loss: 1.2836 - categorical_accuracy: 0.3728 - val_loss: 1.2840 - val_categorical_accuracy: 0.3286\n",
            "Epoch 38/200\n",
            "39/39 [==============================] - 3s 76ms/step - loss: 1.2274 - categorical_accuracy: 0.4373 - val_loss: 1.2804 - val_categorical_accuracy: 0.3857\n",
            "Epoch 39/200\n",
            "39/39 [==============================] - 3s 77ms/step - loss: 1.2232 - categorical_accuracy: 0.4198 - val_loss: 1.3249 - val_categorical_accuracy: 0.3571\n",
            "Epoch 40/200\n",
            "39/39 [==============================] - 3s 75ms/step - loss: 1.2219 - categorical_accuracy: 0.4476 - val_loss: 1.2856 - val_categorical_accuracy: 0.3571\n",
            "Epoch 41/200\n",
            "39/39 [==============================] - 3s 76ms/step - loss: 1.2408 - categorical_accuracy: 0.4368 - val_loss: 1.2416 - val_categorical_accuracy: 0.3714\n",
            "Epoch 42/200\n",
            "39/39 [==============================] - 3s 76ms/step - loss: 1.2358 - categorical_accuracy: 0.4195 - val_loss: 1.2281 - val_categorical_accuracy: 0.3714\n",
            "Epoch 43/200\n",
            "39/39 [==============================] - 3s 76ms/step - loss: 1.2175 - categorical_accuracy: 0.4009 - val_loss: 1.2781 - val_categorical_accuracy: 0.3857\n",
            "Epoch 44/200\n",
            "39/39 [==============================] - 3s 76ms/step - loss: 1.2661 - categorical_accuracy: 0.3912 - val_loss: 1.2879 - val_categorical_accuracy: 0.4000\n",
            "Epoch 45/200\n",
            "39/39 [==============================] - 3s 75ms/step - loss: 1.2544 - categorical_accuracy: 0.4421 - val_loss: 1.2797 - val_categorical_accuracy: 0.3429\n",
            "Epoch 46/200\n",
            "39/39 [==============================] - 3s 76ms/step - loss: 1.2388 - categorical_accuracy: 0.4135 - val_loss: 1.3296 - val_categorical_accuracy: 0.4000\n",
            "Epoch 47/200\n",
            "39/39 [==============================] - 3s 75ms/step - loss: 1.2298 - categorical_accuracy: 0.3947 - val_loss: 1.2865 - val_categorical_accuracy: 0.4000\n",
            "Epoch 48/200\n",
            "39/39 [==============================] - 3s 75ms/step - loss: 1.1810 - categorical_accuracy: 0.4375 - val_loss: 1.2090 - val_categorical_accuracy: 0.4143\n",
            "Epoch 49/200\n",
            "39/39 [==============================] - 3s 76ms/step - loss: 1.2017 - categorical_accuracy: 0.4566 - val_loss: 1.3067 - val_categorical_accuracy: 0.4286\n",
            "Epoch 50/200\n",
            "39/39 [==============================] - 3s 76ms/step - loss: 1.2662 - categorical_accuracy: 0.4231 - val_loss: 1.3199 - val_categorical_accuracy: 0.3571\n",
            "Epoch 51/200\n",
            "39/39 [==============================] - 3s 76ms/step - loss: 1.2423 - categorical_accuracy: 0.4367 - val_loss: 1.2635 - val_categorical_accuracy: 0.3714\n",
            "Epoch 52/200\n",
            "39/39 [==============================] - 3s 76ms/step - loss: 1.2425 - categorical_accuracy: 0.4332 - val_loss: 1.3150 - val_categorical_accuracy: 0.3286\n",
            "Epoch 53/200\n",
            "39/39 [==============================] - 3s 76ms/step - loss: 1.2330 - categorical_accuracy: 0.4158 - val_loss: 1.2808 - val_categorical_accuracy: 0.3429\n",
            "Epoch 54/200\n",
            "39/39 [==============================] - 3s 75ms/step - loss: 1.2276 - categorical_accuracy: 0.4765 - val_loss: 1.2334 - val_categorical_accuracy: 0.3571\n",
            "Epoch 55/200\n",
            "39/39 [==============================] - 3s 76ms/step - loss: 1.1952 - categorical_accuracy: 0.4548 - val_loss: 1.2630 - val_categorical_accuracy: 0.4571\n",
            "Epoch 56/200\n",
            "39/39 [==============================] - 3s 75ms/step - loss: 1.2053 - categorical_accuracy: 0.4372 - val_loss: 1.2545 - val_categorical_accuracy: 0.4286\n",
            "Epoch 57/200\n",
            "39/39 [==============================] - 3s 76ms/step - loss: 1.2351 - categorical_accuracy: 0.4270 - val_loss: 1.2460 - val_categorical_accuracy: 0.3714\n",
            "Epoch 58/200\n",
            "39/39 [==============================] - 3s 75ms/step - loss: 1.2047 - categorical_accuracy: 0.4519 - val_loss: 1.3006 - val_categorical_accuracy: 0.3571\n",
            "Epoch 59/200\n",
            "39/39 [==============================] - 3s 76ms/step - loss: 1.2491 - categorical_accuracy: 0.4177 - val_loss: 1.3153 - val_categorical_accuracy: 0.4000\n",
            "Epoch 60/200\n",
            "39/39 [==============================] - 3s 75ms/step - loss: 1.2096 - categorical_accuracy: 0.4339 - val_loss: 1.2391 - val_categorical_accuracy: 0.4143\n",
            "Epoch 61/200\n",
            "39/39 [==============================] - 3s 75ms/step - loss: 1.2483 - categorical_accuracy: 0.4045 - val_loss: 1.2328 - val_categorical_accuracy: 0.4429\n",
            "Epoch 62/200\n",
            "39/39 [==============================] - 3s 76ms/step - loss: 1.2418 - categorical_accuracy: 0.3888 - val_loss: 1.2760 - val_categorical_accuracy: 0.3857\n",
            "Epoch 63/200\n",
            "39/39 [==============================] - 3s 76ms/step - loss: 1.2522 - categorical_accuracy: 0.4232 - val_loss: 1.2708 - val_categorical_accuracy: 0.4143\n",
            "Epoch 64/200\n",
            "39/39 [==============================] - 3s 75ms/step - loss: 1.2657 - categorical_accuracy: 0.3974 - val_loss: 1.2046 - val_categorical_accuracy: 0.4286\n",
            "Epoch 65/200\n",
            "39/39 [==============================] - 3s 75ms/step - loss: 1.2441 - categorical_accuracy: 0.4215 - val_loss: 1.2421 - val_categorical_accuracy: 0.3571\n",
            "Epoch 66/200\n",
            "39/39 [==============================] - 3s 75ms/step - loss: 1.2086 - categorical_accuracy: 0.4176 - val_loss: 1.2866 - val_categorical_accuracy: 0.4286\n",
            "Epoch 67/200\n",
            "39/39 [==============================] - 3s 75ms/step - loss: 1.2564 - categorical_accuracy: 0.4178 - val_loss: 1.2603 - val_categorical_accuracy: 0.3571\n",
            "Epoch 68/200\n",
            "39/39 [==============================] - 3s 75ms/step - loss: 1.2407 - categorical_accuracy: 0.4250 - val_loss: 1.2616 - val_categorical_accuracy: 0.4286\n",
            "Epoch 69/200\n",
            "39/39 [==============================] - 3s 76ms/step - loss: 1.1942 - categorical_accuracy: 0.4278 - val_loss: 1.2133 - val_categorical_accuracy: 0.4000\n",
            "Epoch 70/200\n",
            "39/39 [==============================] - 3s 75ms/step - loss: 1.2432 - categorical_accuracy: 0.4388 - val_loss: 1.3295 - val_categorical_accuracy: 0.2714\n",
            "Epoch 71/200\n",
            "39/39 [==============================] - 3s 75ms/step - loss: 1.2876 - categorical_accuracy: 0.3447 - val_loss: 1.2618 - val_categorical_accuracy: 0.4143\n",
            "Epoch 72/200\n",
            "39/39 [==============================] - 3s 75ms/step - loss: 1.2168 - categorical_accuracy: 0.4273 - val_loss: 1.1862 - val_categorical_accuracy: 0.3857\n",
            "Epoch 73/200\n",
            "39/39 [==============================] - 3s 75ms/step - loss: 1.1902 - categorical_accuracy: 0.4191 - val_loss: 1.2233 - val_categorical_accuracy: 0.4000\n",
            "Epoch 74/200\n",
            "39/39 [==============================] - 3s 76ms/step - loss: 1.2427 - categorical_accuracy: 0.4193 - val_loss: 1.2976 - val_categorical_accuracy: 0.2857\n",
            "Epoch 75/200\n",
            "39/39 [==============================] - 3s 76ms/step - loss: 1.2417 - categorical_accuracy: 0.3714 - val_loss: 1.2445 - val_categorical_accuracy: 0.3714\n",
            "Epoch 76/200\n",
            "39/39 [==============================] - 3s 76ms/step - loss: 1.2256 - categorical_accuracy: 0.4369 - val_loss: 1.2644 - val_categorical_accuracy: 0.3286\n",
            "Epoch 77/200\n",
            "39/39 [==============================] - 3s 75ms/step - loss: 1.2264 - categorical_accuracy: 0.4165 - val_loss: 1.3134 - val_categorical_accuracy: 0.3286\n",
            "Epoch 78/200\n",
            "39/39 [==============================] - 3s 75ms/step - loss: 1.1858 - categorical_accuracy: 0.4543 - val_loss: 1.2286 - val_categorical_accuracy: 0.4000\n",
            "Epoch 79/200\n",
            "39/39 [==============================] - 3s 75ms/step - loss: 1.2274 - categorical_accuracy: 0.4212 - val_loss: 1.2214 - val_categorical_accuracy: 0.3857\n",
            "Epoch 80/200\n",
            "39/39 [==============================] - 3s 76ms/step - loss: 1.1826 - categorical_accuracy: 0.4358 - val_loss: 1.1957 - val_categorical_accuracy: 0.4571\n",
            "Epoch 81/200\n",
            "39/39 [==============================] - 3s 75ms/step - loss: 1.2156 - categorical_accuracy: 0.4152 - val_loss: 1.2001 - val_categorical_accuracy: 0.4571\n",
            "Epoch 82/200\n",
            "39/39 [==============================] - 3s 76ms/step - loss: 1.2270 - categorical_accuracy: 0.4212 - val_loss: 1.1965 - val_categorical_accuracy: 0.3571\n",
            "Epoch 83/200\n",
            "39/39 [==============================] - 3s 75ms/step - loss: 1.2114 - categorical_accuracy: 0.4360 - val_loss: 1.2130 - val_categorical_accuracy: 0.4286\n",
            "Epoch 84/200\n",
            "39/39 [==============================] - 3s 76ms/step - loss: 1.1877 - categorical_accuracy: 0.4624 - val_loss: 1.2534 - val_categorical_accuracy: 0.3857\n",
            "Epoch 85/200\n",
            "39/39 [==============================] - 3s 75ms/step - loss: 1.2735 - categorical_accuracy: 0.3953 - val_loss: 1.2257 - val_categorical_accuracy: 0.4286\n",
            "Epoch 86/200\n",
            "39/39 [==============================] - 3s 75ms/step - loss: 1.2223 - categorical_accuracy: 0.4217 - val_loss: 1.2183 - val_categorical_accuracy: 0.4429\n",
            "Epoch 87/200\n",
            "39/39 [==============================] - 3s 76ms/step - loss: 1.2462 - categorical_accuracy: 0.3813 - val_loss: 1.2912 - val_categorical_accuracy: 0.3714\n",
            "Epoch 88/200\n",
            "39/39 [==============================] - 3s 76ms/step - loss: 1.2660 - categorical_accuracy: 0.4011 - val_loss: 1.2525 - val_categorical_accuracy: 0.3143\n",
            "Epoch 89/200\n",
            "39/39 [==============================] - 3s 76ms/step - loss: 1.2597 - categorical_accuracy: 0.3764 - val_loss: 1.2180 - val_categorical_accuracy: 0.4000\n",
            "Epoch 90/200\n",
            "39/39 [==============================] - 3s 76ms/step - loss: 1.2127 - categorical_accuracy: 0.4447 - val_loss: 1.1812 - val_categorical_accuracy: 0.4000\n",
            "Epoch 91/200\n",
            "39/39 [==============================] - 3s 75ms/step - loss: 1.2089 - categorical_accuracy: 0.4383 - val_loss: 1.2174 - val_categorical_accuracy: 0.3857\n",
            "Epoch 92/200\n",
            "39/39 [==============================] - 3s 75ms/step - loss: 1.1833 - categorical_accuracy: 0.4629 - val_loss: 1.2169 - val_categorical_accuracy: 0.4000\n",
            "Epoch 93/200\n",
            "39/39 [==============================] - 3s 76ms/step - loss: 1.2565 - categorical_accuracy: 0.4175 - val_loss: 1.2166 - val_categorical_accuracy: 0.3571\n",
            "Epoch 94/200\n",
            "39/39 [==============================] - 3s 75ms/step - loss: 1.1822 - categorical_accuracy: 0.4776 - val_loss: 1.2213 - val_categorical_accuracy: 0.3857\n",
            "Epoch 95/200\n",
            "39/39 [==============================] - 3s 76ms/step - loss: 1.2025 - categorical_accuracy: 0.4296 - val_loss: 1.2546 - val_categorical_accuracy: 0.3571\n",
            "Epoch 96/200\n",
            "39/39 [==============================] - 3s 75ms/step - loss: 1.2364 - categorical_accuracy: 0.3918 - val_loss: 1.2697 - val_categorical_accuracy: 0.4000\n",
            "Epoch 97/200\n",
            "39/39 [==============================] - 3s 76ms/step - loss: 1.1993 - categorical_accuracy: 0.4394 - val_loss: 1.1764 - val_categorical_accuracy: 0.4429\n",
            "Epoch 98/200\n",
            "39/39 [==============================] - 3s 76ms/step - loss: 1.1897 - categorical_accuracy: 0.4152 - val_loss: 1.2197 - val_categorical_accuracy: 0.3857\n",
            "Epoch 99/200\n",
            "39/39 [==============================] - 3s 76ms/step - loss: 1.1729 - categorical_accuracy: 0.4631 - val_loss: 1.2304 - val_categorical_accuracy: 0.3857\n",
            "Epoch 100/200\n",
            "39/39 [==============================] - 3s 75ms/step - loss: 1.1629 - categorical_accuracy: 0.4491 - val_loss: 1.1987 - val_categorical_accuracy: 0.4286\n",
            "Epoch 101/200\n",
            "39/39 [==============================] - 3s 75ms/step - loss: 1.2405 - categorical_accuracy: 0.4205 - val_loss: 1.2597 - val_categorical_accuracy: 0.4286\n",
            "Epoch 102/200\n",
            "39/39 [==============================] - 3s 76ms/step - loss: 1.2751 - categorical_accuracy: 0.4184 - val_loss: 1.2594 - val_categorical_accuracy: 0.4286\n",
            "Epoch 103/200\n",
            "39/39 [==============================] - 3s 75ms/step - loss: 1.2785 - categorical_accuracy: 0.3885 - val_loss: 1.2483 - val_categorical_accuracy: 0.4571\n",
            "Epoch 104/200\n",
            "39/39 [==============================] - 3s 76ms/step - loss: 1.2849 - categorical_accuracy: 0.3931 - val_loss: 1.2599 - val_categorical_accuracy: 0.4286\n",
            "Epoch 105/200\n",
            "39/39 [==============================] - 3s 76ms/step - loss: 1.2722 - categorical_accuracy: 0.3968 - val_loss: 1.3149 - val_categorical_accuracy: 0.3857\n",
            "Epoch 106/200\n",
            "39/39 [==============================] - 3s 76ms/step - loss: 1.2510 - categorical_accuracy: 0.4362 - val_loss: 1.2733 - val_categorical_accuracy: 0.3571\n",
            "Epoch 107/200\n",
            "39/39 [==============================] - 3s 75ms/step - loss: 1.2171 - categorical_accuracy: 0.4304 - val_loss: 1.2310 - val_categorical_accuracy: 0.4286\n",
            "Epoch 108/200\n",
            "39/39 [==============================] - 3s 76ms/step - loss: 1.2154 - categorical_accuracy: 0.4381 - val_loss: 1.2402 - val_categorical_accuracy: 0.4286\n",
            "Epoch 109/200\n",
            "39/39 [==============================] - 3s 76ms/step - loss: 1.2350 - categorical_accuracy: 0.4302 - val_loss: 1.2288 - val_categorical_accuracy: 0.4429\n",
            "Epoch 110/200\n",
            "39/39 [==============================] - 3s 77ms/step - loss: 1.2592 - categorical_accuracy: 0.3954 - val_loss: 1.2435 - val_categorical_accuracy: 0.4000\n",
            "Epoch 111/200\n",
            "39/39 [==============================] - 3s 77ms/step - loss: 1.2071 - categorical_accuracy: 0.4471 - val_loss: 1.2282 - val_categorical_accuracy: 0.4000\n",
            "Epoch 112/200\n",
            "39/39 [==============================] - 3s 75ms/step - loss: 1.2414 - categorical_accuracy: 0.3966 - val_loss: 1.2069 - val_categorical_accuracy: 0.3571\n",
            "Epoch 113/200\n",
            "39/39 [==============================] - 3s 76ms/step - loss: 1.2195 - categorical_accuracy: 0.4307 - val_loss: 1.2521 - val_categorical_accuracy: 0.4000\n",
            "Epoch 114/200\n",
            "39/39 [==============================] - 3s 75ms/step - loss: 1.2379 - categorical_accuracy: 0.3848 - val_loss: 1.2803 - val_categorical_accuracy: 0.3571\n",
            "Epoch 115/200\n",
            "39/39 [==============================] - 3s 75ms/step - loss: 1.2128 - categorical_accuracy: 0.3899 - val_loss: 1.2524 - val_categorical_accuracy: 0.3714\n",
            "Epoch 116/200\n",
            "39/39 [==============================] - 3s 75ms/step - loss: 1.1844 - categorical_accuracy: 0.4337 - val_loss: 1.2333 - val_categorical_accuracy: 0.3714\n",
            "Epoch 117/200\n",
            "39/39 [==============================] - 3s 77ms/step - loss: 1.2122 - categorical_accuracy: 0.4058 - val_loss: 1.2191 - val_categorical_accuracy: 0.3857\n",
            "Epoch 118/200\n",
            "39/39 [==============================] - 3s 76ms/step - loss: 1.1821 - categorical_accuracy: 0.4389 - val_loss: 1.2423 - val_categorical_accuracy: 0.3714\n",
            "Epoch 119/200\n",
            "39/39 [==============================] - 3s 75ms/step - loss: 1.1451 - categorical_accuracy: 0.4789 - val_loss: 1.2664 - val_categorical_accuracy: 0.3571\n",
            "Epoch 120/200\n",
            "39/39 [==============================] - 3s 75ms/step - loss: 1.1644 - categorical_accuracy: 0.4474 - val_loss: 1.2801 - val_categorical_accuracy: 0.3000\n",
            "Epoch 121/200\n",
            "39/39 [==============================] - 3s 75ms/step - loss: 1.2078 - categorical_accuracy: 0.4489 - val_loss: 1.3111 - val_categorical_accuracy: 0.3000\n",
            "Epoch 122/200\n",
            "39/39 [==============================] - 3s 75ms/step - loss: 1.1961 - categorical_accuracy: 0.4466 - val_loss: 1.4033 - val_categorical_accuracy: 0.2857\n",
            "Epoch 123/200\n",
            "39/39 [==============================] - 3s 76ms/step - loss: 1.2061 - categorical_accuracy: 0.4474 - val_loss: 1.2274 - val_categorical_accuracy: 0.4000\n",
            "Epoch 124/200\n",
            "39/39 [==============================] - 3s 76ms/step - loss: 1.1736 - categorical_accuracy: 0.4730 - val_loss: 1.2613 - val_categorical_accuracy: 0.3857\n",
            "Epoch 125/200\n",
            "39/39 [==============================] - 3s 76ms/step - loss: 1.1524 - categorical_accuracy: 0.4451 - val_loss: 1.2007 - val_categorical_accuracy: 0.4143\n",
            "Epoch 126/200\n",
            "39/39 [==============================] - 3s 76ms/step - loss: 1.1722 - categorical_accuracy: 0.4573 - val_loss: 1.2250 - val_categorical_accuracy: 0.3714\n",
            "Epoch 127/200\n",
            "39/39 [==============================] - 3s 75ms/step - loss: 1.1817 - categorical_accuracy: 0.4426 - val_loss: 1.2342 - val_categorical_accuracy: 0.3714\n",
            "Epoch 128/200\n",
            "39/39 [==============================] - 3s 76ms/step - loss: 1.1597 - categorical_accuracy: 0.4654 - val_loss: 1.2397 - val_categorical_accuracy: 0.3571\n",
            "Epoch 129/200\n",
            "39/39 [==============================] - 3s 76ms/step - loss: 1.1513 - categorical_accuracy: 0.4857 - val_loss: 1.2189 - val_categorical_accuracy: 0.4143\n",
            "Epoch 130/200\n",
            "39/39 [==============================] - 3s 75ms/step - loss: 1.1837 - categorical_accuracy: 0.4578 - val_loss: 1.1515 - val_categorical_accuracy: 0.4714\n",
            "Epoch 131/200\n",
            "39/39 [==============================] - 3s 76ms/step - loss: 1.1932 - categorical_accuracy: 0.4127 - val_loss: 1.1693 - val_categorical_accuracy: 0.4286\n",
            "Epoch 132/200\n",
            "39/39 [==============================] - 3s 76ms/step - loss: 1.2000 - categorical_accuracy: 0.4286 - val_loss: 1.1707 - val_categorical_accuracy: 0.4000\n",
            "Epoch 133/200\n",
            "39/39 [==============================] - 3s 76ms/step - loss: 1.1543 - categorical_accuracy: 0.4364 - val_loss: 1.2351 - val_categorical_accuracy: 0.3571\n",
            "Epoch 134/200\n",
            "39/39 [==============================] - 3s 76ms/step - loss: 1.1154 - categorical_accuracy: 0.5344 - val_loss: 1.1945 - val_categorical_accuracy: 0.4286\n",
            "Epoch 135/200\n",
            "39/39 [==============================] - 3s 76ms/step - loss: 1.1585 - categorical_accuracy: 0.4719 - val_loss: 1.1718 - val_categorical_accuracy: 0.3714\n",
            "Epoch 136/200\n",
            "39/39 [==============================] - 3s 76ms/step - loss: 1.1745 - categorical_accuracy: 0.4756 - val_loss: 1.2131 - val_categorical_accuracy: 0.3429\n",
            "Epoch 137/200\n",
            "39/39 [==============================] - 3s 75ms/step - loss: 1.1902 - categorical_accuracy: 0.4372 - val_loss: 1.2069 - val_categorical_accuracy: 0.3571\n",
            "Epoch 138/200\n",
            "39/39 [==============================] - 3s 76ms/step - loss: 1.1800 - categorical_accuracy: 0.4418 - val_loss: 1.2057 - val_categorical_accuracy: 0.3857\n",
            "Epoch 139/200\n",
            "39/39 [==============================] - 3s 75ms/step - loss: 1.1644 - categorical_accuracy: 0.4674 - val_loss: 1.1883 - val_categorical_accuracy: 0.3857\n",
            "Epoch 140/200\n",
            "39/39 [==============================] - 3s 75ms/step - loss: 1.1543 - categorical_accuracy: 0.4666 - val_loss: 1.2235 - val_categorical_accuracy: 0.3714\n",
            "Epoch 141/200\n",
            "39/39 [==============================] - 3s 76ms/step - loss: 1.1709 - categorical_accuracy: 0.4668 - val_loss: 1.2349 - val_categorical_accuracy: 0.3286\n",
            "Epoch 142/200\n",
            "39/39 [==============================] - 3s 75ms/step - loss: 1.2015 - categorical_accuracy: 0.4497 - val_loss: 1.2164 - val_categorical_accuracy: 0.3571\n",
            "Epoch 143/200\n",
            "39/39 [==============================] - 3s 77ms/step - loss: 1.1925 - categorical_accuracy: 0.4364 - val_loss: 1.2152 - val_categorical_accuracy: 0.4571\n",
            "Epoch 144/200\n",
            "39/39 [==============================] - 3s 76ms/step - loss: 1.1856 - categorical_accuracy: 0.4399 - val_loss: 1.1727 - val_categorical_accuracy: 0.4000\n",
            "Epoch 145/200\n",
            "39/39 [==============================] - 3s 76ms/step - loss: 1.1577 - categorical_accuracy: 0.4717 - val_loss: 1.1837 - val_categorical_accuracy: 0.3857\n",
            "Epoch 146/200\n",
            "39/39 [==============================] - 3s 76ms/step - loss: 1.1730 - categorical_accuracy: 0.4613 - val_loss: 1.1728 - val_categorical_accuracy: 0.3857\n",
            "Epoch 147/200\n",
            "39/39 [==============================] - 3s 76ms/step - loss: 1.1868 - categorical_accuracy: 0.4533 - val_loss: 1.1783 - val_categorical_accuracy: 0.4286\n",
            "Epoch 148/200\n",
            "39/39 [==============================] - 3s 76ms/step - loss: 1.2091 - categorical_accuracy: 0.4419 - val_loss: 1.1837 - val_categorical_accuracy: 0.4000\n",
            "Epoch 149/200\n",
            "39/39 [==============================] - 3s 76ms/step - loss: 1.2481 - categorical_accuracy: 0.4474 - val_loss: 1.2142 - val_categorical_accuracy: 0.3857\n",
            "Epoch 150/200\n",
            "39/39 [==============================] - 3s 76ms/step - loss: 1.1384 - categorical_accuracy: 0.4797 - val_loss: 1.2465 - val_categorical_accuracy: 0.4143\n",
            "Epoch 151/200\n",
            "39/39 [==============================] - 3s 76ms/step - loss: 1.1699 - categorical_accuracy: 0.4462 - val_loss: 1.1931 - val_categorical_accuracy: 0.3571\n",
            "Epoch 152/200\n",
            "39/39 [==============================] - 3s 75ms/step - loss: 1.1862 - categorical_accuracy: 0.4528 - val_loss: 1.1665 - val_categorical_accuracy: 0.3714\n",
            "Epoch 153/200\n",
            "39/39 [==============================] - 3s 75ms/step - loss: 1.1463 - categorical_accuracy: 0.4582 - val_loss: 1.2099 - val_categorical_accuracy: 0.3571\n",
            "Epoch 154/200\n",
            "39/39 [==============================] - 3s 75ms/step - loss: 1.1614 - categorical_accuracy: 0.4524 - val_loss: 1.2057 - val_categorical_accuracy: 0.3571\n",
            "Epoch 155/200\n",
            "39/39 [==============================] - 3s 76ms/step - loss: 1.1979 - categorical_accuracy: 0.4436 - val_loss: 1.1882 - val_categorical_accuracy: 0.3429\n",
            "Epoch 156/200\n",
            "39/39 [==============================] - 3s 76ms/step - loss: 1.1286 - categorical_accuracy: 0.5042 - val_loss: 1.1830 - val_categorical_accuracy: 0.3714\n",
            "Epoch 157/200\n",
            "39/39 [==============================] - 3s 76ms/step - loss: 1.1822 - categorical_accuracy: 0.4662 - val_loss: 1.1806 - val_categorical_accuracy: 0.4000\n",
            "Epoch 158/200\n",
            "39/39 [==============================] - 3s 76ms/step - loss: 1.1703 - categorical_accuracy: 0.4847 - val_loss: 1.1498 - val_categorical_accuracy: 0.4000\n",
            "Epoch 159/200\n",
            "39/39 [==============================] - 3s 76ms/step - loss: 1.1517 - categorical_accuracy: 0.4833 - val_loss: 1.1783 - val_categorical_accuracy: 0.4000\n",
            "Epoch 160/200\n",
            "39/39 [==============================] - 3s 75ms/step - loss: 1.1578 - categorical_accuracy: 0.4748 - val_loss: 1.1910 - val_categorical_accuracy: 0.3571\n",
            "Epoch 161/200\n",
            "39/39 [==============================] - 3s 76ms/step - loss: 1.1365 - categorical_accuracy: 0.4637 - val_loss: 1.1911 - val_categorical_accuracy: 0.3857\n",
            "Epoch 162/200\n",
            "39/39 [==============================] - 3s 76ms/step - loss: 1.1967 - categorical_accuracy: 0.4058 - val_loss: 1.1557 - val_categorical_accuracy: 0.3571\n",
            "Epoch 163/200\n",
            "39/39 [==============================] - 3s 77ms/step - loss: 1.1554 - categorical_accuracy: 0.4723 - val_loss: 1.1947 - val_categorical_accuracy: 0.3286\n",
            "Epoch 164/200\n",
            "39/39 [==============================] - 3s 76ms/step - loss: 1.1937 - categorical_accuracy: 0.4390 - val_loss: 1.2083 - val_categorical_accuracy: 0.3571\n",
            "Epoch 165/200\n",
            "39/39 [==============================] - 3s 76ms/step - loss: 1.1942 - categorical_accuracy: 0.4549 - val_loss: 1.1616 - val_categorical_accuracy: 0.3429\n",
            "Epoch 166/200\n",
            "39/39 [==============================] - 3s 76ms/step - loss: 1.1793 - categorical_accuracy: 0.4547 - val_loss: 1.1895 - val_categorical_accuracy: 0.3571\n",
            "Epoch 167/200\n",
            "39/39 [==============================] - 3s 76ms/step - loss: 1.1886 - categorical_accuracy: 0.4579 - val_loss: 1.1844 - val_categorical_accuracy: 0.3857\n",
            "Epoch 168/200\n",
            "39/39 [==============================] - 3s 77ms/step - loss: 1.1786 - categorical_accuracy: 0.4261 - val_loss: 1.1832 - val_categorical_accuracy: 0.4429\n",
            "Epoch 169/200\n",
            "39/39 [==============================] - 3s 76ms/step - loss: 1.1688 - categorical_accuracy: 0.4353 - val_loss: 1.1612 - val_categorical_accuracy: 0.4143\n",
            "Epoch 170/200\n",
            "39/39 [==============================] - 3s 76ms/step - loss: 1.2067 - categorical_accuracy: 0.4322 - val_loss: 1.1665 - val_categorical_accuracy: 0.3714\n",
            "Epoch 171/200\n",
            "39/39 [==============================] - 3s 77ms/step - loss: 1.1805 - categorical_accuracy: 0.4518 - val_loss: 1.1767 - val_categorical_accuracy: 0.3571\n",
            "Epoch 172/200\n",
            "39/39 [==============================] - 3s 77ms/step - loss: 1.1896 - categorical_accuracy: 0.4756 - val_loss: 1.1729 - val_categorical_accuracy: 0.4286\n",
            "Epoch 173/200\n",
            "39/39 [==============================] - 3s 76ms/step - loss: 1.1499 - categorical_accuracy: 0.4702 - val_loss: 1.1924 - val_categorical_accuracy: 0.4143\n",
            "Epoch 174/200\n",
            "39/39 [==============================] - 3s 77ms/step - loss: 1.1429 - categorical_accuracy: 0.4934 - val_loss: 1.1455 - val_categorical_accuracy: 0.4286\n",
            "Epoch 175/200\n",
            "39/39 [==============================] - 3s 76ms/step - loss: 1.2167 - categorical_accuracy: 0.4354 - val_loss: 1.1392 - val_categorical_accuracy: 0.3857\n",
            "Epoch 176/200\n",
            "39/39 [==============================] - 3s 76ms/step - loss: 1.2160 - categorical_accuracy: 0.4312 - val_loss: 1.1753 - val_categorical_accuracy: 0.3857\n",
            "Epoch 177/200\n",
            "39/39 [==============================] - 3s 77ms/step - loss: 1.1633 - categorical_accuracy: 0.4720 - val_loss: 1.1892 - val_categorical_accuracy: 0.3429\n",
            "Epoch 178/200\n",
            "39/39 [==============================] - 3s 76ms/step - loss: 1.1459 - categorical_accuracy: 0.4710 - val_loss: 1.1727 - val_categorical_accuracy: 0.4571\n",
            "Epoch 179/200\n",
            "39/39 [==============================] - 3s 77ms/step - loss: 1.1569 - categorical_accuracy: 0.4817 - val_loss: 1.2034 - val_categorical_accuracy: 0.3429\n",
            "Epoch 180/200\n",
            "39/39 [==============================] - 3s 75ms/step - loss: 1.1581 - categorical_accuracy: 0.4590 - val_loss: 1.1559 - val_categorical_accuracy: 0.4000\n",
            "Epoch 181/200\n",
            "39/39 [==============================] - 3s 77ms/step - loss: 1.1837 - categorical_accuracy: 0.4703 - val_loss: 1.1414 - val_categorical_accuracy: 0.4286\n",
            "Epoch 182/200\n",
            "39/39 [==============================] - 3s 76ms/step - loss: 1.1126 - categorical_accuracy: 0.5272 - val_loss: 1.1697 - val_categorical_accuracy: 0.3857\n",
            "Epoch 183/200\n",
            "39/39 [==============================] - 3s 77ms/step - loss: 1.1745 - categorical_accuracy: 0.4706 - val_loss: 1.1598 - val_categorical_accuracy: 0.4000\n",
            "Epoch 184/200\n",
            "39/39 [==============================] - 3s 76ms/step - loss: 1.1340 - categorical_accuracy: 0.4740 - val_loss: 1.1575 - val_categorical_accuracy: 0.4143\n",
            "Epoch 185/200\n",
            "39/39 [==============================] - 3s 76ms/step - loss: 1.1858 - categorical_accuracy: 0.4517 - val_loss: 1.1618 - val_categorical_accuracy: 0.4429\n",
            "Epoch 186/200\n",
            "39/39 [==============================] - 3s 77ms/step - loss: 1.2468 - categorical_accuracy: 0.4410 - val_loss: 1.1562 - val_categorical_accuracy: 0.3571\n",
            "Epoch 187/200\n",
            "39/39 [==============================] - 3s 76ms/step - loss: 1.1709 - categorical_accuracy: 0.4803 - val_loss: 1.1599 - val_categorical_accuracy: 0.4000\n",
            "Epoch 188/200\n",
            "39/39 [==============================] - 3s 76ms/step - loss: 1.1947 - categorical_accuracy: 0.4210 - val_loss: 1.1492 - val_categorical_accuracy: 0.4286\n",
            "Epoch 189/200\n",
            "39/39 [==============================] - 3s 76ms/step - loss: 1.1833 - categorical_accuracy: 0.4452 - val_loss: 1.1694 - val_categorical_accuracy: 0.4143\n",
            "Epoch 190/200\n",
            "39/39 [==============================] - 3s 76ms/step - loss: 1.1687 - categorical_accuracy: 0.4758 - val_loss: 1.1383 - val_categorical_accuracy: 0.4143\n",
            "Epoch 191/200\n",
            "39/39 [==============================] - 3s 76ms/step - loss: 1.1580 - categorical_accuracy: 0.4773 - val_loss: 1.1711 - val_categorical_accuracy: 0.4143\n",
            "Epoch 192/200\n",
            "39/39 [==============================] - 3s 76ms/step - loss: 1.2040 - categorical_accuracy: 0.4156 - val_loss: 1.1537 - val_categorical_accuracy: 0.4571\n",
            "Epoch 193/200\n",
            "39/39 [==============================] - 3s 76ms/step - loss: 1.1716 - categorical_accuracy: 0.4886 - val_loss: 1.1599 - val_categorical_accuracy: 0.3429\n",
            "Epoch 194/200\n",
            "39/39 [==============================] - 3s 76ms/step - loss: 1.1548 - categorical_accuracy: 0.4707 - val_loss: 1.1627 - val_categorical_accuracy: 0.3857\n",
            "Epoch 195/200\n",
            "39/39 [==============================] - 3s 76ms/step - loss: 1.1682 - categorical_accuracy: 0.5086 - val_loss: 1.1326 - val_categorical_accuracy: 0.4000\n",
            "Epoch 196/200\n",
            "39/39 [==============================] - 3s 76ms/step - loss: 1.1553 - categorical_accuracy: 0.4533 - val_loss: 1.1217 - val_categorical_accuracy: 0.4000\n",
            "Epoch 197/200\n",
            "39/39 [==============================] - 3s 76ms/step - loss: 1.1453 - categorical_accuracy: 0.4874 - val_loss: 1.1493 - val_categorical_accuracy: 0.4000\n",
            "Epoch 198/200\n",
            "39/39 [==============================] - 3s 77ms/step - loss: 1.1370 - categorical_accuracy: 0.4969 - val_loss: 1.1326 - val_categorical_accuracy: 0.4286\n",
            "Epoch 199/200\n",
            "39/39 [==============================] - 3s 77ms/step - loss: 1.1373 - categorical_accuracy: 0.5274 - val_loss: 1.1021 - val_categorical_accuracy: 0.4714\n",
            "Epoch 200/200\n",
            "39/39 [==============================] - 3s 77ms/step - loss: 1.1581 - categorical_accuracy: 0.4982 - val_loss: 1.1169 - val_categorical_accuracy: 0.4286\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBXg3gsrQei2"
      },
      "source": [
        "model.save('/content/drive/MyDrive/Colab Notebooks/SPEECH_EMOTION_Recognition/Nộp bài(chốt hạ)/model_saver/conv1D_melspec_ravdess.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SyfTyHY2mRsz"
      },
      "source": [
        "###test_result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aC1K1ol-mRs1",
        "outputId": "b242fb3b-e8b4-4c2c-ffe4-0e9e23790fd4"
      },
      "source": [
        "d = {0: 'happy',\n",
        "     1: 'sad',\n",
        "     2: 'angry',\n",
        "     3: 'fear'}\n",
        "Y_test_pred = np.argmax(model.predict(X_test), axis=-1)\n",
        "Y_test_pred = list(map(lambda x: d[x], Y_test_pred))\n",
        "y_test = np.argmax(y_test, axis=-1)\n",
        "y_test = list(map(lambda x: d[x], y_test))\n",
        "print(classification_report(y_test, Y_test_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.45      0.38      0.42        13\n",
            "        fear       0.33      0.24      0.28        21\n",
            "       happy       0.50      0.39      0.44        23\n",
            "         sad       0.45      0.75      0.57        20\n",
            "\n",
            "    accuracy                           0.44        77\n",
            "   macro avg       0.44      0.44      0.42        77\n",
            "weighted avg       0.44      0.44      0.42        77\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "svW2gQfTmRs2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "outputId": "69a1b784-5a0f-4c1a-d28a-324e32b66a0b"
      },
      "source": [
        "import scikitplot as skplt\n",
        "\n",
        "skplt.metrics.plot_confusion_matrix(\n",
        "    y_test, \n",
        "    Y_test_pred,\n",
        "    figsize=(8,8))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f7c685a2910>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAecAAAHHCAYAAACFoZBiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3debxVdfno8c8DqCDgiJqJhgOSShqI85CzOKR21bTsV6Zl5lTZcDO7zv0a7P5+9rsNRmaWppmpzYplmVmigmmiVlqmIk5gmCDI9Nw/9qKORzgcDnuftdc6n3ev/Wqv6buevdycZz/f9V1rRWYiSZLaR7+yA5AkSa9mcpYkqc2YnCVJajMmZ0mS2ozJWZKkNmNyliSpzQwoOwBJkpqt/xpvyFw4t6lt5tznJ2bm+KY2ugwmZ0lS7eTCuaw26u1NbXPefV8Z1tQGu2ByliTVUEBU98xtdSOXJKmmrJwlSfUTQETZUfSYlbMkSW3GylmSVE8VPudscpYk1ZPd2pIkqVmsnCVJNeSlVJIkqYmsnCVJ9VThc84mZ0lS/QR2a0uSpOaxcpYk1VBUulvbylmSpDZj5SxJqqcKn3M2OUuS6slubUmS1CxWzpKkGvIOYZIkqYmsnCVJ9RN4zlmSJDWPyVlqkogYFBE/iYgXI+K6lWjnuIi4pZmxlSEiboqI95Qdh/qw6NfcVy8yOavPiYh3RsTkiJgdEU8XSWT3JjR9FLABsG5mHt3TRjLzu5l5QBPieZWI2CsiMiJu7DR/u2L+bd1s57yIuGp562XmQZn57R6GK62kMDlLVRERZwKXAP9JI5FuAnwVOLwJzb8B+EtmLmxCW63yPLBLRKzbYd57gL80awfR4N8W9TkRcXlEPBcRU5ey7KPFj+Bh3WnLf0DqMyJiTeAC4NTMvCEz52Tmgsz8SWZ+vFhntYi4JCKmF69LImK1YtleETGt+Ef2XFF1v7dYdj5wDnBMUZGf2LnCjIgRxT/OAcX08RHxt4h4KSIei4jjOsy/o8N2u0bEPUV3+T0RsWuHZbdFxIUR8buinVuW849/PvBD4Nhi+/7AMcB3Ox2rL0XEkxHxz4iYEhF7FPPHA5/q8Dnv7xDHZyLid8DLwGbFvPcVy78WEdd3aP/zEXFrRIVH7Kj99YvmvpbvCmB855kRsTFwAPBEt0Pv7opSDewCDARu7GKds4GdgTcD2wE7Ap/usPx1wJrARsCJwFciYu3MPJdGNX5tZg7JzG92FUhEDAb+BzgoM4cCuwL3LWW9dYCfFeuuC/wX8LNOle87gfcC6wOrAh/rat/Ad4B3F+8PBKYC0zutcw+NY7AOcDVwXUQMzMybO33O7Tps8x/AScBQ4PFO7X0UeFPxw2MPGsfuPZmZy4lVqozMvB14YSmL/hv4BNDt77vJWX3JusCM5XQ7HwdckJnPZebzwPk0ks4SC4rlCzLz58BsYFQP41kMjI6IQZn5dGY+uJR1DgEeycwrM3NhZl4D/Al4a4d1vpWZf8nMucD3aSTVZcrM3wPrRMQoGkn6O0tZ56rMnFns8/8Cq7H8z3lFZj5YbLOgU3sv0ziO/wVcBZyemdOW057Uc0ue51zyOeeIOBx4KjPvX5HtTM7qS2YCw5Z0Ky/D63l11fd4Me9fbXRK7i8DQ1Y0kMycQ6M7+WTg6Yj4WUS8sRvxLIlpow7Tz/QgniuB04C9WUpPQkR8LCIeLrrSZ9HoLVjeubInu1qYmXcBf6PxZ/P73YhRWjkRzX01/n5M7vA6qevdx+o0TgOds6Khm5zVl9wJvAIc0cU602kM7FpiE17b5dtdc4DVO0y/ruPCzJyYmfsDG9Kohr/RjXiWxPRUD2Na4krgFODnRVX7L0W38yeAtwNrZ+ZawIs0kiosu2uuyy67iDiVRgU+vWhfqpoZmTmuw2vCctbfHNgUuD8i/g4MB+6NiNd1uRUmZ/UhmfkijV+wX4mIIyJi9YhYJSIOiogvFKtdA3w6ItYrBladQ6MbtifuA/aMiE2KwWhnLVkQERtExOHFuedXaHSPL15KGz8Htiwu/xoQEccAWwM/7WFMAGTmY8BbaJxj72wosJDGyO4BEXEOsEaH5c8CI1ZkRHZEbAlcBLyLRvf2JyKiy+53aeWUfylVZj6Qmetn5ojMHAFMA8Zm5jPL2dTkrL6lOH96Jo1BXs/T6Io9jcYIZmgkkMnAH4EHgHuLeT3Z1y+Aa4u2pvDqhNqviGM6jQEkbwE+uJQ2ZgKH0hhQNZNGxXloZs7oSUyd2r4jM5fWKzARuJnG5VWPA/N4dZf1khuszIyIe5e3n+I0wlXA5zPz/sx8hEZX35VLRsJLdRAR19DooRtVXNlxYo/bcrCkJKlu+q0xPFfb6fSmtjnvl5+ckpnjmtroMvjgC0lSPVX4XjjVjVySpJqycpYk1c+/L3+qJCtnSZLajJWzJKmeKnzOuU8l5zXWXifX23DjssOQVtrqq/YvO4Ta69+9Bx1oJTz5+OPMnDmjdQe6wt3afSo5r7fhxnz+6pvKDkNaaWNev3bZIdTe0EF96s9jKQ54y85lh9C2/PZJkmooKt2tXd3IJUmqKStnSVI9Vfics5WzJEltxspZklQ/QaXPOZucJUk15IAwSZLURFbOkqR6ckCYJElqFitnSVI9Vfics8lZklRPdmtLkqRmsXKWJNVPeCmVJElqIitnSVI9Vfics8lZklRLUeHkbLe2JEltxspZklQ7gZWzJElqIitnSVL9RPGqKCtnSZLajJWzJKmGotLnnE3OkqRaqnJytltbkqQ2Y+UsSaolK2dJktQ0Vs6SpFqqcuVscpYk1Y/XOUuSpGaycpYk1U5U/DpnK2dJktqMlbMkqZaqXDmbnCVJtVTl5Gy3tiRJbcbKWZJUS1bOkiSpaaycJUn1401IJElSM1k5t6lTDt6JgYOH0K9fP/r3H8Dnr76p7JBqyePcWtOfmsbHT3sfM2Y8R0Rw7LtO4PiTTi07rFr50Cnv5xc3/5xh663H7XfdV3Y4baXK55xNzm3svAnXscba65QdRu15nFtnwID+nHX+Zxm97Rhmz36JI/bfjd3esg8jR21Vdmi1cexx7+bEk07htA+8t+xQ2op3CCtBRPijQqqA9TfYkNHbjgFgyJChbD5yFM8+M73kqOpll932YK211y47DDVZryTniPhhREyJiAcj4qRi3uyI+ExE3B8RkyJig2L+5sX0AxFxUUTMLubvFRG/jYgfAw9FxAUR8eEO+/hMRHyoNz5Pr4jgolPewSfeOZ5fXH9V2dHUl8e510x74nEemno/243doexQ1EdERFNfvam3KtATMvOFiBgE3BMR1wODgUmZeXZEfAF4P3AR8CXgS5l5TUSc3KmdscDozHwsIkYANwCXREQ/4Fhgx847Ln4MnAQwbMONWvPpWuDCb93IuutvyIsvzODCk49loxFbsPX2O5cdVu14nHvHnDmzOfXEd/DpC7/A0KFrlB2O1BIRcTlwKPBcZo4u5l0MvBWYD/wVeG9mzlpeW73VrX1GRNwPTAI2BkbSCPSnxfIpwIji/S7AdcX7qzu1c3dmPgaQmX8HZkbEGOAA4A+ZObPzjjNzQmaOy8xxa6y1bvM+UYutu/6GAKy5zjB23OcgHn3QgR6t4HFuvQULFnDqCe/ksCOP5cBDjig7HPUl0eTX8l0BjO807xc0isptgb8AZ3WnoZYn54jYC9gP2CUztwP+AAwEFmRmFqstontV/JxO05cBxwPvBS5vRrztYN7cl5k7Z/a/3t9/52/YePNRJUdVPx7n1stMzvrIB9li5ChOPPmMssNRXxK9362dmbcDL3Sad0tmLiwmJwHDuxN+b3Rrrwn8IzNfjog3AsvrM5wEHAlcS6Oruis3AhcAqwDvXNlA28WLM5/n4jNPBGDRokXsftARjNlt75Kjqh+Pc+tNuftOfnjd1YzaajRv3WcnAD76qfPZa7/OxYV66gPvfRe/v+N2Xpg5gze/cVM+/qlzOO7djtxuUyfQyG3L1RvJ+Wbg5Ih4GPgzjeTblQ8DV0XE2cW2Ly5rxcycHxG/BmZl5qJmBVy2DYa/gS9+/5dlh1F7HufWG7fTrjz67Mtlh1FrX/+WAxmXpQWDuIZFxOQO0xMyc0I3YzkbWAh8tzvrtzw5Z+YrwEFLWTSkwzo/AH5QTD4F7JyZGRHHAqOKdW4DbuvYQDEQbGfg6KYHLknSq83IzHErulFEHE9joNi+HU7ndqkdrxfeHvhyNH7yzKLRDfAaEbE1jQFlN2bmI70YnySpAtrhJiQRMR74BPCWzOx2N1LbJefM/C2wXTfWewjYrPURSZKqpow7hEXENcBeNLq/pwHn0hidvRrwiyKeSZnZ+TLh12i75CxJUhVl5juWMvubPWnL5CxJqqfye7V7rJL31pYkqc6snCVJ9RPtMSCsp6ycJUlqM1bOkqRaqnLlbHKWJNVSlZOz3dqSJLUZK2dJUj1Vt3C2cpYkqd1YOUuSaqnK55xNzpKk2ono/XtrN5Pd2pIktRkrZ0lSLVk5S5KkprFyliTVUpUrZ5OzJKmeqpub7daWJKndWDlLkmqpyt3aVs6SJLUZK2dJUv2ElbMkSWoiK2dJUu0EUOHC2eQsSaoj760tSZKayMpZklRLFS6crZwlSWo3Vs6SpFqq8jlnk7MkqX7Cbm1JktREVs6SpNoJoF+/6pbOVs6SJLUZK2dJUi1V+ZyzyVmSVEtVHq1tt7YkSW3GylmSVD8Vv5SqTyXnAf2C9QYNLDuMWnt+7ryyQ+gTpv1jbtkh1N4Vt04rO4TamzbLvxfL0qeSsySpb2g8MrK6pbPnnCVJajNWzpKkGqr285xNzpKkWqpwbrZbW5KkdmPlLEmqpSp3a1s5S5LUZqycJUn1401IJElqL17nLEmSmsrKWZJUSxUunK2cJUlqN1bOkqRa8pyzJEltJqK5r+XvLy6PiOciYmqHeetExC8i4pHi/9fuTuwmZ0mSmuMKYHyneZ8Ebs3MkcCtxfRymZwlSfUTjW7tZr6WJzNvB17oNPtw4NvF+28DR3QnfJOzJEmts0FmPl28fwbYoDsbOSBMklQ7jZuQNL3ZYRExucP0hMyc0N2NMzMjIruzrslZkqTumZGZ41Zwm2cjYsPMfDoiNgSe685GdmtLkmqoueebV+KyrB8D7ynevwf4UXc2snKWJNVSb1/mHBHXAHvR6P6eBpwLfA74fkScCDwOvL07bZmcJUlqgsx8xzIW7buibZmcJUm15B3CJElS01g5S5Lqp5u33GxXJmdJUu00rnOubna2W1uSpDZj5SxJqiUrZ0mS1DRWzpKkWqpw4WxyliTVk93akiSpaaycJUn1U/HrnK2cJUlqM1bOkqTaCVbqMY+lMzlLkmqpwrnZbm1JktqNlbMkqZb6Vbh0tnKWJKnNWDlLkmqpwoWzybmdLVq0iA8ctS/D1t+Qz339mrLDqaVTDt6JgYOH0K9fP/r3H8Dnr76p7JBqye9yax0wahh7br4OmTDtxXl8c9KTLFycZYelldAWyTkizgA+CNybmceVHU+7uP47X+cNm23JnNkvlR1KrZ034TrWWHudssOoNb/LrbPWoAHst+Uwzv75n1mwKPngbpuw0xvW4neP/aPs0EoV4e07m+EUYP+VScwR0RY/NJrluWeeYtJvbuGQo99VdijSSvG73Hr9A1bt349+xf/Pmrug7JDaQr9o7qs3lZ7QIuJSYDPgpoj4HrA5MBpYBTgvM38UESOAK4HBxWanZebvI2Iv4ELgH8AbgS17N/rW+fJ/ns0HPnYeL8+ZXXYo9RbBRae8AyLY/8h3sf+RJpBm87vcWrPmLuTmPz3PFw97IwsWJVOfeYkHn/FYV13plXNmngxMB/amkXx/lZk7FtMXR8Rg4DkalfVY4Bjgfzo0MRb4UGbWJjH//tcTWXvdYYwa/eayQ6m9C791I1+4ZiJnf/kqJl57BQ9NmVR2SLXid7n1Vl+lP2OGr8knfvInPvLDh1htQD92GbFW2WG1hYho6qs3lV45d3IAcFhEfKyYHghsQiN5fzki3gws4tUV8t2Z+diyGoyIk4CTADZ4/fCWBN1sU++9i9/96mYm/eaXzJ//Ci/PfomLPv4BPn3x18sOrXbWXX9DANZcZxg77nMQjz54H1tvv3PJUdWH3+XW2/p1Q3h+9nxeemURAFOefJEthq3OnX+fVXJkWhntlpwDODIz//yqmRHnAc8C29Go9ud1WDynqwYzcwIwAWDU6DdXYvjiSR89h5M+eg4Af7jrDq69/Cv+MWuBeXNfJhcvZtDgIcyb+zL33/kbjjrpI2WHVSt+l1vvhZfns/mw1Vm1fzB/UbL164bw2My5ZYfVFio8HqztkvNE4PSIOD0zMyLGZOYfgDWBaZm5OCLeA/QvN0zVwYszn+fiM08EGpf67H7QEYzZbe+So5JWzN9mzmXyEy9y3viRLFoMT/xjLr/56wtlh1W6oPHwi6pqt+R8IXAJ8MeI6Ac8BhwKfBW4PiLeDdzMcqrlOhmz0+6M2Wn3ssOopQ2Gv4Evfv+XZYfRZ/hdbp0fTn2WH059tuww1ERtkZwzc0SHyQ8sZfkjwLYdZv3vYv5twG0tDE2SVFG9fflTM5U+WluSJL1aW1TOkiQ1VQmXPzWTyVmSVEsVzs12a0uS1G6snCVJtRNAvwqXzlbOkiS1GStnSVItVbhwtnKWJKndWDlLkmrJS6kkSWojEXZrS5KkJrJyliTVkpdSSZKkprFyliTVUnXrZpOzJKmmqjxa225tSZLajJWzJKl2GvfWLjuKnltmco6I/wfkspZn5hktiUiSpD6uq8p5cq9FIUlSM0VU+pzzMpNzZn6743RErJ6ZL7c+JEmSVl6Fc/PyB4RFxC4R8RDwp2J6u4j4assjkySpj+rOaO1LgAOBmQCZeT+wZyuDkiRpZUXRtd2sVzf3+ZGIeDAipkbENRExsCexd+tSqsx8stOsRT3ZmSRJdRURGwFnAOMyczTQHzi2J21151KqJyNiVyAjYhXgQ8DDPdmZJEm9ocRLqQYAgyJiAbA6ML0njXSncj4ZOBXYqNjJm4tpSZJUyMyngC8CTwBPAy9m5i09aWu5lXNmzgCO60njkiSVpQWXUg2LiI6XGU/IzAkd9rc2cDiwKTALuC4i3pWZV63ojpabnCNiM+BLwM40bkpyJ/CRzPzbiu5MkqTe0oJe7RmZOa6L5fsBj2Xm8wARcQOwK7DCybk73dpXA98HNgReD1wHXLOiO5IkqeaeAHaOiNWjUbbvSw/HaHUnOa+emVdm5sLidRXQo6HhkiT1hgjoF9HU1/Jk5l3AD4B7gQdo5NgJXW60DF3dW3ud4u1NEfFJ4Hs0urWPAX7ek51JklRnmXkucO7KttPVOecpNJLxkp8LH+i4f+Csld25JEmtUuXbd3Z1b+1NezMQSZKaqZYPvugoIkYDW9PhXHNmfqdVQUmS1Jd151Kqc4G9aCTnnwMHAXcAJmdJUtuqcOHcrdHaR9EYDv5MZr4X2A5Ys6VRSZLUh3WnW3tuZi6OiIURsQbwHLBxi+OSJKnHgu5d/tSuupOcJ0fEWsA3aIzgnk3jLmGSJLWnqHa3dnfurX1K8fbSiLgZWCMz/9jasCRJ6ru6ugnJ2K6WZea9rQlJkqSVV9dLqf5vF8sS2KfJsbTcqgP6MXztQWWHUWtrDlql7BD6hLN/7iPVVX0LFi0uO4S21dVNSPbuzUAkSWqm7lyO1K6qHLskSbXUrTuESZJUJUF9zzlLklRZ/aqbm5ffrR0N74qIc4rpTSJix9aHJklS39Sdc85fBXYB3lFMvwR8pWURSZLUBP2iua/e1J1u7Z0yc2xE/AEgM/8REau2OC5Jkvqs7iTnBRHRn8a1zUTEeoAXp0mS2lZE/QeE/Q9wI7B+RHyGxlOqPt3SqCRJWklVHhDWnXtrfzciptB4bGQAR2SmtyeSJKlFlpucI2IT4GXgJx3nZeYTrQxMkqSVUeFe7W51a/+MxvnmAAYCmwJ/BrZpYVySJPVZ3enWflPH6eJpVacsY3VJkkoXQL8Kl84rfIewzLw3InZqRTCSJDVLlR8e0Z1zzmd2mOwHjAWmtywiSZL6uO5UzkM7vF9I4xz09a0JR5Kk5qhwr3bXybm4+cjQzPxYL8UjSVKft8zkHBEDMnNhROzWmwFJkrSyIqK2A8LupnF++b6I+DFwHTBnycLMvKHFsUmS1Cd155zzQGAmsA//vt45AZOzJKltVbhw7jI5r1+M1J7Kv5PyEtnSqCRJWkl1vbd2f2AIr07KS5icJUlqka6S89OZeUGvRSJJUpNU/Q5hXd1ApbqfSpKkCuuqct6316KQJKnJKlw4Lzs5Z+YLvRmIJElNE9UeEFbl+4JLklRLK/xUKkmSqiAqPHTKylmSpDZj5SxJqp3GpVRlR9FzJmdJUi1VOTnbrS1JUpuxcpYk1VJU+EJnK2dJktqMlbMkqXaqPiDMylmSpDZj5SxJqp+o6b21JUmqsro+MlKSJJXAyrkNTX9qGh8/7X3MmPEcEcGx7zqB4086teywaueVefM48e3jmT9/PosWLmS/gw/ng2eeXXZYtXPYmzbgwK3WI4CJDz/Pjx54tuyQasdj/FplDQiLiLWAy4DRQAInZOadK9pOy5JzRIwAfpqZo1u1j7oaMKA/Z53/WUZvO4bZs1/iiP13Y7e37MPIUVuVHVqtrLraaky45qesPngICxYs4ISjDmC3vfZn27E7lh1abbxh7UEcuNV6nHnDQyxYtJgLDxnF3Y/P4ul/vlJ2aLXhMW47XwJuzsyjImJVYPWeNGK3dhtaf4MNGb3tGACGDBnK5iNH8ewz00uOqn4igtUHDwFg4cIFLFywsNI3LWhHG689kL88O4dXFi5mccID019i183WLjusWvEYL1tEc1/L31+sCewJfBMgM+dn5qyexN7q5Nw/Ir4REQ9GxC0RMSgi3h8R90TE/RFxfUSsDhARV0TEpRExOSL+EhGHFvOPj4gfRcRtEfFIRJxbzL8gIj68ZEcR8ZmI+FCLP0+vm/bE4zw09X62G7tD2aHU0qJFizjmoN3Yd+zm7LzH3rxpjMe5mR5/YS7bbDiUoasNYLUB/Ri3yVqsN3i1ssOqFY/xsgT9mvzqhk2B54FvRcQfIuKyiBjck+hbnZxHAl/JzG2AWcCRwA2ZuUNmbgc8DJzYYf0RwI7AIcClETGwmL9jse22wNERMQ64HHg3QET0A44Frmrx5+lVc+bM5tQT38GnL/wCQ4euUXY4tdS/f3+uvel3TJz0MFPvm8Kjf36o7JBq5clZ8/jBfdO56NBRXHDwlvxt5hwWZZYdVq14jHvVsKKAXPI6qdPyAcBY4GuZOQaYA3yyJztq9YCwxzLzvuL9FBrJd3REXASsBQwBJnZY//uZuRh4JCL+BryxmP+LzJwJEBE3ALtn5iURMTMixgAbAH9Ysk5HxcE7CeD1wzdu+gdslQULFnDqCe/ksCOP5cBDjig7nNobuuZajNt1D35/2y/ZYtTWZYdTK7f8aQa3/GkGAO/ecTgz58wvOaL68Ri/VtCS65xnZOa4LpZPA6Zl5l3F9A/oYXJudeXccUTCIho/Bq4ATsvMNwHnAwM7rNP5514uZ/5lwPHAe2lU0q+RmRMyc1xmjltn3WErGn8pMpOzPvJBthg5ihNPPqPscGrrhZkzeOnFxumgefPmctdvf82ILUaWHFX9rDmwUQOsN2RVdt10bW575DW/obWSPMbtITOfAZ6MiFHFrH2BHnXHlXEp1VDg6YhYBTgOeKrDsqMj4ts0+u03A/4MjAH2j4h1gLnAEcAJxfo3AhcAqwDv7J3wW2/K3Xfyw+uuZtRWo3nrPjsB8NFPnc9e+40vObJ6mfHcM5xz5sksXryIxYsXs/+hb2PPfQ8qO6za+dSBI1ljtQEsXJx87Y7HmTN/Udkh1Y7HeCmitHtrnw58txip/TcaxeMKKyM5/x/gLhonze+ikayXeAK4G1gDODkz5xWjZ+8GrgeGA1dl5mRojISLiF8DszKzNt/GcTvtyqPPvlx2GLW35Vaj+d5Nd5QdRu397x89XHYItecxXroy7hBWnMrtquu7W1qWnDPz7zQuwl4y/cUOi7+2jM1+mZknL2X+tMx8zYnXYiDYzsDRKxGqJEltpbLXOUfE1sCjwK2Z+UjZ8UiS2seSAWG9eZ1zM7XN7Tsz8/hlzL+CxiCyzvMfonFeWpKkWmmb5CxJUjP5VCpJktQ0Vs6SpFqqcOFscpYk1U9Q7a7hKscuSVItWTlLkuonqPQjYK2cJUlqM1bOkqRaqm7dbHKWJNVQ4HXOkiSpiaycJUm1VN262cpZkqS2Y+UsSaqlCp9yNjlLkuoovM5ZkiQ1j5WzJKl2vLe2JElqKitnSVItec5ZkiQ1jZWzJKmWqls3m5wlSXXkIyMlSVIzWTlLkmrHS6kkSVJTWTlLkmqpyuecTc6SpFqqbmq2W1uSpLZj5SxJqqUK92pbOUuS1G6snCVJtdO4lKq6pbPJWZJUS3ZrS5KkprFyliTVUBAV7ta2cpYkqc1YOUuSaqnK55xNzpKk2qn6aG27tSVJajN9qnJetX8/NlpnUNlh1NpTL8wtO4Q+4TMHb1V2CLW3y+FnlR1C7b3y/MzWNR7V7ta2cpYkqc30qcpZktR3WDlLkqSmsXKWJNVSlW9CYnKWJNVOAP2qm5vt1pYkqd1YOUuSaqnK3dpWzpIktRkrZ0lSLZV1KVVE9AcmA09l5qE9acPkLEmqpRK7tT8EPAys0dMG7NaWJKlJImI4cAhw2cq0Y+UsSaqdEi+lugT4BDB0ZRqxcpYkqXuGRcTkDq+TOi6MiEOB5zJzysruyMpZklRD0YpzzjMyc1wXy3cDDouIg4GBwBoRcVVmvmtFd2TlLEmqn+KRkc18LU9mnpWZwzNzBHAs8KueJGYwOUuS1Hbs1pYk1VKZ9wfLzNuA23q6vZWzJEltxspZklQ7jUupvLe2JElqEitnSVItVbduNjlLkuqqwtnZbm1JktqMlbMkqZZKfCrVSrNyliSpzVg5S5JqqcJXUpmcJUn1VOHcbLe2JEntxspZklRPFS6drZwlSWozVs6SpNoJqn0plclZklQ/UVGotoEAAA92SURBVO3R2nZrS5LUZqycJUm1VOHC2cpZkqR2Y+UsSaqnCpfOVs6SJLUZK2dJUg2Fl1JJktRuvJRKkiQ1jcm5Td0y8Wa23WYU27xxCy7+wufKDqeWpj81jePeNp4D9xjL+D2354oJXyk7pNp5Zd483nXYXrx9/K4cud+OfO2/PlN2SLVw6bnH8fitn2XydZ/617yzP3Awf514EZO+90kmfe+THLj71iVGWL5owas31aJbOyJGAD/NzNElh9IUixYt4sNnnMrPbvoFGw0fzu4778Chhx7GVlv37X9szTZgQH/OOv+zjN52DLNnv8QR++/Gbm/Zh5Gjtio7tNpYdbXVmHDNT1l98BAWLFjACUcdwG577c+2Y3csO7RKu/Ink7j02t9w2YXvftX8/3fVr7nkyltLikrNZOXchu65+24233wLNt1sM1ZddVWOPuZYfvqTH5UdVu2sv8GGjN52DABDhgxl85GjePaZ6SVHVS8RweqDhwCwcOECFi5YSFT5RGCb+N29f+WFF18uO4z2V+HSua2Sc0QMjoifRcT9ETE1Io6JiHMi4p5iekIU/7IjYvtivfuBU0sOvammT3+K4cM3/tf0RhsN56mnnioxovqb9sTjPDT1frYbu0PZodTOokWLOOag3dh37ObsvMfevGmMx7hVTj52T+6+9iwuPfc41ho6qOxwShdN/l9vaqvkDIwHpmfmdkUX9c3AlzNzh2J6EHBose63gNMzc7uuGoyIkyJickRMfn7G8y0NXtU0Z85sTj3xHXz6wi8wdOgaZYdTO/379+fam37HxEkPM/W+KTz654fKDqmWvnHdb9n6reex07Gf45kZ/+RzZ/6vskPSSmi35PwAsH9EfD4i9sjMF4G9I+KuiHgA2AfYJiLWAtbKzNuL7a5cVoOZOSEzx2XmuPWGrdf6T9AEr3/9Rkyb9uS/pp96ahobbbRRiRHV14IFCzj1hHdy2JHHcuAhR5QdTq0NXXMtxu26B7+/7Zdlh1JLz73wEosXJ5nJ5Tf8jnGj31B2SKWLaO6rN7VVcs7MvwBjaSTpiyLiHOCrwFGZ+SbgG8DAEkPsFeN22IFHH32Evz/2GPPnz+e6a7/HIYceVnZYtZOZnPWRD7LFyFGcePIZZYdTSy/MnMFLL84CYN68udz1218zYouRJUdVT68b9u9en8P32Y6H/vp0idFoZbXVaO2IeD3wQmZeFRGzgPcVi2ZExBDgKOAHmTkrImZFxO6ZeQdwXFkxt8KAAQP47y99mbceciCLFi3iPcefwNbbbFN2WLUz5e47+eF1VzNqq9G8dZ+dAPjop85nr/3GlxxZfcx47hnOOfNkFi9exOLFi9n/0Lex574HlR1W5X37s8ezx/YjGbbWEB69+UIuvPTn7Ln9SLYdNZzM5PGnX+D0i64pO8zSVXnoYVslZ+BNwMURsRhYAHwQOAKYCjwD3NNh3fcCl0dEArf0dqCtNv6ggxl/0MFlh1Fr43balUefdcRrK2251Wi+d9MdZYdRO+8564rXzPv2D+/s/UDaWRkXJzdRWyXnzJwITOw0ezLw6aWsOwXoOBjsEy0MTZKkXtNWyVmSpGap8oMv2mpAmCRJsnKWJNVQ4FOpJElSE1k5S5JqqcKFs8lZklRTFc7OdmtLktRmrJwlSbXkpVSSJKlprJwlSbVU5UupTM6SpFqqcG62W1uSpHZj5SxJqqcKl85WzpIktRkrZ0lS7TQe51zd0tnkLEmqn6j2aG27tSVJaoKI2Dgifh0RD0XEgxHxoZ62ZeUsSaqlEgrnhcBHM/PeiBgKTImIX2TmQyvakJWzJElNkJlPZ+a9xfuXgIeBjXrSlpWzJKmeSjznHBEjgDHAXT3Z3uQsSVL3DIuIyR2mJ2TmhM4rRcQQ4Hrgw5n5z57syOQsSaqhaMWlVDMyc1yXe41YhUZi/m5m3tDTHZmcJUm11NuXUkVEAN8EHs7M/1qZthwQJklSc+wG/AewT0TcV7wO7klDVs6SpNoJen88WGbe0azdWjlLktRmrJwlSfVU4dt3mpwlSbVU5Qdf2K0tSVKbsXKWJNWST6WSJElNY+UsSaqlChfOJmdJUg2F3dqSJKmJrJwlSTVV3dLZylmSpDZj5SxJqp3Ac86SJKmJrJwlSbVU4cK5byXne++dMmPQKvF42XGsoGHAjLKDqDmPcet5jHtH1Y7zG1rZeJW7tftUcs7M9cqOYUVFxOTMHFd2HHXmMW49j3Hv8DjXR59KzpKkvsOnUkmSpKaxcm5/E8oOoA/wGLeex7h3eJw7qm7hbHJud5npP7YW8xi3nse4d3icX63CudlubUmS2o3JWbUWEWdExMMR8d2yY6mDiBgREVPLjkPd11f/m0U0/9Wb7NausIgYkJkLy46jzZ0C7JeZ03ragMdZUm+zcu5FEfHDiJgSEQ9GxEnFvNkR8ZmIuD8iJkXEBsX8zYvpByLiooiYXczfKyJ+GxE/Bh6KiAsi4sMd9vGZiPhQKR+wzUTEpcBmwE0RcXZEXB4Rd0fEHyLi8GKdEcXxvLd47VrMf9VxLvFjtKP+EfGN4nt8S0QMioj3R8Q9xff4+ohYHSAiroiISyNickT8JSIOLeYfHxE/iojbIuKRiDi3mO/3eRkiYnBE/Kw4xlMj4piIOKc47lMjYkJEo76LiO2L9e4HTi059NJEk//Xm0zOveuEzNweGAecERHrAoOBSZm5HXA78P5i3S8BX8rMNwGdq76xwIcyc0vgcuDdABHRDzgWuKrln6QCMvNkYDqwN43j/KvM3LGYvjgiBgPPAftn5ljgGOB/OjTR8Tjr30YCX8nMbYBZwJHADZm5Q/E9fhg4scP6I4AdgUOASyNiYDF/x2LbbYGjI2Icfp+7Mh6YnpnbZeZo4Gbgy8VxHw0MAg4t1v0WcHrx36Pviia/epHJuXedUfySnQRsTOOP3Hzgp8XyKTT+kAHsAlxXvL+6Uzt3Z+ZjAJn5d2BmRIwBDgD+kJkzW/UBKuwA4JMRcR9wGzAQ2ARYBfhGRDxA43hv3WGbfx1nvcpjmXlf8X7Jd3Z00dPwAHAcsE2H9b+fmYsz8xHgb8Abi/m/yMyZmTkXuAHY3e9zlx4A9o+Iz0fEHpn5IrB3RNxVHPd9gG0iYi1grcy8vdjuyrICVs95zrmXRMRewH7ALpn5ckTcRiNBLMjMLFZbRPf+m8zpNH0ZcDzwOhqVh14rgCMz88+vmhlxHvAssB2NH6vzOizufJzV8EqH94toVGxXAEdk5v0RcTywV4d1klfL5cz3+7wUmfmXiBgLHAxcFBG30uiyHpeZTxbf5YFdtdHXeCmVumNN4B9FYn4jsPNy1p9Eo8sPGl17XbmRRpfXDsDElYqyviYCp3c4JzemmL8m8HRmLgb+A+hfUnxVNxR4OiJWoVE5d3R0RPSLiM1pjAFY8gNp/4hYJyIGAUcAvyvm+31eioh4PfByZl4FXEzjtAvAjIgYAhwFkJmzgFkRsXuxvPN/D1WAlXPvuRk4OSIepvHHadJy1v8wcFVEnF1s++KyVszM+RHxa2BWZi5qVsA1cyFwCfDH4lzmYzTOz30VuD4i3k3jOFst98z/Ae4Cni/+f2iHZU8AdwNrACdn5rziN9LdwPXAcOCqzJwMfp+78CYaYyUWAwuAD9L4UTMVeAa4p8O67wUuj4gEbuntQNtFlZ9KFf/uUVU7KUa7zs3MjIhjgXdk5uHLWLcfcC9wdHFeT2oLEXEF8NPM/EGn+cfT6I49bSnb+H3WSnvz2O3z1t/e1dQ2hw1ZZUpvPfXLyrl9bQ98ueiGnQWcsLSVImJrGgPKbvQPmarO77Oap/cvf2omK2dJUu2MGTsuf3VHcyvndQYP6LXK2QFhkiS1GZOzJEltxuQsSVKbMTlLyxERiyLivuL+xdctuW90D9u6IiKOKt5fVgyAWta6ey251/cK7uPvETGsu/M7rTN7Bfd1XkR8bEVjlHpDlZ9KZXKWlm9uZr65uH/xfODkjgsjokdXPWTm+zKzq4dq7AWscHKW1OCDL6S+47fAFp2fWhUR/SPi4uIJQX+MiA8ARMOXI+LPEfFLYP0lDRVPZBpXvB8fjadi3R8Rt0bECBo/Aj5SVO17RMR60Xji0z3Fa7di23Wj8XSoByPiMrpx18JYyhPSOiz772L+rRGxXjFv84i4udjmt8Vd7iS1iNc5S91UVMgH0biTGDRunzg6Mx8rEtyLmblDRKwG/C4ibgHGAKNoPFBjAxqPn7y8U7vrAd8A9izaWiczX4jGIy9nZ+YXi/WuBv47M++IiE1o3NpyK+Bc4I7MvCAiDuHVT4RalhOKfQwC7omI64sHTAwGJmfmRyLinKLt04AJNO7u9UhE7ETjzmr79OAwSr2jhK7oZjI5S8s3qHiaFTQq52/S6G7u+NSqA4Btl5xPpnHP7pHAnsA1xW0op0fEr5bS/s7A7R2eNPbCMuLYD9g6/v0XZ43insp7Av+r2PZnEfGPbnymMyLibcX7JU9ImwksBq4t5l8F3FDsY1fgug77Xq0b+5DUQyZnafnmZuabO84oklTH+3AHjefnTuy03sFNjKMfsHNmdnxyFrGC5UEs+wlpS5PFfmd1PgZSOyvhEcxN5TlnqTkmAh8snspERGwZEYOB24FjinPSGwJ7L2XbScCeEbFpse06xfyXePUDJG4BTl8yERFLkuXtwDuLeQcBay8n1q6ekNaP4ulGRZt3ZOY/gcci4uhiHxER2y1nH1L5osmvXmRylprjMhrnk++NiKnA12n0TN0IPFIs+w5wZ+cNM/N54CQaXcj38+9u5Z8Ab1syIAw4AxhXDDh7iH+PGj+fRnJ/kEb39hPLifVmYEA0npD2OV79hLQ5wI7FZ9gHuKCYfxxwYhHfg8BSH8IiqTm8t7YkqXbGbj8ub//9PctfcQUMHdjPe2tLktRXOSBMklRLVb6UyspZkqQ2Y+UsSaqlChfOJmdJUk1VODvbrS1JUpMU98n/c0Q8GhGf7Gk7Vs6SpFrq7SdJRUR/4CvA/sA0Gvet//Fynj63VFbOkiQ1x47Ao5n5t8ycD3yPHt6wx8pZklQ7QSmXUm0EPNlhehqwU08aMjlLkmrn3nunTBy0SgxrcrMDI2Jyh+kJmTmhyfsATM6SpBrKzPEl7PYpGo9gXWJ4MW+Fec5ZkqTmuAcYGRGbRsSqwLHAj3vSkJWzJElNkJkLI+I0Go+Q7Q9cnpkP9qQtn0olSVKbsVtbkqQ2Y3KWJKnNmJwlSWozJmdJktqMyVmSpDZjcpYkqc2YnCVJajMmZ0mS2sz/B4yOfp+qqWtLAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 576x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vOFxBO2mRs3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vQHiqzXuW3ay"
      },
      "source": [
        "# Mel Spectrogram + conv2D:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AbvUHwMIW3bV"
      },
      "source": [
        "audio_duration = 3\n",
        "sampling_rate = 44100\n",
        "input_length = sampling_rate * audio_duration\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTz4bJz0XfIR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "017d7107-4e27-40e9-a3f3-e291ce58ee07"
      },
      "source": [
        "features = []\n",
        "labels = []\n",
        "for i in range(len(Ravdess_DF['Paths'])):\n",
        "  if ((Ravdess_DF['Emotion'][i] == '03') | (Ravdess_DF['Emotion'][i] == '04') | \n",
        "      (Ravdess_DF['Emotion'][i] == '05') | (Ravdess_DF['Emotion'][i] == '06')):\n",
        "    signal, sample_rate = librosa.load(Ravdess_DF['Paths'][i], res_type='kaiser_fast',sr=22050*2)\n",
        "    signal,index = librosa.effects.trim(signal,top_db = 25)\n",
        "    signal = scipy.signal.wiener(signal)\n",
        "\n",
        "    if len(signal) > input_length:\n",
        "      signal = signal[0:input_length]\n",
        "    elif  input_length > len(signal):\n",
        "      max_offset = input_length - len(signal)  \n",
        "      signal = np.pad(signal, (0, max_offset), \"constant\")\n",
        "\n",
        "    melspec = librosa.feature.melspectrogram(signal, sr=sample_rate, n_mels=128,n_fft=2048,hop_length=512)   \n",
        "    melspec = np.expand_dims(melspec, axis=-1)\n",
        "\n",
        "    features.append(melspec)\n",
        "\n",
        "    if Ravdess_DF['Emotion'][i] == '03':\n",
        "      labels.append(0)\n",
        "    elif Ravdess_DF['Emotion'][i] == '04':\n",
        "      labels.append(1)\n",
        "    elif Ravdess_DF['Emotion'][i] == '05':\n",
        "      labels.append(2)\n",
        "    elif Ravdess_DF['Emotion'][i] == '06':\n",
        "      labels.append(3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/scipy/signal/signaltools.py:1456: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  res *= (1 - noise / lVar)\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/signal/signaltools.py:1456: RuntimeWarning: invalid value encountered in multiply\n",
            "  res *= (1 - noise / lVar)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fzmHePCaZiM"
      },
      "source": [
        "X = features\n",
        "y = labels\n",
        "\n",
        "y = np.array(y)\n",
        "y = to_categorical(y)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=0)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=0)\n",
        "\n",
        "X_train = np.array(X_train)\n",
        "X_test = np.array(X_test)\n",
        "X_val = np.array(X_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lsI1T1_wW3bX",
        "outputId": "70dccc31-0d87-40c0-a5e6-aa596beaec42"
      },
      "source": [
        "X_train.shape,X_test.shape,y_train.shape,y_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((621, 128, 259, 1), (77, 128, 259, 1), (621, 4), (77, 4))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LzVUl83kaRQt"
      },
      "source": [
        "### conv2D"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KvxTuJHKW3bY"
      },
      "source": [
        "# CNN I/P Config\n",
        "num_classes = 4\n",
        "input_shape = X_train.shape[1:]\n",
        "learning_rate = 0.0001\n",
        "decay = 1e-6\n",
        "momentum = 0.9"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LAcvZf5UW3bY",
        "outputId": "4387eda2-9f21-4f15-acda-ded854d6a8be"
      },
      "source": [
        "model = Sequential(name='Audio_CNN_2D')\n",
        "\n",
        "# LFLB1\n",
        "model.add(Conv2D(filters=64, kernel_size=(3,3), strides=(1,1), padding='same',input_shape=input_shape))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Conv2D(filters=64, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(4,4), strides=(4,4)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(units=num_classes, activation='softmax'))\n",
        "\n",
        "# Model compilation\n",
        "opt = optimizers.SGD(lr=learning_rate, decay=decay, momentum=momentum, nesterov=True)\n",
        "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"Audio_CNN_2D\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_8 (Conv2D)            (None, 128, 259, 64)      640       \n",
            "_________________________________________________________________\n",
            "batch_normalization_16 (Batc (None, 128, 259, 64)      256       \n",
            "_________________________________________________________________\n",
            "activation_16 (Activation)   (None, 128, 259, 64)      0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2 (None, 64, 129, 64)       0         \n",
            "_________________________________________________________________\n",
            "dropout_16 (Dropout)         (None, 64, 129, 64)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 64, 129, 64)       36928     \n",
            "_________________________________________________________________\n",
            "batch_normalization_17 (Batc (None, 64, 129, 64)       256       \n",
            "_________________________________________________________________\n",
            "activation_17 (Activation)   (None, 64, 129, 64)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_9 (MaxPooling2 (None, 16, 32, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_17 (Dropout)         (None, 16, 32, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 32768)             0         \n",
            "_________________________________________________________________\n",
            "dense_26 (Dense)             (None, 4)                 131076    \n",
            "=================================================================\n",
            "Total params: 169,156\n",
            "Trainable params: 168,900\n",
            "Non-trainable params: 256\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wpkX6KUYW3bb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd4ae23f-27e2-4cce-ace2-e3890f1385d8"
      },
      "source": [
        "#Train Config\n",
        "\n",
        "batch_size = 16\n",
        "num_epochs = 200\n",
        "\n",
        "# Model Training\n",
        "lr_reduce = ReduceLROnPlateau(monitor='val_loss', factor=0.9, patience=20, min_lr=0.000001)\n",
        "# Please change the model name accordingly.\n",
        "mcp_save = ModelCheckpoint('/content/Modelfull_2_1.h5', save_best_only=True, monitor='val_categorical_accuracy', mode='max')\n",
        "cnnhistory=model.fit(X_train, y_train, batch_size=batch_size, epochs=num_epochs,validation_data=(X_val, y_val), callbacks=[mcp_save, lr_reduce])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "39/39 [==============================] - 4s 56ms/step - loss: 2.6464 - categorical_accuracy: 0.2490 - val_loss: 1.5851 - val_categorical_accuracy: 0.3714\n",
            "Epoch 2/200\n",
            "39/39 [==============================] - 1s 31ms/step - loss: 2.0823 - categorical_accuracy: 0.4710 - val_loss: 1.3122 - val_categorical_accuracy: 0.4000\n",
            "Epoch 3/200\n",
            "39/39 [==============================] - 1s 31ms/step - loss: 1.4813 - categorical_accuracy: 0.4849 - val_loss: 1.3845 - val_categorical_accuracy: 0.4429\n",
            "Epoch 4/200\n",
            "39/39 [==============================] - 1s 31ms/step - loss: 1.5190 - categorical_accuracy: 0.5426 - val_loss: 1.2297 - val_categorical_accuracy: 0.3571\n",
            "Epoch 5/200\n",
            "39/39 [==============================] - 1s 31ms/step - loss: 1.3891 - categorical_accuracy: 0.4986 - val_loss: 1.5164 - val_categorical_accuracy: 0.3286\n",
            "Epoch 6/200\n",
            "39/39 [==============================] - 1s 31ms/step - loss: 1.2587 - categorical_accuracy: 0.5642 - val_loss: 1.6284 - val_categorical_accuracy: 0.3286\n",
            "Epoch 7/200\n",
            "39/39 [==============================] - 1s 31ms/step - loss: 1.2993 - categorical_accuracy: 0.5418 - val_loss: 1.6355 - val_categorical_accuracy: 0.3286\n",
            "Epoch 8/200\n",
            "39/39 [==============================] - 1s 31ms/step - loss: 1.3245 - categorical_accuracy: 0.5338 - val_loss: 1.4553 - val_categorical_accuracy: 0.3429\n",
            "Epoch 9/200\n",
            "39/39 [==============================] - 1s 31ms/step - loss: 1.3331 - categorical_accuracy: 0.5399 - val_loss: 1.2393 - val_categorical_accuracy: 0.3429\n",
            "Epoch 10/200\n",
            "39/39 [==============================] - 1s 31ms/step - loss: 1.1205 - categorical_accuracy: 0.6020 - val_loss: 1.3010 - val_categorical_accuracy: 0.3143\n",
            "Epoch 11/200\n",
            "39/39 [==============================] - 1s 32ms/step - loss: 1.0651 - categorical_accuracy: 0.5897 - val_loss: 1.4162 - val_categorical_accuracy: 0.3143\n",
            "Epoch 12/200\n",
            "39/39 [==============================] - 1s 31ms/step - loss: 1.1184 - categorical_accuracy: 0.5486 - val_loss: 1.3795 - val_categorical_accuracy: 0.3143\n",
            "Epoch 13/200\n",
            "39/39 [==============================] - 1s 31ms/step - loss: 0.9734 - categorical_accuracy: 0.5925 - val_loss: 1.3506 - val_categorical_accuracy: 0.3143\n",
            "Epoch 14/200\n",
            "39/39 [==============================] - 1s 31ms/step - loss: 1.0777 - categorical_accuracy: 0.5943 - val_loss: 1.2882 - val_categorical_accuracy: 0.3143\n",
            "Epoch 15/200\n",
            "39/39 [==============================] - 1s 31ms/step - loss: 0.9712 - categorical_accuracy: 0.5955 - val_loss: 1.3933 - val_categorical_accuracy: 0.3000\n",
            "Epoch 16/200\n",
            "39/39 [==============================] - 1s 32ms/step - loss: 1.0860 - categorical_accuracy: 0.5586 - val_loss: 1.2975 - val_categorical_accuracy: 0.3286\n",
            "Epoch 17/200\n",
            "39/39 [==============================] - 1s 31ms/step - loss: 1.0581 - categorical_accuracy: 0.6013 - val_loss: 1.3274 - val_categorical_accuracy: 0.3000\n",
            "Epoch 18/200\n",
            "39/39 [==============================] - 1s 31ms/step - loss: 1.1022 - categorical_accuracy: 0.5847 - val_loss: 1.2711 - val_categorical_accuracy: 0.3286\n",
            "Epoch 19/200\n",
            "39/39 [==============================] - 1s 31ms/step - loss: 0.9546 - categorical_accuracy: 0.6225 - val_loss: 1.2807 - val_categorical_accuracy: 0.3571\n",
            "Epoch 20/200\n",
            "39/39 [==============================] - 1s 32ms/step - loss: 1.0234 - categorical_accuracy: 0.5748 - val_loss: 1.3154 - val_categorical_accuracy: 0.3286\n",
            "Epoch 21/200\n",
            "39/39 [==============================] - 1s 32ms/step - loss: 0.8469 - categorical_accuracy: 0.6251 - val_loss: 1.3035 - val_categorical_accuracy: 0.3143\n",
            "Epoch 22/200\n",
            "39/39 [==============================] - 1s 31ms/step - loss: 1.1516 - categorical_accuracy: 0.5931 - val_loss: 1.2792 - val_categorical_accuracy: 0.3429\n",
            "Epoch 23/200\n",
            "39/39 [==============================] - 1s 31ms/step - loss: 1.0065 - categorical_accuracy: 0.5632 - val_loss: 1.3261 - val_categorical_accuracy: 0.3429\n",
            "Epoch 24/200\n",
            "39/39 [==============================] - 1s 31ms/step - loss: 1.0886 - categorical_accuracy: 0.5860 - val_loss: 1.2695 - val_categorical_accuracy: 0.3571\n",
            "Epoch 25/200\n",
            "39/39 [==============================] - 1s 31ms/step - loss: 0.9242 - categorical_accuracy: 0.6158 - val_loss: 1.2607 - val_categorical_accuracy: 0.3714\n",
            "Epoch 26/200\n",
            "39/39 [==============================] - 1s 31ms/step - loss: 0.9124 - categorical_accuracy: 0.6390 - val_loss: 1.2998 - val_categorical_accuracy: 0.3429\n",
            "Epoch 27/200\n",
            "39/39 [==============================] - 1s 31ms/step - loss: 1.0126 - categorical_accuracy: 0.6273 - val_loss: 1.2563 - val_categorical_accuracy: 0.3714\n",
            "Epoch 28/200\n",
            "39/39 [==============================] - 1s 31ms/step - loss: 0.8974 - categorical_accuracy: 0.6057 - val_loss: 1.2364 - val_categorical_accuracy: 0.3857\n",
            "Epoch 29/200\n",
            "39/39 [==============================] - 1s 31ms/step - loss: 0.9194 - categorical_accuracy: 0.6283 - val_loss: 1.2598 - val_categorical_accuracy: 0.3571\n",
            "Epoch 30/200\n",
            "39/39 [==============================] - 1s 31ms/step - loss: 0.9599 - categorical_accuracy: 0.6208 - val_loss: 1.2611 - val_categorical_accuracy: 0.3286\n",
            "Epoch 31/200\n",
            "39/39 [==============================] - 1s 31ms/step - loss: 0.9227 - categorical_accuracy: 0.6072 - val_loss: 1.2951 - val_categorical_accuracy: 0.3143\n",
            "Epoch 32/200\n",
            "39/39 [==============================] - 1s 31ms/step - loss: 0.8710 - categorical_accuracy: 0.6419 - val_loss: 1.2476 - val_categorical_accuracy: 0.3714\n",
            "Epoch 33/200\n",
            "39/39 [==============================] - 1s 31ms/step - loss: 0.9260 - categorical_accuracy: 0.6348 - val_loss: 1.3781 - val_categorical_accuracy: 0.3143\n",
            "Epoch 34/200\n",
            "39/39 [==============================] - 1s 31ms/step - loss: 0.9175 - categorical_accuracy: 0.6111 - val_loss: 1.2462 - val_categorical_accuracy: 0.3286\n",
            "Epoch 35/200\n",
            "39/39 [==============================] - 1s 31ms/step - loss: 0.8454 - categorical_accuracy: 0.6722 - val_loss: 1.2908 - val_categorical_accuracy: 0.3286\n",
            "Epoch 36/200\n",
            "39/39 [==============================] - 1s 31ms/step - loss: 0.8803 - categorical_accuracy: 0.6615 - val_loss: 1.2949 - val_categorical_accuracy: 0.3286\n",
            "Epoch 37/200\n",
            "39/39 [==============================] - 1s 31ms/step - loss: 0.8764 - categorical_accuracy: 0.6167 - val_loss: 1.3963 - val_categorical_accuracy: 0.3286\n",
            "Epoch 38/200\n",
            "39/39 [==============================] - 1s 31ms/step - loss: 0.9154 - categorical_accuracy: 0.6189 - val_loss: 1.3578 - val_categorical_accuracy: 0.3286\n",
            "Epoch 39/200\n",
            "39/39 [==============================] - 1s 31ms/step - loss: 0.9042 - categorical_accuracy: 0.6228 - val_loss: 1.2615 - val_categorical_accuracy: 0.3429\n",
            "Epoch 40/200\n",
            "39/39 [==============================] - 1s 32ms/step - loss: 0.8787 - categorical_accuracy: 0.6625 - val_loss: 1.2471 - val_categorical_accuracy: 0.3429\n",
            "Epoch 41/200\n",
            "39/39 [==============================] - 1s 31ms/step - loss: 0.8308 - categorical_accuracy: 0.6711 - val_loss: 1.2792 - val_categorical_accuracy: 0.3143\n",
            "Epoch 42/200\n",
            "39/39 [==============================] - 1s 31ms/step - loss: 0.8893 - categorical_accuracy: 0.6268 - val_loss: 1.3275 - val_categorical_accuracy: 0.3000\n",
            "Epoch 43/200\n",
            "39/39 [==============================] - 1s 31ms/step - loss: 0.9495 - categorical_accuracy: 0.6415 - val_loss: 1.3151 - val_categorical_accuracy: 0.3429\n",
            "Epoch 44/200\n",
            "39/39 [==============================] - 1s 31ms/step - loss: 0.9357 - categorical_accuracy: 0.6113 - val_loss: 1.3814 - val_categorical_accuracy: 0.2857\n",
            "Epoch 45/200\n",
            "39/39 [==============================] - 1s 32ms/step - loss: 0.8879 - categorical_accuracy: 0.6108 - val_loss: 1.3195 - val_categorical_accuracy: 0.3143\n",
            "Epoch 46/200\n",
            "39/39 [==============================] - 1s 31ms/step - loss: 0.8323 - categorical_accuracy: 0.6415 - val_loss: 1.3390 - val_categorical_accuracy: 0.3143\n",
            "Epoch 47/200\n",
            "39/39 [==============================] - 1s 31ms/step - loss: 0.8957 - categorical_accuracy: 0.6301 - val_loss: 1.3650 - val_categorical_accuracy: 0.3000\n",
            "Epoch 48/200\n",
            "39/39 [==============================] - 1s 31ms/step - loss: 0.8411 - categorical_accuracy: 0.6232 - val_loss: 1.3095 - val_categorical_accuracy: 0.3714\n",
            "Epoch 49/200\n",
            "39/39 [==============================] - 1s 32ms/step - loss: 0.8367 - categorical_accuracy: 0.6495 - val_loss: 1.3524 - val_categorical_accuracy: 0.3429\n",
            "Epoch 50/200\n",
            "39/39 [==============================] - 1s 31ms/step - loss: 0.8696 - categorical_accuracy: 0.6371 - val_loss: 1.2933 - val_categorical_accuracy: 0.3429\n",
            "Epoch 51/200\n",
            "39/39 [==============================] - 1s 32ms/step - loss: 0.8452 - categorical_accuracy: 0.6607 - val_loss: 1.3042 - val_categorical_accuracy: 0.3571\n",
            "Epoch 52/200\n",
            "39/39 [==============================] - 1s 31ms/step - loss: 0.9412 - categorical_accuracy: 0.6171 - val_loss: 1.2675 - val_categorical_accuracy: 0.3714\n",
            "Epoch 53/200\n",
            "39/39 [==============================] - 1s 31ms/step - loss: 0.8328 - categorical_accuracy: 0.6433 - val_loss: 1.2866 - val_categorical_accuracy: 0.3286\n",
            "Epoch 54/200\n",
            "39/39 [==============================] - 1s 31ms/step - loss: 0.8030 - categorical_accuracy: 0.6522 - val_loss: 1.2853 - val_categorical_accuracy: 0.3143\n",
            "Epoch 55/200\n",
            "39/39 [==============================] - 1s 32ms/step - loss: 0.8793 - categorical_accuracy: 0.6158 - val_loss: 1.2872 - val_categorical_accuracy: 0.3429\n",
            "Epoch 56/200\n",
            "39/39 [==============================] - 1s 32ms/step - loss: 0.8292 - categorical_accuracy: 0.6474 - val_loss: 1.3016 - val_categorical_accuracy: 0.3429\n",
            "Epoch 57/200\n",
            "39/39 [==============================] - 1s 32ms/step - loss: 0.8063 - categorical_accuracy: 0.6602 - val_loss: 1.2644 - val_categorical_accuracy: 0.3429\n",
            "Epoch 58/200\n",
            "39/39 [==============================] - 1s 31ms/step - loss: 0.8269 - categorical_accuracy: 0.6594 - val_loss: 1.2500 - val_categorical_accuracy: 0.3429\n",
            "Epoch 59/200\n",
            "39/39 [==============================] - 1s 31ms/step - loss: 0.8576 - categorical_accuracy: 0.6445 - val_loss: 1.3236 - val_categorical_accuracy: 0.3286\n",
            "Epoch 60/200\n",
            "39/39 [==============================] - 1s 31ms/step - loss: 0.8690 - categorical_accuracy: 0.6382 - val_loss: 1.4046 - val_categorical_accuracy: 0.3429\n",
            "Epoch 61/200\n",
            "39/39 [==============================] - 1s 31ms/step - loss: 0.8954 - categorical_accuracy: 0.6354 - val_loss: 1.3825 - val_categorical_accuracy: 0.3000\n",
            "Epoch 62/200\n",
            "39/39 [==============================] - 1s 32ms/step - loss: 0.7829 - categorical_accuracy: 0.6859 - val_loss: 1.3459 - val_categorical_accuracy: 0.3571\n",
            "Epoch 63/200\n",
            "39/39 [==============================] - 1s 32ms/step - loss: 0.7922 - categorical_accuracy: 0.6741 - val_loss: 1.3510 - val_categorical_accuracy: 0.3429\n",
            "Epoch 64/200\n",
            "39/39 [==============================] - 1s 32ms/step - loss: 0.7921 - categorical_accuracy: 0.6585 - val_loss: 1.4156 - val_categorical_accuracy: 0.3000\n",
            "Epoch 65/200\n",
            "39/39 [==============================] - 1s 31ms/step - loss: 0.7999 - categorical_accuracy: 0.6496 - val_loss: 1.3081 - val_categorical_accuracy: 0.3143\n",
            "Epoch 66/200\n",
            "39/39 [==============================] - 1s 31ms/step - loss: 0.8618 - categorical_accuracy: 0.6495 - val_loss: 1.3813 - val_categorical_accuracy: 0.3286\n",
            "Epoch 67/200\n",
            "39/39 [==============================] - 1s 31ms/step - loss: 0.8494 - categorical_accuracy: 0.6636 - val_loss: 1.3946 - val_categorical_accuracy: 0.3286\n",
            "Epoch 68/200\n",
            "39/39 [==============================] - 1s 31ms/step - loss: 0.9192 - categorical_accuracy: 0.6244 - val_loss: 1.3514 - val_categorical_accuracy: 0.3429\n",
            "Epoch 69/200\n",
            "39/39 [==============================] - 1s 31ms/step - loss: 0.8100 - categorical_accuracy: 0.6749 - val_loss: 1.3325 - val_categorical_accuracy: 0.3571\n",
            "Epoch 70/200\n",
            "39/39 [==============================] - 1s 31ms/step - loss: 0.8229 - categorical_accuracy: 0.6380 - val_loss: 1.5205 - val_categorical_accuracy: 0.3286\n",
            "Epoch 71/200\n",
            "39/39 [==============================] - 1s 31ms/step - loss: 0.8517 - categorical_accuracy: 0.6594 - val_loss: 1.3782 - val_categorical_accuracy: 0.3286\n",
            "Epoch 72/200\n",
            "39/39 [==============================] - 1s 32ms/step - loss: 0.8161 - categorical_accuracy: 0.6837 - val_loss: 1.3622 - val_categorical_accuracy: 0.3286\n",
            "Epoch 73/200\n",
            "39/39 [==============================] - 1s 32ms/step - loss: 0.8818 - categorical_accuracy: 0.6365 - val_loss: 1.3321 - val_categorical_accuracy: 0.3429\n",
            "Epoch 74/200\n",
            "39/39 [==============================] - 1s 31ms/step - loss: 0.8543 - categorical_accuracy: 0.6644 - val_loss: 1.3180 - val_categorical_accuracy: 0.3571\n",
            "Epoch 75/200\n",
            "39/39 [==============================] - 1s 32ms/step - loss: 0.7685 - categorical_accuracy: 0.6989 - val_loss: 1.3362 - val_categorical_accuracy: 0.3571\n",
            "Epoch 76/200\n",
            "39/39 [==============================] - 1s 31ms/step - loss: 0.8151 - categorical_accuracy: 0.6851 - val_loss: 1.3213 - val_categorical_accuracy: 0.3143\n",
            "Epoch 77/200\n",
            "39/39 [==============================] - 1s 31ms/step - loss: 0.8101 - categorical_accuracy: 0.6621 - val_loss: 1.3270 - val_categorical_accuracy: 0.3000\n",
            "Epoch 78/200\n",
            "39/39 [==============================] - 1s 32ms/step - loss: 0.7592 - categorical_accuracy: 0.7060 - val_loss: 1.3146 - val_categorical_accuracy: 0.3143\n",
            "Epoch 79/200\n",
            "39/39 [==============================] - 1s 32ms/step - loss: 0.8320 - categorical_accuracy: 0.6636 - val_loss: 1.3337 - val_categorical_accuracy: 0.3429\n",
            "Epoch 80/200\n",
            "39/39 [==============================] - 1s 32ms/step - loss: 0.8555 - categorical_accuracy: 0.6511 - val_loss: 1.3737 - val_categorical_accuracy: 0.3571\n",
            "Epoch 81/200\n",
            "39/39 [==============================] - 1s 32ms/step - loss: 0.7437 - categorical_accuracy: 0.7289 - val_loss: 1.3383 - val_categorical_accuracy: 0.3143\n",
            "Epoch 82/200\n",
            "39/39 [==============================] - 1s 31ms/step - loss: 0.7691 - categorical_accuracy: 0.7114 - val_loss: 1.3234 - val_categorical_accuracy: 0.3571\n",
            "Epoch 83/200\n",
            "39/39 [==============================] - 1s 31ms/step - loss: 0.8556 - categorical_accuracy: 0.6848 - val_loss: 1.2890 - val_categorical_accuracy: 0.3571\n",
            "Epoch 84/200\n",
            "39/39 [==============================] - 1s 31ms/step - loss: 0.8297 - categorical_accuracy: 0.6553 - val_loss: 1.3221 - val_categorical_accuracy: 0.3571\n",
            "Epoch 85/200\n",
            "39/39 [==============================] - 1s 31ms/step - loss: 0.7610 - categorical_accuracy: 0.6823 - val_loss: 1.3175 - val_categorical_accuracy: 0.3857\n",
            "Epoch 86/200\n",
            "39/39 [==============================] - 1s 32ms/step - loss: 0.7840 - categorical_accuracy: 0.6899 - val_loss: 1.3001 - val_categorical_accuracy: 0.3571\n",
            "Epoch 87/200\n",
            "39/39 [==============================] - 1s 31ms/step - loss: 0.8551 - categorical_accuracy: 0.6754 - val_loss: 1.3300 - val_categorical_accuracy: 0.3857\n",
            "Epoch 88/200\n",
            "39/39 [==============================] - 1s 32ms/step - loss: 0.8219 - categorical_accuracy: 0.6491 - val_loss: 1.3023 - val_categorical_accuracy: 0.3857\n",
            "Epoch 89/200\n",
            "39/39 [==============================] - 1s 31ms/step - loss: 0.7872 - categorical_accuracy: 0.6981 - val_loss: 1.3071 - val_categorical_accuracy: 0.3714\n",
            "Epoch 90/200\n",
            "39/39 [==============================] - 1s 32ms/step - loss: 0.7936 - categorical_accuracy: 0.6422 - val_loss: 1.3303 - val_categorical_accuracy: 0.3714\n",
            "Epoch 91/200\n",
            "39/39 [==============================] - 1s 31ms/step - loss: 0.8043 - categorical_accuracy: 0.6799 - val_loss: 1.3089 - val_categorical_accuracy: 0.3571\n",
            "Epoch 92/200\n",
            "39/39 [==============================] - 1s 31ms/step - loss: 0.7942 - categorical_accuracy: 0.6807 - val_loss: 1.3125 - val_categorical_accuracy: 0.3857\n",
            "Epoch 93/200\n",
            "39/39 [==============================] - 1s 32ms/step - loss: 0.8063 - categorical_accuracy: 0.6989 - val_loss: 1.3125 - val_categorical_accuracy: 0.3714\n",
            "Epoch 94/200\n",
            "39/39 [==============================] - 1s 31ms/step - loss: 0.7773 - categorical_accuracy: 0.6916 - val_loss: 1.3449 - val_categorical_accuracy: 0.3857\n",
            "Epoch 95/200\n",
            "39/39 [==============================] - 1s 32ms/step - loss: 0.7773 - categorical_accuracy: 0.6663 - val_loss: 1.4021 - val_categorical_accuracy: 0.3571\n",
            "Epoch 96/200\n",
            "39/39 [==============================] - 1s 31ms/step - loss: 0.7992 - categorical_accuracy: 0.6788 - val_loss: 1.3548 - val_categorical_accuracy: 0.3857\n",
            "Epoch 97/200\n",
            "39/39 [==============================] - 1s 31ms/step - loss: 0.7995 - categorical_accuracy: 0.6755 - val_loss: 1.4019 - val_categorical_accuracy: 0.3857\n",
            "Epoch 98/200\n",
            "39/39 [==============================] - 1s 32ms/step - loss: 0.7889 - categorical_accuracy: 0.6744 - val_loss: 1.3284 - val_categorical_accuracy: 0.3857\n",
            "Epoch 99/200\n",
            "39/39 [==============================] - 1s 32ms/step - loss: 0.8105 - categorical_accuracy: 0.6706 - val_loss: 1.3898 - val_categorical_accuracy: 0.3571\n",
            "Epoch 100/200\n",
            "39/39 [==============================] - 1s 32ms/step - loss: 0.8109 - categorical_accuracy: 0.6977 - val_loss: 1.3299 - val_categorical_accuracy: 0.4000\n",
            "Epoch 101/200\n",
            "39/39 [==============================] - 1s 32ms/step - loss: 0.7821 - categorical_accuracy: 0.7091 - val_loss: 1.3071 - val_categorical_accuracy: 0.4000\n",
            "Epoch 102/200\n",
            "39/39 [==============================] - 1s 31ms/step - loss: 0.7570 - categorical_accuracy: 0.7179 - val_loss: 1.3380 - val_categorical_accuracy: 0.3857\n",
            "Epoch 103/200\n",
            "39/39 [==============================] - 1s 32ms/step - loss: 0.7797 - categorical_accuracy: 0.6904 - val_loss: 1.3777 - val_categorical_accuracy: 0.3714\n",
            "Epoch 104/200\n",
            "39/39 [==============================] - 1s 32ms/step - loss: 0.7729 - categorical_accuracy: 0.6972 - val_loss: 1.3360 - val_categorical_accuracy: 0.3571\n",
            "Epoch 105/200\n",
            "39/39 [==============================] - 1s 31ms/step - loss: 0.8067 - categorical_accuracy: 0.6868 - val_loss: 1.3220 - val_categorical_accuracy: 0.3714\n",
            "Epoch 106/200\n",
            "39/39 [==============================] - 1s 31ms/step - loss: 0.7665 - categorical_accuracy: 0.6906 - val_loss: 1.3466 - val_categorical_accuracy: 0.3714\n",
            "Epoch 107/200\n",
            "39/39 [==============================] - 1s 32ms/step - loss: 0.7781 - categorical_accuracy: 0.7053 - val_loss: 1.3347 - val_categorical_accuracy: 0.4286\n",
            "Epoch 108/200\n",
            "39/39 [==============================] - 1s 32ms/step - loss: 0.7189 - categorical_accuracy: 0.7354 - val_loss: 1.3587 - val_categorical_accuracy: 0.3571\n",
            "Epoch 109/200\n",
            "39/39 [==============================] - 1s 31ms/step - loss: 0.7692 - categorical_accuracy: 0.7080 - val_loss: 1.3339 - val_categorical_accuracy: 0.3714\n",
            "Epoch 110/200\n",
            "39/39 [==============================] - 1s 32ms/step - loss: 0.7691 - categorical_accuracy: 0.7106 - val_loss: 1.3531 - val_categorical_accuracy: 0.3571\n",
            "Epoch 111/200\n",
            "39/39 [==============================] - 1s 31ms/step - loss: 0.7407 - categorical_accuracy: 0.7167 - val_loss: 1.3626 - val_categorical_accuracy: 0.3571\n",
            "Epoch 112/200\n",
            "39/39 [==============================] - 1s 31ms/step - loss: 0.7973 - categorical_accuracy: 0.6641 - val_loss: 1.4029 - val_categorical_accuracy: 0.3714\n",
            "Epoch 113/200\n",
            "39/39 [==============================] - 1s 32ms/step - loss: 0.7327 - categorical_accuracy: 0.6984 - val_loss: 1.3871 - val_categorical_accuracy: 0.3857\n",
            "Epoch 114/200\n",
            "39/39 [==============================] - 1s 32ms/step - loss: 0.7347 - categorical_accuracy: 0.7170 - val_loss: 1.3522 - val_categorical_accuracy: 0.3857\n",
            "Epoch 115/200\n",
            "39/39 [==============================] - 1s 32ms/step - loss: 0.7142 - categorical_accuracy: 0.7203 - val_loss: 1.3570 - val_categorical_accuracy: 0.4143\n",
            "Epoch 116/200\n",
            "39/39 [==============================] - 1s 32ms/step - loss: 0.7779 - categorical_accuracy: 0.6767 - val_loss: 1.3673 - val_categorical_accuracy: 0.4143\n",
            "Epoch 117/200\n",
            "39/39 [==============================] - 1s 32ms/step - loss: 0.7030 - categorical_accuracy: 0.7256 - val_loss: 1.4259 - val_categorical_accuracy: 0.3857\n",
            "Epoch 118/200\n",
            "39/39 [==============================] - 1s 32ms/step - loss: 0.7642 - categorical_accuracy: 0.6927 - val_loss: 1.3589 - val_categorical_accuracy: 0.3857\n",
            "Epoch 119/200\n",
            "39/39 [==============================] - 1s 32ms/step - loss: 0.7159 - categorical_accuracy: 0.7147 - val_loss: 1.3345 - val_categorical_accuracy: 0.3857\n",
            "Epoch 120/200\n",
            "39/39 [==============================] - 1s 32ms/step - loss: 0.7355 - categorical_accuracy: 0.6891 - val_loss: 1.3464 - val_categorical_accuracy: 0.4000\n",
            "Epoch 121/200\n",
            "39/39 [==============================] - 1s 32ms/step - loss: 0.7861 - categorical_accuracy: 0.7142 - val_loss: 1.3937 - val_categorical_accuracy: 0.4143\n",
            "Epoch 122/200\n",
            "39/39 [==============================] - 1s 31ms/step - loss: 0.8397 - categorical_accuracy: 0.6600 - val_loss: 1.3807 - val_categorical_accuracy: 0.4143\n",
            "Epoch 123/200\n",
            "39/39 [==============================] - 1s 31ms/step - loss: 0.7444 - categorical_accuracy: 0.7169 - val_loss: 1.3589 - val_categorical_accuracy: 0.4000\n",
            "Epoch 124/200\n",
            "39/39 [==============================] - 1s 32ms/step - loss: 0.7262 - categorical_accuracy: 0.7093 - val_loss: 1.3393 - val_categorical_accuracy: 0.4143\n",
            "Epoch 125/200\n",
            "39/39 [==============================] - 1s 31ms/step - loss: 0.7125 - categorical_accuracy: 0.7277 - val_loss: 1.3511 - val_categorical_accuracy: 0.3571\n",
            "Epoch 126/200\n",
            "39/39 [==============================] - 1s 31ms/step - loss: 0.7923 - categorical_accuracy: 0.6619 - val_loss: 1.3309 - val_categorical_accuracy: 0.4286\n",
            "Epoch 127/200\n",
            "39/39 [==============================] - 1s 32ms/step - loss: 0.7882 - categorical_accuracy: 0.6813 - val_loss: 1.3438 - val_categorical_accuracy: 0.4286\n",
            "Epoch 128/200\n",
            "39/39 [==============================] - 1s 31ms/step - loss: 0.7664 - categorical_accuracy: 0.6705 - val_loss: 1.3575 - val_categorical_accuracy: 0.4286\n",
            "Epoch 129/200\n",
            "39/39 [==============================] - 1s 31ms/step - loss: 0.7527 - categorical_accuracy: 0.6961 - val_loss: 1.3364 - val_categorical_accuracy: 0.4429\n",
            "Epoch 130/200\n",
            "39/39 [==============================] - 1s 31ms/step - loss: 0.7561 - categorical_accuracy: 0.7007 - val_loss: 1.3480 - val_categorical_accuracy: 0.4571\n",
            "Epoch 131/200\n",
            "39/39 [==============================] - 1s 32ms/step - loss: 0.7414 - categorical_accuracy: 0.6937 - val_loss: 1.3409 - val_categorical_accuracy: 0.4286\n",
            "Epoch 132/200\n",
            "39/39 [==============================] - 1s 31ms/step - loss: 0.7287 - categorical_accuracy: 0.7146 - val_loss: 1.3589 - val_categorical_accuracy: 0.4286\n",
            "Epoch 133/200\n",
            "39/39 [==============================] - 1s 32ms/step - loss: 0.7500 - categorical_accuracy: 0.6930 - val_loss: 1.3360 - val_categorical_accuracy: 0.4143\n",
            "Epoch 134/200\n",
            "39/39 [==============================] - 1s 32ms/step - loss: 0.7390 - categorical_accuracy: 0.7012 - val_loss: 1.3349 - val_categorical_accuracy: 0.4429\n",
            "Epoch 135/200\n",
            "39/39 [==============================] - 1s 32ms/step - loss: 0.9149 - categorical_accuracy: 0.6998 - val_loss: 1.3254 - val_categorical_accuracy: 0.4000\n",
            "Epoch 136/200\n",
            "39/39 [==============================] - 1s 31ms/step - loss: 0.7277 - categorical_accuracy: 0.7028 - val_loss: 1.3308 - val_categorical_accuracy: 0.4286\n",
            "Epoch 137/200\n",
            "39/39 [==============================] - 1s 32ms/step - loss: 0.7272 - categorical_accuracy: 0.7097 - val_loss: 1.3267 - val_categorical_accuracy: 0.4000\n",
            "Epoch 138/200\n",
            "39/39 [==============================] - 1s 31ms/step - loss: 0.7387 - categorical_accuracy: 0.7091 - val_loss: 1.3551 - val_categorical_accuracy: 0.4000\n",
            "Epoch 139/200\n",
            "39/39 [==============================] - 1s 32ms/step - loss: 0.7406 - categorical_accuracy: 0.7007 - val_loss: 1.3353 - val_categorical_accuracy: 0.4429\n",
            "Epoch 140/200\n",
            "39/39 [==============================] - 1s 32ms/step - loss: 0.7474 - categorical_accuracy: 0.6918 - val_loss: 1.3283 - val_categorical_accuracy: 0.4429\n",
            "Epoch 141/200\n",
            "39/39 [==============================] - 1s 31ms/step - loss: 0.7227 - categorical_accuracy: 0.7119 - val_loss: 1.3443 - val_categorical_accuracy: 0.4143\n",
            "Epoch 142/200\n",
            "39/39 [==============================] - 1s 31ms/step - loss: 0.7515 - categorical_accuracy: 0.6954 - val_loss: 1.3758 - val_categorical_accuracy: 0.4286\n",
            "Epoch 143/200\n",
            "39/39 [==============================] - 1s 32ms/step - loss: 0.7036 - categorical_accuracy: 0.7392 - val_loss: 1.3463 - val_categorical_accuracy: 0.4143\n",
            "Epoch 144/200\n",
            "39/39 [==============================] - 1s 31ms/step - loss: 0.7155 - categorical_accuracy: 0.6970 - val_loss: 1.3629 - val_categorical_accuracy: 0.4000\n",
            "Epoch 145/200\n",
            "39/39 [==============================] - 1s 31ms/step - loss: 0.7284 - categorical_accuracy: 0.7092 - val_loss: 1.3730 - val_categorical_accuracy: 0.3857\n",
            "Epoch 146/200\n",
            "39/39 [==============================] - 1s 31ms/step - loss: 0.7957 - categorical_accuracy: 0.7067 - val_loss: 1.3438 - val_categorical_accuracy: 0.4286\n",
            "Epoch 147/200\n",
            "39/39 [==============================] - 1s 32ms/step - loss: 0.7055 - categorical_accuracy: 0.7347 - val_loss: 1.3469 - val_categorical_accuracy: 0.3857\n",
            "Epoch 148/200\n",
            "39/39 [==============================] - 1s 32ms/step - loss: 0.7081 - categorical_accuracy: 0.6984 - val_loss: 1.3416 - val_categorical_accuracy: 0.4286\n",
            "Epoch 149/200\n",
            "39/39 [==============================] - 1s 31ms/step - loss: 0.6875 - categorical_accuracy: 0.7349 - val_loss: 1.3402 - val_categorical_accuracy: 0.4000\n",
            "Epoch 150/200\n",
            "39/39 [==============================] - 1s 32ms/step - loss: 0.7419 - categorical_accuracy: 0.7155 - val_loss: 1.3541 - val_categorical_accuracy: 0.4286\n",
            "Epoch 151/200\n",
            "39/39 [==============================] - 1s 32ms/step - loss: 0.7435 - categorical_accuracy: 0.7251 - val_loss: 1.3345 - val_categorical_accuracy: 0.4143\n",
            "Epoch 152/200\n",
            "39/39 [==============================] - 1s 32ms/step - loss: 0.7081 - categorical_accuracy: 0.7385 - val_loss: 1.3987 - val_categorical_accuracy: 0.4000\n",
            "Epoch 153/200\n",
            "39/39 [==============================] - 1s 32ms/step - loss: 0.7481 - categorical_accuracy: 0.6861 - val_loss: 1.3603 - val_categorical_accuracy: 0.4143\n",
            "Epoch 154/200\n",
            "39/39 [==============================] - 1s 32ms/step - loss: 0.7274 - categorical_accuracy: 0.7122 - val_loss: 1.3594 - val_categorical_accuracy: 0.4143\n",
            "Epoch 155/200\n",
            "39/39 [==============================] - 1s 32ms/step - loss: 0.7474 - categorical_accuracy: 0.6903 - val_loss: 1.3657 - val_categorical_accuracy: 0.4000\n",
            "Epoch 156/200\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 0.6905 - categorical_accuracy: 0.7350 - val_loss: 1.3752 - val_categorical_accuracy: 0.4000\n",
            "Epoch 157/200\n",
            "39/39 [==============================] - 1s 31ms/step - loss: 0.7368 - categorical_accuracy: 0.6930 - val_loss: 1.3630 - val_categorical_accuracy: 0.4143\n",
            "Epoch 158/200\n",
            "39/39 [==============================] - 1s 32ms/step - loss: 0.9630 - categorical_accuracy: 0.6859 - val_loss: 1.4279 - val_categorical_accuracy: 0.4000\n",
            "Epoch 159/200\n",
            "39/39 [==============================] - 1s 31ms/step - loss: 0.7110 - categorical_accuracy: 0.7006 - val_loss: 1.4055 - val_categorical_accuracy: 0.3571\n",
            "Epoch 160/200\n",
            "39/39 [==============================] - 1s 32ms/step - loss: 0.6682 - categorical_accuracy: 0.7507 - val_loss: 1.3959 - val_categorical_accuracy: 0.3429\n",
            "Epoch 161/200\n",
            "39/39 [==============================] - 1s 32ms/step - loss: 0.6769 - categorical_accuracy: 0.7310 - val_loss: 1.4039 - val_categorical_accuracy: 0.3857\n",
            "Epoch 162/200\n",
            "39/39 [==============================] - 1s 32ms/step - loss: 0.7235 - categorical_accuracy: 0.6929 - val_loss: 1.3886 - val_categorical_accuracy: 0.3857\n",
            "Epoch 163/200\n",
            "39/39 [==============================] - 1s 31ms/step - loss: 0.7060 - categorical_accuracy: 0.7220 - val_loss: 1.3900 - val_categorical_accuracy: 0.3714\n",
            "Epoch 164/200\n",
            "39/39 [==============================] - 1s 32ms/step - loss: 0.7146 - categorical_accuracy: 0.7259 - val_loss: 1.4070 - val_categorical_accuracy: 0.3857\n",
            "Epoch 165/200\n",
            "39/39 [==============================] - 1s 31ms/step - loss: 0.7522 - categorical_accuracy: 0.6867 - val_loss: 1.3855 - val_categorical_accuracy: 0.3714\n",
            "Epoch 166/200\n",
            "39/39 [==============================] - 1s 32ms/step - loss: 0.7356 - categorical_accuracy: 0.7043 - val_loss: 1.4130 - val_categorical_accuracy: 0.3571\n",
            "Epoch 167/200\n",
            "39/39 [==============================] - 1s 31ms/step - loss: 0.7440 - categorical_accuracy: 0.6985 - val_loss: 1.3959 - val_categorical_accuracy: 0.3714\n",
            "Epoch 168/200\n",
            "39/39 [==============================] - 1s 31ms/step - loss: 0.7256 - categorical_accuracy: 0.7057 - val_loss: 1.4023 - val_categorical_accuracy: 0.3714\n",
            "Epoch 169/200\n",
            "39/39 [==============================] - 1s 32ms/step - loss: 0.7255 - categorical_accuracy: 0.7015 - val_loss: 1.4036 - val_categorical_accuracy: 0.3714\n",
            "Epoch 170/200\n",
            "39/39 [==============================] - 1s 32ms/step - loss: 0.7034 - categorical_accuracy: 0.7014 - val_loss: 1.3996 - val_categorical_accuracy: 0.3714\n",
            "Epoch 171/200\n",
            "39/39 [==============================] - 1s 32ms/step - loss: 0.6716 - categorical_accuracy: 0.7266 - val_loss: 1.4199 - val_categorical_accuracy: 0.4143\n",
            "Epoch 172/200\n",
            "39/39 [==============================] - 1s 32ms/step - loss: 0.7406 - categorical_accuracy: 0.7089 - val_loss: 1.4004 - val_categorical_accuracy: 0.4000\n",
            "Epoch 173/200\n",
            "39/39 [==============================] - 1s 31ms/step - loss: 0.7156 - categorical_accuracy: 0.7178 - val_loss: 1.4320 - val_categorical_accuracy: 0.3429\n",
            "Epoch 174/200\n",
            "39/39 [==============================] - 1s 32ms/step - loss: 0.7147 - categorical_accuracy: 0.7216 - val_loss: 1.4590 - val_categorical_accuracy: 0.3571\n",
            "Epoch 175/200\n",
            "39/39 [==============================] - 1s 32ms/step - loss: 0.7419 - categorical_accuracy: 0.7226 - val_loss: 1.4062 - val_categorical_accuracy: 0.3857\n",
            "Epoch 176/200\n",
            "39/39 [==============================] - 1s 32ms/step - loss: 0.7847 - categorical_accuracy: 0.7075 - val_loss: 1.4341 - val_categorical_accuracy: 0.3714\n",
            "Epoch 177/200\n",
            "39/39 [==============================] - 1s 32ms/step - loss: 0.6770 - categorical_accuracy: 0.7294 - val_loss: 1.4268 - val_categorical_accuracy: 0.3714\n",
            "Epoch 178/200\n",
            "39/39 [==============================] - 1s 32ms/step - loss: 0.6679 - categorical_accuracy: 0.7204 - val_loss: 1.4366 - val_categorical_accuracy: 0.4286\n",
            "Epoch 179/200\n",
            "39/39 [==============================] - 1s 32ms/step - loss: 0.7454 - categorical_accuracy: 0.7136 - val_loss: 1.4208 - val_categorical_accuracy: 0.4000\n",
            "Epoch 180/200\n",
            "39/39 [==============================] - 1s 32ms/step - loss: 0.7082 - categorical_accuracy: 0.7186 - val_loss: 1.4223 - val_categorical_accuracy: 0.3857\n",
            "Epoch 181/200\n",
            "39/39 [==============================] - 1s 32ms/step - loss: 0.7334 - categorical_accuracy: 0.7159 - val_loss: 1.4115 - val_categorical_accuracy: 0.3857\n",
            "Epoch 182/200\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 0.6877 - categorical_accuracy: 0.7400 - val_loss: 1.4192 - val_categorical_accuracy: 0.3857\n",
            "Epoch 183/200\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 0.7055 - categorical_accuracy: 0.7308 - val_loss: 1.4671 - val_categorical_accuracy: 0.3857\n",
            "Epoch 184/200\n",
            "39/39 [==============================] - 1s 32ms/step - loss: 0.6918 - categorical_accuracy: 0.7275 - val_loss: 1.4499 - val_categorical_accuracy: 0.3571\n",
            "Epoch 185/200\n",
            "39/39 [==============================] - 1s 32ms/step - loss: 0.6988 - categorical_accuracy: 0.7134 - val_loss: 1.4360 - val_categorical_accuracy: 0.3571\n",
            "Epoch 186/200\n",
            "39/39 [==============================] - 1s 32ms/step - loss: 0.7468 - categorical_accuracy: 0.7098 - val_loss: 1.4675 - val_categorical_accuracy: 0.3714\n",
            "Epoch 187/200\n",
            "39/39 [==============================] - 1s 32ms/step - loss: 0.7437 - categorical_accuracy: 0.6768 - val_loss: 1.4546 - val_categorical_accuracy: 0.3714\n",
            "Epoch 188/200\n",
            "39/39 [==============================] - 1s 31ms/step - loss: 0.7213 - categorical_accuracy: 0.7224 - val_loss: 1.4468 - val_categorical_accuracy: 0.3857\n",
            "Epoch 189/200\n",
            "39/39 [==============================] - 1s 32ms/step - loss: 0.7025 - categorical_accuracy: 0.7171 - val_loss: 1.4017 - val_categorical_accuracy: 0.3857\n",
            "Epoch 190/200\n",
            "39/39 [==============================] - 1s 32ms/step - loss: 0.7007 - categorical_accuracy: 0.7190 - val_loss: 1.4017 - val_categorical_accuracy: 0.4000\n",
            "Epoch 191/200\n",
            "39/39 [==============================] - 1s 31ms/step - loss: 0.7104 - categorical_accuracy: 0.7502 - val_loss: 1.4084 - val_categorical_accuracy: 0.4000\n",
            "Epoch 192/200\n",
            "39/39 [==============================] - 1s 32ms/step - loss: 0.6965 - categorical_accuracy: 0.7169 - val_loss: 1.4054 - val_categorical_accuracy: 0.4000\n",
            "Epoch 193/200\n",
            "39/39 [==============================] - 1s 31ms/step - loss: 0.6721 - categorical_accuracy: 0.7505 - val_loss: 1.4187 - val_categorical_accuracy: 0.4571\n",
            "Epoch 194/200\n",
            "39/39 [==============================] - 1s 32ms/step - loss: 0.7282 - categorical_accuracy: 0.6973 - val_loss: 1.4047 - val_categorical_accuracy: 0.4286\n",
            "Epoch 195/200\n",
            "39/39 [==============================] - 1s 32ms/step - loss: 0.7127 - categorical_accuracy: 0.7419 - val_loss: 1.3937 - val_categorical_accuracy: 0.4143\n",
            "Epoch 196/200\n",
            "39/39 [==============================] - 1s 32ms/step - loss: 0.6857 - categorical_accuracy: 0.7374 - val_loss: 1.3956 - val_categorical_accuracy: 0.4000\n",
            "Epoch 197/200\n",
            "39/39 [==============================] - 1s 32ms/step - loss: 0.7509 - categorical_accuracy: 0.6938 - val_loss: 1.4036 - val_categorical_accuracy: 0.4143\n",
            "Epoch 198/200\n",
            "39/39 [==============================] - 1s 31ms/step - loss: 0.6878 - categorical_accuracy: 0.7325 - val_loss: 1.4234 - val_categorical_accuracy: 0.4000\n",
            "Epoch 199/200\n",
            "39/39 [==============================] - 1s 31ms/step - loss: 0.7092 - categorical_accuracy: 0.7075 - val_loss: 1.4099 - val_categorical_accuracy: 0.3857\n",
            "Epoch 200/200\n",
            "39/39 [==============================] - 1s 32ms/step - loss: 0.7311 - categorical_accuracy: 0.6911 - val_loss: 1.4257 - val_categorical_accuracy: 0.4000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_CZ-oFJW3bd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "onU0xMuWmGmQ"
      },
      "source": [
        "###test_result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9cTZvr8tmGmS",
        "outputId": "22a184d9-3e05-40d3-a804-219825950d0a"
      },
      "source": [
        "d = {0: 'happy',\n",
        "     1: 'sad',\n",
        "     2: 'angry',\n",
        "     3: 'fear'}\n",
        "Y_test_pred = np.argmax(model.predict(X_test), axis=-1)\n",
        "Y_test_pred = list(map(lambda x: d[x], Y_test_pred))\n",
        "y_test = np.argmax(y_test, axis=-1)\n",
        "y_test = list(map(lambda x: d[x], y_test))\n",
        "print(classification_report(y_test, Y_test_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.82      0.69      0.75        13\n",
            "        fear       0.58      0.33      0.42        21\n",
            "       happy       0.53      0.35      0.42        23\n",
            "         sad       0.46      0.90      0.61        20\n",
            "\n",
            "    accuracy                           0.55        77\n",
            "   macro avg       0.60      0.57      0.55        77\n",
            "weighted avg       0.58      0.55      0.53        77\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N6d8QlF3mGmT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "outputId": "c7714b37-fe85-4687-f4d2-d4faa5ef877c"
      },
      "source": [
        "import scikitplot as skplt\n",
        "\n",
        "skplt.metrics.plot_confusion_matrix(\n",
        "    y_test, \n",
        "    Y_test_pred,\n",
        "    figsize=(8,8))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fd8f619d450>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8FTW3csmGmU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52xgoS68UfhO"
      },
      "source": [
        "# Tempogram + basic model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcvwxCrLUlKS"
      },
      "source": [
        "audio_duration = 3\n",
        "sampling_rate = 22050\n",
        "input_length = sampling_rate * audio_duration\n",
        "\n",
        "signal, sr = librosa.load('/content/drive/MyDrive/Colab Notebooks/SPEECH_EMOTION_Recognition/datasets/archive/Actor_02/03-01-02-02-01-01-02.wav')\n",
        "if len(signal) > input_length:\n",
        "  signal = signal[0:input_length]\n",
        "elif  input_length > len(signal):\n",
        "  max_offset = input_length - len(signal)  \n",
        "  signal = np.pad(signal, (0, max_offset), \"constant\")\n",
        "tempogram = librosa.feature.tempogram(signal, sr, win_length=100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aXGU52foX3Aw"
      },
      "source": [
        "tempogram = tempogram.T"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hAMG7mEZVsmd",
        "outputId": "937cb617-bb30-4e6a-9dea-214a6c7a8414"
      },
      "source": [
        "tempogram.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(130, 100)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRIEg1lhUfhZ"
      },
      "source": [
        "features = []\n",
        "labels = []\n",
        "for i in range(len(Ravdess_DF['Paths'])):\n",
        "  if ((Ravdess_DF['Emotion'][i] == '03') | (Ravdess_DF['Emotion'][i] == '04') | \n",
        "      (Ravdess_DF['Emotion'][i] == '05') | (Ravdess_DF['Emotion'][i] == '06')):\n",
        "    signal, sr = librosa.load(Ravdess_DF['Paths'][i])\n",
        "    tempogram = np.mean(librosa.feature.tempogram(signal, sr).T, axis=0)\n",
        "    features.append(tempogram)\n",
        "    if Ravdess_DF['Emotion'][i] == '03':\n",
        "      labels.append(0)\n",
        "    elif Ravdess_DF['Emotion'][i] == '04':\n",
        "      labels.append(1)\n",
        "    elif Ravdess_DF['Emotion'][i] == '05':\n",
        "      labels.append(2)\n",
        "    elif Ravdess_DF['Emotion'][i] == '06':\n",
        "      labels.append(3)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_thKlW8Ufhb"
      },
      "source": [
        "X = features\n",
        "y = labels\n",
        "\n",
        "y = np.array(y)\n",
        "y = to_categorical(y)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=0)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=0)\n",
        "\n",
        "X_train = np.array(X_train)\n",
        "X_test = np.array(X_test)\n",
        "X_val = np.array(X_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dOcjtFWYUfhc"
      },
      "source": [
        "## basic models:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rkfYHWSJUfhd",
        "outputId": "e212f7a6-c1a9-4d98-ff77-d7d95f0c2d37"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(384, input_shape=(384, ), activation = 'relu'))\n",
        "#model.add(Dropout(0.1))\n",
        "model.add(Dense(128, activation = 'relu'))\n",
        "#model.add(Dropout(0.25))\n",
        "model.add(Dense(128, activation = 'relu'))\n",
        "#model.add(Dropout(0.2))\n",
        "model.add(Dense(4, activation = 'softmax'))\n",
        "\n",
        "optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
        "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer=optimizer)\n",
        "early_stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=100, verbose=1, mode='auto')\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_27 (Dense)             (None, 384)               147840    \n",
            "_________________________________________________________________\n",
            "dense_28 (Dense)             (None, 128)               49280     \n",
            "_________________________________________________________________\n",
            "dense_29 (Dense)             (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dense_30 (Dense)             (None, 4)                 516       \n",
            "=================================================================\n",
            "Total params: 214,148\n",
            "Trainable params: 214,148\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RtMiNrW1Ufhf",
        "outputId": "242b597a-920e-47e8-a037-7f83e388a8f6"
      },
      "source": [
        "history = model.fit(X_train, y_train, batch_size=64, epochs=200, \n",
        "                    validation_data=(X_val, y_val))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "10/10 [==============================] - 1s 31ms/step - loss: 1.3947 - accuracy: 0.2082 - val_loss: 1.3959 - val_accuracy: 0.1714\n",
            "Epoch 2/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3718 - accuracy: 0.3334 - val_loss: 1.3828 - val_accuracy: 0.2286\n",
            "Epoch 3/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3539 - accuracy: 0.3023 - val_loss: 1.4426 - val_accuracy: 0.2714\n",
            "Epoch 4/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3408 - accuracy: 0.3508 - val_loss: 1.3802 - val_accuracy: 0.3571\n",
            "Epoch 5/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.3407 - accuracy: 0.3533 - val_loss: 1.3834 - val_accuracy: 0.3000\n",
            "Epoch 6/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.3238 - accuracy: 0.3917 - val_loss: 1.3618 - val_accuracy: 0.3714\n",
            "Epoch 7/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3252 - accuracy: 0.3984 - val_loss: 1.3951 - val_accuracy: 0.3000\n",
            "Epoch 8/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3183 - accuracy: 0.3533 - val_loss: 1.3749 - val_accuracy: 0.3857\n",
            "Epoch 9/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.2779 - accuracy: 0.4125 - val_loss: 1.3609 - val_accuracy: 0.3429\n",
            "Epoch 10/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2864 - accuracy: 0.4090 - val_loss: 1.3977 - val_accuracy: 0.2571\n",
            "Epoch 11/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2510 - accuracy: 0.4184 - val_loss: 1.3146 - val_accuracy: 0.4000\n",
            "Epoch 12/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.2684 - accuracy: 0.4235 - val_loss: 1.3167 - val_accuracy: 0.4143\n",
            "Epoch 13/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.2375 - accuracy: 0.4273 - val_loss: 1.3209 - val_accuracy: 0.3571\n",
            "Epoch 14/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2307 - accuracy: 0.4293 - val_loss: 1.3095 - val_accuracy: 0.4000\n",
            "Epoch 15/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2291 - accuracy: 0.4505 - val_loss: 1.3070 - val_accuracy: 0.4000\n",
            "Epoch 16/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.2062 - accuracy: 0.4595 - val_loss: 1.3547 - val_accuracy: 0.3143\n",
            "Epoch 17/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2073 - accuracy: 0.4575 - val_loss: 1.3214 - val_accuracy: 0.3429\n",
            "Epoch 18/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.1868 - accuracy: 0.4798 - val_loss: 1.3800 - val_accuracy: 0.3429\n",
            "Epoch 19/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.1807 - accuracy: 0.4761 - val_loss: 1.2768 - val_accuracy: 0.4000\n",
            "Epoch 20/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.1527 - accuracy: 0.4939 - val_loss: 1.2835 - val_accuracy: 0.4000\n",
            "Epoch 21/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1824 - accuracy: 0.4790 - val_loss: 1.4651 - val_accuracy: 0.3143\n",
            "Epoch 22/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.2277 - accuracy: 0.4598 - val_loss: 1.3203 - val_accuracy: 0.3857\n",
            "Epoch 23/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1309 - accuracy: 0.5309 - val_loss: 1.3064 - val_accuracy: 0.3571\n",
            "Epoch 24/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1145 - accuracy: 0.5260 - val_loss: 1.3034 - val_accuracy: 0.3571\n",
            "Epoch 25/200\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.1525 - accuracy: 0.4921 - val_loss: 1.2743 - val_accuracy: 0.3571\n",
            "Epoch 26/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1043 - accuracy: 0.5139 - val_loss: 1.2479 - val_accuracy: 0.4143\n",
            "Epoch 27/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1145 - accuracy: 0.5143 - val_loss: 1.2398 - val_accuracy: 0.5000\n",
            "Epoch 28/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.1419 - accuracy: 0.5208 - val_loss: 1.3276 - val_accuracy: 0.4286\n",
            "Epoch 29/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1416 - accuracy: 0.5164 - val_loss: 1.3693 - val_accuracy: 0.3857\n",
            "Epoch 30/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1467 - accuracy: 0.4627 - val_loss: 1.2587 - val_accuracy: 0.3857\n",
            "Epoch 31/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1061 - accuracy: 0.5163 - val_loss: 1.2713 - val_accuracy: 0.3571\n",
            "Epoch 32/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0874 - accuracy: 0.5186 - val_loss: 1.3488 - val_accuracy: 0.3571\n",
            "Epoch 33/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0541 - accuracy: 0.5665 - val_loss: 1.3112 - val_accuracy: 0.3857\n",
            "Epoch 34/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.0999 - accuracy: 0.5094 - val_loss: 1.5537 - val_accuracy: 0.2857\n",
            "Epoch 35/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.1302 - accuracy: 0.5076 - val_loss: 1.3827 - val_accuracy: 0.3571\n",
            "Epoch 36/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0906 - accuracy: 0.5268 - val_loss: 1.3352 - val_accuracy: 0.3857\n",
            "Epoch 37/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.1007 - accuracy: 0.5175 - val_loss: 1.3130 - val_accuracy: 0.3571\n",
            "Epoch 38/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0327 - accuracy: 0.5637 - val_loss: 1.3235 - val_accuracy: 0.3857\n",
            "Epoch 39/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.0257 - accuracy: 0.5667 - val_loss: 1.3278 - val_accuracy: 0.3714\n",
            "Epoch 40/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.0212 - accuracy: 0.5796 - val_loss: 1.3200 - val_accuracy: 0.3571\n",
            "Epoch 41/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.9897 - accuracy: 0.5831 - val_loss: 1.3962 - val_accuracy: 0.3429\n",
            "Epoch 42/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0133 - accuracy: 0.5978 - val_loss: 1.3139 - val_accuracy: 0.4286\n",
            "Epoch 43/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.0110 - accuracy: 0.5866 - val_loss: 1.2588 - val_accuracy: 0.4143\n",
            "Epoch 44/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9808 - accuracy: 0.5893 - val_loss: 1.3780 - val_accuracy: 0.3571\n",
            "Epoch 45/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.9723 - accuracy: 0.5764 - val_loss: 1.3567 - val_accuracy: 0.3714\n",
            "Epoch 46/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.9754 - accuracy: 0.6192 - val_loss: 1.2790 - val_accuracy: 0.4286\n",
            "Epoch 47/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.9874 - accuracy: 0.6267 - val_loss: 1.3328 - val_accuracy: 0.3714\n",
            "Epoch 48/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.9761 - accuracy: 0.5787 - val_loss: 1.2857 - val_accuracy: 0.4286\n",
            "Epoch 49/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9411 - accuracy: 0.5928 - val_loss: 1.3045 - val_accuracy: 0.4286\n",
            "Epoch 50/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9764 - accuracy: 0.6035 - val_loss: 1.4677 - val_accuracy: 0.3857\n",
            "Epoch 51/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.9756 - accuracy: 0.6228 - val_loss: 1.3861 - val_accuracy: 0.3429\n",
            "Epoch 52/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.9754 - accuracy: 0.6017 - val_loss: 1.4754 - val_accuracy: 0.3714\n",
            "Epoch 53/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9921 - accuracy: 0.6086 - val_loss: 1.2727 - val_accuracy: 0.4000\n",
            "Epoch 54/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.9253 - accuracy: 0.5965 - val_loss: 1.3720 - val_accuracy: 0.3571\n",
            "Epoch 55/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.9009 - accuracy: 0.6359 - val_loss: 1.4005 - val_accuracy: 0.3286\n",
            "Epoch 56/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.9472 - accuracy: 0.5977 - val_loss: 1.4197 - val_accuracy: 0.3857\n",
            "Epoch 57/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.9749 - accuracy: 0.5814 - val_loss: 1.3639 - val_accuracy: 0.4143\n",
            "Epoch 58/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.0098 - accuracy: 0.5763 - val_loss: 1.3615 - val_accuracy: 0.3571\n",
            "Epoch 59/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9344 - accuracy: 0.6232 - val_loss: 1.3723 - val_accuracy: 0.3571\n",
            "Epoch 60/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8598 - accuracy: 0.6722 - val_loss: 1.2877 - val_accuracy: 0.4714\n",
            "Epoch 61/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9102 - accuracy: 0.6283 - val_loss: 1.2920 - val_accuracy: 0.4429\n",
            "Epoch 62/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8513 - accuracy: 0.6655 - val_loss: 1.4560 - val_accuracy: 0.4000\n",
            "Epoch 63/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9139 - accuracy: 0.6197 - val_loss: 1.3529 - val_accuracy: 0.4000\n",
            "Epoch 64/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.8660 - accuracy: 0.6632 - val_loss: 1.3401 - val_accuracy: 0.4286\n",
            "Epoch 65/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.8554 - accuracy: 0.6572 - val_loss: 1.3066 - val_accuracy: 0.4429\n",
            "Epoch 66/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8864 - accuracy: 0.6490 - val_loss: 1.3222 - val_accuracy: 0.4429\n",
            "Epoch 67/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.8734 - accuracy: 0.6519 - val_loss: 1.4400 - val_accuracy: 0.3286\n",
            "Epoch 68/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.8910 - accuracy: 0.6196 - val_loss: 1.4744 - val_accuracy: 0.3571\n",
            "Epoch 69/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.8828 - accuracy: 0.6229 - val_loss: 1.3419 - val_accuracy: 0.3857\n",
            "Epoch 70/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.8188 - accuracy: 0.6802 - val_loss: 1.3801 - val_accuracy: 0.3714\n",
            "Epoch 71/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.8417 - accuracy: 0.6603 - val_loss: 1.3741 - val_accuracy: 0.3714\n",
            "Epoch 72/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8370 - accuracy: 0.6864 - val_loss: 1.3486 - val_accuracy: 0.4714\n",
            "Epoch 73/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8068 - accuracy: 0.6728 - val_loss: 1.4658 - val_accuracy: 0.3571\n",
            "Epoch 74/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7865 - accuracy: 0.7066 - val_loss: 1.3251 - val_accuracy: 0.4714\n",
            "Epoch 75/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8799 - accuracy: 0.6323 - val_loss: 1.4289 - val_accuracy: 0.3857\n",
            "Epoch 76/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.8603 - accuracy: 0.6433 - val_loss: 1.4423 - val_accuracy: 0.3286\n",
            "Epoch 77/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7837 - accuracy: 0.7022 - val_loss: 1.3831 - val_accuracy: 0.4000\n",
            "Epoch 78/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.8288 - accuracy: 0.6660 - val_loss: 1.3934 - val_accuracy: 0.4000\n",
            "Epoch 79/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.8526 - accuracy: 0.6572 - val_loss: 1.3942 - val_accuracy: 0.3714\n",
            "Epoch 80/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7402 - accuracy: 0.6887 - val_loss: 1.3312 - val_accuracy: 0.4286\n",
            "Epoch 81/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7699 - accuracy: 0.7025 - val_loss: 1.5414 - val_accuracy: 0.3143\n",
            "Epoch 82/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7514 - accuracy: 0.7137 - val_loss: 1.4269 - val_accuracy: 0.4143\n",
            "Epoch 83/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8232 - accuracy: 0.6357 - val_loss: 1.4926 - val_accuracy: 0.3714\n",
            "Epoch 84/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7855 - accuracy: 0.6867 - val_loss: 1.4469 - val_accuracy: 0.4000\n",
            "Epoch 85/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7230 - accuracy: 0.7229 - val_loss: 1.4050 - val_accuracy: 0.4286\n",
            "Epoch 86/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7417 - accuracy: 0.7294 - val_loss: 1.4059 - val_accuracy: 0.4857\n",
            "Epoch 87/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7322 - accuracy: 0.7123 - val_loss: 1.4823 - val_accuracy: 0.3429\n",
            "Epoch 88/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7246 - accuracy: 0.7226 - val_loss: 1.5083 - val_accuracy: 0.3714\n",
            "Epoch 89/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7237 - accuracy: 0.7190 - val_loss: 1.4343 - val_accuracy: 0.4143\n",
            "Epoch 90/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7156 - accuracy: 0.7083 - val_loss: 1.4354 - val_accuracy: 0.4000\n",
            "Epoch 91/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7362 - accuracy: 0.7040 - val_loss: 1.5627 - val_accuracy: 0.3857\n",
            "Epoch 92/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6786 - accuracy: 0.7411 - val_loss: 1.5089 - val_accuracy: 0.3857\n",
            "Epoch 93/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7046 - accuracy: 0.7350 - val_loss: 1.4156 - val_accuracy: 0.4143\n",
            "Epoch 94/200\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.6630 - accuracy: 0.7570 - val_loss: 1.6063 - val_accuracy: 0.3714\n",
            "Epoch 95/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6979 - accuracy: 0.7138 - val_loss: 1.4969 - val_accuracy: 0.3857\n",
            "Epoch 96/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7015 - accuracy: 0.7199 - val_loss: 1.6459 - val_accuracy: 0.3714\n",
            "Epoch 97/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6480 - accuracy: 0.7393 - val_loss: 1.4125 - val_accuracy: 0.3857\n",
            "Epoch 98/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6389 - accuracy: 0.7578 - val_loss: 1.5806 - val_accuracy: 0.4000\n",
            "Epoch 99/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6169 - accuracy: 0.7521 - val_loss: 1.5461 - val_accuracy: 0.3714\n",
            "Epoch 100/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6687 - accuracy: 0.7525 - val_loss: 1.5090 - val_accuracy: 0.4143\n",
            "Epoch 101/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6188 - accuracy: 0.7604 - val_loss: 1.5708 - val_accuracy: 0.4143\n",
            "Epoch 102/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6214 - accuracy: 0.7693 - val_loss: 1.5686 - val_accuracy: 0.3571\n",
            "Epoch 103/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6103 - accuracy: 0.7363 - val_loss: 1.5455 - val_accuracy: 0.3429\n",
            "Epoch 104/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.5842 - accuracy: 0.7556 - val_loss: 1.4730 - val_accuracy: 0.3857\n",
            "Epoch 105/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.5276 - accuracy: 0.8339 - val_loss: 1.6140 - val_accuracy: 0.3571\n",
            "Epoch 106/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.5309 - accuracy: 0.8027 - val_loss: 1.5263 - val_accuracy: 0.4143\n",
            "Epoch 107/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.5364 - accuracy: 0.8280 - val_loss: 1.5776 - val_accuracy: 0.3429\n",
            "Epoch 108/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.5299 - accuracy: 0.8184 - val_loss: 1.5528 - val_accuracy: 0.3857\n",
            "Epoch 109/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.5201 - accuracy: 0.8184 - val_loss: 1.6790 - val_accuracy: 0.3857\n",
            "Epoch 110/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.5254 - accuracy: 0.7983 - val_loss: 1.6468 - val_accuracy: 0.3143\n",
            "Epoch 111/200\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.5227 - accuracy: 0.8087 - val_loss: 1.6236 - val_accuracy: 0.3714\n",
            "Epoch 112/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.5407 - accuracy: 0.8067 - val_loss: 1.6800 - val_accuracy: 0.4000\n",
            "Epoch 113/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.5288 - accuracy: 0.7959 - val_loss: 1.6332 - val_accuracy: 0.3714\n",
            "Epoch 114/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.4540 - accuracy: 0.8416 - val_loss: 1.7849 - val_accuracy: 0.3143\n",
            "Epoch 115/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.5450 - accuracy: 0.7961 - val_loss: 1.5538 - val_accuracy: 0.4571\n",
            "Epoch 116/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.5022 - accuracy: 0.8124 - val_loss: 1.7079 - val_accuracy: 0.3143\n",
            "Epoch 117/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.4549 - accuracy: 0.8397 - val_loss: 1.7720 - val_accuracy: 0.3286\n",
            "Epoch 118/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.5633 - accuracy: 0.7876 - val_loss: 1.6559 - val_accuracy: 0.3714\n",
            "Epoch 119/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.4355 - accuracy: 0.8648 - val_loss: 1.7403 - val_accuracy: 0.3857\n",
            "Epoch 120/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.5071 - accuracy: 0.8182 - val_loss: 1.8019 - val_accuracy: 0.3714\n",
            "Epoch 121/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.4573 - accuracy: 0.8128 - val_loss: 1.7200 - val_accuracy: 0.3571\n",
            "Epoch 122/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.3815 - accuracy: 0.8813 - val_loss: 1.7643 - val_accuracy: 0.3571\n",
            "Epoch 123/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.4038 - accuracy: 0.8659 - val_loss: 1.8672 - val_accuracy: 0.3571\n",
            "Epoch 124/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.3846 - accuracy: 0.8784 - val_loss: 1.9128 - val_accuracy: 0.3429\n",
            "Epoch 125/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.4242 - accuracy: 0.8442 - val_loss: 1.7668 - val_accuracy: 0.4143\n",
            "Epoch 126/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.4414 - accuracy: 0.8549 - val_loss: 1.8190 - val_accuracy: 0.3857\n",
            "Epoch 127/200\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.4693 - accuracy: 0.8285 - val_loss: 1.8208 - val_accuracy: 0.3143\n",
            "Epoch 128/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.3912 - accuracy: 0.8734 - val_loss: 1.8851 - val_accuracy: 0.3429\n",
            "Epoch 129/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.4310 - accuracy: 0.8429 - val_loss: 1.8563 - val_accuracy: 0.3143\n",
            "Epoch 130/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.3448 - accuracy: 0.8955 - val_loss: 2.0722 - val_accuracy: 0.3286\n",
            "Epoch 131/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.3947 - accuracy: 0.8507 - val_loss: 2.0174 - val_accuracy: 0.3429\n",
            "Epoch 132/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.3880 - accuracy: 0.8661 - val_loss: 1.8793 - val_accuracy: 0.3143\n",
            "Epoch 133/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.3604 - accuracy: 0.8856 - val_loss: 2.0546 - val_accuracy: 0.3571\n",
            "Epoch 134/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.3966 - accuracy: 0.8463 - val_loss: 1.9952 - val_accuracy: 0.3143\n",
            "Epoch 135/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.3514 - accuracy: 0.8864 - val_loss: 2.1269 - val_accuracy: 0.2857\n",
            "Epoch 136/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.3264 - accuracy: 0.8934 - val_loss: 2.0120 - val_accuracy: 0.3714\n",
            "Epoch 137/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.3168 - accuracy: 0.9142 - val_loss: 2.1372 - val_accuracy: 0.3429\n",
            "Epoch 138/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.3130 - accuracy: 0.9081 - val_loss: 2.0143 - val_accuracy: 0.3286\n",
            "Epoch 139/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.3390 - accuracy: 0.8852 - val_loss: 2.0402 - val_accuracy: 0.3714\n",
            "Epoch 140/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.2903 - accuracy: 0.9039 - val_loss: 1.9946 - val_accuracy: 0.3000\n",
            "Epoch 141/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.2505 - accuracy: 0.9235 - val_loss: 2.1385 - val_accuracy: 0.3286\n",
            "Epoch 142/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.2689 - accuracy: 0.9193 - val_loss: 2.0539 - val_accuracy: 0.3286\n",
            "Epoch 143/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.2674 - accuracy: 0.9313 - val_loss: 2.0107 - val_accuracy: 0.3571\n",
            "Epoch 144/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.3031 - accuracy: 0.8957 - val_loss: 2.2853 - val_accuracy: 0.3000\n",
            "Epoch 145/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.3158 - accuracy: 0.8930 - val_loss: 2.1574 - val_accuracy: 0.3714\n",
            "Epoch 146/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.3240 - accuracy: 0.8923 - val_loss: 2.2081 - val_accuracy: 0.3429\n",
            "Epoch 147/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.2940 - accuracy: 0.9106 - val_loss: 2.4003 - val_accuracy: 0.3429\n",
            "Epoch 148/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.3060 - accuracy: 0.8864 - val_loss: 2.1025 - val_accuracy: 0.3714\n",
            "Epoch 149/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.2814 - accuracy: 0.9011 - val_loss: 2.2210 - val_accuracy: 0.3857\n",
            "Epoch 150/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.2573 - accuracy: 0.9215 - val_loss: 2.3819 - val_accuracy: 0.3571\n",
            "Epoch 151/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.2588 - accuracy: 0.9194 - val_loss: 2.2940 - val_accuracy: 0.3714\n",
            "Epoch 152/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.2629 - accuracy: 0.9203 - val_loss: 2.1903 - val_accuracy: 0.3857\n",
            "Epoch 153/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.2637 - accuracy: 0.9245 - val_loss: 2.3792 - val_accuracy: 0.3143\n",
            "Epoch 154/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.2381 - accuracy: 0.9330 - val_loss: 2.1583 - val_accuracy: 0.3714\n",
            "Epoch 155/200\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1969 - accuracy: 0.9559 - val_loss: 2.3201 - val_accuracy: 0.4000\n",
            "Epoch 156/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1984 - accuracy: 0.9598 - val_loss: 2.4027 - val_accuracy: 0.3000\n",
            "Epoch 157/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1918 - accuracy: 0.9465 - val_loss: 2.5030 - val_accuracy: 0.3571\n",
            "Epoch 158/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1912 - accuracy: 0.9510 - val_loss: 2.3306 - val_accuracy: 0.3714\n",
            "Epoch 159/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.2712 - accuracy: 0.9079 - val_loss: 2.5753 - val_accuracy: 0.3571\n",
            "Epoch 160/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.2054 - accuracy: 0.9355 - val_loss: 2.4267 - val_accuracy: 0.3000\n",
            "Epoch 161/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.2202 - accuracy: 0.9231 - val_loss: 2.4381 - val_accuracy: 0.3429\n",
            "Epoch 162/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.2357 - accuracy: 0.9314 - val_loss: 2.5880 - val_accuracy: 0.3571\n",
            "Epoch 163/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.2588 - accuracy: 0.9053 - val_loss: 2.3298 - val_accuracy: 0.3857\n",
            "Epoch 164/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.2358 - accuracy: 0.9185 - val_loss: 2.5195 - val_accuracy: 0.3143\n",
            "Epoch 165/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1686 - accuracy: 0.9474 - val_loss: 2.6378 - val_accuracy: 0.3286\n",
            "Epoch 166/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.2170 - accuracy: 0.9321 - val_loss: 2.6593 - val_accuracy: 0.3143\n",
            "Epoch 167/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.2987 - accuracy: 0.8932 - val_loss: 2.5757 - val_accuracy: 0.3143\n",
            "Epoch 168/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.2269 - accuracy: 0.9212 - val_loss: 2.3929 - val_accuracy: 0.3429\n",
            "Epoch 169/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1953 - accuracy: 0.9471 - val_loss: 2.4627 - val_accuracy: 0.3143\n",
            "Epoch 170/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1742 - accuracy: 0.9464 - val_loss: 2.7368 - val_accuracy: 0.3286\n",
            "Epoch 171/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1596 - accuracy: 0.9613 - val_loss: 2.5563 - val_accuracy: 0.3857\n",
            "Epoch 172/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1448 - accuracy: 0.9615 - val_loss: 2.7065 - val_accuracy: 0.3429\n",
            "Epoch 173/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1472 - accuracy: 0.9682 - val_loss: 2.7100 - val_accuracy: 0.3571\n",
            "Epoch 174/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1129 - accuracy: 0.9785 - val_loss: 2.8956 - val_accuracy: 0.3000\n",
            "Epoch 175/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1357 - accuracy: 0.9757 - val_loss: 2.5478 - val_accuracy: 0.3429\n",
            "Epoch 176/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1305 - accuracy: 0.9771 - val_loss: 2.8140 - val_accuracy: 0.3429\n",
            "Epoch 177/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1067 - accuracy: 0.9806 - val_loss: 2.7998 - val_accuracy: 0.3143\n",
            "Epoch 178/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1059 - accuracy: 0.9783 - val_loss: 2.7078 - val_accuracy: 0.3714\n",
            "Epoch 179/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1101 - accuracy: 0.9725 - val_loss: 2.8010 - val_accuracy: 0.3286\n",
            "Epoch 180/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0937 - accuracy: 0.9895 - val_loss: 2.8989 - val_accuracy: 0.3286\n",
            "Epoch 181/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1112 - accuracy: 0.9746 - val_loss: 2.9414 - val_accuracy: 0.3429\n",
            "Epoch 182/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1097 - accuracy: 0.9723 - val_loss: 2.8191 - val_accuracy: 0.3429\n",
            "Epoch 183/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0901 - accuracy: 0.9898 - val_loss: 2.7899 - val_accuracy: 0.3143\n",
            "Epoch 184/200\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1005 - accuracy: 0.9843 - val_loss: 3.1413 - val_accuracy: 0.3571\n",
            "Epoch 185/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1422 - accuracy: 0.9648 - val_loss: 2.8222 - val_accuracy: 0.3714\n",
            "Epoch 186/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0823 - accuracy: 0.9931 - val_loss: 2.7834 - val_accuracy: 0.3571\n",
            "Epoch 187/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0903 - accuracy: 0.9806 - val_loss: 2.8657 - val_accuracy: 0.3857\n",
            "Epoch 188/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0890 - accuracy: 0.9889 - val_loss: 3.0623 - val_accuracy: 0.3429\n",
            "Epoch 189/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0955 - accuracy: 0.9879 - val_loss: 3.1365 - val_accuracy: 0.3286\n",
            "Epoch 190/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0886 - accuracy: 0.9723 - val_loss: 2.9656 - val_accuracy: 0.3714\n",
            "Epoch 191/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1000 - accuracy: 0.9751 - val_loss: 3.0502 - val_accuracy: 0.3857\n",
            "Epoch 192/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1188 - accuracy: 0.9593 - val_loss: 2.8969 - val_accuracy: 0.3429\n",
            "Epoch 193/200\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.2016 - accuracy: 0.9235 - val_loss: 3.0665 - val_accuracy: 0.3143\n",
            "Epoch 194/200\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1670 - accuracy: 0.9442 - val_loss: 2.7868 - val_accuracy: 0.4000\n",
            "Epoch 195/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1486 - accuracy: 0.9617 - val_loss: 3.0274 - val_accuracy: 0.3000\n",
            "Epoch 196/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1446 - accuracy: 0.9589 - val_loss: 2.8724 - val_accuracy: 0.4000\n",
            "Epoch 197/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1284 - accuracy: 0.9663 - val_loss: 3.4349 - val_accuracy: 0.3286\n",
            "Epoch 198/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.2009 - accuracy: 0.9298 - val_loss: 2.8004 - val_accuracy: 0.3714\n",
            "Epoch 199/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1922 - accuracy: 0.9250 - val_loss: 2.9716 - val_accuracy: 0.3286\n",
            "Epoch 200/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1277 - accuracy: 0.9681 - val_loss: 2.7669 - val_accuracy: 0.3714\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eMBkex9tUfhf"
      },
      "source": [
        "model.save('/content/drive/MyDrive/Colab Notebooks/SPEECH_EMOTION_Recognition/Nộp bài(chốt hạ)/model_saver/basic_tempogram_ravdess.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IkazhV_OUfhg"
      },
      "source": [
        "###test_result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AHzPRDEUUfhh",
        "outputId": "a738157d-75a8-402e-d399-e968560a1485"
      },
      "source": [
        "d = {0: 'happy',\n",
        "     1: 'sad',\n",
        "     2: 'angry',\n",
        "     3: 'fear'}\n",
        "Y_test_pred = np.argmax(model.predict(X_test), axis=-1)\n",
        "Y_test_pred = list(map(lambda x: d[x], Y_test_pred))\n",
        "y_test = np.argmax(y_test, axis=-1)\n",
        "y_test = list(map(lambda x: d[x], y_test))\n",
        "print(classification_report(y_test, Y_test_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.42      0.62      0.50        13\n",
            "        fear       0.38      0.52      0.44        21\n",
            "       happy       0.39      0.30      0.34        23\n",
            "         sad       0.64      0.35      0.45        20\n",
            "\n",
            "    accuracy                           0.43        77\n",
            "   macro avg       0.46      0.45      0.43        77\n",
            "weighted avg       0.46      0.43      0.42        77\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "id": "fPqHBDBhUfhj",
        "outputId": "2aea2a2f-0720-45b5-fa5e-01d575df91d2"
      },
      "source": [
        "skplt.metrics.plot_confusion_matrix(\n",
        "    y_test, \n",
        "    Y_test_pred,\n",
        "    figsize=(8,8))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fd8e7d62c10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 115
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y4YWk4_ZW4wc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q8JULeSZXNcL"
      },
      "source": [
        "# Tempogram + conv1D"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sOUqwufbXNcd"
      },
      "source": [
        "features = []\n",
        "labels = []\n",
        "for i in range(len(Ravdess_DF['Paths'])):\n",
        "  if ((Ravdess_DF['Emotion'][i] == '03') | (Ravdess_DF['Emotion'][i] == '04') | \n",
        "      (Ravdess_DF['Emotion'][i] == '05') | (Ravdess_DF['Emotion'][i] == '06')):\n",
        "    \n",
        "    signal, sr = librosa.load(Ravdess_DF['Paths'][i])\n",
        "    if len(signal) > input_length:\n",
        "        signal = signal[0:input_length]\n",
        "    elif  input_length > len(signal):\n",
        "        max_offset = input_length - len(signal)  \n",
        "        signal = np.pad(signal, (0, max_offset), \"constant\")\n",
        "    tempogram = librosa.feature.tempogram(signal, sr)\n",
        "    features.append(tempogram)\n",
        "    if Ravdess_DF['Emotion'][i] == '03':\n",
        "      labels.append(0)\n",
        "    elif Ravdess_DF['Emotion'][i] == '04':\n",
        "      labels.append(1)\n",
        "    elif Ravdess_DF['Emotion'][i] == '05':\n",
        "      labels.append(2)\n",
        "    elif Ravdess_DF['Emotion'][i] == '06':\n",
        "      labels.append(3)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDZ1IDBSXNce"
      },
      "source": [
        "X = features\n",
        "y = labels\n",
        "\n",
        "y = np.array(y)\n",
        "y = to_categorical(y)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=0)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=0)\n",
        "\n",
        "X_train = np.array(X_train)\n",
        "X_test = np.array(X_test)\n",
        "X_val = np.array(X_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ytS1moepYT3l",
        "outputId": "71e12c53-b917-4c2a-e10f-c3241fe37d0c"
      },
      "source": [
        "X_train.shape,X_test.shape,y_train.shape,y_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((621, 384, 259), (77, 384, 259), (621, 4), (77, 4))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RKGOhIllYlwH"
      },
      "source": [
        "### conv1D"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0yrT1F9IYlwI"
      },
      "source": [
        "\n",
        "# CNN I/P Config\n",
        "num_classes = 4\n",
        "input_shape = X_train.shape[1:]\n",
        "learning_rate = 0.0001\n",
        "decay = 1e-6\n",
        "momentum = 0.9\n",
        "\n",
        "#LSTM Configuration\n",
        "num_lstm = 256"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EHg7H9sOYlwK",
        "outputId": "be630a36-21db-423a-9bc0-cfd96b45a689"
      },
      "source": [
        "model = Sequential(name='Audio_CNN_1D')\n",
        "\n",
        "# LFLB1\n",
        "model.add(Conv1D(filters=64, kernel_size=(3), strides=1, padding='same', data_format='channels_last',input_shape=input_shape))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('elu'))\n",
        "model.add(MaxPooling1D(pool_size=4, strides=4))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "# LFLB2\n",
        "model.add(Conv1D(filters=64, kernel_size=3, strides=1, padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('elu'))\n",
        "model.add(MaxPooling1D(pool_size=4, strides=4))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# LFLB3\n",
        "model.add(Conv1D(filters=128, kernel_size=3, strides=1, padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('elu'))\n",
        "model.add(MaxPooling1D(pool_size=4, strides=4))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# LFLB4\n",
        "model.add(Conv1D(filters=128, kernel_size=3, strides=1, padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('elu'))\n",
        "model.add(MaxPooling1D(pool_size=4, strides=4))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# LSTM\n",
        "model.add(LSTM(units=num_lstm))\n",
        "\n",
        "# FC\n",
        "model.add(Dense(units=num_classes, activation='softmax'))\n",
        "\n",
        "# Model compilation\n",
        "opt= keras.optimizers.Adam(lr=0.01, beta_1=0.9,  beta_2=0.999, amsgrad=False)\n",
        "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
        "\n",
        "model.summary()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"Audio_CNN_1D\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_8 (Conv1D)            (None, 384, 64)           49792     \n",
            "_________________________________________________________________\n",
            "batch_normalization_18 (Batc (None, 384, 64)           256       \n",
            "_________________________________________________________________\n",
            "activation_18 (Activation)   (None, 384, 64)           0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_8 (MaxPooling1 (None, 96, 64)            0         \n",
            "_________________________________________________________________\n",
            "dropout_18 (Dropout)         (None, 96, 64)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_9 (Conv1D)            (None, 96, 64)            12352     \n",
            "_________________________________________________________________\n",
            "batch_normalization_19 (Batc (None, 96, 64)            256       \n",
            "_________________________________________________________________\n",
            "activation_19 (Activation)   (None, 96, 64)            0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_9 (MaxPooling1 (None, 24, 64)            0         \n",
            "_________________________________________________________________\n",
            "dropout_19 (Dropout)         (None, 24, 64)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_10 (Conv1D)           (None, 24, 128)           24704     \n",
            "_________________________________________________________________\n",
            "batch_normalization_20 (Batc (None, 24, 128)           512       \n",
            "_________________________________________________________________\n",
            "activation_20 (Activation)   (None, 24, 128)           0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_10 (MaxPooling (None, 6, 128)            0         \n",
            "_________________________________________________________________\n",
            "dropout_20 (Dropout)         (None, 6, 128)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_11 (Conv1D)           (None, 6, 128)            49280     \n",
            "_________________________________________________________________\n",
            "batch_normalization_21 (Batc (None, 6, 128)            512       \n",
            "_________________________________________________________________\n",
            "activation_21 (Activation)   (None, 6, 128)            0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_11 (MaxPooling (None, 1, 128)            0         \n",
            "_________________________________________________________________\n",
            "dropout_21 (Dropout)         (None, 1, 128)            0         \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 256)               394240    \n",
            "_________________________________________________________________\n",
            "dense_31 (Dense)             (None, 4)                 1028      \n",
            "=================================================================\n",
            "Total params: 532,932\n",
            "Trainable params: 532,164\n",
            "Non-trainable params: 768\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xGb90pjgYlwM",
        "outputId": "b2a7fc13-1b0e-4c1e-aecb-3c432a78d9df"
      },
      "source": [
        "#Train Config\n",
        "\n",
        "batch_size = 16\n",
        "num_epochs = 200\n",
        "\n",
        "# Model Training\n",
        "lr_reduce = ReduceLROnPlateau(monitor='val_loss', factor=0.9, patience=20, min_lr=0.000001)\n",
        "# Please change the model name accordingly.\n",
        "mcp_save = ModelCheckpoint('/content/Audio_1DCNN.h5', save_best_only=True, monitor='val_categorical_accuracy', mode='max')\n",
        "cnnhistory=model.fit(X_train, y_train, batch_size=batch_size, epochs=num_epochs,validation_data=(X_val, y_val), callbacks=[mcp_save, lr_reduce])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "39/39 [==============================] - 6s 42ms/step - loss: 1.5590 - categorical_accuracy: 0.2156 - val_loss: 1.4084 - val_categorical_accuracy: 0.1857\n",
            "Epoch 2/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.3978 - categorical_accuracy: 0.2334 - val_loss: 1.3876 - val_categorical_accuracy: 0.1857\n",
            "Epoch 3/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.3916 - categorical_accuracy: 0.2618 - val_loss: 1.3675 - val_categorical_accuracy: 0.3143\n",
            "Epoch 4/200\n",
            "39/39 [==============================] - 0s 13ms/step - loss: 1.4079 - categorical_accuracy: 0.2614 - val_loss: 1.3751 - val_categorical_accuracy: 0.2857\n",
            "Epoch 5/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.3902 - categorical_accuracy: 0.2686 - val_loss: 1.3652 - val_categorical_accuracy: 0.3143\n",
            "Epoch 6/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.3892 - categorical_accuracy: 0.2317 - val_loss: 1.3902 - val_categorical_accuracy: 0.2143\n",
            "Epoch 7/200\n",
            "39/39 [==============================] - 0s 11ms/step - loss: 1.3861 - categorical_accuracy: 0.2577 - val_loss: 1.3669 - val_categorical_accuracy: 0.2857\n",
            "Epoch 8/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.3833 - categorical_accuracy: 0.3118 - val_loss: 1.4434 - val_categorical_accuracy: 0.2143\n",
            "Epoch 9/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.3627 - categorical_accuracy: 0.3478 - val_loss: 1.3545 - val_categorical_accuracy: 0.3143\n",
            "Epoch 10/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.3498 - categorical_accuracy: 0.3539 - val_loss: 1.3290 - val_categorical_accuracy: 0.4286\n",
            "Epoch 11/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.3767 - categorical_accuracy: 0.3082 - val_loss: 1.3150 - val_categorical_accuracy: 0.4429\n",
            "Epoch 12/200\n",
            "39/39 [==============================] - 1s 13ms/step - loss: 1.3185 - categorical_accuracy: 0.3790 - val_loss: 1.3451 - val_categorical_accuracy: 0.3571\n",
            "Epoch 13/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.3163 - categorical_accuracy: 0.3792 - val_loss: 1.3732 - val_categorical_accuracy: 0.2857\n",
            "Epoch 14/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.3068 - categorical_accuracy: 0.3663 - val_loss: 1.4352 - val_categorical_accuracy: 0.2143\n",
            "Epoch 15/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.3330 - categorical_accuracy: 0.3884 - val_loss: 1.3470 - val_categorical_accuracy: 0.3286\n",
            "Epoch 16/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.2998 - categorical_accuracy: 0.4134 - val_loss: 1.4292 - val_categorical_accuracy: 0.2429\n",
            "Epoch 17/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.3326 - categorical_accuracy: 0.3680 - val_loss: 1.5767 - val_categorical_accuracy: 0.1857\n",
            "Epoch 18/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.3425 - categorical_accuracy: 0.3748 - val_loss: 1.5006 - val_categorical_accuracy: 0.1571\n",
            "Epoch 19/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.3096 - categorical_accuracy: 0.3913 - val_loss: 1.3568 - val_categorical_accuracy: 0.3286\n",
            "Epoch 20/200\n",
            "39/39 [==============================] - 0s 11ms/step - loss: 1.3109 - categorical_accuracy: 0.3793 - val_loss: 1.4097 - val_categorical_accuracy: 0.2571\n",
            "Epoch 21/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.2959 - categorical_accuracy: 0.4090 - val_loss: 1.4148 - val_categorical_accuracy: 0.3571\n",
            "Epoch 22/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.2785 - categorical_accuracy: 0.3963 - val_loss: 1.2941 - val_categorical_accuracy: 0.3286\n",
            "Epoch 23/200\n",
            "39/39 [==============================] - 1s 13ms/step - loss: 1.2984 - categorical_accuracy: 0.4071 - val_loss: 1.4014 - val_categorical_accuracy: 0.2429\n",
            "Epoch 24/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.2899 - categorical_accuracy: 0.3876 - val_loss: 1.2760 - val_categorical_accuracy: 0.3143\n",
            "Epoch 25/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.2631 - categorical_accuracy: 0.4242 - val_loss: 1.5315 - val_categorical_accuracy: 0.2000\n",
            "Epoch 26/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.2712 - categorical_accuracy: 0.4378 - val_loss: 1.4094 - val_categorical_accuracy: 0.2714\n",
            "Epoch 27/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.2975 - categorical_accuracy: 0.3865 - val_loss: 1.3789 - val_categorical_accuracy: 0.3571\n",
            "Epoch 28/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.2927 - categorical_accuracy: 0.3706 - val_loss: 1.2956 - val_categorical_accuracy: 0.3429\n",
            "Epoch 29/200\n",
            "39/39 [==============================] - 1s 13ms/step - loss: 1.3125 - categorical_accuracy: 0.3843 - val_loss: 1.4249 - val_categorical_accuracy: 0.2429\n",
            "Epoch 30/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.3075 - categorical_accuracy: 0.4031 - val_loss: 1.2770 - val_categorical_accuracy: 0.3429\n",
            "Epoch 31/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.2673 - categorical_accuracy: 0.3907 - val_loss: 1.3251 - val_categorical_accuracy: 0.2857\n",
            "Epoch 32/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.3090 - categorical_accuracy: 0.3430 - val_loss: 1.2650 - val_categorical_accuracy: 0.4143\n",
            "Epoch 33/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.2777 - categorical_accuracy: 0.4271 - val_loss: 1.3728 - val_categorical_accuracy: 0.2857\n",
            "Epoch 34/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.2587 - categorical_accuracy: 0.4218 - val_loss: 1.4327 - val_categorical_accuracy: 0.2000\n",
            "Epoch 35/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.3077 - categorical_accuracy: 0.3738 - val_loss: 1.4653 - val_categorical_accuracy: 0.3000\n",
            "Epoch 36/200\n",
            "39/39 [==============================] - 0s 11ms/step - loss: 1.2843 - categorical_accuracy: 0.3937 - val_loss: 1.4463 - val_categorical_accuracy: 0.1714\n",
            "Epoch 37/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.2453 - categorical_accuracy: 0.4290 - val_loss: 1.3158 - val_categorical_accuracy: 0.3286\n",
            "Epoch 38/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.2697 - categorical_accuracy: 0.4145 - val_loss: 1.7776 - val_categorical_accuracy: 0.1857\n",
            "Epoch 39/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.2632 - categorical_accuracy: 0.4307 - val_loss: 1.5096 - val_categorical_accuracy: 0.2857\n",
            "Epoch 40/200\n",
            "39/39 [==============================] - 0s 13ms/step - loss: 1.2523 - categorical_accuracy: 0.4189 - val_loss: 1.4539 - val_categorical_accuracy: 0.3143\n",
            "Epoch 41/200\n",
            "39/39 [==============================] - 0s 11ms/step - loss: 1.2891 - categorical_accuracy: 0.3664 - val_loss: 1.4974 - val_categorical_accuracy: 0.2857\n",
            "Epoch 42/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.3364 - categorical_accuracy: 0.3836 - val_loss: 1.3846 - val_categorical_accuracy: 0.3714\n",
            "Epoch 43/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.3235 - categorical_accuracy: 0.3814 - val_loss: 1.4805 - val_categorical_accuracy: 0.1857\n",
            "Epoch 44/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.2553 - categorical_accuracy: 0.4211 - val_loss: 1.5595 - val_categorical_accuracy: 0.1857\n",
            "Epoch 45/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.2734 - categorical_accuracy: 0.4153 - val_loss: 1.5815 - val_categorical_accuracy: 0.1714\n",
            "Epoch 46/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.2637 - categorical_accuracy: 0.3962 - val_loss: 1.7303 - val_categorical_accuracy: 0.1857\n",
            "Epoch 47/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.3262 - categorical_accuracy: 0.3696 - val_loss: 1.3171 - val_categorical_accuracy: 0.3000\n",
            "Epoch 48/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.3061 - categorical_accuracy: 0.3771 - val_loss: 1.6315 - val_categorical_accuracy: 0.2000\n",
            "Epoch 49/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.2177 - categorical_accuracy: 0.4575 - val_loss: 1.4721 - val_categorical_accuracy: 0.3143\n",
            "Epoch 50/200\n",
            "39/39 [==============================] - 0s 13ms/step - loss: 1.2668 - categorical_accuracy: 0.3965 - val_loss: 1.7250 - val_categorical_accuracy: 0.1857\n",
            "Epoch 51/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.2373 - categorical_accuracy: 0.4365 - val_loss: 1.3758 - val_categorical_accuracy: 0.3429\n",
            "Epoch 52/200\n",
            "39/39 [==============================] - 0s 11ms/step - loss: 1.2570 - categorical_accuracy: 0.4173 - val_loss: 1.3642 - val_categorical_accuracy: 0.2714\n",
            "Epoch 53/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.2774 - categorical_accuracy: 0.4044 - val_loss: 1.2805 - val_categorical_accuracy: 0.3857\n",
            "Epoch 54/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.2413 - categorical_accuracy: 0.4323 - val_loss: 1.4177 - val_categorical_accuracy: 0.3000\n",
            "Epoch 55/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.3132 - categorical_accuracy: 0.3769 - val_loss: 1.3427 - val_categorical_accuracy: 0.2714\n",
            "Epoch 56/200\n",
            "39/39 [==============================] - 0s 13ms/step - loss: 1.2476 - categorical_accuracy: 0.4192 - val_loss: 1.6141 - val_categorical_accuracy: 0.1714\n",
            "Epoch 57/200\n",
            "39/39 [==============================] - 1s 13ms/step - loss: 1.2304 - categorical_accuracy: 0.4182 - val_loss: 1.4467 - val_categorical_accuracy: 0.2143\n",
            "Epoch 58/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.2289 - categorical_accuracy: 0.4118 - val_loss: 1.3710 - val_categorical_accuracy: 0.3429\n",
            "Epoch 59/200\n",
            "39/39 [==============================] - 1s 13ms/step - loss: 1.2441 - categorical_accuracy: 0.4018 - val_loss: 1.3266 - val_categorical_accuracy: 0.2857\n",
            "Epoch 60/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.2477 - categorical_accuracy: 0.4143 - val_loss: 1.4037 - val_categorical_accuracy: 0.2571\n",
            "Epoch 61/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.2009 - categorical_accuracy: 0.4520 - val_loss: 1.6078 - val_categorical_accuracy: 0.2857\n",
            "Epoch 62/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.2516 - categorical_accuracy: 0.3995 - val_loss: 1.5101 - val_categorical_accuracy: 0.2286\n",
            "Epoch 63/200\n",
            "39/39 [==============================] - 1s 13ms/step - loss: 1.2333 - categorical_accuracy: 0.4285 - val_loss: 1.4099 - val_categorical_accuracy: 0.2143\n",
            "Epoch 64/200\n",
            "39/39 [==============================] - 0s 11ms/step - loss: 1.2021 - categorical_accuracy: 0.4092 - val_loss: 1.3964 - val_categorical_accuracy: 0.2429\n",
            "Epoch 65/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.2208 - categorical_accuracy: 0.4209 - val_loss: 1.3609 - val_categorical_accuracy: 0.3857\n",
            "Epoch 66/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.2084 - categorical_accuracy: 0.4311 - val_loss: 1.3622 - val_categorical_accuracy: 0.2571\n",
            "Epoch 67/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.2311 - categorical_accuracy: 0.4404 - val_loss: 1.2931 - val_categorical_accuracy: 0.3286\n",
            "Epoch 68/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.2243 - categorical_accuracy: 0.4561 - val_loss: 1.3939 - val_categorical_accuracy: 0.3000\n",
            "Epoch 69/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.2575 - categorical_accuracy: 0.4235 - val_loss: 1.3551 - val_categorical_accuracy: 0.3429\n",
            "Epoch 70/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.2606 - categorical_accuracy: 0.4129 - val_loss: 1.4002 - val_categorical_accuracy: 0.2571\n",
            "Epoch 71/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.2507 - categorical_accuracy: 0.4201 - val_loss: 1.3711 - val_categorical_accuracy: 0.2714\n",
            "Epoch 72/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.2486 - categorical_accuracy: 0.4017 - val_loss: 1.3589 - val_categorical_accuracy: 0.2714\n",
            "Epoch 73/200\n",
            "39/39 [==============================] - 0s 13ms/step - loss: 1.2346 - categorical_accuracy: 0.4184 - val_loss: 1.5034 - val_categorical_accuracy: 0.2714\n",
            "Epoch 74/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.2137 - categorical_accuracy: 0.4613 - val_loss: 1.3172 - val_categorical_accuracy: 0.3000\n",
            "Epoch 75/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.2122 - categorical_accuracy: 0.4507 - val_loss: 1.5154 - val_categorical_accuracy: 0.2714\n",
            "Epoch 76/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.2285 - categorical_accuracy: 0.4315 - val_loss: 1.4782 - val_categorical_accuracy: 0.2143\n",
            "Epoch 77/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.2165 - categorical_accuracy: 0.4151 - val_loss: 1.3200 - val_categorical_accuracy: 0.2857\n",
            "Epoch 78/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.1947 - categorical_accuracy: 0.4327 - val_loss: 1.3024 - val_categorical_accuracy: 0.3286\n",
            "Epoch 79/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.2797 - categorical_accuracy: 0.3891 - val_loss: 1.4040 - val_categorical_accuracy: 0.2714\n",
            "Epoch 80/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.2183 - categorical_accuracy: 0.3984 - val_loss: 1.4658 - val_categorical_accuracy: 0.2857\n",
            "Epoch 81/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.2091 - categorical_accuracy: 0.4740 - val_loss: 1.4153 - val_categorical_accuracy: 0.3429\n",
            "Epoch 82/200\n",
            "39/39 [==============================] - 1s 13ms/step - loss: 1.2230 - categorical_accuracy: 0.3971 - val_loss: 1.6046 - val_categorical_accuracy: 0.3286\n",
            "Epoch 83/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.2365 - categorical_accuracy: 0.4290 - val_loss: 1.3497 - val_categorical_accuracy: 0.3143\n",
            "Epoch 84/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.1725 - categorical_accuracy: 0.4876 - val_loss: 1.6457 - val_categorical_accuracy: 0.2571\n",
            "Epoch 85/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.2299 - categorical_accuracy: 0.4190 - val_loss: 1.6425 - val_categorical_accuracy: 0.2571\n",
            "Epoch 86/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.1935 - categorical_accuracy: 0.4614 - val_loss: 1.7102 - val_categorical_accuracy: 0.1857\n",
            "Epoch 87/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.2105 - categorical_accuracy: 0.4092 - val_loss: 1.3894 - val_categorical_accuracy: 0.2857\n",
            "Epoch 88/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.1709 - categorical_accuracy: 0.4712 - val_loss: 1.3923 - val_categorical_accuracy: 0.4286\n",
            "Epoch 89/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.1707 - categorical_accuracy: 0.4781 - val_loss: 1.6355 - val_categorical_accuracy: 0.1857\n",
            "Epoch 90/200\n",
            "39/39 [==============================] - 0s 11ms/step - loss: 1.1585 - categorical_accuracy: 0.4761 - val_loss: 1.7035 - val_categorical_accuracy: 0.2857\n",
            "Epoch 91/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.2277 - categorical_accuracy: 0.4138 - val_loss: 1.6746 - val_categorical_accuracy: 0.1857\n",
            "Epoch 92/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.2529 - categorical_accuracy: 0.3893 - val_loss: 1.4663 - val_categorical_accuracy: 0.2857\n",
            "Epoch 93/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.2204 - categorical_accuracy: 0.4401 - val_loss: 1.5541 - val_categorical_accuracy: 0.2143\n",
            "Epoch 94/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.2017 - categorical_accuracy: 0.4535 - val_loss: 1.4811 - val_categorical_accuracy: 0.3143\n",
            "Epoch 95/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.2547 - categorical_accuracy: 0.4023 - val_loss: 1.6094 - val_categorical_accuracy: 0.2714\n",
            "Epoch 96/200\n",
            "39/39 [==============================] - 1s 13ms/step - loss: 1.1661 - categorical_accuracy: 0.4775 - val_loss: 1.5058 - val_categorical_accuracy: 0.3286\n",
            "Epoch 97/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.1858 - categorical_accuracy: 0.4630 - val_loss: 1.6258 - val_categorical_accuracy: 0.3000\n",
            "Epoch 98/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.1934 - categorical_accuracy: 0.4555 - val_loss: 1.7089 - val_categorical_accuracy: 0.2571\n",
            "Epoch 99/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.1908 - categorical_accuracy: 0.4780 - val_loss: 1.5812 - val_categorical_accuracy: 0.1857\n",
            "Epoch 100/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.2232 - categorical_accuracy: 0.4393 - val_loss: 1.8104 - val_categorical_accuracy: 0.1857\n",
            "Epoch 101/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.1911 - categorical_accuracy: 0.4855 - val_loss: 1.6591 - val_categorical_accuracy: 0.2000\n",
            "Epoch 102/200\n",
            "39/39 [==============================] - 0s 13ms/step - loss: 1.2110 - categorical_accuracy: 0.4129 - val_loss: 1.5521 - val_categorical_accuracy: 0.1714\n",
            "Epoch 103/200\n",
            "39/39 [==============================] - 1s 13ms/step - loss: 1.1611 - categorical_accuracy: 0.4713 - val_loss: 1.7320 - val_categorical_accuracy: 0.2000\n",
            "Epoch 104/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.1981 - categorical_accuracy: 0.4552 - val_loss: 1.5183 - val_categorical_accuracy: 0.2714\n",
            "Epoch 105/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.1567 - categorical_accuracy: 0.4831 - val_loss: 1.7693 - val_categorical_accuracy: 0.1857\n",
            "Epoch 106/200\n",
            "39/39 [==============================] - 1s 13ms/step - loss: 1.1842 - categorical_accuracy: 0.4427 - val_loss: 1.4742 - val_categorical_accuracy: 0.2714\n",
            "Epoch 107/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.1958 - categorical_accuracy: 0.4559 - val_loss: 1.3901 - val_categorical_accuracy: 0.3857\n",
            "Epoch 108/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.2398 - categorical_accuracy: 0.4506 - val_loss: 1.4954 - val_categorical_accuracy: 0.3000\n",
            "Epoch 109/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.2236 - categorical_accuracy: 0.4397 - val_loss: 1.3983 - val_categorical_accuracy: 0.3857\n",
            "Epoch 110/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.1756 - categorical_accuracy: 0.4809 - val_loss: 1.4307 - val_categorical_accuracy: 0.3143\n",
            "Epoch 111/200\n",
            "39/39 [==============================] - 0s 11ms/step - loss: 1.1455 - categorical_accuracy: 0.4861 - val_loss: 1.8757 - val_categorical_accuracy: 0.2000\n",
            "Epoch 112/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.1425 - categorical_accuracy: 0.4924 - val_loss: 1.7843 - val_categorical_accuracy: 0.2714\n",
            "Epoch 113/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.1834 - categorical_accuracy: 0.4745 - val_loss: 1.6756 - val_categorical_accuracy: 0.2000\n",
            "Epoch 114/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.2315 - categorical_accuracy: 0.4063 - val_loss: 1.4308 - val_categorical_accuracy: 0.3286\n",
            "Epoch 115/200\n",
            "39/39 [==============================] - 1s 13ms/step - loss: 1.1735 - categorical_accuracy: 0.4777 - val_loss: 1.6402 - val_categorical_accuracy: 0.2429\n",
            "Epoch 116/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.1866 - categorical_accuracy: 0.4322 - val_loss: 1.7044 - val_categorical_accuracy: 0.2857\n",
            "Epoch 117/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.2225 - categorical_accuracy: 0.4510 - val_loss: 1.6093 - val_categorical_accuracy: 0.2714\n",
            "Epoch 118/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.1945 - categorical_accuracy: 0.4629 - val_loss: 1.5604 - val_categorical_accuracy: 0.2429\n",
            "Epoch 119/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.1434 - categorical_accuracy: 0.4843 - val_loss: 1.7111 - val_categorical_accuracy: 0.2714\n",
            "Epoch 120/200\n",
            "39/39 [==============================] - 1s 13ms/step - loss: 1.1517 - categorical_accuracy: 0.5057 - val_loss: 1.6670 - val_categorical_accuracy: 0.2857\n",
            "Epoch 121/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.1898 - categorical_accuracy: 0.4512 - val_loss: 1.7075 - val_categorical_accuracy: 0.2571\n",
            "Epoch 122/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.1398 - categorical_accuracy: 0.5106 - val_loss: 1.3412 - val_categorical_accuracy: 0.3429\n",
            "Epoch 123/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.1493 - categorical_accuracy: 0.4657 - val_loss: 1.4045 - val_categorical_accuracy: 0.3000\n",
            "Epoch 124/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.1658 - categorical_accuracy: 0.4993 - val_loss: 1.3172 - val_categorical_accuracy: 0.3143\n",
            "Epoch 125/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.1557 - categorical_accuracy: 0.4782 - val_loss: 1.5688 - val_categorical_accuracy: 0.3000\n",
            "Epoch 126/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.1864 - categorical_accuracy: 0.5036 - val_loss: 1.4362 - val_categorical_accuracy: 0.2714\n",
            "Epoch 127/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.1656 - categorical_accuracy: 0.4768 - val_loss: 1.3366 - val_categorical_accuracy: 0.3143\n",
            "Epoch 128/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.1903 - categorical_accuracy: 0.4654 - val_loss: 1.3203 - val_categorical_accuracy: 0.4571\n",
            "Epoch 129/200\n",
            "39/39 [==============================] - 0s 13ms/step - loss: 1.1480 - categorical_accuracy: 0.5044 - val_loss: 1.4882 - val_categorical_accuracy: 0.2286\n",
            "Epoch 130/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.1564 - categorical_accuracy: 0.4748 - val_loss: 1.5894 - val_categorical_accuracy: 0.2571\n",
            "Epoch 131/200\n",
            "39/39 [==============================] - 0s 13ms/step - loss: 1.1148 - categorical_accuracy: 0.5195 - val_loss: 1.5882 - val_categorical_accuracy: 0.2429\n",
            "Epoch 132/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.1293 - categorical_accuracy: 0.4939 - val_loss: 1.5901 - val_categorical_accuracy: 0.2571\n",
            "Epoch 133/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.1467 - categorical_accuracy: 0.4766 - val_loss: 1.7269 - val_categorical_accuracy: 0.2571\n",
            "Epoch 134/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.1612 - categorical_accuracy: 0.4666 - val_loss: 1.4589 - val_categorical_accuracy: 0.2857\n",
            "Epoch 135/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.1558 - categorical_accuracy: 0.4860 - val_loss: 1.5072 - val_categorical_accuracy: 0.3000\n",
            "Epoch 136/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.2062 - categorical_accuracy: 0.4487 - val_loss: 1.3787 - val_categorical_accuracy: 0.3714\n",
            "Epoch 137/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.1582 - categorical_accuracy: 0.4716 - val_loss: 1.4442 - val_categorical_accuracy: 0.3143\n",
            "Epoch 138/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.1716 - categorical_accuracy: 0.4659 - val_loss: 1.4940 - val_categorical_accuracy: 0.3000\n",
            "Epoch 139/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.1330 - categorical_accuracy: 0.4975 - val_loss: 1.3054 - val_categorical_accuracy: 0.3571\n",
            "Epoch 140/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.2063 - categorical_accuracy: 0.4685 - val_loss: 1.3944 - val_categorical_accuracy: 0.3143\n",
            "Epoch 141/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.1156 - categorical_accuracy: 0.4964 - val_loss: 1.3674 - val_categorical_accuracy: 0.3286\n",
            "Epoch 142/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.1671 - categorical_accuracy: 0.4547 - val_loss: 1.4005 - val_categorical_accuracy: 0.2857\n",
            "Epoch 143/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.1973 - categorical_accuracy: 0.4498 - val_loss: 1.4403 - val_categorical_accuracy: 0.2714\n",
            "Epoch 144/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.1818 - categorical_accuracy: 0.4754 - val_loss: 1.4517 - val_categorical_accuracy: 0.2857\n",
            "Epoch 145/200\n",
            "39/39 [==============================] - 0s 13ms/step - loss: 1.1437 - categorical_accuracy: 0.4891 - val_loss: 1.5158 - val_categorical_accuracy: 0.3143\n",
            "Epoch 146/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.1068 - categorical_accuracy: 0.4991 - val_loss: 1.3770 - val_categorical_accuracy: 0.4000\n",
            "Epoch 147/200\n",
            "39/39 [==============================] - 1s 14ms/step - loss: 1.1612 - categorical_accuracy: 0.4806 - val_loss: 1.4206 - val_categorical_accuracy: 0.3286\n",
            "Epoch 148/200\n",
            "39/39 [==============================] - 1s 13ms/step - loss: 1.2132 - categorical_accuracy: 0.4582 - val_loss: 1.3467 - val_categorical_accuracy: 0.3000\n",
            "Epoch 149/200\n",
            "39/39 [==============================] - 0s 13ms/step - loss: 1.1637 - categorical_accuracy: 0.4671 - val_loss: 1.5131 - val_categorical_accuracy: 0.2571\n",
            "Epoch 150/200\n",
            "39/39 [==============================] - 1s 14ms/step - loss: 1.1283 - categorical_accuracy: 0.5110 - val_loss: 1.5212 - val_categorical_accuracy: 0.2714\n",
            "Epoch 151/200\n",
            "39/39 [==============================] - 1s 14ms/step - loss: 1.1460 - categorical_accuracy: 0.4600 - val_loss: 1.5048 - val_categorical_accuracy: 0.3000\n",
            "Epoch 152/200\n",
            "39/39 [==============================] - 0s 13ms/step - loss: 1.1207 - categorical_accuracy: 0.4929 - val_loss: 1.5583 - val_categorical_accuracy: 0.3000\n",
            "Epoch 153/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.1253 - categorical_accuracy: 0.5032 - val_loss: 1.5364 - val_categorical_accuracy: 0.2857\n",
            "Epoch 154/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.1445 - categorical_accuracy: 0.4699 - val_loss: 1.4106 - val_categorical_accuracy: 0.3143\n",
            "Epoch 155/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.1292 - categorical_accuracy: 0.4945 - val_loss: 1.5778 - val_categorical_accuracy: 0.2714\n",
            "Epoch 156/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.1491 - categorical_accuracy: 0.4771 - val_loss: 1.4986 - val_categorical_accuracy: 0.3000\n",
            "Epoch 157/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.1240 - categorical_accuracy: 0.5086 - val_loss: 1.4650 - val_categorical_accuracy: 0.2714\n",
            "Epoch 158/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.1309 - categorical_accuracy: 0.5092 - val_loss: 1.3454 - val_categorical_accuracy: 0.3429\n",
            "Epoch 159/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.0914 - categorical_accuracy: 0.5296 - val_loss: 1.4458 - val_categorical_accuracy: 0.3286\n",
            "Epoch 160/200\n",
            "39/39 [==============================] - 1s 13ms/step - loss: 1.1109 - categorical_accuracy: 0.4828 - val_loss: 1.6292 - val_categorical_accuracy: 0.2857\n",
            "Epoch 161/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.1528 - categorical_accuracy: 0.4790 - val_loss: 1.5941 - val_categorical_accuracy: 0.2714\n",
            "Epoch 162/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.0903 - categorical_accuracy: 0.4907 - val_loss: 1.6808 - val_categorical_accuracy: 0.2714\n",
            "Epoch 163/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.1008 - categorical_accuracy: 0.5004 - val_loss: 1.3579 - val_categorical_accuracy: 0.3286\n",
            "Epoch 164/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.0992 - categorical_accuracy: 0.5129 - val_loss: 1.3917 - val_categorical_accuracy: 0.3143\n",
            "Epoch 165/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.1336 - categorical_accuracy: 0.5077 - val_loss: 1.5870 - val_categorical_accuracy: 0.2857\n",
            "Epoch 166/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.1315 - categorical_accuracy: 0.4950 - val_loss: 1.5117 - val_categorical_accuracy: 0.3000\n",
            "Epoch 167/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.1189 - categorical_accuracy: 0.4902 - val_loss: 1.6104 - val_categorical_accuracy: 0.2429\n",
            "Epoch 168/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.0934 - categorical_accuracy: 0.4960 - val_loss: 1.3915 - val_categorical_accuracy: 0.3429\n",
            "Epoch 169/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.1088 - categorical_accuracy: 0.4915 - val_loss: 1.5531 - val_categorical_accuracy: 0.2857\n",
            "Epoch 170/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.0968 - categorical_accuracy: 0.5032 - val_loss: 1.5796 - val_categorical_accuracy: 0.2857\n",
            "Epoch 171/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.0924 - categorical_accuracy: 0.5056 - val_loss: 1.5194 - val_categorical_accuracy: 0.3286\n",
            "Epoch 172/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.1579 - categorical_accuracy: 0.4638 - val_loss: 1.5136 - val_categorical_accuracy: 0.2714\n",
            "Epoch 173/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.1109 - categorical_accuracy: 0.5053 - val_loss: 1.3818 - val_categorical_accuracy: 0.3429\n",
            "Epoch 174/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.1794 - categorical_accuracy: 0.4657 - val_loss: 1.3967 - val_categorical_accuracy: 0.3857\n",
            "Epoch 175/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.1394 - categorical_accuracy: 0.4982 - val_loss: 1.5370 - val_categorical_accuracy: 0.3143\n",
            "Epoch 176/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.1662 - categorical_accuracy: 0.5104 - val_loss: 1.3730 - val_categorical_accuracy: 0.3429\n",
            "Epoch 177/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.1039 - categorical_accuracy: 0.4976 - val_loss: 1.3794 - val_categorical_accuracy: 0.3000\n",
            "Epoch 178/200\n",
            "39/39 [==============================] - 1s 13ms/step - loss: 1.1007 - categorical_accuracy: 0.4954 - val_loss: 1.3995 - val_categorical_accuracy: 0.2857\n",
            "Epoch 179/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.1458 - categorical_accuracy: 0.4576 - val_loss: 1.7102 - val_categorical_accuracy: 0.2286\n",
            "Epoch 180/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.1009 - categorical_accuracy: 0.4902 - val_loss: 1.5558 - val_categorical_accuracy: 0.2571\n",
            "Epoch 181/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.0892 - categorical_accuracy: 0.5264 - val_loss: 1.4242 - val_categorical_accuracy: 0.3143\n",
            "Epoch 182/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.0917 - categorical_accuracy: 0.5352 - val_loss: 1.3357 - val_categorical_accuracy: 0.3000\n",
            "Epoch 183/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.1241 - categorical_accuracy: 0.5399 - val_loss: 1.7794 - val_categorical_accuracy: 0.2714\n",
            "Epoch 184/200\n",
            "39/39 [==============================] - 0s 13ms/step - loss: 1.0928 - categorical_accuracy: 0.5043 - val_loss: 1.5268 - val_categorical_accuracy: 0.2571\n",
            "Epoch 185/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.0775 - categorical_accuracy: 0.5439 - val_loss: 1.7457 - val_categorical_accuracy: 0.2714\n",
            "Epoch 186/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.1040 - categorical_accuracy: 0.4874 - val_loss: 1.5076 - val_categorical_accuracy: 0.3286\n",
            "Epoch 187/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.0874 - categorical_accuracy: 0.5301 - val_loss: 1.3913 - val_categorical_accuracy: 0.2857\n",
            "Epoch 188/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.1045 - categorical_accuracy: 0.5001 - val_loss: 1.5536 - val_categorical_accuracy: 0.2857\n",
            "Epoch 189/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.0966 - categorical_accuracy: 0.5032 - val_loss: 1.4676 - val_categorical_accuracy: 0.2857\n",
            "Epoch 190/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.0453 - categorical_accuracy: 0.5280 - val_loss: 1.4568 - val_categorical_accuracy: 0.2857\n",
            "Epoch 191/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.1307 - categorical_accuracy: 0.4759 - val_loss: 1.7174 - val_categorical_accuracy: 0.2571\n",
            "Epoch 192/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.0275 - categorical_accuracy: 0.5083 - val_loss: 1.9555 - val_categorical_accuracy: 0.2571\n",
            "Epoch 193/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.1460 - categorical_accuracy: 0.4659 - val_loss: 1.7125 - val_categorical_accuracy: 0.2714\n",
            "Epoch 194/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.0925 - categorical_accuracy: 0.5081 - val_loss: 1.7762 - val_categorical_accuracy: 0.2714\n",
            "Epoch 195/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.0750 - categorical_accuracy: 0.4939 - val_loss: 1.4974 - val_categorical_accuracy: 0.3143\n",
            "Epoch 196/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.0999 - categorical_accuracy: 0.5133 - val_loss: 1.7666 - val_categorical_accuracy: 0.2429\n",
            "Epoch 197/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.0816 - categorical_accuracy: 0.5209 - val_loss: 1.4645 - val_categorical_accuracy: 0.3143\n",
            "Epoch 198/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.0982 - categorical_accuracy: 0.4904 - val_loss: 1.4551 - val_categorical_accuracy: 0.3571\n",
            "Epoch 199/200\n",
            "39/39 [==============================] - 1s 13ms/step - loss: 1.1052 - categorical_accuracy: 0.5015 - val_loss: 1.4596 - val_categorical_accuracy: 0.3143\n",
            "Epoch 200/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 1.0572 - categorical_accuracy: 0.5437 - val_loss: 1.4458 - val_categorical_accuracy: 0.3714\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7EK00Y1YlwN"
      },
      "source": [
        "model.save('/content/drive/MyDrive/Colab Notebooks/SPEECH_EMOTION_Recognition/Nộp bài(chốt hạ)/model_saver/conv1D_tempogram_ravdess.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-IJkqk5GYqZv"
      },
      "source": [
        "###test_result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6xsvUv0uYqZw",
        "outputId": "bd2b3dbe-d5ff-435f-da12-50005835e7e6"
      },
      "source": [
        "d = {0: 'happy',\n",
        "     1: 'sad',\n",
        "     2: 'angry',\n",
        "     3: 'fear'}\n",
        "Y_test_pred = np.argmax(model.predict(X_test), axis=-1)\n",
        "Y_test_pred = list(map(lambda x: d[x], Y_test_pred))\n",
        "y_test = np.argmax(y_test, axis=-1)\n",
        "y_test = list(map(lambda x: d[x], y_test))\n",
        "print(classification_report(y_test, Y_test_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.56      0.38      0.45        13\n",
            "        fear       0.36      0.57      0.44        21\n",
            "       happy       0.29      0.09      0.13        23\n",
            "         sad       0.43      0.60      0.50        20\n",
            "\n",
            "    accuracy                           0.40        77\n",
            "   macro avg       0.41      0.41      0.38        77\n",
            "weighted avg       0.39      0.40      0.37        77\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "id": "4BqxboO8YqZx",
        "outputId": "6acfc060-cd70-4bfc-dd9a-05f5a8efa129"
      },
      "source": [
        "import scikitplot as skplt\n",
        "\n",
        "skplt.metrics.plot_confusion_matrix(\n",
        "    y_test, \n",
        "    Y_test_pred,\n",
        "    figsize=(8,8))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fd8e6b93a90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 128
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAecAAAHLCAYAAADyY1AZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de7xc87n48c+TBEFCEKWoEreWuKeIVqo0inLwK6VNS1D3a28OR1VLW6en55zSq6aqFEUVLapotY5SJBHU/XKaKhGNRDkSVOw8vz9mpd1Jc9nZmZk1a+3P22teZtZa813PLGM/83zXd31XZCaSJKlz9Cs7AEmSNC+TsyRJHcbkLElShzE5S5LUYUzOkiR1GJOzJEkdxuQsSVITRMSFETEtIh7qtuxrEfFYRPwhIq6NiCE9acvkLElSc1wE7D7fsl8BwzNzC+AJ4LSeNGRyliSpCTLzduDF+ZbdkplvFi/vBtbpSVsmZ0mS2uMw4Jc92XBAiwORJKnt+q/09sw3X2tqm/naCw8Dr3dbNC4zx/XkvRFxOvAmcFlPtjc5S5JqJ998jeU2+XBT23z9/m+/npkjlvR9ETEW2AvYNXt4QwuTsySphgKi/DO3EbE7cArw3sx8tafvKz9ySZJqICIuB+4CNomIZyPicOBbwGDgVxFxf0Sc35O2rJwlSfUTQERbd5mZH1nA4h/0pi0rZ0mSOoyVsySpnjrgnHNvmZwlSfXU5m7tZqruzwpJkmrKylmSVEOdcSlVb1U3ckmSasrKWZJUTxU+52xyliTVT2C3tiRJah4rZ0lSDUWlu7WtnCVJ6jBWzpKkeqrwOWeTsySpnuzWliRJzWLlLEmqIWcIkyRJTWTlLEmqn8BzzpIkqXlMzlKTRMTyEXF9RLwcEVctRTtjIuKWZsZWhoj4ZUQcUnYc6sOiX3MfbWRyVp8TER+NiIkRMTMiphZJ5D1NaHp/YA1gtcw8oLeNZOZlmblbE+KZR0TsHBEZEdfOt3zLYvltPWznCxFx6eK2y8w9MvPiXoYrLaUwOUtVERGfAs4FvkIjka4LfAfYpwnNvx14IjPfbEJbrfICMDIiVuu27BDgiWbtIBr82yItBf8HUp8RESsDZwHHZeY1mTkrM2dn5vWZ+dlim+Ui4tyIeK54nBsRyxXrdo6IZyPi0xExrai6Dy3WfRH4PHBgUZEfPn+FGRHrFRXqgOL12Ij4Y0S8EhGTI2JMt+V3dHvfjhExoegunxARO3Zbd1tEnB0Rdxbt3BIRQxdxGN4AfgYcVLy/P3AgcNl8x+q8iHgmIv4vIu6NiJ2K5bsD/9btcz7QLY4vR8SdwKvAsGLZJ4r1342Iq7u1/9WIuDWiwiN21Pn6RXMf7Qy9rXuTyjUSGAhcu4htTgd2ALYCtgS2Az7Xbf2awMrA2sDhwLcjYpXMPJNGNX5lZg7KzB8sKpCIWBH4BrBHZg4GdgTuX8B2qwK/KLZdDfhv4BfzVb4fBQ4F3gIsC3xmUfsGfgQcXDz/APAQ8Nx820ygcQxWBX4MXBURAzPzpvk+55bd3vNx4EhgMPD0fO19Gti8+OGxE41jd0hm5mJilfokk7P6ktWA6Yvpdh4DnJWZ0zLzBeCLNJLOXLOL9bMz80ZgJrBJL+OZAwyPiOUzc2pmPryAbT4IPJmZl2Tmm5l5OfAYsHe3bX6YmU9k5mvAT2gk1YXKzN8Dq0bEJjSS9I8WsM2lmTmj2Od/Acux+M95UWY+XLxn9nztvUrjOP43cClwQmY+u5j2pN6bez9nzzlLHW8GMHRut/JCrMW8Vd/TxbK/tzFfcn8VGLSkgWTmLBrdyUcDUyPiFxHxjh7EMzemtbu9fr4X8VwCHA+8jwX0JETEZyLi0aIr/SUavQWL6i4HeGZRKzPzHuCPNP5s/qQHMUpLJ6K5jzYyOasvuQv4G7DvIrZ5jsbArrnW5Z+7fHtqFrBCt9drdl+ZmTdn5mjgrTSq4e/3IJ65MU3pZUxzXQIcC9xYVLV/V3Q7nwJ8GFglM4cAL9NIqgAL64peZBd1RBxHowJ/rmhf0kKYnNVnZObLNAZtfTsi9o2IFSJimYjYIyL+o9jscuBzEbF6MbDq8zS6YXvjfmBURKxbDEY7be6KiFgjIvYpzj3/jUb3+JwFtHEjsHFx+deAiDgQ2BS4oZcxAZCZk4H30jjHPr/BwJs0RnYPiIjPAyt1W/8XYL0lGZEdERsDXwI+RqN7+5SIWGT3u7R0vJRKqozi/OmnaAzyeoFGV+zxNEYwQyOBTAT+ADwITCqW9WZfvwKuLNq6l3kTar8ijueAF2kkymMW0MYMYC8aA6pm0Kg498rM6b2Jab6278jMBfUK3AzcROPyqqeB15m3y3ruBCszImLS4vZTnEa4FPhqZj6QmU/SGPF9ydyR8JLmFQ6WlCTVTb+V1snltj+hqW2+/utT783MEU1tdCG88YUkqZ4qPBdOdSOXJKmmrJwlSfVTwuVPzWTlLElSh7FyliTVU4XPOfep5LziyqvmqmuuvfgNpQ636grLlh1C7XXN8UqWVpvyzJ/564vTW9f3XOFu7T6VnFddc20+Oe7nZYchLbWPbLVO2SHU3kuzZi9+Iy2VA/bYqewQOlafSs6SpL4iKt2tXd3IJUmqKStnSVI9Vfics5WzJEkdxspZklQ/QaXPOZucJUk15IAwSZLURFbOkqR6ckCYJElqFitnSVI9Vfics8lZklRPdmtLkqRmsXKWJNVPeCmVJElqIitnSVI9Vfics8lZklRLUeHkbLe2JEkdxspZklQ7gZWzJElqIitnSVL9RPGoKCtnSZI6jJWzJKmGotLnnE3OkqRaqnJytltbkqQOY+UsSaolK2dJktQ0Vs6SpFqqcuVscpYk1Y/XOUuSpIi4MCKmRcRD3ZatGhG/iogni3+v0pO2TM6SpNqJ4jrnZj564CJg9/mWnQrcmpkbAbcWrxfL5CxJUhNk5u3Ai/Mt3ge4uHh+MbBvT9rynLMkqZZaMCBsaERM7PZ6XGaOW8x71sjMqcXz54E1erIjk7MkqZZakJynZ+aI3r45MzMisifb2q0tSVLr/CUi3gpQ/HtaT95kcpYk1VIJA8IW5DrgkOL5IcDPe/Imk7MkSU0QEZcDdwGbRMSzEXE48O/A6Ih4Enh/8XqxPOcsSaqfEiYhycyPLGTVrkvalpWzJEkdxsq5Q33pwFEst8KK9OvXn379+/PJcT06TaEl5HFurU8edyS/vvlGhq6+Or+9676yw6mlqVOe5bSTjmD69GlEBB8ecygf/8RxZYfVEZxbWy1xzNcvY9CQVcsOo/Y8zq1z4Ec/zqFHHMNJxxxWdii1NWDAAE458xw23XwrZs18hf1334mRo3Zhw43fWXZopZo7Q1hVVbJbOyL8USFVwA7v3olVVunRVMLqpdXXWJNNN98KgBUHDWbYRpsw7fmpi3mXOl1bklxE/Ax4GzAQOC8zx0XETOA8YC/gNWCfzPxLRGwAXAasSGPI+cmZOSgidgbOBv4KvCMirgBezMxzi318GZiWmee14zO1WkQw7rNjiYAd9v4II/de2DgDLQ2Ps+pkyjNP8+hDD7DF1r2eJ6NWqlw5t6sCPSwzX4yI5YEJEXE1jeR7d2aeHhH/ARwBfIlGwj4vMy+PiKPna2cbYHhmTo6I9YBrgHMjoh9wELDd/DuOiCOBIwFWWWOt1ny6Fjj+m1ey8upr8spfp/O9zxzCW9bdgA22/KePp6XkcVZdzJo1k5OOGMNpX/wqgwavVHY4Wkrt6tY+MSIeAO6mUUFvBLwB3FCsvxdYr3g+EriqeP7j+doZn5mTATLzT8CMiNga2A24LzNnzL/jzByXmSMyc8SKK1fnvOLKq68JwOBVhrL5e3bjz48+UHJE9eRxVh3Mnj2bk48Yw177HcjoPfcpO5zOEU1+tFHLk3PRHf1+YGRmbgncR6N7e3Zmzp1jtIueVfGz5nt9ATAWOBS4sBnxdoK/vfYqr7868+/PH5/4O966/sYlR1U/HmfVQWZyxqePZdiGmzD2qBPKDqdzRMfMENYr7ejWXhn4a2a+GhHvAHZYzPZ3Ax8CrqTRVb0o1wJnAcsAH13aQDvFzL9O54dnHAPAnK4uttl1b96x/XtLjqp+PM6td8zhH+euO27nxRnT2XbTYXz61DP46MGHlh1WrUyacBfXXX05G79zM/YbPRKAk0/9Au/d9QMlR6al0Y7kfBNwdEQ8CjxOI/kuysnApRFxevHelxe2YWa+ERG/BV7KzK5mBVy21dZal8/84Bdlh1F7HufW++4PLik7hNrbdrsdeWTKzLLD6EgOCFuEzPwbsMcCVg3qts1PgZ8WL6cAOxS31joI2KTY5jbgtu4NFAPBdgAOaHrgkiSVpBOvF94W+FY0fvK8BCxw9oKI2JTGgLJrM/PJNsYnSaoAK+cmyszfAVv2YLtHgGGtj0iSVDXOECZJkpqq4ypnSZKaorqFs5WzJEmdxspZklQ/Ue0BYVbOkiR1GCtnSVItVblyNjlLkmqpysnZbm1JkjqMlbMkqZ6qWzhbOUuS1GmsnCVJtVTlc84mZ0lS7UQ4t7YkSWoiK2dJUi1ZOUuSpKaxcpYk1VKVK2eTsySpnqqbm+3WliSp01g5S5Jqqcrd2lbOkiR1GCtnSVL9hJWzJElqIitnSVLtBFDhwtnkLEmqI+fWliRJTWTlLEmqpQoXzlbOkiR1GitnSVItVfmcs8lZklQ/Ybe2JElqIitnSVLtBNCvX3VLZytnSZI6jJWzJKmWqnzO2eQsSaqlKo/WtltbkqQOY+UsSaqfil9K1aeS88oDl2GPjdYoO4xa2+aD/1p2CH3CHr/4atkh1N4vn/xL2SHU3suvzy47hI7Vp5KzJKlvaNwysrqls+ecJUnqMFbOkqQaqvb9nE3OkqRaqnButltbkqROY+UsSaqlKndrWzlLktRhrJwlSfXjJCSSJHUWr3OWJElNZeUsSaqlChfOVs6SJHUaK2dJUi15zlmSpA4T0dxHz/YZn4yIhyPioYi4PCIG9iZ2k7MkSU0QEWsDJwIjMnM40B84qDdt2a0tSaqfKK1bewCwfETMBlYAnutNI1bOkiQ1QWZOAf4T+DMwFXg5M2/pTVsmZ0lS7TQmIWn6OeehETGx2+PIefYZsQqwD7A+sBawYkR8rDfx260tSVLPTM/MEYtY/35gcma+ABAR1wA7Apcu6Y5MzpKkGooyzjn/GdghIlYAXgN2BSb2piGTsySpltqdmzPznoj4KTAJeBO4DxjXm7ZMzpIkNUlmngmcubTtmJwlSbXkDGGSJKlprJwlSfWzBFNudiKTsySpdhrXOVc3O9utLUlSh7FyliTVkpWzJElqGitnSVItVbhwNjlLkurJbm1JktQ0Vs6SpPqp+HXOVs6SJHUYK2dJUu1EObeMbBqTsySpliqcm+3WliSp01g5S5JqqV+FS2crZ0mSOoyVsySplipcOJucO9HUKc9y2klHMH36NCKCD485lI9/4riyw6qF888cwx6jhvPCi68w4oCvAPCVk/dlz1HDeWN2F5Ofnc6RZ17KyzNfKznSevC73B5fOnAUy62wIv369adf//58ctzPyw5JS6kjknNEnAgcA0zKzDFlx1O2AQMGcMqZ57Dp5lsxa+Yr7L/7TowctQsbbvzOskOrvEuuv5vzr/wfLjj74L8vu/Xuxzjjm9fR1TWHL524D589bDc+9w3/uDWD3+X2OebrlzFoyKplh9ExIpy+sxmOBUYvTWKOiI74odEMq6+xJptuvhUAKw4azLCNNmHa81NLjqoe7pz0v7z48qvzLLv17sfo6poDwPgHJ7P2GkPKCK2W/C6rTP2iuY+2xt7e3f2ziDgfGAb8MiJOj4gLI2J8RNwXEfsU26wXEb+LiEnFY8di+c7F8uuAR0r8GC0z5ZmnefShB9hi6xFlh9InHLzPSG6+s5ZfpdL5XW6diGDcZ8fy9SP/hbuuv7zscNQEpVebmXl0ROwOvA/4FPCbzDwsIoYA4yPi18A0GpX16xGxEXA5MPf/8G2A4Zk5uYz4W2nWrJmcdMQYTvviVxk0eKWyw6m9Uw7/AF1dc7jixgllh1I7fpdb6/hvXsnKq6/JK3+dzvc+cwhvWXcDNthyu7LDKp3d2s2zG3BqRNwP3AYMBNYFlgG+HxEPAlcBm3Z7z/hFJeaIODIiJkbExBdnTG9d5E02e/ZsTj5iDHvtdyCj99yn7HBq72N7b8+eo4Yz9vSLyg6ldvwut97Kq68JwOBVhrL5e3bjz48+UHJEWlqdlpwD+FBmblU81s3MR4FPAn8BtqRRMS/b7T2zFtVgZo7LzBGZOWLV1Ya2LPBmykzO+PSxDNtwE8YedULZ4dTe6B3fyafGvp/9T/4er70+u+xwasXvcuv97bVXef3VmX9//vjE3/HW9TcuOarOENHcRzuV3q09n5uBEyLihMzMiNg6M+8DVgaezcw5EXEI0L/cMFtr0oS7uO7qy9n4nZux3+iRAJx86hd4764fKDmy6rv4nLHstO1GDB0yiKduOpuzz7+Rzx66G8stO4Abvns8AOMf/BMnfvmKkiOtB7/LrTfzr9P54RnHADCnq4ttdt2bd2z/3pKjKl/QuPlFVXVacj4bOBf4Q0T0AyYDewHfAa6OiIOBm1hMtVx12263I49MmVl2GLV0yGkX/dOyi392V/sD6SP8Lrfeamuty2d+8Iuyw1CTdURyzsz1ur08agHrnwS26LboX4vlt9E4Ny1J0jzafflTM3XaOWdJkvq8jqicJUlqqohKX0plcpYk1VKFc7Pd2pIkdRorZ0lS7QTQr8Kls5WzJEkdxspZklRLFS6crZwlSeo0Vs6SpFryUipJkjpIGTeraCa7tSVJ6jBWzpKkWvJSKkmS1DRWzpKkWqpu3WxyliTVVJVHa9utLUlSh7FyliTVTmNu7bKj6L2FJueI+CaQC1ufmSe2JCJJkvq4RVXOE9sWhSRJzRRR6XPOC03OmXlx99cRsUJmvtr6kCRJWnoVzs2LHxAWESMj4hHgseL1lhHxnZZHJklSH9WT0drnAh8AZgBk5gPAqFYGJUnS0oqia7tZj3bq0aVUmfnMfIu6WhCLJEmiZ5dSPRMROwIZEcsAJwGPtjYsSZJ6r+qXUvWkcj4aOA5YG3gO2Kp4LUmSWmCxlXNmTgfGtCEWSZKapsqXUvVktPawiLg+Il6IiGkR8fOIGNaO4CRJ6q1o8qOdetKt/WPgJ8BbgbWAq4DLWxmUJEl9WU+S8wqZeUlmvlk8LgUGtjowSZJ6KwL6RTT10U6Lmlt71eLpLyPiVOAKGnNtHwjc2IbYJEnqkxY1IOxeGsl47s+Fo7qtS+C0VgUlSdLSqvB4sEXOrb1+OwORJKmZqjxau0f3c46I4cCmdDvXnJk/alVQkiT1ZYtNzhFxJrAzjeR8I7AHcAdgcpYkdawKF849Gq29P7Ar8HxmHgpsCazc0qgkSerDetKt/VpmzomINyNiJWAa8LYWxyVJUq8F7b/8qZl6kpwnRsQQ4Ps0RnDPBO5qaVSSJC2NKKdbu8iXFwDDaVzZdFhmLnHO7Mnc2scWT8+PiJuAlTLzD0u6I0mS+oDzgJsyc/+IWBZYoTeNLGoSkm0WtS4zJ/Vmh5IktUO7L6WKiJWBUcBYgMx8A3ijN20tqnL+r0WsS2CX3uywTMsN6Mf6b1mx7DAkVcA3f+Zt61tt2kuvlx3CkhoaERO7vR6XmeO6vV4feAH4YURsSeNU8EmZOWtJd7SoSUjet6SNSZLUKXpyOdISmp6ZIxaxfgCwDXBCZt4TEecBpwJnLOmOWhC7JEl90rPAs5l5T/H6pzSS9RLr0QxhkiRVSdD+c86Z+XxEPBMRm2Tm4zTmCHmkN22ZnCVJtdSvnMucTwAuK0Zq/xE4tDeN9GT6zgDGAMMy86yIWBdYMzPH92aHkiTVVWbeDyzqvHSP9OSc83eAkcBHitevAN9e2h1LktRK/aK5j3bqSbf29pm5TUTcB5CZfy3KdUmS1AI9Sc6zI6I/jWubiYjVgTktjUqSpKUQUf/7OX8DuBZ4S0R8mcZdqj7X0qgkSVpKJQ0Ia4qezK19WUTcS2NIeAD7ZqZT50iS1CI9Ga29LvAqcH33ZZn551YGJknS0qhwr3aPurV/QeN8cwADacwd+jiwWQvjkiSpz+pJt/bm3V8Xd6s6diGbS5JUugD6Vbh0XuIZwjJzUkRs34pgJElqlirfPKIn55w/1e1lPxqTeD/XsogkSerjelI5D+72/E0a56Cvbk04kiQ1R4V7tRednIvJRwZn5mfaFI8kSX3eQpNzRAzIzDcj4t3tDEiSpKUVEbUdEDaexvnl+yPiOuAqYNbclZl5TYtjkySpT+rJOeeBwAxgF/5xvXMCJmdJUseqcOG8yOT8lmKk9kP8IynPlS2NSpKkpVTXubX7A4OYNynPZXKWJKlFFpWcp2bmWW2LRJKkJqn6DGGLmkClup9KkqQKW1TlvGvbopAkqckqXDgvPDln5ovtDESSpKaJag8Iq/K84JIk1dIS35VKkqQqiAoPnbJyliSpw1g5S5Jqp3EpVdlR9J7JWZJUS1VOznZrS5LUYaycJUm1FBW+0NnKWZKkDmPlLEmqnaoPCLNyliSpw1g5S5LqJ2o6t7YkSVVW11tGSpKkEpicO9QtN9/EFpttwmbv2JCv/ce/lx1ObZx/5hievvUcJl71b39f9pWT9+X+az7H+CtP48r/OoKVBy1fYoT1MnXKs4zdfw/22nlb9n7fCC654Ntlh1RLY0etx02njOLmfx3FoaPWKzucjjB3QFgzH+3UsuQcEetFxEOtar/Ourq6OPnE4/j59b/kvj88wlVXXM6jjzxSdli1cMn1d7PPcfMmiFvvfoxtD/gK2x14Dk8+PY3PHrZbSdHVz4ABAzjlzHO44bZ7ueL63/Lji77PU088WnZYtbLxmoM4aId12ffrd7Dn137HLputwduHrlB2WFpKVs4daML48WywwYasP2wYyy67LAcceBA3XP/zssOqhTsn/S8vvvzqPMtuvfsxurrmADD+wcmsvcaQMkKrpdXXWJNNN98KgBUHDWbYRpsw7fmpJUdVLxuuMYj7n36J12fPoWtOMv6pGey+xZplh9URIpr7aKdWJ+f+EfH9iHg4Im6JiOUj4oiImBARD0TE1RGxAkBEXBQR50fExIh4IiL2KpaPjYifR8RtEfFkRJxZLD8rIk6eu6OI+HJEnNTiz9MWzz03hXXWedvfX6+99jpMmTKlxIj6joP3GcnNd9pL0QpTnnmaRx96gC22HlF2KLXy+NSZbDdsFYassAwDl+nHzpu+hbcO8dQMBP2a/GinVifnjYBvZ+ZmwEvAh4BrMvNdmbkl8ChweLft1wO2Az4InB8RA4vl2xXv3QI4ICJGABcCBwNERD/gIODSFn8e1dgph3+Arq45XHHjhLJDqZ1Zs2Zy0hFjOO2LX2XQ4JXKDqdW/nfaTM7/zR/50dHbc/FR2/HIlP+ja06WHZaWUqsvpZqcmfcXz++lkXyHR8SXgCHAIODmbtv/JDPnAE9GxB+BdxTLf5WZMwAi4hrgPZl5bkTMiIitgTWA++Zu011EHAkcCfC2dddt+gdshbXWWptnn33m76+nTHmWtddeu8SI6u9je2/PnqOGs8dR3yg7lNqZPXs2Jx8xhr32O5DRe+5Tdji19JN7nuEn9zT+Znxmz014/uXXS46ofEG1r3NudeX8t27Pu2j8GLgIOD4zNwe+CAzsts38P/dyMcsvAMYCh9KopP9JZo7LzBGZOWL1oasvafylGPGud/HUU0/yp8mTeeONN7jqyiv44F7/UnZYtTV6x3fyqbHvZ/+Tv8drr88uO5xayUzO+PSxDNtwE8YedULZ4dTWaoOWBWCtIQPZfYs1+fm9ngarujImIRkMTI2IZYAxQPdv0QERcTGwPjAMeBzYGhgdEasCrwH7AocV218LnAUsA3y0PeG33oABA/j6ed9i7w9+gK6uLg4ZexibbrZZ2WHVwsXnjGWnbTdi6JBBPHXT2Zx9/o189tDdWG7ZAdzw3eMBGP/gnzjxy1eUHGk9TJpwF9ddfTkbv3Mz9hs9EoCTT/0C7931AyVHVi/fPXRbhqywDG92JZ+/+iFeef3NskMqXwmXPzVTGcn5DOAe4IXi34O7rfszMB5YCTg6M18vbvk1HrgaWAe4NDMnAmTmGxHxW+ClzOxq30dovd332JPd99iz7DBq55DTLvqnZRf/7K72B9JHbLvdjjwyZWbZYdTeh7/pd3hBqjxDWMuSc2b+CRje7fV/dlv93YW87deZefQClj+bmfvOv7AYCLYDcMBShCpJUkep7HXOEbEp8BRwa2Y+WXY8kqTOMXdAWFWvc+6YG19k5tiFLL+IxiCy+Zc/QuO8tCRJtdIxyVmSpGaq8jnnynZrS5JUV1bOkqRaqnDhbHKWJNVPUO2u4SrHLklSLVk5S5LqJyAq3K9t5SxJUoexcpYk1VJ162aTsySphgKvc5YkSU1k5SxJqqXq1s1WzpIkdRwrZ0lSLVX4lLPJWZJUR+F1zpIkqXmsnCVJtePc2pIkqamsnCVJtVTWOeeI6A9MBKZk5l69acPKWZKk5joJeHRpGjA5S5JqKZr86NE+I9YBPghcsDSx260tSaqf8m4ZeS5wCjB4aRqxcpYkqWeGRsTEbo8ju6+MiL2AaZl579LuyMpZklQ7LbqUanpmjljE+ncD/xIRewIDgZUi4tLM/NiS7sjKWZKkJsjM0zJzncxcDzgI+E1vEjNYOUuSaqrK03eanCVJtVRmas7M24Dbevt+u7UlSeowVs6SpFqqcK+2lbMkSZ3GylmSVDuNS6mqWzqbnCVJtWS3tiRJahorZ0lSDQVR4W5tK2dJkjqMlbMkqZaqfM7Z5CxJqp2qj9a2W1uSpA7Tpyrnv705h8nTZpUdRq1d8sN/KzsEqSmev+2XZYdQe7Nfebl1jUe1u7WtnCVJ6jB9qnKWJPUdVs6SJKlprJwlSbVU5UlITM6SpNoJoF91c7Pd2pIkdRorZ0lSLVW5W9vKWZKkDmPlLEmqpSpfSmVyliTVkt3akiSpaaycJUm146VUkiSpqaycJUk1FJU+5+NkqvgAAA8mSURBVGxyliTVj7eMlCRJzWTlLEmqpQoXzlbOkiR1GitnSVLtNC6lqm7tbOUsSVKHsXKWJNVSdetmk7Mkqa4qnJ3t1pYkqcNYOUuSaqnKM4RZOUuS1GGsnCVJtVThK6lMzpKkeqpwbrZbW5KkTmPlLEmqpwqXzlbOkiR1GCtnSVLtBNW+lMrkLEmqn6j2aG27tSVJ6jBWzpKkWqpw4WzlLElSp7FyliTVU4VLZytnSZI6jJWzJKmGwkupJEnqNF5KJUmSmsbKuQNNnfIsp510BNOnTyMi+PCYQ/n4J44rO6xa6urq4tQxe7DqW9bktG/8qOxwasfvcmucf+YY9hg1nBdefIURB3wFgK+cvC97jhrOG7O7mPzsdI4881JenvlayZGWJ6j0eLB6VM4RsV5EPFR2HM0yYMAATjnzHG647V6uuP63/Pii7/PUE4+WHVYt3fjjC1h7/Y3KDqO2/C63xiXX380+x317nmW33v0Y2x7wFbY78ByefHoanz1st5KiUzPUIjnXzeprrMmmm28FwIqDBjNso02Y9vzUkqOqnxl/eY5Jd9zKrvt9pOxQasvvcmvcOel/efHlV+dZduvdj9HVNQeA8Q9OZu01hpQRWmeJJj/aqKO6tSNiReAnwDpAf+BsYBNgb2B54PfAUZmZEbEtcGHx1ltKCLctpjzzNI8+9ABbbD2i7FBq54dfO5OPnfQ5Xn91Ztmh9Al+l9vn4H1G8tNbJpUdRumqPFq70yrn3YHnMnPLzBwO3AR8KzPfVbxeHtir2PaHwAmZueWiGoyIIyNiYkRMfHHG9JYG32yzZs3kpCPGcNoXv8qgwSuVHU6t3Hv7r1h51aFssOkWZYfSJ/hdbp9TDv8AXV1zuOLGCWWHoqXQacn5QWB0RHw1InbKzJeB90XEPRHxILALsFlEDAGGZObtxfsuWViDmTkuM0dk5ohVVxva+k/QJLNnz+bkI8aw134HMnrPfcoOp3Yeu38iE//nFo7dc3u+fuqxPDThTr5x+gllh1VLfpfb52N7b8+eo4Yz9vSLyg6lI0Q099FOHdWtnZlPRMQ2wJ7AlyLiVuA4YERmPhMRXwAGlhljO2QmZ3z6WIZtuAljjzJhtMKYE09jzImnAfDwxN9z3Y/O58Qvf7PkqOrH73L7jN7xnXxq7PvZ7RPn8drrs8sOR0upoyrniFgLeDUzLwW+BmxTrJoeEYOA/QEy8yXgpYh4T7F+TNuDbaFJE+7iuqsv557f/w/7jR7JfqNH8j+33lx2WNIS87vcGhefM5bbLv40G799DZ666WwO2XckX//XDzN4hYHc8N3jufuKU/nG6QeVHWbpKjwerLMqZ2Bz4GsRMQeYDRwD7As8BDwPdD+JcihwYUQkNRsQtu12O/LIFAcptctmI3ZksxE7lh1GLfldbo1DTrvon5Zd/LO72h9IJ6v4hc4dlZwz82Zg/p/VE4HPLWDbe4Hug8FOaWFokiS1TUclZ0mSmsVLqSRJUtOYnCVJtRO0/1KqiHhbRPw2Ih6JiIcj4qTexm+3tiRJzfEm8OnMnBQRg4F7I+JXmfnIkjZkcpYk1VK7zzhn5lRgavH8lYh4FFgbMDlLkgS0IjsPjYiJ3V6Py8xxC9x1xHrA1sA9vdmRyVmSpJ6ZnpmLvXNLMWnW1cDJmfl/vdmRyVmSVEtlXEoVEcvQSMyXZeY1vW3H0dqSJDVBRATwA+DRzPzvpWnL5CxJqqUS7kr1buDjwC4RcX/x2LM3sdutLUmqpRJGa9/RrN1aOUuS1GGsnCVJ9VTdqbWtnCVJ6jRWzpKk2mnczrm6pbPJWZJUPz0fYd2R7NaWJKnDWDlLkmqpwoWzlbMkSZ3GylmSVE8VLp2tnCVJ6jBWzpKkGgovpZIkqdN4KZUkSWoaK2dJUu0ElR4PZuUsSVKnsXKWJNVThUtnk7MkqZaqPFrbbm1JkjqMlbMkqZa8lEqSJDWNlbMkqZYqXDibnCVJNRR2a0uSpCaycpYk1VR1S2crZ0mSOoyVsySpdgLPOUuSpCaycpYk1VKFC+e+lZwf/sN90zdde9DTZcexhIYC08sOouY8xq3nMW6Pqh3nt7ey8Sp3a/ep5JyZq5cdw5KKiImZOaLsOOrMY9x6HuP28DjXR59KzpKkvsO7UkmSpKaxcu5848oOoA/wGLeex7g9PM7dVbdwNjl3usz0f7YW8xi3nse4PTzO86pwbrZbW5KkTmNyVq1FxIkR8WhEXFZ2LHUQEetFxENlx6Ge66v/zSKa/2gnu7UrLCIGZOabZcfR4Y4F3p+Zz/a2AY+zpHazcm6jiPhZRNwbEQ9HxJHFspkR8eWIeCAi7o6INYrlGxSvH4yIL0XEzGL5zhHxu4i4DngkIs6KiJO77ePLEXFSKR+ww0TE+cAw4JcRcXpEXBgR4yPivojYp9hmveJ4TioeOxbL5znOJX6MTtQ/Ir5ffI9viYjlI+KIiJhQfI+vjogVACLioog4PyImRsQTEbFXsXxsRPw8Im6LiCcj4sxiud/nhYiIFSPiF8UxfigiDoyIzxfH/aGIGBfRqO8iYttiuweA40oOvTTR5H/ayeTcXodl5rbACODEiFgNWBG4OzO3BG4Hjii2PQ84LzM3B+av+rYBTsrMjYELgYMBIqIfcBBwacs/SQVk5tHAc8D7aBzn32TmdsXrr0XEisA0YHRmbgMcCHyjWxPdj7P+YSPg25m5GfAS8CHgmsx8V/E9fhQ4vNv26wHbAR8Ezo+IgcXy7Yr3bgEcEBEj8Pu8KLsDz2Xmlpk5HLgJ+FZx3IcDywN7Fdv+EDih+O/Rd0WTH21kcm6vE4tfsncDb6PxR+4N4IZi/b00/pABjASuKp7/eL52xmfmZIDM/BMwIyK2BnYD7svMGa36ABW2G3BqRNwP3AYMBNYFlgG+HxEP0jjem3Z7z9+Ps+YxOTPvL57P/c4OL3oaHgTGAJt12/4nmTknM58E/gi8o1j+q8yckZmvAdcA7/H7vEgPAqMj4qsRsVNmvgy8LyLuKY77LsBmETEEGJKZtxfvu6SsgNV7nnNuk4jYGXg/MDIzX42I22gkiNmZmcVmXfTsv8ms+V5fAIwF1qRReeifBfChzHx8noURXwD+AmxJ48fq691Wz3+c1fC3bs+7aFRsFwH7ZuYDETEW2LnbNsm8cjHL/T4vQGY+ERHbAHsCX4qIW2l0WY/IzGeK7/LARbXR13gplXpiZeCvRWJ+B7DDYra/m0aXHzS69hblWhpdXu8Cbl6qKOvrZuCEbufkti6WrwxMzcw5wMeB/iXFV3WDgakRsQyNyrm7AyKiX0RsQGMMwNwfSKMjYtWIWB7YF7izWO73eQEiYi3g1cy8FPgajdMuANMjYhCwP0BmvgS8FBHvKdbP/99DFWDl3D43AUdHxKM0/jjdvZjtTwYujYjTi/e+vLANM/ONiPgt8FJmdjUr4Jo5GzgX+ENxLnMyjfNz3wGujoiDaRxnq+XeOQO4B3ih+Pfgbuv+DIwHVgKOzszXi99I44GrgXWASzNzIvh9XoTNaYyVmAPMBo6h8aPmIeB5YEK3bQ8FLoyIBG5pd6Cdosp3pYp/9KiqkxSjXV/LzIyIg4CPZOY+C9m2HzAJOKA4ryd1hIi4CLghM3863/KxNLpjj1/Ae/w+a6lttc22eevv7mlqm0MHLXNvu+76ZeXcubYFvlV0w74EHLagjSJiUxoDyq71D5mqzu+zmqf9lz81k5WzJKl2tt5mRP7mjuZWzquuOKBtlbMDwiRJ6jAmZ0mSOozJWZKkDmNylhYjIroi4v5i/uKr5s4b3cu2LoqI/YvnFxQDoBa27c5z5/pewn38KSKG9nT5fNvMXMJ9fSEiPrOkMUrtUOW7UpmcpcV7LTO3KuYvfgM4uvvKiOjVVQ+Z+YnMXNRNNXYGljg5S2rwxhdS3/E7YMP571oVEf0j4mvFHYL+EBFHAUTDtyLi8Yj4NfCWuQ0Vd2QaUTzfPRp3xXogIm6NiPVo/Aj4ZFG17xQRq0fjjk8Tise7i/euFo27Qz0cERfQg1kLYwF3SOu27uvF8lsjYvVi2QYRcVPxnt8Vs9xJahGvc5Z6qKiQ96Axkxg0pk8cnpmTiwT3cma+KyKWA+6MiFuArYFNaNxQYw0at5+8cL52Vwe+D4wq2lo1M1+Mxi0vZ2bmfxbb/Rj4embeERHr0pja8p3AmcAdmXlWRHyQee8ItTCHFftYHpgQEVcXN5hYEZiYmZ+MiM8XbR8PjKMxu9eTEbE9jZnVdunFYZTao4Su6GYyOUuLt3xxNytoVM4/oNHd3P2uVbsBW8w9n0xjzu6NgFHA5cU0lM9FxG8W0P4OwO3d7jT24kLieD+wafzjL85KxZzKo4D/V7z3FxHx1x58phMjYr/i+dw7pM0A5gBXFssvBa4p9rEjcFW3fS/Xg31I6iWTs7R4r2XmVt0XFEmq+zzcQeP+uTfPt92eTYyjH7BDZna/cxaxhOVBLPwOaQuSxX5fmv8YSJ2shFswN5XnnKXmuBk4prgrExGxcUSsCNwOHFick34r8L4FvPduYFRErF+8d9Vi+SvMewOJW4AT5r6IiLnJ8nbgo8WyPYBVFhProu6Q1o/i7kZFm3dk5v8BkyPigGIfERFbLmYfUvmiyY82MjlLzXEBjfPJkyLiIeB7NHqmrgWeLNb9CLhr/jdm5gvAkTS6kB/gH93K1wP7zR0QBpwIjCgGnD3CP0aNf5FGcn+YRvf2nxcT603AgGjcIe3fmfcOabOA7YrPsAtwVrF8DHB4Ed/DwAJvwiKpOZxbW5JUO9tsOyJv//2ExW+4BAYP7Ofc2pIk9VUOCJMk1VKVL6WycpYkqcNYOUuSaqnChbPJWZJUUxXOznZrS5LUJMU8+Y9HxFMRcWpv27FyliTVUrvvJBUR/YFvA6OBZ2nMW3/dYu4+t0BWzpIkNcd2wFOZ+cfMfAO4gl5O2GPlLEmqnaCUS6nWBp7p9vpZYPveNGRyliTVzqRJ9968/DIxtMnNDoyIid1ej8vMcU3eB2ByliTVUGbuXsJup9C4Betc6xTLlpjnnCVJao4JwEYRsX5ELAscBFzXm4asnCVJaoLMfDMijqdxC9n+wIWZ+XBv2vKuVJIkdRi7tSVJ6jAmZ0mSOozJWZKkDmNyliSpw5icJUnqMCZnSZI6jMlZkqQOY3KWJKnD/H/Qk0WYCuFteQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 576x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPjLuB-oYqZ_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ncl1wszZ1Ds"
      },
      "source": [
        "# Tempogram + conv2D"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6Ur96d1Z1D0"
      },
      "source": [
        "features = []\n",
        "labels = []\n",
        "for i in range(len(Ravdess_DF['Paths'])):\n",
        "  if ((Ravdess_DF['Emotion'][i] == '03') | (Ravdess_DF['Emotion'][i] == '04') | \n",
        "      (Ravdess_DF['Emotion'][i] == '05') | (Ravdess_DF['Emotion'][i] == '06')):\n",
        "    \n",
        "    signal, sr = librosa.load(Ravdess_DF['Paths'][i])\n",
        "    if len(signal) > input_length:\n",
        "        signal = signal[0:input_length]\n",
        "    elif  input_length > len(signal):\n",
        "        max_offset = input_length - len(signal)  \n",
        "        signal = np.pad(signal, (0, max_offset), \"constant\")\n",
        "    tempogram = librosa.feature.tempogram(signal, sr)\n",
        "    tempogram = np.expand_dims(tempogram, axis=-1)\n",
        "    features.append(tempogram)\n",
        "    if Ravdess_DF['Emotion'][i] == '03':\n",
        "      labels.append(0)\n",
        "    elif Ravdess_DF['Emotion'][i] == '04':\n",
        "      labels.append(1)\n",
        "    elif Ravdess_DF['Emotion'][i] == '05':\n",
        "      labels.append(2)\n",
        "    elif Ravdess_DF['Emotion'][i] == '06':\n",
        "      labels.append(3)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bnzxRACvZ1D1"
      },
      "source": [
        "X = features\n",
        "y = labels\n",
        "\n",
        "y = np.array(y)\n",
        "y = to_categorical(y)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=0)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=0)\n",
        "\n",
        "X_train = np.array(X_train)\n",
        "X_test = np.array(X_test)\n",
        "X_val = np.array(X_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YZkj391HZ1D1",
        "outputId": "673a0abe-9ce3-42b2-80de-921336ad79fa"
      },
      "source": [
        "X_train.shape,X_test.shape,y_train.shape,y_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((621, 384, 259, 1), (77, 384, 259, 1), (621, 4), (77, 4))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OAXECwCLaYWp"
      },
      "source": [
        "### conv2D"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c4RsyEHoaYW5"
      },
      "source": [
        "# CNN I/P Config\n",
        "num_classes = 4\n",
        "input_shape = X_train.shape[1:]\n",
        "learning_rate = 0.0001\n",
        "decay = 1e-6\n",
        "momentum = 0.9"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6xX_1MaMaYW7",
        "outputId": "7e3fcd9e-19e3-4bfd-bf2a-ef7f7cc44d12"
      },
      "source": [
        "model = Sequential(name='Audio_CNN_2D')\n",
        "\n",
        "# LFLB1\n",
        "model.add(Conv2D(filters=64, kernel_size=(3,3), strides=(1,1), padding='same',input_shape=input_shape))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Conv2D(filters=64, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(4,4), strides=(4,4)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(units=num_classes, activation='softmax'))\n",
        "\n",
        "# Model compilation\n",
        "opt = optimizers.SGD(lr=learning_rate, decay=decay, momentum=momentum, nesterov=True)\n",
        "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"Audio_CNN_2D\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_10 (Conv2D)           (None, 384, 259, 64)      640       \n",
            "_________________________________________________________________\n",
            "batch_normalization_22 (Batc (None, 384, 259, 64)      256       \n",
            "_________________________________________________________________\n",
            "activation_22 (Activation)   (None, 384, 259, 64)      0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_10 (MaxPooling (None, 192, 129, 64)      0         \n",
            "_________________________________________________________________\n",
            "dropout_22 (Dropout)         (None, 192, 129, 64)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 192, 129, 64)      36928     \n",
            "_________________________________________________________________\n",
            "batch_normalization_23 (Batc (None, 192, 129, 64)      256       \n",
            "_________________________________________________________________\n",
            "activation_23 (Activation)   (None, 192, 129, 64)      0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_11 (MaxPooling (None, 48, 32, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_23 (Dropout)         (None, 48, 32, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten_5 (Flatten)          (None, 98304)             0         \n",
            "_________________________________________________________________\n",
            "dense_32 (Dense)             (None, 4)                 393220    \n",
            "=================================================================\n",
            "Total params: 431,300\n",
            "Trainable params: 431,044\n",
            "Non-trainable params: 256\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yHM3CD7YaYW9",
        "outputId": "9eff3191-abb3-4654-a134-634a104cd2fd"
      },
      "source": [
        "#Train Config\n",
        "\n",
        "batch_size = 16\n",
        "num_epochs = 200\n",
        "\n",
        "# Model Training\n",
        "lr_reduce = ReduceLROnPlateau(monitor='val_loss', factor=0.9, patience=20, min_lr=0.000001)\n",
        "# Please change the model name accordingly.\n",
        "mcp_save = ModelCheckpoint('/content/Modelfull_2_1.h5', save_best_only=True, monitor='val_categorical_accuracy', mode='max')\n",
        "cnnhistory=model.fit(X_train, y_train, batch_size=batch_size, epochs=num_epochs,validation_data=(X_val, y_val), callbacks=[mcp_save, lr_reduce])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "39/39 [==============================] - 7s 122ms/step - loss: 13.8097 - categorical_accuracy: 0.2308 - val_loss: 1.4164 - val_categorical_accuracy: 0.1857\n",
            "Epoch 2/200\n",
            "39/39 [==============================] - 3s 87ms/step - loss: 4.2879 - categorical_accuracy: 0.3322 - val_loss: 1.9323 - val_categorical_accuracy: 0.1857\n",
            "Epoch 3/200\n",
            "39/39 [==============================] - 3s 86ms/step - loss: 4.0681 - categorical_accuracy: 0.3206 - val_loss: 2.1488 - val_categorical_accuracy: 0.1857\n",
            "Epoch 4/200\n",
            "39/39 [==============================] - 3s 86ms/step - loss: 3.3103 - categorical_accuracy: 0.3460 - val_loss: 2.6095 - val_categorical_accuracy: 0.1857\n",
            "Epoch 5/200\n",
            "39/39 [==============================] - 3s 87ms/step - loss: 3.1421 - categorical_accuracy: 0.3314 - val_loss: 2.0948 - val_categorical_accuracy: 0.1857\n",
            "Epoch 6/200\n",
            "39/39 [==============================] - 3s 87ms/step - loss: 3.4386 - categorical_accuracy: 0.3424 - val_loss: 3.3177 - val_categorical_accuracy: 0.1857\n",
            "Epoch 7/200\n",
            "39/39 [==============================] - 3s 86ms/step - loss: 2.2397 - categorical_accuracy: 0.4272 - val_loss: 2.9498 - val_categorical_accuracy: 0.1857\n",
            "Epoch 8/200\n",
            "39/39 [==============================] - 3s 86ms/step - loss: 2.4016 - categorical_accuracy: 0.3586 - val_loss: 2.5387 - val_categorical_accuracy: 0.1857\n",
            "Epoch 9/200\n",
            "39/39 [==============================] - 3s 87ms/step - loss: 2.6913 - categorical_accuracy: 0.3759 - val_loss: 2.9594 - val_categorical_accuracy: 0.1857\n",
            "Epoch 10/200\n",
            "39/39 [==============================] - 3s 86ms/step - loss: 2.0128 - categorical_accuracy: 0.3930 - val_loss: 2.8506 - val_categorical_accuracy: 0.1857\n",
            "Epoch 11/200\n",
            "39/39 [==============================] - 3s 86ms/step - loss: 1.9746 - categorical_accuracy: 0.4071 - val_loss: 2.0101 - val_categorical_accuracy: 0.1857\n",
            "Epoch 12/200\n",
            "39/39 [==============================] - 3s 86ms/step - loss: 2.1305 - categorical_accuracy: 0.3947 - val_loss: 2.1569 - val_categorical_accuracy: 0.2143\n",
            "Epoch 13/200\n",
            "39/39 [==============================] - 3s 88ms/step - loss: 1.8957 - categorical_accuracy: 0.4028 - val_loss: 2.6580 - val_categorical_accuracy: 0.1857\n",
            "Epoch 14/200\n",
            "39/39 [==============================] - 3s 86ms/step - loss: 2.0184 - categorical_accuracy: 0.4179 - val_loss: 2.1920 - val_categorical_accuracy: 0.3429\n",
            "Epoch 15/200\n",
            "39/39 [==============================] - 3s 86ms/step - loss: 2.3898 - categorical_accuracy: 0.3340 - val_loss: 1.9562 - val_categorical_accuracy: 0.2000\n",
            "Epoch 16/200\n",
            "39/39 [==============================] - 3s 87ms/step - loss: 1.9623 - categorical_accuracy: 0.4588 - val_loss: 3.0457 - val_categorical_accuracy: 0.1857\n",
            "Epoch 17/200\n",
            "39/39 [==============================] - 3s 87ms/step - loss: 1.7925 - categorical_accuracy: 0.4303 - val_loss: 2.4273 - val_categorical_accuracy: 0.3000\n",
            "Epoch 18/200\n",
            "39/39 [==============================] - 3s 86ms/step - loss: 1.8870 - categorical_accuracy: 0.4466 - val_loss: 2.1103 - val_categorical_accuracy: 0.1857\n",
            "Epoch 19/200\n",
            "39/39 [==============================] - 3s 87ms/step - loss: 2.0439 - categorical_accuracy: 0.3612 - val_loss: 2.2364 - val_categorical_accuracy: 0.2143\n",
            "Epoch 20/200\n",
            "39/39 [==============================] - 3s 87ms/step - loss: 1.9711 - categorical_accuracy: 0.3909 - val_loss: 2.2610 - val_categorical_accuracy: 0.1857\n",
            "Epoch 21/200\n",
            "39/39 [==============================] - 3s 87ms/step - loss: 1.9207 - categorical_accuracy: 0.4201 - val_loss: 1.4531 - val_categorical_accuracy: 0.4000\n",
            "Epoch 22/200\n",
            "39/39 [==============================] - 3s 87ms/step - loss: 1.5746 - categorical_accuracy: 0.4448 - val_loss: 2.5765 - val_categorical_accuracy: 0.2000\n",
            "Epoch 23/200\n",
            "39/39 [==============================] - 3s 87ms/step - loss: 1.8093 - categorical_accuracy: 0.4095 - val_loss: 1.7547 - val_categorical_accuracy: 0.2571\n",
            "Epoch 24/200\n",
            "39/39 [==============================] - 3s 87ms/step - loss: 1.7164 - categorical_accuracy: 0.4137 - val_loss: 1.9594 - val_categorical_accuracy: 0.2000\n",
            "Epoch 25/200\n",
            "39/39 [==============================] - 3s 87ms/step - loss: 1.5909 - categorical_accuracy: 0.4438 - val_loss: 1.8539 - val_categorical_accuracy: 0.3000\n",
            "Epoch 26/200\n",
            "39/39 [==============================] - 3s 87ms/step - loss: 1.7049 - categorical_accuracy: 0.4018 - val_loss: 2.9922 - val_categorical_accuracy: 0.2000\n",
            "Epoch 27/200\n",
            "39/39 [==============================] - 3s 87ms/step - loss: 1.5774 - categorical_accuracy: 0.4674 - val_loss: 1.8471 - val_categorical_accuracy: 0.3143\n",
            "Epoch 28/200\n",
            "39/39 [==============================] - 3s 87ms/step - loss: 1.5926 - categorical_accuracy: 0.4452 - val_loss: 1.5369 - val_categorical_accuracy: 0.3429\n",
            "Epoch 29/200\n",
            "39/39 [==============================] - 3s 88ms/step - loss: 1.6822 - categorical_accuracy: 0.4549 - val_loss: 2.7726 - val_categorical_accuracy: 0.2000\n",
            "Epoch 30/200\n",
            "39/39 [==============================] - 3s 87ms/step - loss: 1.5896 - categorical_accuracy: 0.4235 - val_loss: 1.4788 - val_categorical_accuracy: 0.3857\n",
            "Epoch 31/200\n",
            "39/39 [==============================] - 3s 87ms/step - loss: 1.6503 - categorical_accuracy: 0.4658 - val_loss: 3.7936 - val_categorical_accuracy: 0.1857\n",
            "Epoch 32/200\n",
            "39/39 [==============================] - 3s 88ms/step - loss: 1.7723 - categorical_accuracy: 0.4339 - val_loss: 2.0629 - val_categorical_accuracy: 0.2286\n",
            "Epoch 33/200\n",
            "39/39 [==============================] - 3s 87ms/step - loss: 1.8093 - categorical_accuracy: 0.4270 - val_loss: 2.4725 - val_categorical_accuracy: 0.1857\n",
            "Epoch 34/200\n",
            "39/39 [==============================] - 3s 87ms/step - loss: 1.4033 - categorical_accuracy: 0.4790 - val_loss: 2.3466 - val_categorical_accuracy: 0.3000\n",
            "Epoch 35/200\n",
            "39/39 [==============================] - 3s 87ms/step - loss: 1.5070 - categorical_accuracy: 0.4745 - val_loss: 1.4435 - val_categorical_accuracy: 0.3714\n",
            "Epoch 36/200\n",
            "39/39 [==============================] - 3s 87ms/step - loss: 1.7716 - categorical_accuracy: 0.4409 - val_loss: 2.7453 - val_categorical_accuracy: 0.1857\n",
            "Epoch 37/200\n",
            "39/39 [==============================] - 3s 87ms/step - loss: 1.6997 - categorical_accuracy: 0.4460 - val_loss: 2.3395 - val_categorical_accuracy: 0.2143\n",
            "Epoch 38/200\n",
            "39/39 [==============================] - 3s 88ms/step - loss: 1.4706 - categorical_accuracy: 0.4949 - val_loss: 2.5326 - val_categorical_accuracy: 0.2286\n",
            "Epoch 39/200\n",
            "39/39 [==============================] - 3s 88ms/step - loss: 1.5928 - categorical_accuracy: 0.4594 - val_loss: 2.5548 - val_categorical_accuracy: 0.2143\n",
            "Epoch 40/200\n",
            "39/39 [==============================] - 3s 87ms/step - loss: 1.5039 - categorical_accuracy: 0.4396 - val_loss: 2.4493 - val_categorical_accuracy: 0.2429\n",
            "Epoch 41/200\n",
            "39/39 [==============================] - 3s 87ms/step - loss: 1.4813 - categorical_accuracy: 0.4838 - val_loss: 2.7512 - val_categorical_accuracy: 0.2286\n",
            "Epoch 42/200\n",
            "39/39 [==============================] - 3s 87ms/step - loss: 1.3969 - categorical_accuracy: 0.5041 - val_loss: 2.2893 - val_categorical_accuracy: 0.2000\n",
            "Epoch 43/200\n",
            "39/39 [==============================] - 3s 87ms/step - loss: 1.4825 - categorical_accuracy: 0.4715 - val_loss: 2.1557 - val_categorical_accuracy: 0.2429\n",
            "Epoch 44/200\n",
            "39/39 [==============================] - 3s 87ms/step - loss: 1.4650 - categorical_accuracy: 0.4943 - val_loss: 2.2690 - val_categorical_accuracy: 0.3286\n",
            "Epoch 45/200\n",
            "39/39 [==============================] - 3s 87ms/step - loss: 1.5215 - categorical_accuracy: 0.4617 - val_loss: 2.7102 - val_categorical_accuracy: 0.1857\n",
            "Epoch 46/200\n",
            "39/39 [==============================] - 3s 87ms/step - loss: 1.5828 - categorical_accuracy: 0.4328 - val_loss: 2.2235 - val_categorical_accuracy: 0.3000\n",
            "Epoch 47/200\n",
            "39/39 [==============================] - 3s 88ms/step - loss: 1.3567 - categorical_accuracy: 0.4723 - val_loss: 2.0566 - val_categorical_accuracy: 0.3000\n",
            "Epoch 48/200\n",
            "39/39 [==============================] - 3s 87ms/step - loss: 1.5300 - categorical_accuracy: 0.4517 - val_loss: 2.7060 - val_categorical_accuracy: 0.2000\n",
            "Epoch 49/200\n",
            "39/39 [==============================] - 3s 87ms/step - loss: 1.5276 - categorical_accuracy: 0.4511 - val_loss: 2.1438 - val_categorical_accuracy: 0.3143\n",
            "Epoch 50/200\n",
            "39/39 [==============================] - 3s 87ms/step - loss: 1.2842 - categorical_accuracy: 0.5015 - val_loss: 2.0338 - val_categorical_accuracy: 0.3000\n",
            "Epoch 51/200\n",
            "39/39 [==============================] - 3s 87ms/step - loss: 1.2649 - categorical_accuracy: 0.5264 - val_loss: 2.2033 - val_categorical_accuracy: 0.3286\n",
            "Epoch 52/200\n",
            "39/39 [==============================] - 3s 87ms/step - loss: 1.4205 - categorical_accuracy: 0.4769 - val_loss: 2.4733 - val_categorical_accuracy: 0.2000\n",
            "Epoch 53/200\n",
            "39/39 [==============================] - 3s 87ms/step - loss: 1.3346 - categorical_accuracy: 0.4920 - val_loss: 1.9177 - val_categorical_accuracy: 0.3000\n",
            "Epoch 54/200\n",
            "39/39 [==============================] - 3s 87ms/step - loss: 1.3670 - categorical_accuracy: 0.4680 - val_loss: 1.7496 - val_categorical_accuracy: 0.3000\n",
            "Epoch 55/200\n",
            "39/39 [==============================] - 3s 87ms/step - loss: 1.3124 - categorical_accuracy: 0.5166 - val_loss: 1.9432 - val_categorical_accuracy: 0.2714\n",
            "Epoch 56/200\n",
            "39/39 [==============================] - 3s 87ms/step - loss: 1.3302 - categorical_accuracy: 0.4645 - val_loss: 2.3955 - val_categorical_accuracy: 0.2143\n",
            "Epoch 57/200\n",
            "39/39 [==============================] - 3s 87ms/step - loss: 1.3916 - categorical_accuracy: 0.4877 - val_loss: 2.0597 - val_categorical_accuracy: 0.3286\n",
            "Epoch 58/200\n",
            "39/39 [==============================] - 3s 87ms/step - loss: 1.4993 - categorical_accuracy: 0.4541 - val_loss: 2.5173 - val_categorical_accuracy: 0.1857\n",
            "Epoch 59/200\n",
            "39/39 [==============================] - 3s 87ms/step - loss: 1.3356 - categorical_accuracy: 0.4907 - val_loss: 2.1557 - val_categorical_accuracy: 0.3286\n",
            "Epoch 60/200\n",
            "39/39 [==============================] - 3s 88ms/step - loss: 1.3420 - categorical_accuracy: 0.5026 - val_loss: 1.8130 - val_categorical_accuracy: 0.2857\n",
            "Epoch 61/200\n",
            "39/39 [==============================] - 3s 87ms/step - loss: 1.3819 - categorical_accuracy: 0.4940 - val_loss: 2.6040 - val_categorical_accuracy: 0.2143\n",
            "Epoch 62/200\n",
            "39/39 [==============================] - 3s 88ms/step - loss: 1.2415 - categorical_accuracy: 0.5080 - val_loss: 1.9557 - val_categorical_accuracy: 0.2429\n",
            "Epoch 63/200\n",
            "39/39 [==============================] - 3s 87ms/step - loss: 1.2931 - categorical_accuracy: 0.5071 - val_loss: 2.3966 - val_categorical_accuracy: 0.2143\n",
            "Epoch 64/200\n",
            "39/39 [==============================] - 3s 87ms/step - loss: 1.2023 - categorical_accuracy: 0.5553 - val_loss: 1.7734 - val_categorical_accuracy: 0.3143\n",
            "Epoch 65/200\n",
            "39/39 [==============================] - 3s 87ms/step - loss: 1.3144 - categorical_accuracy: 0.5226 - val_loss: 1.6119 - val_categorical_accuracy: 0.2143\n",
            "Epoch 66/200\n",
            "39/39 [==============================] - 3s 87ms/step - loss: 1.3279 - categorical_accuracy: 0.4872 - val_loss: 1.9012 - val_categorical_accuracy: 0.2571\n",
            "Epoch 67/200\n",
            "39/39 [==============================] - 3s 87ms/step - loss: 1.1530 - categorical_accuracy: 0.5518 - val_loss: 2.5105 - val_categorical_accuracy: 0.1857\n",
            "Epoch 68/200\n",
            "39/39 [==============================] - 3s 87ms/step - loss: 1.2056 - categorical_accuracy: 0.5230 - val_loss: 2.9629 - val_categorical_accuracy: 0.2000\n",
            "Epoch 69/200\n",
            "39/39 [==============================] - 3s 86ms/step - loss: 1.2183 - categorical_accuracy: 0.5172 - val_loss: 2.1785 - val_categorical_accuracy: 0.2286\n",
            "Epoch 70/200\n",
            "39/39 [==============================] - 3s 88ms/step - loss: 1.2360 - categorical_accuracy: 0.5492 - val_loss: 1.7877 - val_categorical_accuracy: 0.2429\n",
            "Epoch 71/200\n",
            "39/39 [==============================] - 3s 86ms/step - loss: 1.2544 - categorical_accuracy: 0.5258 - val_loss: 1.5715 - val_categorical_accuracy: 0.3000\n",
            "Epoch 72/200\n",
            "39/39 [==============================] - 3s 87ms/step - loss: 1.3121 - categorical_accuracy: 0.4998 - val_loss: 2.7513 - val_categorical_accuracy: 0.2429\n",
            "Epoch 73/200\n",
            "39/39 [==============================] - 3s 87ms/step - loss: 1.3258 - categorical_accuracy: 0.5334 - val_loss: 3.2744 - val_categorical_accuracy: 0.1857\n",
            "Epoch 74/200\n",
            "39/39 [==============================] - 3s 87ms/step - loss: 1.3123 - categorical_accuracy: 0.5013 - val_loss: 1.7093 - val_categorical_accuracy: 0.3143\n",
            "Epoch 75/200\n",
            "39/39 [==============================] - 3s 87ms/step - loss: 1.2050 - categorical_accuracy: 0.5314 - val_loss: 2.3249 - val_categorical_accuracy: 0.2000\n",
            "Epoch 76/200\n",
            "39/39 [==============================] - 3s 87ms/step - loss: 1.1238 - categorical_accuracy: 0.5636 - val_loss: 2.3896 - val_categorical_accuracy: 0.2286\n",
            "Epoch 77/200\n",
            "39/39 [==============================] - 3s 86ms/step - loss: 1.1806 - categorical_accuracy: 0.5552 - val_loss: 2.0018 - val_categorical_accuracy: 0.2857\n",
            "Epoch 78/200\n",
            "39/39 [==============================] - 3s 86ms/step - loss: 1.2685 - categorical_accuracy: 0.5445 - val_loss: 2.2479 - val_categorical_accuracy: 0.1857\n",
            "Epoch 79/200\n",
            "39/39 [==============================] - 3s 87ms/step - loss: 1.1872 - categorical_accuracy: 0.5325 - val_loss: 2.1409 - val_categorical_accuracy: 0.3000\n",
            "Epoch 80/200\n",
            "39/39 [==============================] - 3s 88ms/step - loss: 1.3441 - categorical_accuracy: 0.5031 - val_loss: 1.8357 - val_categorical_accuracy: 0.2286\n",
            "Epoch 81/200\n",
            "39/39 [==============================] - 3s 87ms/step - loss: 1.2240 - categorical_accuracy: 0.5386 - val_loss: 2.4062 - val_categorical_accuracy: 0.2286\n",
            "Epoch 82/200\n",
            "39/39 [==============================] - 3s 88ms/step - loss: 1.2301 - categorical_accuracy: 0.5459 - val_loss: 1.8240 - val_categorical_accuracy: 0.3286\n",
            "Epoch 83/200\n",
            "39/39 [==============================] - 3s 87ms/step - loss: 1.2129 - categorical_accuracy: 0.5469 - val_loss: 2.4202 - val_categorical_accuracy: 0.2143\n",
            "Epoch 84/200\n",
            "39/39 [==============================] - 3s 86ms/step - loss: 1.2143 - categorical_accuracy: 0.5438 - val_loss: 2.4000 - val_categorical_accuracy: 0.1857\n",
            "Epoch 85/200\n",
            "39/39 [==============================] - 3s 87ms/step - loss: 1.1684 - categorical_accuracy: 0.5243 - val_loss: 1.6467 - val_categorical_accuracy: 0.3000\n",
            "Epoch 86/200\n",
            "39/39 [==============================] - 3s 86ms/step - loss: 1.1928 - categorical_accuracy: 0.5185 - val_loss: 1.9874 - val_categorical_accuracy: 0.3000\n",
            "Epoch 87/200\n",
            "39/39 [==============================] - 3s 86ms/step - loss: 1.2341 - categorical_accuracy: 0.5218 - val_loss: 2.0130 - val_categorical_accuracy: 0.3571\n",
            "Epoch 88/200\n",
            "39/39 [==============================] - 3s 87ms/step - loss: 1.1698 - categorical_accuracy: 0.5493 - val_loss: 2.2681 - val_categorical_accuracy: 0.2000\n",
            "Epoch 89/200\n",
            "39/39 [==============================] - 3s 87ms/step - loss: 1.1711 - categorical_accuracy: 0.5322 - val_loss: 1.8011 - val_categorical_accuracy: 0.2857\n",
            "Epoch 90/200\n",
            "39/39 [==============================] - 3s 87ms/step - loss: 1.1822 - categorical_accuracy: 0.5293 - val_loss: 1.6845 - val_categorical_accuracy: 0.3857\n",
            "Epoch 91/200\n",
            "39/39 [==============================] - 3s 87ms/step - loss: 1.1625 - categorical_accuracy: 0.5489 - val_loss: 1.9662 - val_categorical_accuracy: 0.2857\n",
            "Epoch 92/200\n",
            "39/39 [==============================] - 3s 87ms/step - loss: 1.1854 - categorical_accuracy: 0.5169 - val_loss: 1.5369 - val_categorical_accuracy: 0.3286\n",
            "Epoch 93/200\n",
            "39/39 [==============================] - 3s 87ms/step - loss: 1.2086 - categorical_accuracy: 0.5291 - val_loss: 1.9884 - val_categorical_accuracy: 0.2286\n",
            "Epoch 94/200\n",
            "39/39 [==============================] - 3s 87ms/step - loss: 1.1695 - categorical_accuracy: 0.5617 - val_loss: 1.7748 - val_categorical_accuracy: 0.3286\n",
            "Epoch 95/200\n",
            "39/39 [==============================] - 3s 87ms/step - loss: 1.2197 - categorical_accuracy: 0.5467 - val_loss: 2.0783 - val_categorical_accuracy: 0.2429\n",
            "Epoch 96/200\n",
            "39/39 [==============================] - 3s 88ms/step - loss: 1.1915 - categorical_accuracy: 0.5106 - val_loss: 1.8834 - val_categorical_accuracy: 0.2286\n",
            "Epoch 97/200\n",
            "39/39 [==============================] - 3s 87ms/step - loss: 1.1511 - categorical_accuracy: 0.5224 - val_loss: 1.8954 - val_categorical_accuracy: 0.2286\n",
            "Epoch 98/200\n",
            "39/39 [==============================] - 3s 87ms/step - loss: 1.1204 - categorical_accuracy: 0.5335 - val_loss: 1.8514 - val_categorical_accuracy: 0.2286\n",
            "Epoch 99/200\n",
            "39/39 [==============================] - 3s 87ms/step - loss: 1.1066 - categorical_accuracy: 0.5369 - val_loss: 1.9679 - val_categorical_accuracy: 0.2857\n",
            "Epoch 100/200\n",
            "39/39 [==============================] - 3s 87ms/step - loss: 1.1719 - categorical_accuracy: 0.5133 - val_loss: 1.6952 - val_categorical_accuracy: 0.3286\n",
            "Epoch 101/200\n",
            "39/39 [==============================] - 3s 86ms/step - loss: 1.1811 - categorical_accuracy: 0.5499 - val_loss: 1.8113 - val_categorical_accuracy: 0.2714\n",
            "Epoch 102/200\n",
            "39/39 [==============================] - 3s 87ms/step - loss: 1.1281 - categorical_accuracy: 0.5575 - val_loss: 2.1483 - val_categorical_accuracy: 0.2714\n",
            "Epoch 103/200\n",
            "39/39 [==============================] - 3s 88ms/step - loss: 1.1771 - categorical_accuracy: 0.5109 - val_loss: 2.0752 - val_categorical_accuracy: 0.2286\n",
            "Epoch 104/200\n",
            "39/39 [==============================] - 3s 86ms/step - loss: 1.0823 - categorical_accuracy: 0.5616 - val_loss: 2.1878 - val_categorical_accuracy: 0.1857\n",
            "Epoch 105/200\n",
            "39/39 [==============================] - 3s 87ms/step - loss: 1.1541 - categorical_accuracy: 0.5100 - val_loss: 2.0666 - val_categorical_accuracy: 0.2714\n",
            "Epoch 106/200\n",
            "39/39 [==============================] - 3s 87ms/step - loss: 1.1348 - categorical_accuracy: 0.5257 - val_loss: 1.4259 - val_categorical_accuracy: 0.3429\n",
            "Epoch 107/200\n",
            "39/39 [==============================] - 3s 87ms/step - loss: 1.1253 - categorical_accuracy: 0.5793 - val_loss: 2.2901 - val_categorical_accuracy: 0.2714\n",
            "Epoch 108/200\n",
            "39/39 [==============================] - 3s 88ms/step - loss: 1.1111 - categorical_accuracy: 0.5658 - val_loss: 2.3671 - val_categorical_accuracy: 0.2143\n",
            "Epoch 109/200\n",
            "39/39 [==============================] - 3s 87ms/step - loss: 1.0672 - categorical_accuracy: 0.5527 - val_loss: 2.2994 - val_categorical_accuracy: 0.2000\n",
            "Epoch 110/200\n",
            "39/39 [==============================] - 3s 88ms/step - loss: 1.0818 - categorical_accuracy: 0.5724 - val_loss: 2.2779 - val_categorical_accuracy: 0.2000\n",
            "Epoch 111/200\n",
            "39/39 [==============================] - 3s 87ms/step - loss: 1.1879 - categorical_accuracy: 0.5351 - val_loss: 1.7570 - val_categorical_accuracy: 0.3429\n",
            "Epoch 112/200\n",
            "39/39 [==============================] - 3s 87ms/step - loss: 1.0084 - categorical_accuracy: 0.6286 - val_loss: 2.1093 - val_categorical_accuracy: 0.2571\n",
            "Epoch 113/200\n",
            "39/39 [==============================] - 3s 87ms/step - loss: 1.0087 - categorical_accuracy: 0.5993 - val_loss: 1.8715 - val_categorical_accuracy: 0.2571\n",
            "Epoch 114/200\n",
            "39/39 [==============================] - 3s 87ms/step - loss: 1.0166 - categorical_accuracy: 0.5918 - val_loss: 2.4049 - val_categorical_accuracy: 0.2000\n",
            "Epoch 115/200\n",
            "39/39 [==============================] - 3s 88ms/step - loss: 1.1178 - categorical_accuracy: 0.5663 - val_loss: 2.5143 - val_categorical_accuracy: 0.2000\n",
            "Epoch 116/200\n",
            "39/39 [==============================] - 3s 87ms/step - loss: 1.1426 - categorical_accuracy: 0.5626 - val_loss: 1.6646 - val_categorical_accuracy: 0.3143\n",
            "Epoch 117/200\n",
            "39/39 [==============================] - 3s 87ms/step - loss: 1.0628 - categorical_accuracy: 0.5519 - val_loss: 1.5614 - val_categorical_accuracy: 0.3429\n",
            "Epoch 118/200\n",
            "39/39 [==============================] - 3s 88ms/step - loss: 1.0970 - categorical_accuracy: 0.5773 - val_loss: 2.0482 - val_categorical_accuracy: 0.3286\n",
            "Epoch 119/200\n",
            "39/39 [==============================] - 3s 86ms/step - loss: 1.0095 - categorical_accuracy: 0.6146 - val_loss: 1.8142 - val_categorical_accuracy: 0.2429\n",
            "Epoch 120/200\n",
            "39/39 [==============================] - 3s 88ms/step - loss: 1.0324 - categorical_accuracy: 0.5786 - val_loss: 2.0215 - val_categorical_accuracy: 0.2000\n",
            "Epoch 121/200\n",
            "39/39 [==============================] - 3s 87ms/step - loss: 1.0974 - categorical_accuracy: 0.5733 - val_loss: 1.7935 - val_categorical_accuracy: 0.3429\n",
            "Epoch 122/200\n",
            "39/39 [==============================] - 3s 88ms/step - loss: 1.0225 - categorical_accuracy: 0.5783 - val_loss: 1.5039 - val_categorical_accuracy: 0.3429\n",
            "Epoch 123/200\n",
            "39/39 [==============================] - 3s 88ms/step - loss: 1.1913 - categorical_accuracy: 0.4920 - val_loss: 1.6818 - val_categorical_accuracy: 0.2429\n",
            "Epoch 124/200\n",
            "39/39 [==============================] - 3s 88ms/step - loss: 1.0810 - categorical_accuracy: 0.5686 - val_loss: 1.4708 - val_categorical_accuracy: 0.3429\n",
            "Epoch 125/200\n",
            "39/39 [==============================] - 3s 87ms/step - loss: 1.0167 - categorical_accuracy: 0.5900 - val_loss: 2.1813 - val_categorical_accuracy: 0.2143\n",
            "Epoch 126/200\n",
            "39/39 [==============================] - 3s 88ms/step - loss: 1.0044 - categorical_accuracy: 0.6175 - val_loss: 1.8119 - val_categorical_accuracy: 0.3143\n",
            "Epoch 127/200\n",
            "39/39 [==============================] - 3s 88ms/step - loss: 1.0648 - categorical_accuracy: 0.6048 - val_loss: 1.6433 - val_categorical_accuracy: 0.2571\n",
            "Epoch 128/200\n",
            "39/39 [==============================] - 3s 87ms/step - loss: 1.1004 - categorical_accuracy: 0.5597 - val_loss: 2.0494 - val_categorical_accuracy: 0.2286\n",
            "Epoch 129/200\n",
            "39/39 [==============================] - 3s 86ms/step - loss: 1.0755 - categorical_accuracy: 0.5819 - val_loss: 1.8778 - val_categorical_accuracy: 0.3286\n",
            "Epoch 130/200\n",
            "39/39 [==============================] - 3s 88ms/step - loss: 0.9945 - categorical_accuracy: 0.5788 - val_loss: 1.8066 - val_categorical_accuracy: 0.2714\n",
            "Epoch 131/200\n",
            "39/39 [==============================] - 3s 87ms/step - loss: 1.0469 - categorical_accuracy: 0.5862 - val_loss: 1.8751 - val_categorical_accuracy: 0.3571\n",
            "Epoch 132/200\n",
            "39/39 [==============================] - 3s 87ms/step - loss: 1.0293 - categorical_accuracy: 0.5650 - val_loss: 1.9391 - val_categorical_accuracy: 0.3286\n",
            "Epoch 133/200\n",
            "39/39 [==============================] - 3s 87ms/step - loss: 0.9683 - categorical_accuracy: 0.5867 - val_loss: 1.9999 - val_categorical_accuracy: 0.2143\n",
            "Epoch 134/200\n",
            "39/39 [==============================] - 3s 88ms/step - loss: 1.0402 - categorical_accuracy: 0.5895 - val_loss: 1.7047 - val_categorical_accuracy: 0.3429\n",
            "Epoch 135/200\n",
            "39/39 [==============================] - 3s 87ms/step - loss: 1.0308 - categorical_accuracy: 0.5992 - val_loss: 2.2312 - val_categorical_accuracy: 0.2000\n",
            "Epoch 136/200\n",
            "39/39 [==============================] - 3s 88ms/step - loss: 1.0658 - categorical_accuracy: 0.5834 - val_loss: 1.8712 - val_categorical_accuracy: 0.2429\n",
            "Epoch 137/200\n",
            "39/39 [==============================] - 3s 88ms/step - loss: 1.0185 - categorical_accuracy: 0.5859 - val_loss: 1.8220 - val_categorical_accuracy: 0.2714\n",
            "Epoch 138/200\n",
            "39/39 [==============================] - 3s 88ms/step - loss: 1.0444 - categorical_accuracy: 0.5817 - val_loss: 1.8712 - val_categorical_accuracy: 0.3143\n",
            "Epoch 139/200\n",
            "39/39 [==============================] - 3s 87ms/step - loss: 1.0230 - categorical_accuracy: 0.5791 - val_loss: 1.8482 - val_categorical_accuracy: 0.2571\n",
            "Epoch 140/200\n",
            "39/39 [==============================] - 3s 87ms/step - loss: 0.9102 - categorical_accuracy: 0.6356 - val_loss: 1.6280 - val_categorical_accuracy: 0.3286\n",
            "Epoch 141/200\n",
            "39/39 [==============================] - 3s 87ms/step - loss: 1.0385 - categorical_accuracy: 0.5713 - val_loss: 1.6706 - val_categorical_accuracy: 0.2714\n",
            "Epoch 142/200\n",
            "39/39 [==============================] - 3s 89ms/step - loss: 1.0114 - categorical_accuracy: 0.5918 - val_loss: 1.9868 - val_categorical_accuracy: 0.2286\n",
            "Epoch 143/200\n",
            "39/39 [==============================] - 3s 88ms/step - loss: 1.0429 - categorical_accuracy: 0.5702 - val_loss: 2.0476 - val_categorical_accuracy: 0.2143\n",
            "Epoch 144/200\n",
            "39/39 [==============================] - 3s 88ms/step - loss: 0.9743 - categorical_accuracy: 0.6390 - val_loss: 1.6725 - val_categorical_accuracy: 0.2571\n",
            "Epoch 145/200\n",
            "39/39 [==============================] - 3s 87ms/step - loss: 0.9418 - categorical_accuracy: 0.6255 - val_loss: 2.1079 - val_categorical_accuracy: 0.2286\n",
            "Epoch 146/200\n",
            "39/39 [==============================] - 3s 87ms/step - loss: 0.9187 - categorical_accuracy: 0.6234 - val_loss: 1.8893 - val_categorical_accuracy: 0.2571\n",
            "Epoch 147/200\n",
            "39/39 [==============================] - 3s 87ms/step - loss: 1.0685 - categorical_accuracy: 0.5591 - val_loss: 1.7145 - val_categorical_accuracy: 0.3143\n",
            "Epoch 148/200\n",
            "39/39 [==============================] - 3s 87ms/step - loss: 0.9585 - categorical_accuracy: 0.6047 - val_loss: 2.1239 - val_categorical_accuracy: 0.2000\n",
            "Epoch 149/200\n",
            "39/39 [==============================] - 3s 87ms/step - loss: 1.0363 - categorical_accuracy: 0.6146 - val_loss: 1.7993 - val_categorical_accuracy: 0.2143\n",
            "Epoch 150/200\n",
            "39/39 [==============================] - 3s 87ms/step - loss: 0.9734 - categorical_accuracy: 0.6025 - val_loss: 2.0636 - val_categorical_accuracy: 0.1857\n",
            "Epoch 151/200\n",
            "39/39 [==============================] - 3s 88ms/step - loss: 1.0025 - categorical_accuracy: 0.6006 - val_loss: 1.5353 - val_categorical_accuracy: 0.3286\n",
            "Epoch 152/200\n",
            "39/39 [==============================] - 3s 88ms/step - loss: 1.0280 - categorical_accuracy: 0.6035 - val_loss: 2.0962 - val_categorical_accuracy: 0.2286\n",
            "Epoch 153/200\n",
            "39/39 [==============================] - 3s 87ms/step - loss: 0.9163 - categorical_accuracy: 0.6026 - val_loss: 1.8069 - val_categorical_accuracy: 0.2571\n",
            "Epoch 154/200\n",
            "39/39 [==============================] - 3s 88ms/step - loss: 0.9726 - categorical_accuracy: 0.5951 - val_loss: 1.9623 - val_categorical_accuracy: 0.2429\n",
            "Epoch 155/200\n",
            "39/39 [==============================] - 3s 87ms/step - loss: 1.0166 - categorical_accuracy: 0.6271 - val_loss: 1.9026 - val_categorical_accuracy: 0.2429\n",
            "Epoch 156/200\n",
            "39/39 [==============================] - 3s 87ms/step - loss: 0.9682 - categorical_accuracy: 0.6045 - val_loss: 1.7935 - val_categorical_accuracy: 0.2714\n",
            "Epoch 157/200\n",
            "39/39 [==============================] - 3s 88ms/step - loss: 0.9762 - categorical_accuracy: 0.6070 - val_loss: 1.7692 - val_categorical_accuracy: 0.2571\n",
            "Epoch 158/200\n",
            "39/39 [==============================] - 3s 87ms/step - loss: 0.9246 - categorical_accuracy: 0.6600 - val_loss: 1.9950 - val_categorical_accuracy: 0.2429\n",
            "Epoch 159/200\n",
            "39/39 [==============================] - 3s 88ms/step - loss: 1.0325 - categorical_accuracy: 0.5963 - val_loss: 1.6503 - val_categorical_accuracy: 0.2714\n",
            "Epoch 160/200\n",
            "39/39 [==============================] - 3s 88ms/step - loss: 1.0012 - categorical_accuracy: 0.5977 - val_loss: 1.4965 - val_categorical_accuracy: 0.4143\n",
            "Epoch 161/200\n",
            "39/39 [==============================] - 3s 87ms/step - loss: 1.0709 - categorical_accuracy: 0.5243 - val_loss: 2.2915 - val_categorical_accuracy: 0.2286\n",
            "Epoch 162/200\n",
            "39/39 [==============================] - 3s 87ms/step - loss: 1.0234 - categorical_accuracy: 0.5944 - val_loss: 1.4248 - val_categorical_accuracy: 0.4000\n",
            "Epoch 163/200\n",
            "39/39 [==============================] - 3s 86ms/step - loss: 0.9608 - categorical_accuracy: 0.6437 - val_loss: 1.4337 - val_categorical_accuracy: 0.4000\n",
            "Epoch 164/200\n",
            "39/39 [==============================] - 3s 88ms/step - loss: 0.9694 - categorical_accuracy: 0.6274 - val_loss: 1.7972 - val_categorical_accuracy: 0.2714\n",
            "Epoch 165/200\n",
            "39/39 [==============================] - 3s 88ms/step - loss: 0.9380 - categorical_accuracy: 0.6119 - val_loss: 2.0690 - val_categorical_accuracy: 0.2286\n",
            "Epoch 166/200\n",
            "39/39 [==============================] - 3s 88ms/step - loss: 0.9571 - categorical_accuracy: 0.6147 - val_loss: 2.2252 - val_categorical_accuracy: 0.2286\n",
            "Epoch 167/200\n",
            "39/39 [==============================] - 3s 87ms/step - loss: 0.9517 - categorical_accuracy: 0.6063 - val_loss: 1.9213 - val_categorical_accuracy: 0.2429\n",
            "Epoch 168/200\n",
            "39/39 [==============================] - 3s 88ms/step - loss: 0.9322 - categorical_accuracy: 0.6313 - val_loss: 1.8526 - val_categorical_accuracy: 0.2714\n",
            "Epoch 169/200\n",
            "39/39 [==============================] - 3s 87ms/step - loss: 0.9520 - categorical_accuracy: 0.6105 - val_loss: 1.8147 - val_categorical_accuracy: 0.3000\n",
            "Epoch 170/200\n",
            "39/39 [==============================] - 3s 88ms/step - loss: 0.8883 - categorical_accuracy: 0.6578 - val_loss: 1.6478 - val_categorical_accuracy: 0.3000\n",
            "Epoch 171/200\n",
            "39/39 [==============================] - 3s 88ms/step - loss: 0.8511 - categorical_accuracy: 0.6532 - val_loss: 2.1332 - val_categorical_accuracy: 0.2143\n",
            "Epoch 172/200\n",
            "39/39 [==============================] - 3s 88ms/step - loss: 0.9390 - categorical_accuracy: 0.5975 - val_loss: 1.5770 - val_categorical_accuracy: 0.3286\n",
            "Epoch 173/200\n",
            "39/39 [==============================] - 3s 88ms/step - loss: 0.9528 - categorical_accuracy: 0.6109 - val_loss: 1.6667 - val_categorical_accuracy: 0.3143\n",
            "Epoch 174/200\n",
            "39/39 [==============================] - 3s 88ms/step - loss: 0.8540 - categorical_accuracy: 0.6324 - val_loss: 1.8016 - val_categorical_accuracy: 0.2429\n",
            "Epoch 175/200\n",
            "39/39 [==============================] - 3s 88ms/step - loss: 0.9617 - categorical_accuracy: 0.6213 - val_loss: 1.7424 - val_categorical_accuracy: 0.3000\n",
            "Epoch 176/200\n",
            "39/39 [==============================] - 3s 88ms/step - loss: 0.9873 - categorical_accuracy: 0.5921 - val_loss: 2.1480 - val_categorical_accuracy: 0.2429\n",
            "Epoch 177/200\n",
            "39/39 [==============================] - 3s 87ms/step - loss: 0.8124 - categorical_accuracy: 0.6847 - val_loss: 2.5937 - val_categorical_accuracy: 0.1857\n",
            "Epoch 178/200\n",
            "39/39 [==============================] - 3s 87ms/step - loss: 0.9420 - categorical_accuracy: 0.6257 - val_loss: 1.3386 - val_categorical_accuracy: 0.5000\n",
            "Epoch 179/200\n",
            "39/39 [==============================] - 3s 87ms/step - loss: 0.9639 - categorical_accuracy: 0.6231 - val_loss: 1.8053 - val_categorical_accuracy: 0.3000\n",
            "Epoch 180/200\n",
            "39/39 [==============================] - 3s 88ms/step - loss: 0.9040 - categorical_accuracy: 0.6523 - val_loss: 1.8088 - val_categorical_accuracy: 0.2429\n",
            "Epoch 181/200\n",
            "39/39 [==============================] - 3s 87ms/step - loss: 0.9093 - categorical_accuracy: 0.6466 - val_loss: 1.6179 - val_categorical_accuracy: 0.3429\n",
            "Epoch 182/200\n",
            "39/39 [==============================] - 3s 86ms/step - loss: 0.9055 - categorical_accuracy: 0.6307 - val_loss: 1.8355 - val_categorical_accuracy: 0.2857\n",
            "Epoch 183/200\n",
            "39/39 [==============================] - 3s 87ms/step - loss: 0.8726 - categorical_accuracy: 0.6857 - val_loss: 1.7335 - val_categorical_accuracy: 0.3000\n",
            "Epoch 184/200\n",
            "39/39 [==============================] - 3s 87ms/step - loss: 0.9055 - categorical_accuracy: 0.6375 - val_loss: 1.4996 - val_categorical_accuracy: 0.3429\n",
            "Epoch 185/200\n",
            "39/39 [==============================] - 3s 87ms/step - loss: 0.8585 - categorical_accuracy: 0.6484 - val_loss: 1.9366 - val_categorical_accuracy: 0.2429\n",
            "Epoch 186/200\n",
            "39/39 [==============================] - 3s 87ms/step - loss: 0.8420 - categorical_accuracy: 0.6602 - val_loss: 1.9162 - val_categorical_accuracy: 0.2429\n",
            "Epoch 187/200\n",
            "39/39 [==============================] - 3s 88ms/step - loss: 0.8244 - categorical_accuracy: 0.6758 - val_loss: 1.6477 - val_categorical_accuracy: 0.3429\n",
            "Epoch 188/200\n",
            "39/39 [==============================] - 3s 88ms/step - loss: 0.9084 - categorical_accuracy: 0.6186 - val_loss: 1.4020 - val_categorical_accuracy: 0.4286\n",
            "Epoch 189/200\n",
            "39/39 [==============================] - 3s 87ms/step - loss: 0.9439 - categorical_accuracy: 0.5912 - val_loss: 1.7817 - val_categorical_accuracy: 0.3143\n",
            "Epoch 190/200\n",
            "39/39 [==============================] - 3s 87ms/step - loss: 0.9662 - categorical_accuracy: 0.6170 - val_loss: 1.9287 - val_categorical_accuracy: 0.3429\n",
            "Epoch 191/200\n",
            "39/39 [==============================] - 3s 87ms/step - loss: 1.0770 - categorical_accuracy: 0.5809 - val_loss: 1.9307 - val_categorical_accuracy: 0.2571\n",
            "Epoch 192/200\n",
            "39/39 [==============================] - 3s 87ms/step - loss: 0.8262 - categorical_accuracy: 0.6612 - val_loss: 1.8745 - val_categorical_accuracy: 0.2857\n",
            "Epoch 193/200\n",
            "39/39 [==============================] - 3s 88ms/step - loss: 0.8681 - categorical_accuracy: 0.6472 - val_loss: 1.8949 - val_categorical_accuracy: 0.2571\n",
            "Epoch 194/200\n",
            "39/39 [==============================] - 3s 89ms/step - loss: 0.8584 - categorical_accuracy: 0.6314 - val_loss: 1.9007 - val_categorical_accuracy: 0.3000\n",
            "Epoch 195/200\n",
            "39/39 [==============================] - 3s 87ms/step - loss: 0.9320 - categorical_accuracy: 0.6416 - val_loss: 2.1003 - val_categorical_accuracy: 0.2286\n",
            "Epoch 196/200\n",
            "39/39 [==============================] - 3s 87ms/step - loss: 0.8920 - categorical_accuracy: 0.6500 - val_loss: 2.2268 - val_categorical_accuracy: 0.2143\n",
            "Epoch 197/200\n",
            "39/39 [==============================] - 3s 87ms/step - loss: 0.7931 - categorical_accuracy: 0.6943 - val_loss: 1.7956 - val_categorical_accuracy: 0.3000\n",
            "Epoch 198/200\n",
            "39/39 [==============================] - 3s 88ms/step - loss: 0.8080 - categorical_accuracy: 0.6622 - val_loss: 1.9314 - val_categorical_accuracy: 0.2714\n",
            "Epoch 199/200\n",
            "39/39 [==============================] - 3s 89ms/step - loss: 0.7886 - categorical_accuracy: 0.6937 - val_loss: 1.7955 - val_categorical_accuracy: 0.3143\n",
            "Epoch 200/200\n",
            "39/39 [==============================] - 3s 88ms/step - loss: 0.9526 - categorical_accuracy: 0.6076 - val_loss: 2.0302 - val_categorical_accuracy: 0.2429\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wbd4kBYxaYW-"
      },
      "source": [
        "model.save('/content/drive/MyDrive/Colab Notebooks/SPEECH_EMOTION_Recognition/Nộp bài(chốt hạ)/model_saver/conv2D_tempogram_ravdess.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BFVwS5gkZ1D6"
      },
      "source": [
        "###test_result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ayz0uTrCZ1D7",
        "outputId": "7ac42a7f-e48d-4d93-f3d1-cca51916803d"
      },
      "source": [
        "d = {0: 'happy',\n",
        "     1: 'sad',\n",
        "     2: 'angry',\n",
        "     3: 'fear'}\n",
        "Y_test_pred = np.argmax(model.predict(X_test), axis=-1)\n",
        "Y_test_pred = list(map(lambda x: d[x], Y_test_pred))\n",
        "y_test = np.argmax(y_test, axis=-1)\n",
        "y_test = list(map(lambda x: d[x], y_test))\n",
        "print(classification_report(y_test, Y_test_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.50      0.08      0.13        13\n",
            "        fear       0.40      0.38      0.39        21\n",
            "       happy       0.00      0.00      0.00        23\n",
            "         sad       0.35      0.90      0.50        20\n",
            "\n",
            "    accuracy                           0.35        77\n",
            "   macro avg       0.31      0.34      0.26        77\n",
            "weighted avg       0.28      0.35      0.26        77\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "id": "yQ2f7Tp7Z1D8",
        "outputId": "d42db12f-de92-45c3-b75e-9e302e8b4a7d"
      },
      "source": [
        "import scikitplot as skplt\n",
        "\n",
        "skplt.metrics.plot_confusion_matrix(\n",
        "    y_test, \n",
        "    Y_test_pred,\n",
        "    figsize=(8,8))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fdaeb80ad50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 137
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2x9nMZ6DZ1D8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qLKgMiv0bNC8"
      },
      "source": [
        "# Combined feature + basic model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mpYPfJvfeuCL"
      },
      "source": [
        "signal, sr = librosa.load('/content/drive/MyDrive/Colab Notebooks/SPEECH_EMOTION_Recognition/datasets/archive/Actor_03/03-01-01-01-02-01-03.wav')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cAjx6gNxe1oa"
      },
      "source": [
        "mfcc = np.mean(librosa.feature.mfcc(y=signal, sr=sr, n_mfcc=39).T,axis=0)\n",
        "mel_spec = np.mean(librosa.feature.melspectrogram(signal, sr, n_mels=28).T, axis=0)\n",
        "tempogram = np.mean(librosa.feature.tempogram(signal, sr, win_length=24).T, axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f8OeNYEVe1sH"
      },
      "source": [
        "mfcc = pd.DataFrame(mfcc)\n",
        "mel_spec = pd.DataFrame(mel_spec)\n",
        "tempogram = pd.DataFrame(tempogram)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VAqhTK5Ve1vr"
      },
      "source": [
        "a = mfcc.append(mel_spec).append(tempogram)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ah72kj66gBsu",
        "outputId": "ec73488d-b826-4903-a1af-2c0acd5a4f9b"
      },
      "source": [
        "np.array(a[0]).shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(91,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 163
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WHzMperfhcJh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVHB0C0fbNDK"
      },
      "source": [
        "features = []\n",
        "labels = []\n",
        "for i in range(len(Ravdess_DF['Paths'])):\n",
        "  if ((Ravdess_DF['Emotion'][i] == '03') | (Ravdess_DF['Emotion'][i] == '04') | \n",
        "      (Ravdess_DF['Emotion'][i] == '05') | (Ravdess_DF['Emotion'][i] == '06')):\n",
        "    signal, sr = librosa.load(Ravdess_DF['Paths'][i])\n",
        "    if len(signal) > input_length:\n",
        "        signal = signal[0:input_length]\n",
        "    elif  input_length > len(signal):\n",
        "        max_offset = input_length - len(signal)  \n",
        "        signal = np.pad(signal, (0, max_offset), \"constant\")\n",
        "    mfcc = np.mean(librosa.feature.mfcc(y=signal, sr=sr, n_mfcc=39).T,axis=0)\n",
        "    mel_spec = np.mean(librosa.feature.melspectrogram(signal, sr, n_mels=28).T, axis=0)\n",
        "    tempogram = np.mean(librosa.feature.tempogram(signal, sr, win_length=24).T, axis=0)\n",
        "\n",
        "    mfcc = pd.DataFrame(mfcc)\n",
        "    mel_spec = pd.DataFrame(mel_spec)\n",
        "    tempogram = pd.DataFrame(tempogram)\n",
        "    feature = mfcc.append(mel_spec).append(tempogram)\n",
        "    feature = np.array(feature[0])\n",
        "    features.append(feature)\n",
        "    if Ravdess_DF['Emotion'][i] == '03':\n",
        "      labels.append(0)\n",
        "    elif Ravdess_DF['Emotion'][i] == '04':\n",
        "      labels.append(1)\n",
        "    elif Ravdess_DF['Emotion'][i] == '05':\n",
        "      labels.append(2)\n",
        "    elif Ravdess_DF['Emotion'][i] == '06':\n",
        "      labels.append(3)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6e2Kzf1whcUF"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "sc = StandardScaler()\n",
        "features = sc.fit_transform(features)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HdJCV4lVbNDL"
      },
      "source": [
        "X = features\n",
        "y = labels\n",
        "\n",
        "y = np.array(y)\n",
        "y = to_categorical(y)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=0)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=0)\n",
        "\n",
        "X_train = np.array(X_train)\n",
        "X_test = np.array(X_test)\n",
        "X_val = np.array(X_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "raK241T-jG41",
        "outputId": "94fbaf52-98a2-4b36-a185-f68bcc0b6a79"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(621, 91)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 171
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XSNUyBRPbNDM"
      },
      "source": [
        "## basic models:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MtpRYpB3bNDN",
        "outputId": "ef24fee2-9dd3-47c5-bbd5-8be4ec16d53a"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(91, input_shape=(91, ), activation = 'relu'))\n",
        "#model.add(Dropout(0.1))\n",
        "model.add(Dense(128, activation = 'relu'))\n",
        "#model.add(Dropout(0.25))\n",
        "model.add(Dense(128, activation = 'relu'))\n",
        "#model.add(Dropout(0.2))\n",
        "model.add(Dense(4, activation = 'softmax'))\n",
        "\n",
        "optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
        "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer=optimizer)\n",
        "early_stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=100, verbose=1, mode='auto')\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_33 (Dense)             (None, 91)                8372      \n",
            "_________________________________________________________________\n",
            "dense_34 (Dense)             (None, 128)               11776     \n",
            "_________________________________________________________________\n",
            "dense_35 (Dense)             (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dense_36 (Dense)             (None, 4)                 516       \n",
            "=================================================================\n",
            "Total params: 37,176\n",
            "Trainable params: 37,176\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xwrMDDGabNDN",
        "outputId": "10abff98-0135-4463-90b8-7bc833721254"
      },
      "source": [
        "history = model.fit(X_train, y_train, batch_size=64, epochs=200, \n",
        "                    validation_data=(X_val, y_val))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "10/10 [==============================] - 1s 35ms/step - loss: 1.3870 - accuracy: 0.2791 - val_loss: 1.2473 - val_accuracy: 0.4429\n",
            "Epoch 2/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1523 - accuracy: 0.5117 - val_loss: 1.2327 - val_accuracy: 0.4429\n",
            "Epoch 3/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0308 - accuracy: 0.5462 - val_loss: 1.1705 - val_accuracy: 0.5000\n",
            "Epoch 4/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9137 - accuracy: 0.6341 - val_loss: 1.1354 - val_accuracy: 0.5000\n",
            "Epoch 5/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8272 - accuracy: 0.6762 - val_loss: 1.0916 - val_accuracy: 0.5429\n",
            "Epoch 6/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6991 - accuracy: 0.7601 - val_loss: 1.0475 - val_accuracy: 0.5429\n",
            "Epoch 7/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6535 - accuracy: 0.7772 - val_loss: 0.9789 - val_accuracy: 0.6000\n",
            "Epoch 8/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.5618 - accuracy: 0.8445 - val_loss: 0.9613 - val_accuracy: 0.5857\n",
            "Epoch 9/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.4860 - accuracy: 0.8580 - val_loss: 1.0018 - val_accuracy: 0.5714\n",
            "Epoch 10/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.4100 - accuracy: 0.8829 - val_loss: 0.9119 - val_accuracy: 0.6143\n",
            "Epoch 11/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.3539 - accuracy: 0.8976 - val_loss: 0.9840 - val_accuracy: 0.5714\n",
            "Epoch 12/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.2883 - accuracy: 0.9257 - val_loss: 0.9078 - val_accuracy: 0.6714\n",
            "Epoch 13/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.2313 - accuracy: 0.9402 - val_loss: 0.8817 - val_accuracy: 0.6714\n",
            "Epoch 14/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.2100 - accuracy: 0.9492 - val_loss: 0.9725 - val_accuracy: 0.6286\n",
            "Epoch 15/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.1921 - accuracy: 0.9579 - val_loss: 0.9257 - val_accuracy: 0.6857\n",
            "Epoch 16/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.1241 - accuracy: 0.9932 - val_loss: 0.9158 - val_accuracy: 0.6571\n",
            "Epoch 17/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.1113 - accuracy: 0.9896 - val_loss: 0.9596 - val_accuracy: 0.6429\n",
            "Epoch 18/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0857 - accuracy: 0.9933 - val_loss: 0.9376 - val_accuracy: 0.6714\n",
            "Epoch 19/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0791 - accuracy: 0.9983 - val_loss: 0.9885 - val_accuracy: 0.6286\n",
            "Epoch 20/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0662 - accuracy: 1.0000 - val_loss: 0.9835 - val_accuracy: 0.7000\n",
            "Epoch 21/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0446 - accuracy: 0.9986 - val_loss: 1.0100 - val_accuracy: 0.6714\n",
            "Epoch 22/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0405 - accuracy: 0.9983 - val_loss: 0.9778 - val_accuracy: 0.7143\n",
            "Epoch 23/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0374 - accuracy: 1.0000 - val_loss: 1.0207 - val_accuracy: 0.6857\n",
            "Epoch 24/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0334 - accuracy: 0.9992 - val_loss: 1.0981 - val_accuracy: 0.7000\n",
            "Epoch 25/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0244 - accuracy: 1.0000 - val_loss: 1.0277 - val_accuracy: 0.7000\n",
            "Epoch 26/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0191 - accuracy: 1.0000 - val_loss: 1.1080 - val_accuracy: 0.7000\n",
            "Epoch 27/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0188 - accuracy: 1.0000 - val_loss: 1.0893 - val_accuracy: 0.7143\n",
            "Epoch 28/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0166 - accuracy: 1.0000 - val_loss: 1.1009 - val_accuracy: 0.7000\n",
            "Epoch 29/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0135 - accuracy: 1.0000 - val_loss: 1.1099 - val_accuracy: 0.7000\n",
            "Epoch 30/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0121 - accuracy: 1.0000 - val_loss: 1.1389 - val_accuracy: 0.7000\n",
            "Epoch 31/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 1.1417 - val_accuracy: 0.7000\n",
            "Epoch 32/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 1.1467 - val_accuracy: 0.7000\n",
            "Epoch 33/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 1.1655 - val_accuracy: 0.7000\n",
            "Epoch 34/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 1.1763 - val_accuracy: 0.7000\n",
            "Epoch 35/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 1.1870 - val_accuracy: 0.7143\n",
            "Epoch 36/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 1.2083 - val_accuracy: 0.7000\n",
            "Epoch 37/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 1.2230 - val_accuracy: 0.7000\n",
            "Epoch 38/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 1.2150 - val_accuracy: 0.7000\n",
            "Epoch 39/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 1.2239 - val_accuracy: 0.7143\n",
            "Epoch 40/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.2355 - val_accuracy: 0.7143\n",
            "Epoch 41/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.2467 - val_accuracy: 0.7143\n",
            "Epoch 42/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.2609 - val_accuracy: 0.7000\n",
            "Epoch 43/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.2671 - val_accuracy: 0.7000\n",
            "Epoch 44/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.2848 - val_accuracy: 0.7000\n",
            "Epoch 45/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.2725 - val_accuracy: 0.7143\n",
            "Epoch 46/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.2878 - val_accuracy: 0.7143\n",
            "Epoch 47/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.3009 - val_accuracy: 0.7000\n",
            "Epoch 48/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.3018 - val_accuracy: 0.7143\n",
            "Epoch 49/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.3129 - val_accuracy: 0.7143\n",
            "Epoch 50/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.3184 - val_accuracy: 0.7143\n",
            "Epoch 51/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.3309 - val_accuracy: 0.7143\n",
            "Epoch 52/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.3313 - val_accuracy: 0.7143\n",
            "Epoch 53/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.3420 - val_accuracy: 0.7143\n",
            "Epoch 54/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.3475 - val_accuracy: 0.7143\n",
            "Epoch 55/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.3527 - val_accuracy: 0.7143\n",
            "Epoch 56/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.3570 - val_accuracy: 0.7143\n",
            "Epoch 57/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.3602 - val_accuracy: 0.7143\n",
            "Epoch 58/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.3676 - val_accuracy: 0.7143\n",
            "Epoch 59/200\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.3789 - val_accuracy: 0.7143\n",
            "Epoch 60/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.3834 - val_accuracy: 0.7143\n",
            "Epoch 61/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.3817 - val_accuracy: 0.7143\n",
            "Epoch 62/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.3885 - val_accuracy: 0.7143\n",
            "Epoch 63/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.4040 - val_accuracy: 0.7143\n",
            "Epoch 64/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.4004 - val_accuracy: 0.7143\n",
            "Epoch 65/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.4026 - val_accuracy: 0.7143\n",
            "Epoch 66/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.4143 - val_accuracy: 0.7143\n",
            "Epoch 67/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.4199 - val_accuracy: 0.7143\n",
            "Epoch 68/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.4239 - val_accuracy: 0.7143\n",
            "Epoch 69/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.4278 - val_accuracy: 0.7143\n",
            "Epoch 70/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.4317 - val_accuracy: 0.7143\n",
            "Epoch 71/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.4390 - val_accuracy: 0.7143\n",
            "Epoch 72/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.4475 - val_accuracy: 0.7143\n",
            "Epoch 73/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.4496 - val_accuracy: 0.7143\n",
            "Epoch 74/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.4545 - val_accuracy: 0.7143\n",
            "Epoch 75/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 9.6260e-04 - accuracy: 1.0000 - val_loss: 1.4547 - val_accuracy: 0.7143\n",
            "Epoch 76/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 9.0573e-04 - accuracy: 1.0000 - val_loss: 1.4577 - val_accuracy: 0.7143\n",
            "Epoch 77/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 8.8386e-04 - accuracy: 1.0000 - val_loss: 1.4716 - val_accuracy: 0.7143\n",
            "Epoch 78/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 8.4881e-04 - accuracy: 1.0000 - val_loss: 1.4719 - val_accuracy: 0.7143\n",
            "Epoch 79/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 7.9044e-04 - accuracy: 1.0000 - val_loss: 1.4790 - val_accuracy: 0.7143\n",
            "Epoch 80/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 8.4358e-04 - accuracy: 1.0000 - val_loss: 1.4829 - val_accuracy: 0.7143\n",
            "Epoch 81/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 8.3558e-04 - accuracy: 1.0000 - val_loss: 1.4864 - val_accuracy: 0.7143\n",
            "Epoch 82/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 7.4817e-04 - accuracy: 1.0000 - val_loss: 1.4939 - val_accuracy: 0.7143\n",
            "Epoch 83/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 8.2539e-04 - accuracy: 1.0000 - val_loss: 1.4984 - val_accuracy: 0.7143\n",
            "Epoch 84/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 7.3504e-04 - accuracy: 1.0000 - val_loss: 1.5002 - val_accuracy: 0.7143\n",
            "Epoch 85/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 7.4233e-04 - accuracy: 1.0000 - val_loss: 1.5077 - val_accuracy: 0.7143\n",
            "Epoch 86/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 7.3065e-04 - accuracy: 1.0000 - val_loss: 1.5089 - val_accuracy: 0.7143\n",
            "Epoch 87/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 6.8544e-04 - accuracy: 1.0000 - val_loss: 1.5114 - val_accuracy: 0.7143\n",
            "Epoch 88/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 6.4535e-04 - accuracy: 1.0000 - val_loss: 1.5186 - val_accuracy: 0.7143\n",
            "Epoch 89/200\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 6.4504e-04 - accuracy: 1.0000 - val_loss: 1.5202 - val_accuracy: 0.7143\n",
            "Epoch 90/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.8757e-04 - accuracy: 1.0000 - val_loss: 1.5262 - val_accuracy: 0.7143\n",
            "Epoch 91/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 5.7860e-04 - accuracy: 1.0000 - val_loss: 1.5299 - val_accuracy: 0.7143\n",
            "Epoch 92/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 5.8197e-04 - accuracy: 1.0000 - val_loss: 1.5350 - val_accuracy: 0.7143\n",
            "Epoch 93/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.6135e-04 - accuracy: 1.0000 - val_loss: 1.5362 - val_accuracy: 0.7143\n",
            "Epoch 94/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 6.2302e-04 - accuracy: 1.0000 - val_loss: 1.5413 - val_accuracy: 0.7143\n",
            "Epoch 95/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 5.5244e-04 - accuracy: 1.0000 - val_loss: 1.5441 - val_accuracy: 0.7143\n",
            "Epoch 96/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.2028e-04 - accuracy: 1.0000 - val_loss: 1.5476 - val_accuracy: 0.7143\n",
            "Epoch 97/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 5.1530e-04 - accuracy: 1.0000 - val_loss: 1.5512 - val_accuracy: 0.7143\n",
            "Epoch 98/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 5.1906e-04 - accuracy: 1.0000 - val_loss: 1.5555 - val_accuracy: 0.7143\n",
            "Epoch 99/200\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 5.1604e-04 - accuracy: 1.0000 - val_loss: 1.5620 - val_accuracy: 0.7143\n",
            "Epoch 100/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.4650e-04 - accuracy: 1.0000 - val_loss: 1.5641 - val_accuracy: 0.7143\n",
            "Epoch 101/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 4.4912e-04 - accuracy: 1.0000 - val_loss: 1.5647 - val_accuracy: 0.7143\n",
            "Epoch 102/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 4.7508e-04 - accuracy: 1.0000 - val_loss: 1.5716 - val_accuracy: 0.7143\n",
            "Epoch 103/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 5.0034e-04 - accuracy: 1.0000 - val_loss: 1.5702 - val_accuracy: 0.7143\n",
            "Epoch 104/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 4.7655e-04 - accuracy: 1.0000 - val_loss: 1.5758 - val_accuracy: 0.7143\n",
            "Epoch 105/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.6948e-04 - accuracy: 1.0000 - val_loss: 1.5794 - val_accuracy: 0.7143\n",
            "Epoch 106/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.2737e-04 - accuracy: 1.0000 - val_loss: 1.5830 - val_accuracy: 0.7143\n",
            "Epoch 107/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.0631e-04 - accuracy: 1.0000 - val_loss: 1.5874 - val_accuracy: 0.7143\n",
            "Epoch 108/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 3.9967e-04 - accuracy: 1.0000 - val_loss: 1.5901 - val_accuracy: 0.7143\n",
            "Epoch 109/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 3.9840e-04 - accuracy: 1.0000 - val_loss: 1.5916 - val_accuracy: 0.7143\n",
            "Epoch 110/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 3.9806e-04 - accuracy: 1.0000 - val_loss: 1.5930 - val_accuracy: 0.7143\n",
            "Epoch 111/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.9081e-04 - accuracy: 1.0000 - val_loss: 1.5969 - val_accuracy: 0.7143\n",
            "Epoch 112/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.4743e-04 - accuracy: 1.0000 - val_loss: 1.6020 - val_accuracy: 0.7143\n",
            "Epoch 113/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 3.5991e-04 - accuracy: 1.0000 - val_loss: 1.6059 - val_accuracy: 0.7143\n",
            "Epoch 114/200\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 3.5170e-04 - accuracy: 1.0000 - val_loss: 1.6075 - val_accuracy: 0.7143\n",
            "Epoch 115/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.4460e-04 - accuracy: 1.0000 - val_loss: 1.6109 - val_accuracy: 0.7143\n",
            "Epoch 116/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.2067e-04 - accuracy: 1.0000 - val_loss: 1.6156 - val_accuracy: 0.7143\n",
            "Epoch 117/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.3967e-04 - accuracy: 1.0000 - val_loss: 1.6158 - val_accuracy: 0.7143\n",
            "Epoch 118/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 3.3442e-04 - accuracy: 1.0000 - val_loss: 1.6197 - val_accuracy: 0.7143\n",
            "Epoch 119/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.0853e-04 - accuracy: 1.0000 - val_loss: 1.6193 - val_accuracy: 0.7143\n",
            "Epoch 120/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.3445e-04 - accuracy: 1.0000 - val_loss: 1.6218 - val_accuracy: 0.7143\n",
            "Epoch 121/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.0943e-04 - accuracy: 1.0000 - val_loss: 1.6253 - val_accuracy: 0.7143\n",
            "Epoch 122/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 3.0835e-04 - accuracy: 1.0000 - val_loss: 1.6291 - val_accuracy: 0.7143\n",
            "Epoch 123/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 2.7899e-04 - accuracy: 1.0000 - val_loss: 1.6350 - val_accuracy: 0.7143\n",
            "Epoch 124/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.0047e-04 - accuracy: 1.0000 - val_loss: 1.6366 - val_accuracy: 0.7143\n",
            "Epoch 125/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.7406e-04 - accuracy: 1.0000 - val_loss: 1.6391 - val_accuracy: 0.7143\n",
            "Epoch 126/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.7174e-04 - accuracy: 1.0000 - val_loss: 1.6424 - val_accuracy: 0.7143\n",
            "Epoch 127/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.8432e-04 - accuracy: 1.0000 - val_loss: 1.6450 - val_accuracy: 0.7143\n",
            "Epoch 128/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.8276e-04 - accuracy: 1.0000 - val_loss: 1.6471 - val_accuracy: 0.7143\n",
            "Epoch 129/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 2.6256e-04 - accuracy: 1.0000 - val_loss: 1.6490 - val_accuracy: 0.7143\n",
            "Epoch 130/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 2.5678e-04 - accuracy: 1.0000 - val_loss: 1.6517 - val_accuracy: 0.7143\n",
            "Epoch 131/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.5581e-04 - accuracy: 1.0000 - val_loss: 1.6530 - val_accuracy: 0.7143\n",
            "Epoch 132/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.6046e-04 - accuracy: 1.0000 - val_loss: 1.6572 - val_accuracy: 0.7143\n",
            "Epoch 133/200\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.4396e-04 - accuracy: 1.0000 - val_loss: 1.6598 - val_accuracy: 0.7143\n",
            "Epoch 134/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.4611e-04 - accuracy: 1.0000 - val_loss: 1.6626 - val_accuracy: 0.7143\n",
            "Epoch 135/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.4723e-04 - accuracy: 1.0000 - val_loss: 1.6657 - val_accuracy: 0.7143\n",
            "Epoch 136/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.4228e-04 - accuracy: 1.0000 - val_loss: 1.6681 - val_accuracy: 0.7143\n",
            "Epoch 137/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 2.1793e-04 - accuracy: 1.0000 - val_loss: 1.6702 - val_accuracy: 0.7143\n",
            "Epoch 138/200\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.2653e-04 - accuracy: 1.0000 - val_loss: 1.6728 - val_accuracy: 0.7143\n",
            "Epoch 139/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.1755e-04 - accuracy: 1.0000 - val_loss: 1.6794 - val_accuracy: 0.7143\n",
            "Epoch 140/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 2.1585e-04 - accuracy: 1.0000 - val_loss: 1.6776 - val_accuracy: 0.7143\n",
            "Epoch 141/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.2218e-04 - accuracy: 1.0000 - val_loss: 1.6810 - val_accuracy: 0.7143\n",
            "Epoch 142/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.9755e-04 - accuracy: 1.0000 - val_loss: 1.6821 - val_accuracy: 0.7143\n",
            "Epoch 143/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.0612e-04 - accuracy: 1.0000 - val_loss: 1.6859 - val_accuracy: 0.7143\n",
            "Epoch 144/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.0515e-04 - accuracy: 1.0000 - val_loss: 1.6881 - val_accuracy: 0.7143\n",
            "Epoch 145/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.1038e-04 - accuracy: 1.0000 - val_loss: 1.6905 - val_accuracy: 0.7143\n",
            "Epoch 146/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.9817e-04 - accuracy: 1.0000 - val_loss: 1.6920 - val_accuracy: 0.7143\n",
            "Epoch 147/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.7291e-04 - accuracy: 1.0000 - val_loss: 1.6957 - val_accuracy: 0.7143\n",
            "Epoch 148/200\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.8185e-04 - accuracy: 1.0000 - val_loss: 1.6967 - val_accuracy: 0.7143\n",
            "Epoch 149/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.8190e-04 - accuracy: 1.0000 - val_loss: 1.6986 - val_accuracy: 0.7143\n",
            "Epoch 150/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.8250e-04 - accuracy: 1.0000 - val_loss: 1.7013 - val_accuracy: 0.7143\n",
            "Epoch 151/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.9023e-04 - accuracy: 1.0000 - val_loss: 1.7044 - val_accuracy: 0.7143\n",
            "Epoch 152/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.8094e-04 - accuracy: 1.0000 - val_loss: 1.7062 - val_accuracy: 0.7143\n",
            "Epoch 153/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.6569e-04 - accuracy: 1.0000 - val_loss: 1.7090 - val_accuracy: 0.7143\n",
            "Epoch 154/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.7700e-04 - accuracy: 1.0000 - val_loss: 1.7123 - val_accuracy: 0.7143\n",
            "Epoch 155/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.8028e-04 - accuracy: 1.0000 - val_loss: 1.7131 - val_accuracy: 0.7143\n",
            "Epoch 156/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.5727e-04 - accuracy: 1.0000 - val_loss: 1.7141 - val_accuracy: 0.7143\n",
            "Epoch 157/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.6165e-04 - accuracy: 1.0000 - val_loss: 1.7157 - val_accuracy: 0.7143\n",
            "Epoch 158/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.6422e-04 - accuracy: 1.0000 - val_loss: 1.7199 - val_accuracy: 0.7143\n",
            "Epoch 159/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.5183e-04 - accuracy: 1.0000 - val_loss: 1.7237 - val_accuracy: 0.7143\n",
            "Epoch 160/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.6209e-04 - accuracy: 1.0000 - val_loss: 1.7250 - val_accuracy: 0.7143\n",
            "Epoch 161/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.5337e-04 - accuracy: 1.0000 - val_loss: 1.7266 - val_accuracy: 0.7143\n",
            "Epoch 162/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.5343e-04 - accuracy: 1.0000 - val_loss: 1.7290 - val_accuracy: 0.7143\n",
            "Epoch 163/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.4770e-04 - accuracy: 1.0000 - val_loss: 1.7311 - val_accuracy: 0.7143\n",
            "Epoch 164/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.5732e-04 - accuracy: 1.0000 - val_loss: 1.7321 - val_accuracy: 0.7143\n",
            "Epoch 165/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3814e-04 - accuracy: 1.0000 - val_loss: 1.7353 - val_accuracy: 0.7143\n",
            "Epoch 166/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.5191e-04 - accuracy: 1.0000 - val_loss: 1.7381 - val_accuracy: 0.7143\n",
            "Epoch 167/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.5370e-04 - accuracy: 1.0000 - val_loss: 1.7407 - val_accuracy: 0.7143\n",
            "Epoch 168/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.5035e-04 - accuracy: 1.0000 - val_loss: 1.7422 - val_accuracy: 0.7143\n",
            "Epoch 169/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.3288e-04 - accuracy: 1.0000 - val_loss: 1.7446 - val_accuracy: 0.7143\n",
            "Epoch 170/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.3863e-04 - accuracy: 1.0000 - val_loss: 1.7461 - val_accuracy: 0.7143\n",
            "Epoch 171/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.3194e-04 - accuracy: 1.0000 - val_loss: 1.7496 - val_accuracy: 0.7143\n",
            "Epoch 172/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.3066e-04 - accuracy: 1.0000 - val_loss: 1.7503 - val_accuracy: 0.7143\n",
            "Epoch 173/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2614e-04 - accuracy: 1.0000 - val_loss: 1.7512 - val_accuracy: 0.7143\n",
            "Epoch 174/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.2840e-04 - accuracy: 1.0000 - val_loss: 1.7554 - val_accuracy: 0.7143\n",
            "Epoch 175/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.3150e-04 - accuracy: 1.0000 - val_loss: 1.7566 - val_accuracy: 0.7143\n",
            "Epoch 176/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.2739e-04 - accuracy: 1.0000 - val_loss: 1.7578 - val_accuracy: 0.7143\n",
            "Epoch 177/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.2547e-04 - accuracy: 1.0000 - val_loss: 1.7597 - val_accuracy: 0.7143\n",
            "Epoch 178/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.2564e-04 - accuracy: 1.0000 - val_loss: 1.7619 - val_accuracy: 0.7143\n",
            "Epoch 179/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.1478e-04 - accuracy: 1.0000 - val_loss: 1.7653 - val_accuracy: 0.7143\n",
            "Epoch 180/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.1914e-04 - accuracy: 1.0000 - val_loss: 1.7658 - val_accuracy: 0.7143\n",
            "Epoch 181/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.1317e-04 - accuracy: 1.0000 - val_loss: 1.7672 - val_accuracy: 0.7143\n",
            "Epoch 182/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.3324e-04 - accuracy: 1.0000 - val_loss: 1.7700 - val_accuracy: 0.7143\n",
            "Epoch 183/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.1644e-04 - accuracy: 1.0000 - val_loss: 1.7705 - val_accuracy: 0.7143\n",
            "Epoch 184/200\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.1384e-04 - accuracy: 1.0000 - val_loss: 1.7717 - val_accuracy: 0.7143\n",
            "Epoch 185/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.0975e-04 - accuracy: 1.0000 - val_loss: 1.7745 - val_accuracy: 0.7143\n",
            "Epoch 186/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.1192e-04 - accuracy: 1.0000 - val_loss: 1.7775 - val_accuracy: 0.7143\n",
            "Epoch 187/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.0491e-04 - accuracy: 1.0000 - val_loss: 1.7793 - val_accuracy: 0.7143\n",
            "Epoch 188/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.0940e-04 - accuracy: 1.0000 - val_loss: 1.7804 - val_accuracy: 0.7143\n",
            "Epoch 189/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.0704e-04 - accuracy: 1.0000 - val_loss: 1.7812 - val_accuracy: 0.7143\n",
            "Epoch 190/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.0736e-04 - accuracy: 1.0000 - val_loss: 1.7847 - val_accuracy: 0.7143\n",
            "Epoch 191/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 9.9655e-05 - accuracy: 1.0000 - val_loss: 1.7855 - val_accuracy: 0.7143\n",
            "Epoch 192/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 9.9744e-05 - accuracy: 1.0000 - val_loss: 1.7871 - val_accuracy: 0.7143\n",
            "Epoch 193/200\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.0679e-04 - accuracy: 1.0000 - val_loss: 1.7910 - val_accuracy: 0.7143\n",
            "Epoch 194/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.0118e-04 - accuracy: 1.0000 - val_loss: 1.7940 - val_accuracy: 0.7143\n",
            "Epoch 195/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.0342e-04 - accuracy: 1.0000 - val_loss: 1.7925 - val_accuracy: 0.7143\n",
            "Epoch 196/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.0252e-04 - accuracy: 1.0000 - val_loss: 1.7954 - val_accuracy: 0.7143\n",
            "Epoch 197/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.0037e-04 - accuracy: 1.0000 - val_loss: 1.7979 - val_accuracy: 0.7143\n",
            "Epoch 198/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 8.9519e-05 - accuracy: 1.0000 - val_loss: 1.7974 - val_accuracy: 0.7143\n",
            "Epoch 199/200\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 8.7414e-05 - accuracy: 1.0000 - val_loss: 1.7998 - val_accuracy: 0.7143\n",
            "Epoch 200/200\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 9.3706e-05 - accuracy: 1.0000 - val_loss: 1.8020 - val_accuracy: 0.7143\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ktsOoIOXbNDO"
      },
      "source": [
        "model.save('/content/drive/MyDrive/Colab Notebooks/SPEECH_EMOTION_Recognition/Nộp bài(chốt hạ)/model_saver/basic_combined_ravdess.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FwsQwDu7bNDQ"
      },
      "source": [
        "###test_result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vej6UJ74bNDQ",
        "outputId": "2fba68f1-f0a0-4564-9385-a131b4dc6171"
      },
      "source": [
        "d = {0: 'happy',\n",
        "     1: 'sad',\n",
        "     2: 'angry',\n",
        "     3: 'fear'}\n",
        "Y_test_pred = np.argmax(model.predict(X_test), axis=-1)\n",
        "Y_test_pred = list(map(lambda x: d[x], Y_test_pred))\n",
        "y_test = np.argmax(y_test, axis=-1)\n",
        "y_test = list(map(lambda x: d[x], y_test))\n",
        "print(classification_report(y_test, Y_test_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       1.00      0.92      0.96        13\n",
            "        fear       0.62      0.62      0.62        21\n",
            "       happy       0.75      0.65      0.70        23\n",
            "         sad       0.62      0.75      0.68        20\n",
            "\n",
            "    accuracy                           0.71        77\n",
            "   macro avg       0.75      0.74      0.74        77\n",
            "weighted avg       0.72      0.71      0.72        77\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "id": "1DdBxgcIbNDR",
        "outputId": "9d718330-a816-4dda-c9a0-0337c1d50d97"
      },
      "source": [
        "skplt.metrics.plot_confusion_matrix(\n",
        "    y_test, \n",
        "    Y_test_pred,\n",
        "    figsize=(8,8))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fd8e3530d10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 176
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ExtfqtTnbNDS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}