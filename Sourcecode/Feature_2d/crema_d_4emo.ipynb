{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "crema_d_4emo.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "mgFLWJEX41OI",
        "MandPEm7iKC8",
        "hBVPJsi8jVXy",
        "DrgtYxBXziOW",
        "NR2GYIPltbbE",
        "LLLeABg0tl-u",
        "8JPwepBQ2ndF",
        "ZBa191VcuvUo",
        "8jZBJ97Bu6Jw",
        "_7YOAt2TIKPI",
        "jNEbmeonPxXR",
        "vQHiqzXuW3ay",
        "52xgoS68UfhO",
        "Q8JULeSZXNcL",
        "7ncl1wszZ1Ds",
        "qLKgMiv0bNC8"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NK7b1z3Ta62Q",
        "outputId": "dec94305-4aa4-4c69-a171-f150389edeab"
      },
      "source": [
        "pip install scikit-plot"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting scikit-plot\n",
            "  Downloading https://files.pythonhosted.org/packages/7c/47/32520e259340c140a4ad27c1b97050dd3254fdc517b1d59974d47037510e/scikit_plot-0.3.7-py3-none-any.whl\n",
            "Requirement already satisfied: matplotlib>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from scikit-plot) (3.2.2)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.7/dist-packages (from scikit-plot) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy>=0.9 in /usr/local/lib/python3.7/dist-packages (from scikit-plot) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.10 in /usr/local/lib/python3.7/dist-packages (from scikit-plot) (1.0.1)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.4.0->scikit-plot) (1.19.5)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.4.0->scikit-plot) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.4.0->scikit-plot) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.4.0->scikit-plot) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.4.0->scikit-plot) (1.3.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib>=1.4.0->scikit-plot) (1.15.0)\n",
            "Installing collected packages: scikit-plot\n",
            "Successfully installed scikit-plot-0.3.7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5umKdM5YaoRI"
      },
      "source": [
        "import librosa\n",
        "import glob\n",
        "import os\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow.keras as keras\n",
        "import tensorflow as tf\n",
        "import json\n",
        "import pandas as pd\n",
        "from keras.layers import Conv2D, Dense, Dropout, Flatten, AveragePooling2D, Activation, MaxPooling2D\n",
        "from keras.optimizers import Adam\n",
        "from keras import optimizers\n",
        "from keras.models import Sequential\n",
        "\n",
        "import keras \n",
        "from keras.layers import Conv1D, BatchNormalization, MaxPool2D, MaxPooling1D, LSTM\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.utils.np_utils import to_categorical\n",
        "\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
        "pd.options.display.max_rows = 999999\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "import scipy\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dUfsoWWIa0ah"
      },
      "source": [
        "DATA_PATH = \"/content/drive/MyDrive/Colab Notebooks/SPEECH_EMOTION_Recognition/datasets/CREMA_D/AudioWAV/\"\n",
        "\n",
        "ActorID = []\n",
        "Statement = []\n",
        "Emotion  = []\n",
        "Emotional_level = []\n",
        "Paths = []\n",
        "\n",
        "links = os.listdir(DATA_PATH)\n",
        "for f in links:\n",
        "  file_path = os.path.join(DATA_PATH, f)\n",
        "  Paths.append(file_path)\n",
        "  ActorID.append(f.split('.')[0].split('_')[0])\n",
        "  Statement.append(f.split('.')[0].split('_')[1])\n",
        "  Emotion.append(f.split('.')[0].split('_')[2])\n",
        "  Emotional_level.append(f.split('.')[0].split('_')[3])\n",
        "\n",
        "CREMA_D_df = pd.DataFrame()\n",
        "CREMA_D_df['ActorID'] = ActorID\n",
        "CREMA_D_df['Statement'] = Statement\n",
        "CREMA_D_df['Emotion'] = Emotion\n",
        "CREMA_D_df['Emotional_level'] = Emotional_level\n",
        "CREMA_D_df['Paths'] = Paths"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mgFLWJEX41OI"
      },
      "source": [
        "\n",
        "# mfcc_13 + basic model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fRv0l6Iw3Kvy",
        "execution": {
          "iopub.status.busy": "2021-06-12T05:29:22.599372Z",
          "iopub.execute_input": "2021-06-12T05:29:22.599854Z",
          "iopub.status.idle": "2021-06-12T05:43:40.908032Z",
          "shell.execute_reply.started": "2021-06-12T05:29:22.599811Z",
          "shell.execute_reply": "2021-06-12T05:43:40.906398Z"
        },
        "trusted": true
      },
      "source": [
        "data = {'labels': [],\n",
        "        'features': []}\n",
        "\n",
        "for i in range(len(CREMA_D_df)):\n",
        "  if ((CREMA_D_df['Emotion'][i] == 'HAP') | (CREMA_D_df['Emotion'][i] == 'SAD') | \n",
        "      (CREMA_D_df['Emotion'][i] == 'ANG') | (CREMA_D_df['Emotion'][i] == 'FEA')):\n",
        "    \n",
        "    if CREMA_D_df['Emotion'][i] == 'HAP':\n",
        "      data['labels'].append(0)\n",
        "    elif CREMA_D_df['Emotion'][i] == 'SAD':\n",
        "      data['labels'].append(1)\n",
        "    elif CREMA_D_df['Emotion'][i] == 'ANG':\n",
        "      data['labels'].append(2)\n",
        "    elif CREMA_D_df['Emotion'][i] == 'FEA':\n",
        "      data['labels'].append(3)\n",
        "\n",
        "\n",
        "    signal, sr =  librosa.load(CREMA_D_df['Paths'][i])\n",
        "    mfcc = np.mean(librosa.feature.mfcc(y=signal, sr=sr, n_mfcc=13).T,axis=0).tolist()\n",
        "    data['features'].append(mfcc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FmRZVhte5ZM4",
        "execution": {
          "iopub.status.busy": "2021-06-12T05:44:58.692964Z",
          "iopub.execute_input": "2021-06-12T05:44:58.693400Z",
          "iopub.status.idle": "2021-06-12T05:44:58.724940Z",
          "shell.execute_reply.started": "2021-06-12T05:44:58.693367Z",
          "shell.execute_reply": "2021-06-12T05:44:58.723838Z"
        },
        "trusted": true
      },
      "source": [
        "X = data['features']\n",
        "y = data['labels']\n",
        "\n",
        "y = np.array(data['labels'])\n",
        "y = to_categorical(y)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=0)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=0)\n",
        "\n",
        "X_train = np.array(X_train)\n",
        "X_test = np.array(X_test)\n",
        "X_val = np.array(X_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4nRODQ9P5Vy6"
      },
      "source": [
        "## basic model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xp0or-Sq5Vy8",
        "execution": {
          "iopub.status.busy": "2021-06-12T05:45:02.159579Z",
          "iopub.execute_input": "2021-06-12T05:45:02.159948Z",
          "iopub.status.idle": "2021-06-12T05:45:05.285505Z",
          "shell.execute_reply.started": "2021-06-12T05:45:02.159902Z",
          "shell.execute_reply": "2021-06-12T05:45:05.284564Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aaaf9aaa-df92-4d20-c727-a6f342a23a4c"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(13, input_shape=(13, ), activation = 'relu'))\n",
        "#model.add(Dropout(0.1))\n",
        "model.add(Dense(128, activation = 'relu'))\n",
        "#model.add(Dropout(0.25))\n",
        "model.add(Dense(128, activation = 'relu'))\n",
        "#model.add(Dropout(0.2))\n",
        "model.add(Dense(4, activation = 'softmax'))\n",
        "\n",
        "optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
        "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer=optimizer)\n",
        "early_stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=100, verbose=1, mode='auto')\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_8 (Dense)              (None, 13)                182       \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 128)               1792      \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 4)                 516       \n",
            "=================================================================\n",
            "Total params: 19,002\n",
            "Trainable params: 19,002\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nWleuS9J5Vy_",
        "execution": {
          "iopub.status.busy": "2021-06-12T05:45:07.791555Z",
          "iopub.execute_input": "2021-06-12T05:45:07.791947Z",
          "iopub.status.idle": "2021-06-12T05:45:35.451581Z",
          "shell.execute_reply.started": "2021-06-12T05:45:07.791916Z",
          "shell.execute_reply": "2021-06-12T05:45:35.450630Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33e9fd19-fb53-4a3b-c31b-fbc42a90d290"
      },
      "source": [
        "history = model.fit(X_train, y_train, batch_size=64, epochs=200, \n",
        "                    validation_data=(X_val, y_val))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "65/65 [==============================] - 1s 7ms/step - loss: 4.5049 - accuracy: 0.3124 - val_loss: 1.4361 - val_accuracy: 0.4083\n",
            "Epoch 2/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 1.3354 - accuracy: 0.3990 - val_loss: 2.3611 - val_accuracy: 0.2533\n",
            "Epoch 3/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 1.7035 - accuracy: 0.3541 - val_loss: 1.2757 - val_accuracy: 0.4192\n",
            "Epoch 4/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 1.2502 - accuracy: 0.4153 - val_loss: 1.3721 - val_accuracy: 0.4105\n",
            "Epoch 5/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 1.3076 - accuracy: 0.4074 - val_loss: 1.2565 - val_accuracy: 0.4454\n",
            "Epoch 6/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 1.3355 - accuracy: 0.4065 - val_loss: 1.3161 - val_accuracy: 0.4039\n",
            "Epoch 7/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 1.3154 - accuracy: 0.4229 - val_loss: 1.1782 - val_accuracy: 0.4410\n",
            "Epoch 8/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 1.2286 - accuracy: 0.4358 - val_loss: 1.2916 - val_accuracy: 0.4279\n",
            "Epoch 9/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 1.1929 - accuracy: 0.4495 - val_loss: 1.5635 - val_accuracy: 0.3013\n",
            "Epoch 10/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 1.3723 - accuracy: 0.4096 - val_loss: 1.5870 - val_accuracy: 0.3297\n",
            "Epoch 11/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 1.2600 - accuracy: 0.4483 - val_loss: 1.1789 - val_accuracy: 0.4367\n",
            "Epoch 12/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 1.1419 - accuracy: 0.4756 - val_loss: 1.4077 - val_accuracy: 0.3537\n",
            "Epoch 13/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 1.1977 - accuracy: 0.4613 - val_loss: 1.1983 - val_accuracy: 0.4389\n",
            "Epoch 14/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 1.1765 - accuracy: 0.4519 - val_loss: 1.4383 - val_accuracy: 0.3734\n",
            "Epoch 15/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 1.3432 - accuracy: 0.4295 - val_loss: 1.4042 - val_accuracy: 0.4345\n",
            "Epoch 16/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 1.2843 - accuracy: 0.4407 - val_loss: 1.1829 - val_accuracy: 0.4323\n",
            "Epoch 17/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 1.1864 - accuracy: 0.4574 - val_loss: 1.4035 - val_accuracy: 0.4258\n",
            "Epoch 18/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 1.2193 - accuracy: 0.4560 - val_loss: 1.4347 - val_accuracy: 0.3472\n",
            "Epoch 19/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 1.1727 - accuracy: 0.4586 - val_loss: 1.2451 - val_accuracy: 0.4410\n",
            "Epoch 20/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 1.2328 - accuracy: 0.4452 - val_loss: 1.2529 - val_accuracy: 0.4476\n",
            "Epoch 21/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 1.1840 - accuracy: 0.4562 - val_loss: 1.2495 - val_accuracy: 0.4716\n",
            "Epoch 22/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 1.1568 - accuracy: 0.4670 - val_loss: 1.1846 - val_accuracy: 0.4345\n",
            "Epoch 23/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 1.1176 - accuracy: 0.4967 - val_loss: 1.1646 - val_accuracy: 0.4563\n",
            "Epoch 24/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 1.1386 - accuracy: 0.4721 - val_loss: 1.2216 - val_accuracy: 0.4214\n",
            "Epoch 25/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 1.1643 - accuracy: 0.4800 - val_loss: 1.2236 - val_accuracy: 0.3865\n",
            "Epoch 26/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 1.1577 - accuracy: 0.4717 - val_loss: 1.2083 - val_accuracy: 0.4083\n",
            "Epoch 27/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 1.1170 - accuracy: 0.4928 - val_loss: 1.1266 - val_accuracy: 0.4716\n",
            "Epoch 28/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 1.1261 - accuracy: 0.4671 - val_loss: 1.1660 - val_accuracy: 0.4563\n",
            "Epoch 29/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 1.1132 - accuracy: 0.4909 - val_loss: 1.1783 - val_accuracy: 0.4760\n",
            "Epoch 30/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 1.1222 - accuracy: 0.4927 - val_loss: 1.1610 - val_accuracy: 0.4410\n",
            "Epoch 31/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 1.0887 - accuracy: 0.5082 - val_loss: 1.1700 - val_accuracy: 0.4716\n",
            "Epoch 32/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 1.0901 - accuracy: 0.5042 - val_loss: 1.1442 - val_accuracy: 0.4934\n",
            "Epoch 33/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 1.0788 - accuracy: 0.5138 - val_loss: 1.1436 - val_accuracy: 0.4869\n",
            "Epoch 34/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 1.1013 - accuracy: 0.4940 - val_loss: 1.2233 - val_accuracy: 0.4410\n",
            "Epoch 35/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 1.1064 - accuracy: 0.4917 - val_loss: 1.1309 - val_accuracy: 0.4607\n",
            "Epoch 36/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 1.1085 - accuracy: 0.5007 - val_loss: 1.4046 - val_accuracy: 0.3668\n",
            "Epoch 37/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 1.2001 - accuracy: 0.4680 - val_loss: 1.1421 - val_accuracy: 0.4716\n",
            "Epoch 38/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 1.0937 - accuracy: 0.4965 - val_loss: 1.1194 - val_accuracy: 0.4738\n",
            "Epoch 39/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 1.0873 - accuracy: 0.5044 - val_loss: 1.1120 - val_accuracy: 0.4869\n",
            "Epoch 40/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 1.0636 - accuracy: 0.5051 - val_loss: 1.1406 - val_accuracy: 0.4432\n",
            "Epoch 41/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 1.1132 - accuracy: 0.4790 - val_loss: 1.2182 - val_accuracy: 0.4148\n",
            "Epoch 42/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 1.0971 - accuracy: 0.4893 - val_loss: 1.1159 - val_accuracy: 0.4738\n",
            "Epoch 43/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 1.0635 - accuracy: 0.5134 - val_loss: 1.1069 - val_accuracy: 0.4782\n",
            "Epoch 44/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 1.0692 - accuracy: 0.5186 - val_loss: 1.1946 - val_accuracy: 0.4301\n",
            "Epoch 45/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 1.0822 - accuracy: 0.4953 - val_loss: 1.1275 - val_accuracy: 0.4651\n",
            "Epoch 46/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 1.0681 - accuracy: 0.4957 - val_loss: 1.1253 - val_accuracy: 0.5066\n",
            "Epoch 47/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 1.0591 - accuracy: 0.5190 - val_loss: 1.0997 - val_accuracy: 0.4913\n",
            "Epoch 48/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 1.0563 - accuracy: 0.5163 - val_loss: 1.0966 - val_accuracy: 0.5022\n",
            "Epoch 49/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 1.0649 - accuracy: 0.5171 - val_loss: 1.0807 - val_accuracy: 0.4956\n",
            "Epoch 50/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 1.0625 - accuracy: 0.5117 - val_loss: 1.1365 - val_accuracy: 0.4716\n",
            "Epoch 51/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 1.0665 - accuracy: 0.5061 - val_loss: 1.2052 - val_accuracy: 0.4782\n",
            "Epoch 52/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 1.0869 - accuracy: 0.5105 - val_loss: 1.0859 - val_accuracy: 0.4934\n",
            "Epoch 53/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 1.0442 - accuracy: 0.5306 - val_loss: 1.0955 - val_accuracy: 0.5087\n",
            "Epoch 54/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 1.0614 - accuracy: 0.4937 - val_loss: 1.1075 - val_accuracy: 0.4782\n",
            "Epoch 55/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 1.0722 - accuracy: 0.5061 - val_loss: 1.1033 - val_accuracy: 0.4847\n",
            "Epoch 56/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 1.0282 - accuracy: 0.5452 - val_loss: 1.0751 - val_accuracy: 0.4956\n",
            "Epoch 57/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 1.0341 - accuracy: 0.5253 - val_loss: 1.0908 - val_accuracy: 0.4782\n",
            "Epoch 58/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 1.0163 - accuracy: 0.5443 - val_loss: 1.0594 - val_accuracy: 0.5218\n",
            "Epoch 59/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 1.0482 - accuracy: 0.5078 - val_loss: 1.0652 - val_accuracy: 0.5109\n",
            "Epoch 60/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 1.0292 - accuracy: 0.5347 - val_loss: 1.0946 - val_accuracy: 0.5000\n",
            "Epoch 61/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 1.0500 - accuracy: 0.5175 - val_loss: 1.0881 - val_accuracy: 0.4825\n",
            "Epoch 62/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 1.0404 - accuracy: 0.5169 - val_loss: 1.0767 - val_accuracy: 0.5240\n",
            "Epoch 63/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 1.0270 - accuracy: 0.5384 - val_loss: 1.0667 - val_accuracy: 0.5218\n",
            "Epoch 64/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 1.0129 - accuracy: 0.5424 - val_loss: 1.0897 - val_accuracy: 0.5262\n",
            "Epoch 65/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 1.0322 - accuracy: 0.5291 - val_loss: 1.0744 - val_accuracy: 0.5044\n",
            "Epoch 66/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 1.0025 - accuracy: 0.5405 - val_loss: 1.0776 - val_accuracy: 0.5066\n",
            "Epoch 67/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 1.0285 - accuracy: 0.5307 - val_loss: 1.1098 - val_accuracy: 0.4803\n",
            "Epoch 68/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 1.0137 - accuracy: 0.5377 - val_loss: 1.0686 - val_accuracy: 0.5175\n",
            "Epoch 69/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 1.0167 - accuracy: 0.5503 - val_loss: 1.0940 - val_accuracy: 0.4891\n",
            "Epoch 70/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 1.0256 - accuracy: 0.5436 - val_loss: 1.0829 - val_accuracy: 0.4891\n",
            "Epoch 71/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.9967 - accuracy: 0.5370 - val_loss: 1.0849 - val_accuracy: 0.4956\n",
            "Epoch 72/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 1.0058 - accuracy: 0.5313 - val_loss: 1.0769 - val_accuracy: 0.5131\n",
            "Epoch 73/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 1.0249 - accuracy: 0.5409 - val_loss: 1.0861 - val_accuracy: 0.4934\n",
            "Epoch 74/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.9847 - accuracy: 0.5467 - val_loss: 1.0633 - val_accuracy: 0.5131\n",
            "Epoch 75/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.9946 - accuracy: 0.5502 - val_loss: 1.0802 - val_accuracy: 0.4782\n",
            "Epoch 76/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.9996 - accuracy: 0.5354 - val_loss: 1.0851 - val_accuracy: 0.5131\n",
            "Epoch 77/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 1.0158 - accuracy: 0.5429 - val_loss: 1.0883 - val_accuracy: 0.4978\n",
            "Epoch 78/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 1.0027 - accuracy: 0.5466 - val_loss: 1.0652 - val_accuracy: 0.5284\n",
            "Epoch 79/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.9996 - accuracy: 0.5439 - val_loss: 1.0887 - val_accuracy: 0.5000\n",
            "Epoch 80/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.9848 - accuracy: 0.5531 - val_loss: 1.0723 - val_accuracy: 0.5000\n",
            "Epoch 81/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.9843 - accuracy: 0.5602 - val_loss: 1.0820 - val_accuracy: 0.5066\n",
            "Epoch 82/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.9828 - accuracy: 0.5540 - val_loss: 1.0571 - val_accuracy: 0.5262\n",
            "Epoch 83/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.9887 - accuracy: 0.5464 - val_loss: 1.0862 - val_accuracy: 0.5087\n",
            "Epoch 84/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 1.0101 - accuracy: 0.5461 - val_loss: 1.0646 - val_accuracy: 0.5240\n",
            "Epoch 85/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.9660 - accuracy: 0.5822 - val_loss: 1.0601 - val_accuracy: 0.5087\n",
            "Epoch 86/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.9778 - accuracy: 0.5609 - val_loss: 1.0600 - val_accuracy: 0.5153\n",
            "Epoch 87/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.9822 - accuracy: 0.5604 - val_loss: 1.0786 - val_accuracy: 0.4934\n",
            "Epoch 88/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.9781 - accuracy: 0.5592 - val_loss: 1.0571 - val_accuracy: 0.5240\n",
            "Epoch 89/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.9464 - accuracy: 0.5835 - val_loss: 1.0681 - val_accuracy: 0.5197\n",
            "Epoch 90/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.9845 - accuracy: 0.5618 - val_loss: 1.0680 - val_accuracy: 0.5087\n",
            "Epoch 91/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.9664 - accuracy: 0.5683 - val_loss: 1.0760 - val_accuracy: 0.5306\n",
            "Epoch 92/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.9865 - accuracy: 0.5481 - val_loss: 1.0672 - val_accuracy: 0.5087\n",
            "Epoch 93/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.9743 - accuracy: 0.5549 - val_loss: 1.0706 - val_accuracy: 0.5066\n",
            "Epoch 94/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.9455 - accuracy: 0.5813 - val_loss: 1.0670 - val_accuracy: 0.5175\n",
            "Epoch 95/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.9676 - accuracy: 0.5665 - val_loss: 1.1100 - val_accuracy: 0.4847\n",
            "Epoch 96/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.9643 - accuracy: 0.5855 - val_loss: 1.0633 - val_accuracy: 0.5197\n",
            "Epoch 97/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.9603 - accuracy: 0.5672 - val_loss: 1.0588 - val_accuracy: 0.5197\n",
            "Epoch 98/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.9741 - accuracy: 0.5643 - val_loss: 1.0679 - val_accuracy: 0.5022\n",
            "Epoch 99/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.9493 - accuracy: 0.5743 - val_loss: 1.0869 - val_accuracy: 0.5066\n",
            "Epoch 100/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.9427 - accuracy: 0.5881 - val_loss: 1.0608 - val_accuracy: 0.5328\n",
            "Epoch 101/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.9493 - accuracy: 0.5851 - val_loss: 1.0635 - val_accuracy: 0.5131\n",
            "Epoch 102/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.9507 - accuracy: 0.5813 - val_loss: 1.0887 - val_accuracy: 0.4847\n",
            "Epoch 103/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.9403 - accuracy: 0.5787 - val_loss: 1.0761 - val_accuracy: 0.5328\n",
            "Epoch 104/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.9275 - accuracy: 0.5902 - val_loss: 1.0818 - val_accuracy: 0.5022\n",
            "Epoch 105/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.9414 - accuracy: 0.5885 - val_loss: 1.0828 - val_accuracy: 0.5197\n",
            "Epoch 106/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.9617 - accuracy: 0.5730 - val_loss: 1.0665 - val_accuracy: 0.5000\n",
            "Epoch 107/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.9394 - accuracy: 0.5724 - val_loss: 1.0518 - val_accuracy: 0.5284\n",
            "Epoch 108/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.9492 - accuracy: 0.5874 - val_loss: 1.0790 - val_accuracy: 0.4956\n",
            "Epoch 109/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.9203 - accuracy: 0.5957 - val_loss: 1.0848 - val_accuracy: 0.5087\n",
            "Epoch 110/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.9368 - accuracy: 0.5903 - val_loss: 1.0693 - val_accuracy: 0.5131\n",
            "Epoch 111/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.9223 - accuracy: 0.5989 - val_loss: 1.0550 - val_accuracy: 0.5262\n",
            "Epoch 112/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.9459 - accuracy: 0.5866 - val_loss: 1.0690 - val_accuracy: 0.5284\n",
            "Epoch 113/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.9243 - accuracy: 0.5900 - val_loss: 1.0584 - val_accuracy: 0.5240\n",
            "Epoch 114/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.9396 - accuracy: 0.5742 - val_loss: 1.0650 - val_accuracy: 0.5022\n",
            "Epoch 115/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.9279 - accuracy: 0.5894 - val_loss: 1.1140 - val_accuracy: 0.4803\n",
            "Epoch 116/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.9210 - accuracy: 0.5816 - val_loss: 1.0723 - val_accuracy: 0.5087\n",
            "Epoch 117/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.9122 - accuracy: 0.5988 - val_loss: 1.0687 - val_accuracy: 0.5306\n",
            "Epoch 118/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.9279 - accuracy: 0.5919 - val_loss: 1.0721 - val_accuracy: 0.5218\n",
            "Epoch 119/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.9121 - accuracy: 0.5890 - val_loss: 1.0698 - val_accuracy: 0.5240\n",
            "Epoch 120/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.9055 - accuracy: 0.6110 - val_loss: 1.0798 - val_accuracy: 0.5240\n",
            "Epoch 121/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.9063 - accuracy: 0.6006 - val_loss: 1.0636 - val_accuracy: 0.5109\n",
            "Epoch 122/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.9038 - accuracy: 0.6022 - val_loss: 1.0890 - val_accuracy: 0.5349\n",
            "Epoch 123/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.9088 - accuracy: 0.5959 - val_loss: 1.1022 - val_accuracy: 0.5306\n",
            "Epoch 124/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.9076 - accuracy: 0.6004 - val_loss: 1.0416 - val_accuracy: 0.5568\n",
            "Epoch 125/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.9049 - accuracy: 0.6047 - val_loss: 1.0554 - val_accuracy: 0.5262\n",
            "Epoch 126/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.9313 - accuracy: 0.5741 - val_loss: 1.0883 - val_accuracy: 0.5240\n",
            "Epoch 127/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.9206 - accuracy: 0.5860 - val_loss: 1.0612 - val_accuracy: 0.5328\n",
            "Epoch 128/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.8940 - accuracy: 0.6189 - val_loss: 1.0486 - val_accuracy: 0.5480\n",
            "Epoch 129/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.9064 - accuracy: 0.5927 - val_loss: 1.0789 - val_accuracy: 0.5153\n",
            "Epoch 130/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.8982 - accuracy: 0.5923 - val_loss: 1.0639 - val_accuracy: 0.5306\n",
            "Epoch 131/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.8951 - accuracy: 0.6087 - val_loss: 1.0819 - val_accuracy: 0.5087\n",
            "Epoch 132/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.8850 - accuracy: 0.6041 - val_loss: 1.0716 - val_accuracy: 0.5218\n",
            "Epoch 133/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.9062 - accuracy: 0.5830 - val_loss: 1.0832 - val_accuracy: 0.4978\n",
            "Epoch 134/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.8809 - accuracy: 0.6101 - val_loss: 1.0895 - val_accuracy: 0.5175\n",
            "Epoch 135/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.9024 - accuracy: 0.5926 - val_loss: 1.0712 - val_accuracy: 0.5175\n",
            "Epoch 136/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.8895 - accuracy: 0.6138 - val_loss: 1.1038 - val_accuracy: 0.4956\n",
            "Epoch 137/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.8989 - accuracy: 0.6004 - val_loss: 1.0664 - val_accuracy: 0.5175\n",
            "Epoch 138/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.8932 - accuracy: 0.6035 - val_loss: 1.0701 - val_accuracy: 0.5175\n",
            "Epoch 139/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.8593 - accuracy: 0.6290 - val_loss: 1.0865 - val_accuracy: 0.5306\n",
            "Epoch 140/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.8684 - accuracy: 0.6236 - val_loss: 1.0876 - val_accuracy: 0.5000\n",
            "Epoch 141/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.8474 - accuracy: 0.6198 - val_loss: 1.1237 - val_accuracy: 0.5044\n",
            "Epoch 142/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.8547 - accuracy: 0.6232 - val_loss: 1.0879 - val_accuracy: 0.5131\n",
            "Epoch 143/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.8393 - accuracy: 0.6368 - val_loss: 1.0787 - val_accuracy: 0.5371\n",
            "Epoch 144/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.8782 - accuracy: 0.6173 - val_loss: 1.0823 - val_accuracy: 0.5262\n",
            "Epoch 145/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.8764 - accuracy: 0.6088 - val_loss: 1.0765 - val_accuracy: 0.5328\n",
            "Epoch 146/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.8640 - accuracy: 0.6165 - val_loss: 1.0734 - val_accuracy: 0.5306\n",
            "Epoch 147/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.8830 - accuracy: 0.6067 - val_loss: 1.0809 - val_accuracy: 0.5240\n",
            "Epoch 148/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.8531 - accuracy: 0.6299 - val_loss: 1.0789 - val_accuracy: 0.5415\n",
            "Epoch 149/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.8488 - accuracy: 0.6278 - val_loss: 1.0688 - val_accuracy: 0.5284\n",
            "Epoch 150/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.8534 - accuracy: 0.6301 - val_loss: 1.0814 - val_accuracy: 0.5306\n",
            "Epoch 151/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.8459 - accuracy: 0.6266 - val_loss: 1.1026 - val_accuracy: 0.5240\n",
            "Epoch 152/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.8452 - accuracy: 0.6238 - val_loss: 1.0793 - val_accuracy: 0.5459\n",
            "Epoch 153/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.8357 - accuracy: 0.6295 - val_loss: 1.0832 - val_accuracy: 0.5131\n",
            "Epoch 154/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.8531 - accuracy: 0.6280 - val_loss: 1.0754 - val_accuracy: 0.5306\n",
            "Epoch 155/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.8627 - accuracy: 0.6189 - val_loss: 1.1493 - val_accuracy: 0.5000\n",
            "Epoch 156/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.8645 - accuracy: 0.6204 - val_loss: 1.0747 - val_accuracy: 0.5371\n",
            "Epoch 157/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.8440 - accuracy: 0.6346 - val_loss: 1.0849 - val_accuracy: 0.5218\n",
            "Epoch 158/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.8489 - accuracy: 0.6377 - val_loss: 1.0847 - val_accuracy: 0.5349\n",
            "Epoch 159/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.8268 - accuracy: 0.6434 - val_loss: 1.0785 - val_accuracy: 0.5131\n",
            "Epoch 160/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.8274 - accuracy: 0.6475 - val_loss: 1.0875 - val_accuracy: 0.5306\n",
            "Epoch 161/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.8196 - accuracy: 0.6432 - val_loss: 1.0989 - val_accuracy: 0.5131\n",
            "Epoch 162/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.8062 - accuracy: 0.6629 - val_loss: 1.0917 - val_accuracy: 0.5218\n",
            "Epoch 163/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.8198 - accuracy: 0.6473 - val_loss: 1.1141 - val_accuracy: 0.5153\n",
            "Epoch 164/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.8196 - accuracy: 0.6466 - val_loss: 1.1252 - val_accuracy: 0.5371\n",
            "Epoch 165/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.8020 - accuracy: 0.6527 - val_loss: 1.1091 - val_accuracy: 0.5109\n",
            "Epoch 166/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.8236 - accuracy: 0.6367 - val_loss: 1.1119 - val_accuracy: 0.5153\n",
            "Epoch 167/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.8466 - accuracy: 0.6183 - val_loss: 1.1221 - val_accuracy: 0.5153\n",
            "Epoch 168/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.8063 - accuracy: 0.6533 - val_loss: 1.1200 - val_accuracy: 0.5153\n",
            "Epoch 169/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.8145 - accuracy: 0.6377 - val_loss: 1.1036 - val_accuracy: 0.5328\n",
            "Epoch 170/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.7929 - accuracy: 0.6553 - val_loss: 1.1136 - val_accuracy: 0.5197\n",
            "Epoch 171/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.7992 - accuracy: 0.6519 - val_loss: 1.1010 - val_accuracy: 0.5502\n",
            "Epoch 172/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.8181 - accuracy: 0.6473 - val_loss: 1.1223 - val_accuracy: 0.5197\n",
            "Epoch 173/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.7955 - accuracy: 0.6609 - val_loss: 1.1330 - val_accuracy: 0.5284\n",
            "Epoch 174/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.7904 - accuracy: 0.6479 - val_loss: 1.1452 - val_accuracy: 0.5218\n",
            "Epoch 175/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.7951 - accuracy: 0.6547 - val_loss: 1.1549 - val_accuracy: 0.5175\n",
            "Epoch 176/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.7909 - accuracy: 0.6585 - val_loss: 1.1350 - val_accuracy: 0.5284\n",
            "Epoch 177/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.7914 - accuracy: 0.6559 - val_loss: 1.1497 - val_accuracy: 0.5087\n",
            "Epoch 178/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.7851 - accuracy: 0.6576 - val_loss: 1.1568 - val_accuracy: 0.5328\n",
            "Epoch 179/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.7892 - accuracy: 0.6661 - val_loss: 1.1288 - val_accuracy: 0.5415\n",
            "Epoch 180/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.7707 - accuracy: 0.6712 - val_loss: 1.1534 - val_accuracy: 0.5131\n",
            "Epoch 181/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.7803 - accuracy: 0.6650 - val_loss: 1.1557 - val_accuracy: 0.5109\n",
            "Epoch 182/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.7839 - accuracy: 0.6625 - val_loss: 1.1749 - val_accuracy: 0.5218\n",
            "Epoch 183/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.7834 - accuracy: 0.6681 - val_loss: 1.1508 - val_accuracy: 0.5306\n",
            "Epoch 184/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.7653 - accuracy: 0.6821 - val_loss: 1.1787 - val_accuracy: 0.5109\n",
            "Epoch 185/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.7918 - accuracy: 0.6642 - val_loss: 1.1533 - val_accuracy: 0.5218\n",
            "Epoch 186/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.7469 - accuracy: 0.6795 - val_loss: 1.1665 - val_accuracy: 0.5328\n",
            "Epoch 187/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.7709 - accuracy: 0.6583 - val_loss: 1.1585 - val_accuracy: 0.5175\n",
            "Epoch 188/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.7427 - accuracy: 0.6792 - val_loss: 1.1956 - val_accuracy: 0.4978\n",
            "Epoch 189/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.7544 - accuracy: 0.6671 - val_loss: 1.1584 - val_accuracy: 0.5393\n",
            "Epoch 190/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.7604 - accuracy: 0.6732 - val_loss: 1.1855 - val_accuracy: 0.4956\n",
            "Epoch 191/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.7655 - accuracy: 0.6704 - val_loss: 1.1953 - val_accuracy: 0.5087\n",
            "Epoch 192/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.7524 - accuracy: 0.6792 - val_loss: 1.2159 - val_accuracy: 0.5087\n",
            "Epoch 193/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.7633 - accuracy: 0.6737 - val_loss: 1.1670 - val_accuracy: 0.5000\n",
            "Epoch 194/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.7455 - accuracy: 0.6910 - val_loss: 1.1635 - val_accuracy: 0.4956\n",
            "Epoch 195/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.7517 - accuracy: 0.6800 - val_loss: 1.2206 - val_accuracy: 0.5109\n",
            "Epoch 196/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.7337 - accuracy: 0.6751 - val_loss: 1.2007 - val_accuracy: 0.5306\n",
            "Epoch 197/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.7459 - accuracy: 0.6787 - val_loss: 1.1990 - val_accuracy: 0.5218\n",
            "Epoch 198/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.7454 - accuracy: 0.6821 - val_loss: 1.2261 - val_accuracy: 0.4934\n",
            "Epoch 199/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.7440 - accuracy: 0.6824 - val_loss: 1.1974 - val_accuracy: 0.5240\n",
            "Epoch 200/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.7234 - accuracy: 0.6876 - val_loss: 1.1705 - val_accuracy: 0.5240\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_RoKupGabjlC"
      },
      "source": [
        "model.save('/content/drive/MyDrive/Colab Notebooks/SPEECH_EMOTION_Recognition/Nộp bài(chốt hạ)/model_saver/basic_mfcc13_cremad.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zy5l6YUakCQp"
      },
      "source": [
        "###test_result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VyJOB76K5VzA",
        "execution": {
          "iopub.status.busy": "2021-06-12T05:45:41.629805Z",
          "iopub.execute_input": "2021-06-12T05:45:41.630161Z",
          "iopub.status.idle": "2021-06-12T05:45:41.786756Z",
          "shell.execute_reply.started": "2021-06-12T05:45:41.630121Z",
          "shell.execute_reply": "2021-06-12T05:45:41.785499Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1a304ac-3f49-482c-dbbf-e39f36d00fb4"
      },
      "source": [
        "d = {0: 'happy',\n",
        "     1: 'sad',\n",
        "     2: 'angry',\n",
        "     3: 'fear'}\n",
        "Y_test_pred = np.argmax(model.predict(X_test), axis=-1)\n",
        "Y_test_pred = list(map(lambda x: d[x], Y_test_pred))\n",
        "y_test = np.argmax(y_test, axis=-1)\n",
        "y_test = list(map(lambda x: d[x], y_test))\n",
        "print(classification_report(y_test, Y_test_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.67      0.62      0.65       136\n",
            "        fear       0.43      0.43      0.43       134\n",
            "       happy       0.47      0.45      0.46       120\n",
            "         sad       0.61      0.70      0.65       119\n",
            "\n",
            "    accuracy                           0.55       509\n",
            "   macro avg       0.55      0.55      0.55       509\n",
            "weighted avg       0.55      0.55      0.55       509\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmwdO_F15VzC",
        "execution": {
          "iopub.status.busy": "2021-06-12T05:45:47.991956Z",
          "iopub.execute_input": "2021-06-12T05:45:47.992400Z",
          "iopub.status.idle": "2021-06-12T05:45:48.358940Z",
          "shell.execute_reply.started": "2021-06-12T05:45:47.992353Z",
          "shell.execute_reply": "2021-06-12T05:45:48.357523Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 483
        },
        "outputId": "a40952c4-c505-465a-c2a4-df84f6d13920"
      },
      "source": [
        "import scikitplot as skplt\n",
        "\n",
        "skplt.metrics.plot_confusion_matrix(\n",
        "    y_test, \n",
        "    Y_test_pred,\n",
        "    figsize=(8,8))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f11aa8ed3d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MandPEm7iKC8"
      },
      "source": [
        "\n",
        "# mfcc_26 + basic model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-12T05:29:22.599372Z",
          "iopub.execute_input": "2021-06-12T05:29:22.599854Z",
          "iopub.status.idle": "2021-06-12T05:43:40.908032Z",
          "shell.execute_reply.started": "2021-06-12T05:29:22.599811Z",
          "shell.execute_reply": "2021-06-12T05:43:40.906398Z"
        },
        "trusted": true,
        "id": "VW32JwtjiKDP"
      },
      "source": [
        "data = {'labels': [],\n",
        "        'features': []}\n",
        "\n",
        "for i in range(len(CREMA_D_df)):\n",
        "  if ((CREMA_D_df['Emotion'][i] == 'HAP') | (CREMA_D_df['Emotion'][i] == 'SAD') | \n",
        "      (CREMA_D_df['Emotion'][i] == 'ANG') | (CREMA_D_df['Emotion'][i] == 'FEA')):\n",
        "    \n",
        "    if CREMA_D_df['Emotion'][i] == 'HAP':\n",
        "      data['labels'].append(0)\n",
        "    elif CREMA_D_df['Emotion'][i] == 'SAD':\n",
        "      data['labels'].append(1)\n",
        "    elif CREMA_D_df['Emotion'][i] == 'ANG':\n",
        "      data['labels'].append(2)\n",
        "    elif CREMA_D_df['Emotion'][i] == 'FEA':\n",
        "      data['labels'].append(3)\n",
        "\n",
        "\n",
        "    signal, sr =  librosa.load(CREMA_D_df['Paths'][i])\n",
        "    mfcc = np.mean(librosa.feature.mfcc(y=signal, sr=sr, n_mfcc=26).T,axis=0).tolist()\n",
        "    data['features'].append(mfcc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-12T05:44:58.692964Z",
          "iopub.execute_input": "2021-06-12T05:44:58.693400Z",
          "iopub.status.idle": "2021-06-12T05:44:58.724940Z",
          "shell.execute_reply.started": "2021-06-12T05:44:58.693367Z",
          "shell.execute_reply": "2021-06-12T05:44:58.723838Z"
        },
        "trusted": true,
        "id": "8u7lO54riKDR"
      },
      "source": [
        "X = data['features']\n",
        "y = data['labels']\n",
        "\n",
        "y = np.array(data['labels'])\n",
        "y = to_categorical(y)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=0)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=0)\n",
        "\n",
        "X_train = np.array(X_train)\n",
        "X_test = np.array(X_test)\n",
        "X_val = np.array(X_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZTZm4ycQiKDS"
      },
      "source": [
        "## basic model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-12T05:45:02.159579Z",
          "iopub.execute_input": "2021-06-12T05:45:02.159948Z",
          "iopub.status.idle": "2021-06-12T05:45:05.285505Z",
          "shell.execute_reply.started": "2021-06-12T05:45:02.159902Z",
          "shell.execute_reply": "2021-06-12T05:45:05.284564Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vLM43-VUiKDT",
        "outputId": "e29b9e20-4d4c-4cca-885a-c1ad4a2a2eb4"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(26, input_shape=(26, ), activation = 'relu'))\n",
        "#model.add(Dropout(0.1))\n",
        "model.add(Dense(128, activation = 'relu'))\n",
        "#model.add(Dropout(0.25))\n",
        "model.add(Dense(128, activation = 'relu'))\n",
        "#model.add(Dropout(0.2))\n",
        "model.add(Dense(4, activation = 'softmax'))\n",
        "\n",
        "optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
        "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer=optimizer)\n",
        "early_stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=100, verbose=1, mode='auto')\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_12 (Dense)             (None, 26)                702       \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 128)               3456      \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 4)                 516       \n",
            "=================================================================\n",
            "Total params: 21,186\n",
            "Trainable params: 21,186\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-12T05:45:07.791555Z",
          "iopub.execute_input": "2021-06-12T05:45:07.791947Z",
          "iopub.status.idle": "2021-06-12T05:45:35.451581Z",
          "shell.execute_reply.started": "2021-06-12T05:45:07.791916Z",
          "shell.execute_reply": "2021-06-12T05:45:35.450630Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pdUx47T3iKDW",
        "outputId": "2228ffdf-7e0e-49a4-b61b-347b10d8360d"
      },
      "source": [
        "history = model.fit(X_train, y_train, batch_size=64, epochs=200, \n",
        "                    validation_data=(X_val, y_val))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "65/65 [==============================] - 1s 8ms/step - loss: 5.4713 - accuracy: 0.2847 - val_loss: 1.4014 - val_accuracy: 0.3450\n",
            "Epoch 2/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 1.3078 - accuracy: 0.4327 - val_loss: 1.2215 - val_accuracy: 0.4585\n",
            "Epoch 3/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 1.1802 - accuracy: 0.4670 - val_loss: 1.1541 - val_accuracy: 0.4716\n",
            "Epoch 4/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 1.2250 - accuracy: 0.4520 - val_loss: 1.3797 - val_accuracy: 0.4105\n",
            "Epoch 5/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 1.3191 - accuracy: 0.4213 - val_loss: 1.3507 - val_accuracy: 0.4454\n",
            "Epoch 6/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 1.2066 - accuracy: 0.4590 - val_loss: 1.4735 - val_accuracy: 0.3603\n",
            "Epoch 7/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 1.1692 - accuracy: 0.4803 - val_loss: 1.1981 - val_accuracy: 0.4367\n",
            "Epoch 8/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 1.2432 - accuracy: 0.4677 - val_loss: 1.1866 - val_accuracy: 0.4651\n",
            "Epoch 9/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 1.1333 - accuracy: 0.4859 - val_loss: 1.4173 - val_accuracy: 0.3668\n",
            "Epoch 10/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 1.2536 - accuracy: 0.4422 - val_loss: 1.0957 - val_accuracy: 0.4760\n",
            "Epoch 11/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 1.1147 - accuracy: 0.4887 - val_loss: 1.2047 - val_accuracy: 0.4454\n",
            "Epoch 12/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 1.1741 - accuracy: 0.4747 - val_loss: 1.1845 - val_accuracy: 0.4498\n",
            "Epoch 13/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 1.0852 - accuracy: 0.5014 - val_loss: 1.1011 - val_accuracy: 0.4891\n",
            "Epoch 14/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 1.1086 - accuracy: 0.4898 - val_loss: 1.2759 - val_accuracy: 0.4869\n",
            "Epoch 15/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 1.1642 - accuracy: 0.4764 - val_loss: 1.1339 - val_accuracy: 0.4345\n",
            "Epoch 16/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 1.1423 - accuracy: 0.4804 - val_loss: 1.2551 - val_accuracy: 0.4716\n",
            "Epoch 17/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 1.1585 - accuracy: 0.4737 - val_loss: 1.1359 - val_accuracy: 0.4738\n",
            "Epoch 18/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 1.0849 - accuracy: 0.5124 - val_loss: 1.2590 - val_accuracy: 0.4563\n",
            "Epoch 19/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 1.0930 - accuracy: 0.5119 - val_loss: 1.0998 - val_accuracy: 0.4825\n",
            "Epoch 20/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 1.0683 - accuracy: 0.5043 - val_loss: 1.0658 - val_accuracy: 0.4956\n",
            "Epoch 21/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 1.0281 - accuracy: 0.5248 - val_loss: 1.1548 - val_accuracy: 0.5044\n",
            "Epoch 22/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 1.1173 - accuracy: 0.4889 - val_loss: 1.0808 - val_accuracy: 0.5000\n",
            "Epoch 23/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 1.0371 - accuracy: 0.5274 - val_loss: 1.0755 - val_accuracy: 0.5175\n",
            "Epoch 24/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 1.0607 - accuracy: 0.5221 - val_loss: 1.0881 - val_accuracy: 0.4934\n",
            "Epoch 25/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 1.0398 - accuracy: 0.5399 - val_loss: 1.0589 - val_accuracy: 0.4956\n",
            "Epoch 26/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 1.0033 - accuracy: 0.5447 - val_loss: 1.0723 - val_accuracy: 0.4825\n",
            "Epoch 27/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 1.0180 - accuracy: 0.5435 - val_loss: 1.0714 - val_accuracy: 0.4847\n",
            "Epoch 28/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 1.0253 - accuracy: 0.5376 - val_loss: 1.1024 - val_accuracy: 0.4629\n",
            "Epoch 29/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 1.0306 - accuracy: 0.5283 - val_loss: 1.0788 - val_accuracy: 0.4891\n",
            "Epoch 30/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 1.0162 - accuracy: 0.5377 - val_loss: 1.0858 - val_accuracy: 0.5000\n",
            "Epoch 31/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 1.0020 - accuracy: 0.5387 - val_loss: 1.1348 - val_accuracy: 0.4367\n",
            "Epoch 32/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 1.0249 - accuracy: 0.5335 - val_loss: 1.0813 - val_accuracy: 0.4738\n",
            "Epoch 33/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.9916 - accuracy: 0.5559 - val_loss: 1.0739 - val_accuracy: 0.4891\n",
            "Epoch 34/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 1.0162 - accuracy: 0.5378 - val_loss: 1.0835 - val_accuracy: 0.4913\n",
            "Epoch 35/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 1.0186 - accuracy: 0.5341 - val_loss: 1.1392 - val_accuracy: 0.4563\n",
            "Epoch 36/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 1.0490 - accuracy: 0.5265 - val_loss: 1.0959 - val_accuracy: 0.4978\n",
            "Epoch 37/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.9922 - accuracy: 0.5646 - val_loss: 1.0631 - val_accuracy: 0.5066\n",
            "Epoch 38/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.9804 - accuracy: 0.5671 - val_loss: 1.0980 - val_accuracy: 0.4782\n",
            "Epoch 39/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.9957 - accuracy: 0.5554 - val_loss: 1.0846 - val_accuracy: 0.4956\n",
            "Epoch 40/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.9807 - accuracy: 0.5659 - val_loss: 1.0909 - val_accuracy: 0.5066\n",
            "Epoch 41/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 1.0067 - accuracy: 0.5497 - val_loss: 1.0857 - val_accuracy: 0.5240\n",
            "Epoch 42/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.9761 - accuracy: 0.5697 - val_loss: 1.0653 - val_accuracy: 0.5328\n",
            "Epoch 43/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.9574 - accuracy: 0.5732 - val_loss: 1.1582 - val_accuracy: 0.4432\n",
            "Epoch 44/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.9819 - accuracy: 0.5395 - val_loss: 1.0688 - val_accuracy: 0.5218\n",
            "Epoch 45/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.9512 - accuracy: 0.5817 - val_loss: 1.0419 - val_accuracy: 0.5066\n",
            "Epoch 46/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.9485 - accuracy: 0.5763 - val_loss: 1.0945 - val_accuracy: 0.4913\n",
            "Epoch 47/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.9429 - accuracy: 0.5762 - val_loss: 1.0896 - val_accuracy: 0.5175\n",
            "Epoch 48/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.9521 - accuracy: 0.5689 - val_loss: 1.0356 - val_accuracy: 0.5284\n",
            "Epoch 49/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.9537 - accuracy: 0.5698 - val_loss: 1.0787 - val_accuracy: 0.5197\n",
            "Epoch 50/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.9294 - accuracy: 0.5836 - val_loss: 1.0869 - val_accuracy: 0.5066\n",
            "Epoch 51/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.9459 - accuracy: 0.5807 - val_loss: 1.0408 - val_accuracy: 0.5262\n",
            "Epoch 52/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.9177 - accuracy: 0.5905 - val_loss: 1.0553 - val_accuracy: 0.5218\n",
            "Epoch 53/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.9390 - accuracy: 0.5870 - val_loss: 1.0544 - val_accuracy: 0.5197\n",
            "Epoch 54/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.9147 - accuracy: 0.5983 - val_loss: 1.0660 - val_accuracy: 0.5240\n",
            "Epoch 55/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.8990 - accuracy: 0.6085 - val_loss: 1.0408 - val_accuracy: 0.5393\n",
            "Epoch 56/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.9188 - accuracy: 0.5850 - val_loss: 1.0695 - val_accuracy: 0.5328\n",
            "Epoch 57/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.9146 - accuracy: 0.5831 - val_loss: 1.0735 - val_accuracy: 0.5197\n",
            "Epoch 58/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.8990 - accuracy: 0.6090 - val_loss: 1.1005 - val_accuracy: 0.4716\n",
            "Epoch 59/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.9062 - accuracy: 0.6112 - val_loss: 1.1482 - val_accuracy: 0.4978\n",
            "Epoch 60/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.9451 - accuracy: 0.5786 - val_loss: 1.0595 - val_accuracy: 0.5262\n",
            "Epoch 61/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.9198 - accuracy: 0.5966 - val_loss: 1.0412 - val_accuracy: 0.5546\n",
            "Epoch 62/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.8983 - accuracy: 0.6009 - val_loss: 1.1104 - val_accuracy: 0.4956\n",
            "Epoch 63/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.8989 - accuracy: 0.6122 - val_loss: 1.0723 - val_accuracy: 0.5393\n",
            "Epoch 64/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.8944 - accuracy: 0.5956 - val_loss: 1.0855 - val_accuracy: 0.5262\n",
            "Epoch 65/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.8865 - accuracy: 0.6109 - val_loss: 1.0636 - val_accuracy: 0.5371\n",
            "Epoch 66/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.8961 - accuracy: 0.6129 - val_loss: 1.0670 - val_accuracy: 0.5371\n",
            "Epoch 67/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.8752 - accuracy: 0.6201 - val_loss: 1.0843 - val_accuracy: 0.5131\n",
            "Epoch 68/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.8936 - accuracy: 0.5979 - val_loss: 1.0696 - val_accuracy: 0.5349\n",
            "Epoch 69/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.8687 - accuracy: 0.6271 - val_loss: 1.0951 - val_accuracy: 0.5328\n",
            "Epoch 70/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.8860 - accuracy: 0.6127 - val_loss: 1.0775 - val_accuracy: 0.5328\n",
            "Epoch 71/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.8769 - accuracy: 0.6102 - val_loss: 1.0838 - val_accuracy: 0.5328\n",
            "Epoch 72/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.8767 - accuracy: 0.6104 - val_loss: 1.0872 - val_accuracy: 0.5524\n",
            "Epoch 73/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.8663 - accuracy: 0.6242 - val_loss: 1.0812 - val_accuracy: 0.5328\n",
            "Epoch 74/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.8750 - accuracy: 0.6146 - val_loss: 1.0896 - val_accuracy: 0.5284\n",
            "Epoch 75/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.8798 - accuracy: 0.6120 - val_loss: 1.0512 - val_accuracy: 0.5349\n",
            "Epoch 76/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.8475 - accuracy: 0.6263 - val_loss: 1.0787 - val_accuracy: 0.5349\n",
            "Epoch 77/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.8546 - accuracy: 0.6187 - val_loss: 1.1092 - val_accuracy: 0.5415\n",
            "Epoch 78/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.8813 - accuracy: 0.6182 - val_loss: 1.1217 - val_accuracy: 0.5153\n",
            "Epoch 79/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.8677 - accuracy: 0.6282 - val_loss: 1.0692 - val_accuracy: 0.5524\n",
            "Epoch 80/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.8265 - accuracy: 0.6401 - val_loss: 1.0513 - val_accuracy: 0.5524\n",
            "Epoch 81/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.8280 - accuracy: 0.6409 - val_loss: 1.0783 - val_accuracy: 0.5349\n",
            "Epoch 82/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.8491 - accuracy: 0.6304 - val_loss: 1.0853 - val_accuracy: 0.5240\n",
            "Epoch 83/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.7915 - accuracy: 0.6504 - val_loss: 1.0973 - val_accuracy: 0.5262\n",
            "Epoch 84/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.8264 - accuracy: 0.6364 - val_loss: 1.0724 - val_accuracy: 0.5262\n",
            "Epoch 85/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.8160 - accuracy: 0.6407 - val_loss: 1.0968 - val_accuracy: 0.5502\n",
            "Epoch 86/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.8330 - accuracy: 0.6371 - val_loss: 1.1166 - val_accuracy: 0.4913\n",
            "Epoch 87/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.8217 - accuracy: 0.6459 - val_loss: 1.0686 - val_accuracy: 0.5611\n",
            "Epoch 88/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.7709 - accuracy: 0.6716 - val_loss: 1.0924 - val_accuracy: 0.5066\n",
            "Epoch 89/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.8297 - accuracy: 0.6502 - val_loss: 1.1054 - val_accuracy: 0.5459\n",
            "Epoch 90/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.8137 - accuracy: 0.6473 - val_loss: 1.1082 - val_accuracy: 0.5349\n",
            "Epoch 91/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.8146 - accuracy: 0.6369 - val_loss: 1.0881 - val_accuracy: 0.5502\n",
            "Epoch 92/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.8124 - accuracy: 0.6380 - val_loss: 1.0953 - val_accuracy: 0.5328\n",
            "Epoch 93/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.7866 - accuracy: 0.6616 - val_loss: 1.1127 - val_accuracy: 0.5546\n",
            "Epoch 94/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.8094 - accuracy: 0.6466 - val_loss: 1.1225 - val_accuracy: 0.5459\n",
            "Epoch 95/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.7962 - accuracy: 0.6501 - val_loss: 1.0906 - val_accuracy: 0.5480\n",
            "Epoch 96/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.7998 - accuracy: 0.6564 - val_loss: 1.1342 - val_accuracy: 0.5480\n",
            "Epoch 97/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.8065 - accuracy: 0.6400 - val_loss: 1.0909 - val_accuracy: 0.5524\n",
            "Epoch 98/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.7825 - accuracy: 0.6690 - val_loss: 1.1816 - val_accuracy: 0.4847\n",
            "Epoch 99/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.8132 - accuracy: 0.6338 - val_loss: 1.0939 - val_accuracy: 0.5611\n",
            "Epoch 100/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.7649 - accuracy: 0.6763 - val_loss: 1.1008 - val_accuracy: 0.5568\n",
            "Epoch 101/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.7744 - accuracy: 0.6593 - val_loss: 1.1016 - val_accuracy: 0.5284\n",
            "Epoch 102/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.8011 - accuracy: 0.6451 - val_loss: 1.1351 - val_accuracy: 0.5349\n",
            "Epoch 103/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.7980 - accuracy: 0.6536 - val_loss: 1.1180 - val_accuracy: 0.5524\n",
            "Epoch 104/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.7765 - accuracy: 0.6653 - val_loss: 1.1146 - val_accuracy: 0.5502\n",
            "Epoch 105/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.7513 - accuracy: 0.6889 - val_loss: 1.1054 - val_accuracy: 0.5437\n",
            "Epoch 106/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.7382 - accuracy: 0.6804 - val_loss: 1.1442 - val_accuracy: 0.5218\n",
            "Epoch 107/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.7607 - accuracy: 0.6782 - val_loss: 1.1137 - val_accuracy: 0.5611\n",
            "Epoch 108/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.7557 - accuracy: 0.6813 - val_loss: 1.1488 - val_accuracy: 0.5349\n",
            "Epoch 109/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.7615 - accuracy: 0.6750 - val_loss: 1.1795 - val_accuracy: 0.5000\n",
            "Epoch 110/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.7698 - accuracy: 0.6553 - val_loss: 1.1471 - val_accuracy: 0.5459\n",
            "Epoch 111/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.7312 - accuracy: 0.6826 - val_loss: 1.1661 - val_accuracy: 0.5306\n",
            "Epoch 112/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.7550 - accuracy: 0.6792 - val_loss: 1.1966 - val_accuracy: 0.5044\n",
            "Epoch 113/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.7901 - accuracy: 0.6365 - val_loss: 1.1434 - val_accuracy: 0.5437\n",
            "Epoch 114/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.7293 - accuracy: 0.6846 - val_loss: 1.1339 - val_accuracy: 0.5437\n",
            "Epoch 115/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.7024 - accuracy: 0.6997 - val_loss: 1.1644 - val_accuracy: 0.5568\n",
            "Epoch 116/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.7444 - accuracy: 0.6810 - val_loss: 1.1552 - val_accuracy: 0.5742\n",
            "Epoch 117/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.7233 - accuracy: 0.6861 - val_loss: 1.2049 - val_accuracy: 0.5328\n",
            "Epoch 118/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.7103 - accuracy: 0.6948 - val_loss: 1.2034 - val_accuracy: 0.5197\n",
            "Epoch 119/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.7298 - accuracy: 0.6884 - val_loss: 1.2055 - val_accuracy: 0.5153\n",
            "Epoch 120/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.7017 - accuracy: 0.7022 - val_loss: 1.1835 - val_accuracy: 0.5437\n",
            "Epoch 121/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.6930 - accuracy: 0.7092 - val_loss: 1.1723 - val_accuracy: 0.5524\n",
            "Epoch 122/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.7081 - accuracy: 0.6860 - val_loss: 1.2230 - val_accuracy: 0.5197\n",
            "Epoch 123/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.7170 - accuracy: 0.6894 - val_loss: 1.1663 - val_accuracy: 0.5415\n",
            "Epoch 124/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.7038 - accuracy: 0.6993 - val_loss: 1.1874 - val_accuracy: 0.5044\n",
            "Epoch 125/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.7169 - accuracy: 0.6850 - val_loss: 1.1908 - val_accuracy: 0.5328\n",
            "Epoch 126/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.6925 - accuracy: 0.7031 - val_loss: 1.2330 - val_accuracy: 0.5349\n",
            "Epoch 127/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.6920 - accuracy: 0.7066 - val_loss: 1.2168 - val_accuracy: 0.5437\n",
            "Epoch 128/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.6970 - accuracy: 0.7046 - val_loss: 1.2906 - val_accuracy: 0.5175\n",
            "Epoch 129/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.6879 - accuracy: 0.7070 - val_loss: 1.2260 - val_accuracy: 0.5175\n",
            "Epoch 130/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.6890 - accuracy: 0.7084 - val_loss: 1.2663 - val_accuracy: 0.5371\n",
            "Epoch 131/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.6669 - accuracy: 0.7247 - val_loss: 1.2743 - val_accuracy: 0.5000\n",
            "Epoch 132/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.6846 - accuracy: 0.7067 - val_loss: 1.2616 - val_accuracy: 0.5415\n",
            "Epoch 133/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.6716 - accuracy: 0.7141 - val_loss: 1.2558 - val_accuracy: 0.5306\n",
            "Epoch 134/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.6823 - accuracy: 0.7188 - val_loss: 1.2930 - val_accuracy: 0.5109\n",
            "Epoch 135/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.6636 - accuracy: 0.7158 - val_loss: 1.2741 - val_accuracy: 0.5393\n",
            "Epoch 136/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.6634 - accuracy: 0.7196 - val_loss: 1.2703 - val_accuracy: 0.5284\n",
            "Epoch 137/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.6474 - accuracy: 0.7237 - val_loss: 1.3233 - val_accuracy: 0.5109\n",
            "Epoch 138/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.6537 - accuracy: 0.7088 - val_loss: 1.3068 - val_accuracy: 0.5218\n",
            "Epoch 139/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.6691 - accuracy: 0.7157 - val_loss: 1.3835 - val_accuracy: 0.5371\n",
            "Epoch 140/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.6686 - accuracy: 0.7200 - val_loss: 1.3186 - val_accuracy: 0.5328\n",
            "Epoch 141/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.6503 - accuracy: 0.7254 - val_loss: 1.3220 - val_accuracy: 0.4913\n",
            "Epoch 142/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.6259 - accuracy: 0.7414 - val_loss: 1.2901 - val_accuracy: 0.5262\n",
            "Epoch 143/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.6167 - accuracy: 0.7362 - val_loss: 1.3241 - val_accuracy: 0.5349\n",
            "Epoch 144/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.6255 - accuracy: 0.7411 - val_loss: 1.3325 - val_accuracy: 0.5328\n",
            "Epoch 145/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.6426 - accuracy: 0.7195 - val_loss: 1.3565 - val_accuracy: 0.5066\n",
            "Epoch 146/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.6372 - accuracy: 0.7319 - val_loss: 1.3262 - val_accuracy: 0.5000\n",
            "Epoch 147/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.6095 - accuracy: 0.7507 - val_loss: 1.3023 - val_accuracy: 0.5218\n",
            "Epoch 148/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.6080 - accuracy: 0.7502 - val_loss: 1.3143 - val_accuracy: 0.5262\n",
            "Epoch 149/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.6266 - accuracy: 0.7221 - val_loss: 1.3811 - val_accuracy: 0.5131\n",
            "Epoch 150/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.6248 - accuracy: 0.7363 - val_loss: 1.3657 - val_accuracy: 0.5218\n",
            "Epoch 151/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.5987 - accuracy: 0.7471 - val_loss: 1.3445 - val_accuracy: 0.5437\n",
            "Epoch 152/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.5837 - accuracy: 0.7496 - val_loss: 1.3694 - val_accuracy: 0.5415\n",
            "Epoch 153/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.6203 - accuracy: 0.7357 - val_loss: 1.3940 - val_accuracy: 0.5218\n",
            "Epoch 154/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.5754 - accuracy: 0.7602 - val_loss: 1.4755 - val_accuracy: 0.5131\n",
            "Epoch 155/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.6171 - accuracy: 0.7367 - val_loss: 1.3692 - val_accuracy: 0.5262\n",
            "Epoch 156/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.5887 - accuracy: 0.7531 - val_loss: 1.4000 - val_accuracy: 0.5153\n",
            "Epoch 157/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.5963 - accuracy: 0.7486 - val_loss: 1.4044 - val_accuracy: 0.5306\n",
            "Epoch 158/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.5631 - accuracy: 0.7619 - val_loss: 1.4274 - val_accuracy: 0.5349\n",
            "Epoch 159/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.5563 - accuracy: 0.7665 - val_loss: 1.4086 - val_accuracy: 0.5022\n",
            "Epoch 160/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.5946 - accuracy: 0.7547 - val_loss: 1.4134 - val_accuracy: 0.5240\n",
            "Epoch 161/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.5538 - accuracy: 0.7628 - val_loss: 1.5044 - val_accuracy: 0.5022\n",
            "Epoch 162/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.5591 - accuracy: 0.7501 - val_loss: 1.4495 - val_accuracy: 0.5066\n",
            "Epoch 163/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.5725 - accuracy: 0.7580 - val_loss: 1.4843 - val_accuracy: 0.5066\n",
            "Epoch 164/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.5328 - accuracy: 0.7746 - val_loss: 1.4660 - val_accuracy: 0.5066\n",
            "Epoch 165/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.5698 - accuracy: 0.7632 - val_loss: 1.4502 - val_accuracy: 0.5044\n",
            "Epoch 166/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.5760 - accuracy: 0.7531 - val_loss: 1.4241 - val_accuracy: 0.5109\n",
            "Epoch 167/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.5292 - accuracy: 0.7744 - val_loss: 1.4743 - val_accuracy: 0.5284\n",
            "Epoch 168/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.5459 - accuracy: 0.7680 - val_loss: 1.5727 - val_accuracy: 0.5131\n",
            "Epoch 169/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.5649 - accuracy: 0.7610 - val_loss: 1.4639 - val_accuracy: 0.5175\n",
            "Epoch 170/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.5222 - accuracy: 0.7859 - val_loss: 1.4570 - val_accuracy: 0.5131\n",
            "Epoch 171/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.5593 - accuracy: 0.7592 - val_loss: 1.4859 - val_accuracy: 0.5000\n",
            "Epoch 172/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.5407 - accuracy: 0.7709 - val_loss: 1.5558 - val_accuracy: 0.5306\n",
            "Epoch 173/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.5106 - accuracy: 0.7800 - val_loss: 1.5093 - val_accuracy: 0.5131\n",
            "Epoch 174/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.5313 - accuracy: 0.7774 - val_loss: 1.5526 - val_accuracy: 0.5131\n",
            "Epoch 175/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.5051 - accuracy: 0.7941 - val_loss: 1.4711 - val_accuracy: 0.5306\n",
            "Epoch 176/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.5442 - accuracy: 0.7678 - val_loss: 1.5364 - val_accuracy: 0.5284\n",
            "Epoch 177/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.5377 - accuracy: 0.7742 - val_loss: 1.4965 - val_accuracy: 0.5393\n",
            "Epoch 178/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.5192 - accuracy: 0.7734 - val_loss: 1.5052 - val_accuracy: 0.5175\n",
            "Epoch 179/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.5125 - accuracy: 0.7879 - val_loss: 1.5189 - val_accuracy: 0.5044\n",
            "Epoch 180/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.5264 - accuracy: 0.7789 - val_loss: 1.5181 - val_accuracy: 0.4956\n",
            "Epoch 181/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.5328 - accuracy: 0.7737 - val_loss: 1.5417 - val_accuracy: 0.5087\n",
            "Epoch 182/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.4887 - accuracy: 0.8024 - val_loss: 1.5896 - val_accuracy: 0.4934\n",
            "Epoch 183/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.4760 - accuracy: 0.8015 - val_loss: 1.5556 - val_accuracy: 0.5087\n",
            "Epoch 184/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.5146 - accuracy: 0.7848 - val_loss: 1.5857 - val_accuracy: 0.5240\n",
            "Epoch 185/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.4878 - accuracy: 0.8035 - val_loss: 1.5876 - val_accuracy: 0.5044\n",
            "Epoch 186/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.5117 - accuracy: 0.7798 - val_loss: 1.5907 - val_accuracy: 0.5087\n",
            "Epoch 187/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.4682 - accuracy: 0.8017 - val_loss: 1.5536 - val_accuracy: 0.5022\n",
            "Epoch 188/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.4700 - accuracy: 0.8045 - val_loss: 1.6652 - val_accuracy: 0.4760\n",
            "Epoch 189/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.4920 - accuracy: 0.7910 - val_loss: 1.6083 - val_accuracy: 0.5087\n",
            "Epoch 190/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.4709 - accuracy: 0.8026 - val_loss: 1.6701 - val_accuracy: 0.4956\n",
            "Epoch 191/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.5155 - accuracy: 0.7900 - val_loss: 1.5932 - val_accuracy: 0.5044\n",
            "Epoch 192/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.4693 - accuracy: 0.8052 - val_loss: 1.6303 - val_accuracy: 0.5000\n",
            "Epoch 193/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.4764 - accuracy: 0.8069 - val_loss: 1.5964 - val_accuracy: 0.4978\n",
            "Epoch 194/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.4730 - accuracy: 0.8048 - val_loss: 1.6278 - val_accuracy: 0.5197\n",
            "Epoch 195/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.4373 - accuracy: 0.8296 - val_loss: 1.6965 - val_accuracy: 0.5284\n",
            "Epoch 196/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.4478 - accuracy: 0.8162 - val_loss: 1.5859 - val_accuracy: 0.4934\n",
            "Epoch 197/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.4367 - accuracy: 0.8162 - val_loss: 1.6314 - val_accuracy: 0.5175\n",
            "Epoch 198/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.4568 - accuracy: 0.8059 - val_loss: 1.6978 - val_accuracy: 0.5109\n",
            "Epoch 199/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.4696 - accuracy: 0.7998 - val_loss: 1.7800 - val_accuracy: 0.5022\n",
            "Epoch 200/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.4797 - accuracy: 0.8046 - val_loss: 1.7331 - val_accuracy: 0.5066\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6TaZ3RWeiKDX"
      },
      "source": [
        "model.save('/content/drive/MyDrive/Colab Notebooks/SPEECH_EMOTION_Recognition/Nộp bài(chốt hạ)/model_saver/basic_mfcc26_cremad.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "agMGT6QhiKDZ"
      },
      "source": [
        "###test_result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-12T05:45:41.629805Z",
          "iopub.execute_input": "2021-06-12T05:45:41.630161Z",
          "iopub.status.idle": "2021-06-12T05:45:41.786756Z",
          "shell.execute_reply.started": "2021-06-12T05:45:41.630121Z",
          "shell.execute_reply": "2021-06-12T05:45:41.785499Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dcHUwGpriKDa",
        "outputId": "33040c8c-c466-4a0d-f831-6165fef048b0"
      },
      "source": [
        "d = {0: 'happy',\n",
        "     1: 'sad',\n",
        "     2: 'angry',\n",
        "     3: 'fear'}\n",
        "Y_test_pred = np.argmax(model.predict(X_test), axis=-1)\n",
        "Y_test_pred = list(map(lambda x: d[x], Y_test_pred))\n",
        "y_test = np.argmax(y_test, axis=-1)\n",
        "y_test = list(map(lambda x: d[x], y_test))\n",
        "print(classification_report(y_test, Y_test_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.59      0.60      0.59       136\n",
            "        fear       0.42      0.38      0.40       134\n",
            "       happy       0.38      0.49      0.43       120\n",
            "         sad       0.65      0.52      0.58       119\n",
            "\n",
            "    accuracy                           0.50       509\n",
            "   macro avg       0.51      0.50      0.50       509\n",
            "weighted avg       0.51      0.50      0.50       509\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-12T05:45:47.991956Z",
          "iopub.execute_input": "2021-06-12T05:45:47.992400Z",
          "iopub.status.idle": "2021-06-12T05:45:48.358940Z",
          "shell.execute_reply.started": "2021-06-12T05:45:47.992353Z",
          "shell.execute_reply": "2021-06-12T05:45:48.357523Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 483
        },
        "id": "x72HbxeZiKDc",
        "outputId": "a5564c55-8ada-4cdb-8e93-8489a02e7d84"
      },
      "source": [
        "import scikitplot as skplt\n",
        "\n",
        "skplt.metrics.plot_confusion_matrix(\n",
        "    y_test, \n",
        "    Y_test_pred,\n",
        "    figsize=(8,8))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f11a4c012d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3S2kHfHYiqwN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hBVPJsi8jVXy"
      },
      "source": [
        "\n",
        "# mfcc_39 + basic model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-12T05:29:22.599372Z",
          "iopub.execute_input": "2021-06-12T05:29:22.599854Z",
          "iopub.status.idle": "2021-06-12T05:43:40.908032Z",
          "shell.execute_reply.started": "2021-06-12T05:29:22.599811Z",
          "shell.execute_reply": "2021-06-12T05:43:40.906398Z"
        },
        "trusted": true,
        "id": "UnOXqwaqjVYZ"
      },
      "source": [
        "data = {'labels': [],\n",
        "        'features': []}\n",
        "\n",
        "for i in range(len(CREMA_D_df)):\n",
        "  if ((CREMA_D_df['Emotion'][i] == 'HAP') | (CREMA_D_df['Emotion'][i] == 'SAD') | \n",
        "      (CREMA_D_df['Emotion'][i] == 'ANG') | (CREMA_D_df['Emotion'][i] == 'FEA')):\n",
        "    \n",
        "    if CREMA_D_df['Emotion'][i] == 'HAP':\n",
        "      data['labels'].append(0)\n",
        "    elif CREMA_D_df['Emotion'][i] == 'SAD':\n",
        "      data['labels'].append(1)\n",
        "    elif CREMA_D_df['Emotion'][i] == 'ANG':\n",
        "      data['labels'].append(2)\n",
        "    elif CREMA_D_df['Emotion'][i] == 'FEA':\n",
        "      data['labels'].append(3)\n",
        "\n",
        "\n",
        "    signal, sr =  librosa.load(CREMA_D_df['Paths'][i])\n",
        "    mfcc = np.mean(librosa.feature.mfcc(y=signal, sr=sr, n_mfcc=39).T,axis=0).tolist()\n",
        "    data['features'].append(mfcc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-12T05:44:58.692964Z",
          "iopub.execute_input": "2021-06-12T05:44:58.693400Z",
          "iopub.status.idle": "2021-06-12T05:44:58.724940Z",
          "shell.execute_reply.started": "2021-06-12T05:44:58.693367Z",
          "shell.execute_reply": "2021-06-12T05:44:58.723838Z"
        },
        "trusted": true,
        "id": "SFchCSMBjVYb"
      },
      "source": [
        "X = data['features']\n",
        "y = data['labels']\n",
        "\n",
        "y = np.array(data['labels'])\n",
        "y = to_categorical(y)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=0)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=0)\n",
        "\n",
        "X_train = np.array(X_train)\n",
        "X_test = np.array(X_test)\n",
        "X_val = np.array(X_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i6UlMEUWjVYc"
      },
      "source": [
        "## basic model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-12T05:45:02.159579Z",
          "iopub.execute_input": "2021-06-12T05:45:02.159948Z",
          "iopub.status.idle": "2021-06-12T05:45:05.285505Z",
          "shell.execute_reply.started": "2021-06-12T05:45:02.159902Z",
          "shell.execute_reply": "2021-06-12T05:45:05.284564Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Tyw1OWajVYd",
        "outputId": "2bee9304-f685-415e-e194-8863bcb4a8a8"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(39, input_shape=(39, ), activation = 'relu'))\n",
        "#model.add(Dropout(0.1))\n",
        "model.add(Dense(128, activation = 'relu'))\n",
        "#model.add(Dropout(0.25))\n",
        "model.add(Dense(128, activation = 'relu'))\n",
        "#model.add(Dropout(0.2))\n",
        "model.add(Dense(4, activation = 'softmax'))\n",
        "\n",
        "optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
        "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer=optimizer)\n",
        "early_stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=100, verbose=1, mode='auto')\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_16 (Dense)             (None, 39)                1560      \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 128)               5120      \n",
            "_________________________________________________________________\n",
            "dense_18 (Dense)             (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             (None, 4)                 516       \n",
            "=================================================================\n",
            "Total params: 23,708\n",
            "Trainable params: 23,708\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-12T05:45:07.791555Z",
          "iopub.execute_input": "2021-06-12T05:45:07.791947Z",
          "iopub.status.idle": "2021-06-12T05:45:35.451581Z",
          "shell.execute_reply.started": "2021-06-12T05:45:07.791916Z",
          "shell.execute_reply": "2021-06-12T05:45:35.450630Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5pC2zzMXjVYf",
        "outputId": "a9d454de-f33b-48f9-c31f-77d6652d9c79"
      },
      "source": [
        "history = model.fit(X_train, y_train, batch_size=64, epochs=200, \n",
        "                    validation_data=(X_val, y_val))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "65/65 [==============================] - 1s 7ms/step - loss: 6.1641 - accuracy: 0.3211 - val_loss: 1.5156 - val_accuracy: 0.3668\n",
            "Epoch 2/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 1.3711 - accuracy: 0.4141 - val_loss: 1.4710 - val_accuracy: 0.4192\n",
            "Epoch 3/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 1.3542 - accuracy: 0.4126 - val_loss: 1.3285 - val_accuracy: 0.3865\n",
            "Epoch 4/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 1.3851 - accuracy: 0.4095 - val_loss: 1.1999 - val_accuracy: 0.4389\n",
            "Epoch 5/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 1.3650 - accuracy: 0.4133 - val_loss: 1.1296 - val_accuracy: 0.4934\n",
            "Epoch 6/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 1.2298 - accuracy: 0.4660 - val_loss: 1.2965 - val_accuracy: 0.4345\n",
            "Epoch 7/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 1.2742 - accuracy: 0.4395 - val_loss: 1.5124 - val_accuracy: 0.4476\n",
            "Epoch 8/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 1.2273 - accuracy: 0.4704 - val_loss: 1.3348 - val_accuracy: 0.3777\n",
            "Epoch 9/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 1.2701 - accuracy: 0.4581 - val_loss: 1.1077 - val_accuracy: 0.4738\n",
            "Epoch 10/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 1.1375 - accuracy: 0.4955 - val_loss: 1.3863 - val_accuracy: 0.4432\n",
            "Epoch 11/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 1.1688 - accuracy: 0.4689 - val_loss: 1.1730 - val_accuracy: 0.4825\n",
            "Epoch 12/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 1.1709 - accuracy: 0.4792 - val_loss: 1.5041 - val_accuracy: 0.3886\n",
            "Epoch 13/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 1.2379 - accuracy: 0.4632 - val_loss: 1.0925 - val_accuracy: 0.4869\n",
            "Epoch 14/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 1.0968 - accuracy: 0.5044 - val_loss: 1.1683 - val_accuracy: 0.4520\n",
            "Epoch 15/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 1.1170 - accuracy: 0.4852 - val_loss: 1.1499 - val_accuracy: 0.4760\n",
            "Epoch 16/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 1.0747 - accuracy: 0.5144 - val_loss: 1.1619 - val_accuracy: 0.4498\n",
            "Epoch 17/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 1.1445 - accuracy: 0.4830 - val_loss: 1.1939 - val_accuracy: 0.4607\n",
            "Epoch 18/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 1.1231 - accuracy: 0.4952 - val_loss: 1.2468 - val_accuracy: 0.3930\n",
            "Epoch 19/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 1.1104 - accuracy: 0.4934 - val_loss: 1.2005 - val_accuracy: 0.4127\n",
            "Epoch 20/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 1.0557 - accuracy: 0.5141 - val_loss: 1.0969 - val_accuracy: 0.5087\n",
            "Epoch 21/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 1.0679 - accuracy: 0.5185 - val_loss: 1.0941 - val_accuracy: 0.4956\n",
            "Epoch 22/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 1.1185 - accuracy: 0.5053 - val_loss: 1.0572 - val_accuracy: 0.5306\n",
            "Epoch 23/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 1.0512 - accuracy: 0.5319 - val_loss: 1.1431 - val_accuracy: 0.4782\n",
            "Epoch 24/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 1.0961 - accuracy: 0.4993 - val_loss: 1.0916 - val_accuracy: 0.5000\n",
            "Epoch 25/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 1.0674 - accuracy: 0.5200 - val_loss: 1.0695 - val_accuracy: 0.5197\n",
            "Epoch 26/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 1.0222 - accuracy: 0.5412 - val_loss: 1.0422 - val_accuracy: 0.5459\n",
            "Epoch 27/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 1.0402 - accuracy: 0.5224 - val_loss: 1.0514 - val_accuracy: 0.5153\n",
            "Epoch 28/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 1.0275 - accuracy: 0.5452 - val_loss: 1.2191 - val_accuracy: 0.4127\n",
            "Epoch 29/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 1.0731 - accuracy: 0.5152 - val_loss: 1.0874 - val_accuracy: 0.5044\n",
            "Epoch 30/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 1.0870 - accuracy: 0.5085 - val_loss: 1.0808 - val_accuracy: 0.5131\n",
            "Epoch 31/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 1.0296 - accuracy: 0.5498 - val_loss: 1.0530 - val_accuracy: 0.5328\n",
            "Epoch 32/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 1.0408 - accuracy: 0.5257 - val_loss: 1.0597 - val_accuracy: 0.5175\n",
            "Epoch 33/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.9937 - accuracy: 0.5522 - val_loss: 1.1172 - val_accuracy: 0.5000\n",
            "Epoch 34/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 1.0393 - accuracy: 0.5236 - val_loss: 1.0549 - val_accuracy: 0.5087\n",
            "Epoch 35/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 1.0076 - accuracy: 0.5457 - val_loss: 1.0887 - val_accuracy: 0.5284\n",
            "Epoch 36/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.9901 - accuracy: 0.5594 - val_loss: 1.0393 - val_accuracy: 0.5175\n",
            "Epoch 37/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 1.0393 - accuracy: 0.5372 - val_loss: 1.1318 - val_accuracy: 0.5000\n",
            "Epoch 38/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 1.0248 - accuracy: 0.5330 - val_loss: 1.0822 - val_accuracy: 0.4738\n",
            "Epoch 39/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 1.0544 - accuracy: 0.5272 - val_loss: 1.0593 - val_accuracy: 0.4934\n",
            "Epoch 40/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 1.0165 - accuracy: 0.5358 - val_loss: 1.0418 - val_accuracy: 0.5284\n",
            "Epoch 41/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 1.0043 - accuracy: 0.5502 - val_loss: 1.0360 - val_accuracy: 0.5240\n",
            "Epoch 42/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.9984 - accuracy: 0.5484 - val_loss: 1.0458 - val_accuracy: 0.5437\n",
            "Epoch 43/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 1.0030 - accuracy: 0.5520 - val_loss: 1.0939 - val_accuracy: 0.5349\n",
            "Epoch 44/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.9959 - accuracy: 0.5453 - val_loss: 1.1153 - val_accuracy: 0.4672\n",
            "Epoch 45/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.9827 - accuracy: 0.5614 - val_loss: 1.0411 - val_accuracy: 0.5393\n",
            "Epoch 46/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.9618 - accuracy: 0.5694 - val_loss: 1.0249 - val_accuracy: 0.5502\n",
            "Epoch 47/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.9913 - accuracy: 0.5539 - val_loss: 1.0242 - val_accuracy: 0.5546\n",
            "Epoch 48/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.9666 - accuracy: 0.5642 - val_loss: 1.1145 - val_accuracy: 0.4607\n",
            "Epoch 49/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.9798 - accuracy: 0.5519 - val_loss: 1.0646 - val_accuracy: 0.5262\n",
            "Epoch 50/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.9531 - accuracy: 0.5754 - val_loss: 1.0677 - val_accuracy: 0.5328\n",
            "Epoch 51/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.9738 - accuracy: 0.5602 - val_loss: 1.0617 - val_accuracy: 0.5175\n",
            "Epoch 52/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.9616 - accuracy: 0.5672 - val_loss: 1.0589 - val_accuracy: 0.5415\n",
            "Epoch 53/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.9399 - accuracy: 0.5885 - val_loss: 1.1068 - val_accuracy: 0.5087\n",
            "Epoch 54/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.9540 - accuracy: 0.5666 - val_loss: 1.0310 - val_accuracy: 0.5262\n",
            "Epoch 55/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.9422 - accuracy: 0.5848 - val_loss: 1.0593 - val_accuracy: 0.5459\n",
            "Epoch 56/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.9660 - accuracy: 0.5765 - val_loss: 1.0659 - val_accuracy: 0.5087\n",
            "Epoch 57/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.9481 - accuracy: 0.5726 - val_loss: 1.0185 - val_accuracy: 0.5437\n",
            "Epoch 58/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.9240 - accuracy: 0.5932 - val_loss: 1.0741 - val_accuracy: 0.5218\n",
            "Epoch 59/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.9413 - accuracy: 0.5800 - val_loss: 1.0344 - val_accuracy: 0.5393\n",
            "Epoch 60/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.9391 - accuracy: 0.5933 - val_loss: 1.0403 - val_accuracy: 0.5262\n",
            "Epoch 61/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.9279 - accuracy: 0.5963 - val_loss: 1.0215 - val_accuracy: 0.5371\n",
            "Epoch 62/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.9482 - accuracy: 0.5706 - val_loss: 1.0209 - val_accuracy: 0.5590\n",
            "Epoch 63/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.8989 - accuracy: 0.6066 - val_loss: 1.0378 - val_accuracy: 0.5262\n",
            "Epoch 64/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.9659 - accuracy: 0.5837 - val_loss: 1.0201 - val_accuracy: 0.5415\n",
            "Epoch 65/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.8976 - accuracy: 0.6022 - val_loss: 1.0316 - val_accuracy: 0.5546\n",
            "Epoch 66/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.8967 - accuracy: 0.6028 - val_loss: 1.0128 - val_accuracy: 0.5611\n",
            "Epoch 67/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.8981 - accuracy: 0.6065 - val_loss: 1.0860 - val_accuracy: 0.5371\n",
            "Epoch 68/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.9139 - accuracy: 0.5893 - val_loss: 1.0825 - val_accuracy: 0.5437\n",
            "Epoch 69/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.9342 - accuracy: 0.5924 - val_loss: 1.0556 - val_accuracy: 0.5371\n",
            "Epoch 70/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.9179 - accuracy: 0.5978 - val_loss: 1.0020 - val_accuracy: 0.5590\n",
            "Epoch 71/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.8865 - accuracy: 0.6095 - val_loss: 1.0735 - val_accuracy: 0.5175\n",
            "Epoch 72/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.9278 - accuracy: 0.5793 - val_loss: 1.0271 - val_accuracy: 0.5524\n",
            "Epoch 73/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.8625 - accuracy: 0.6261 - val_loss: 1.0517 - val_accuracy: 0.5306\n",
            "Epoch 74/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.8790 - accuracy: 0.6228 - val_loss: 1.0588 - val_accuracy: 0.5153\n",
            "Epoch 75/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.8996 - accuracy: 0.5953 - val_loss: 1.0380 - val_accuracy: 0.5459\n",
            "Epoch 76/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.8580 - accuracy: 0.6325 - val_loss: 1.0397 - val_accuracy: 0.5393\n",
            "Epoch 77/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.8690 - accuracy: 0.6212 - val_loss: 1.0059 - val_accuracy: 0.5677\n",
            "Epoch 78/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.8534 - accuracy: 0.6285 - val_loss: 1.0195 - val_accuracy: 0.5524\n",
            "Epoch 79/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.8371 - accuracy: 0.6335 - val_loss: 1.0024 - val_accuracy: 0.5852\n",
            "Epoch 80/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.8541 - accuracy: 0.6305 - val_loss: 1.0026 - val_accuracy: 0.5546\n",
            "Epoch 81/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.8488 - accuracy: 0.6185 - val_loss: 1.0478 - val_accuracy: 0.5262\n",
            "Epoch 82/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.8577 - accuracy: 0.6311 - val_loss: 1.0078 - val_accuracy: 0.5590\n",
            "Epoch 83/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.8425 - accuracy: 0.6330 - val_loss: 1.0441 - val_accuracy: 0.5262\n",
            "Epoch 84/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.8567 - accuracy: 0.6282 - val_loss: 1.0239 - val_accuracy: 0.5371\n",
            "Epoch 85/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.8395 - accuracy: 0.6275 - val_loss: 1.0270 - val_accuracy: 0.5590\n",
            "Epoch 86/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.8519 - accuracy: 0.6164 - val_loss: 0.9970 - val_accuracy: 0.5764\n",
            "Epoch 87/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.8303 - accuracy: 0.6271 - val_loss: 1.0614 - val_accuracy: 0.5459\n",
            "Epoch 88/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.8037 - accuracy: 0.6493 - val_loss: 1.0216 - val_accuracy: 0.5677\n",
            "Epoch 89/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.8370 - accuracy: 0.6248 - val_loss: 1.0473 - val_accuracy: 0.5437\n",
            "Epoch 90/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.8074 - accuracy: 0.6512 - val_loss: 1.0323 - val_accuracy: 0.5109\n",
            "Epoch 91/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.8193 - accuracy: 0.6508 - val_loss: 1.0007 - val_accuracy: 0.5633\n",
            "Epoch 92/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.8003 - accuracy: 0.6507 - val_loss: 1.0067 - val_accuracy: 0.5742\n",
            "Epoch 93/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.7764 - accuracy: 0.6659 - val_loss: 1.0810 - val_accuracy: 0.5022\n",
            "Epoch 94/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.7759 - accuracy: 0.6715 - val_loss: 1.0153 - val_accuracy: 0.5546\n",
            "Epoch 95/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.7936 - accuracy: 0.6612 - val_loss: 1.0337 - val_accuracy: 0.5480\n",
            "Epoch 96/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.8007 - accuracy: 0.6470 - val_loss: 1.0246 - val_accuracy: 0.5655\n",
            "Epoch 97/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.7713 - accuracy: 0.6669 - val_loss: 1.0239 - val_accuracy: 0.5721\n",
            "Epoch 98/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.7750 - accuracy: 0.6674 - val_loss: 1.0244 - val_accuracy: 0.5655\n",
            "Epoch 99/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.7577 - accuracy: 0.6754 - val_loss: 1.0685 - val_accuracy: 0.5262\n",
            "Epoch 100/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.7774 - accuracy: 0.6598 - val_loss: 1.0446 - val_accuracy: 0.5524\n",
            "Epoch 101/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.7604 - accuracy: 0.6742 - val_loss: 1.0423 - val_accuracy: 0.5568\n",
            "Epoch 102/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.7629 - accuracy: 0.6736 - val_loss: 1.0805 - val_accuracy: 0.5175\n",
            "Epoch 103/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.7441 - accuracy: 0.6787 - val_loss: 1.0872 - val_accuracy: 0.5284\n",
            "Epoch 104/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.7382 - accuracy: 0.6917 - val_loss: 1.1013 - val_accuracy: 0.5415\n",
            "Epoch 105/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.7401 - accuracy: 0.6801 - val_loss: 1.1225 - val_accuracy: 0.5524\n",
            "Epoch 106/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.7633 - accuracy: 0.6836 - val_loss: 1.0475 - val_accuracy: 0.5786\n",
            "Epoch 107/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.7256 - accuracy: 0.6837 - val_loss: 1.0896 - val_accuracy: 0.5328\n",
            "Epoch 108/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.7454 - accuracy: 0.6822 - val_loss: 1.0571 - val_accuracy: 0.5524\n",
            "Epoch 109/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.7340 - accuracy: 0.6841 - val_loss: 1.0748 - val_accuracy: 0.5262\n",
            "Epoch 110/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.6999 - accuracy: 0.6900 - val_loss: 1.0800 - val_accuracy: 0.5546\n",
            "Epoch 111/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.7150 - accuracy: 0.6920 - val_loss: 1.1033 - val_accuracy: 0.5284\n",
            "Epoch 112/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.7004 - accuracy: 0.7070 - val_loss: 1.0785 - val_accuracy: 0.5590\n",
            "Epoch 113/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.6828 - accuracy: 0.7171 - val_loss: 1.1093 - val_accuracy: 0.5524\n",
            "Epoch 114/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.7262 - accuracy: 0.6874 - val_loss: 1.0789 - val_accuracy: 0.5721\n",
            "Epoch 115/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.7058 - accuracy: 0.6949 - val_loss: 1.1140 - val_accuracy: 0.5633\n",
            "Epoch 116/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.6898 - accuracy: 0.7038 - val_loss: 1.0660 - val_accuracy: 0.5611\n",
            "Epoch 117/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.6819 - accuracy: 0.7052 - val_loss: 1.1267 - val_accuracy: 0.5262\n",
            "Epoch 118/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.6664 - accuracy: 0.7245 - val_loss: 1.1090 - val_accuracy: 0.5480\n",
            "Epoch 119/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.6716 - accuracy: 0.7195 - val_loss: 1.0596 - val_accuracy: 0.5895\n",
            "Epoch 120/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.6633 - accuracy: 0.7206 - val_loss: 1.2599 - val_accuracy: 0.5000\n",
            "Epoch 121/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.6860 - accuracy: 0.7063 - val_loss: 1.0878 - val_accuracy: 0.5764\n",
            "Epoch 122/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.6596 - accuracy: 0.7185 - val_loss: 1.1195 - val_accuracy: 0.5677\n",
            "Epoch 123/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.6580 - accuracy: 0.7258 - val_loss: 1.1015 - val_accuracy: 0.5611\n",
            "Epoch 124/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.6395 - accuracy: 0.7274 - val_loss: 1.1404 - val_accuracy: 0.5153\n",
            "Epoch 125/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.6493 - accuracy: 0.7362 - val_loss: 1.1665 - val_accuracy: 0.5393\n",
            "Epoch 126/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.6542 - accuracy: 0.7277 - val_loss: 1.1410 - val_accuracy: 0.5349\n",
            "Epoch 127/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.6282 - accuracy: 0.7443 - val_loss: 1.1119 - val_accuracy: 0.5371\n",
            "Epoch 128/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.6467 - accuracy: 0.7262 - val_loss: 1.1109 - val_accuracy: 0.5721\n",
            "Epoch 129/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.6402 - accuracy: 0.7293 - val_loss: 1.1167 - val_accuracy: 0.5677\n",
            "Epoch 130/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.6110 - accuracy: 0.7466 - val_loss: 1.1079 - val_accuracy: 0.5721\n",
            "Epoch 131/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.6338 - accuracy: 0.7395 - val_loss: 1.1522 - val_accuracy: 0.5677\n",
            "Epoch 132/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.6106 - accuracy: 0.7431 - val_loss: 1.1130 - val_accuracy: 0.5808\n",
            "Epoch 133/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.5927 - accuracy: 0.7577 - val_loss: 1.1759 - val_accuracy: 0.5699\n",
            "Epoch 134/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.5847 - accuracy: 0.7625 - val_loss: 1.0893 - val_accuracy: 0.5524\n",
            "Epoch 135/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.5931 - accuracy: 0.7526 - val_loss: 1.1114 - val_accuracy: 0.5939\n",
            "Epoch 136/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.5617 - accuracy: 0.7752 - val_loss: 1.2297 - val_accuracy: 0.5349\n",
            "Epoch 137/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.5756 - accuracy: 0.7628 - val_loss: 1.1416 - val_accuracy: 0.5721\n",
            "Epoch 138/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.5553 - accuracy: 0.7707 - val_loss: 1.1479 - val_accuracy: 0.5437\n",
            "Epoch 139/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.5757 - accuracy: 0.7702 - val_loss: 1.1395 - val_accuracy: 0.5742\n",
            "Epoch 140/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.5776 - accuracy: 0.7615 - val_loss: 1.1854 - val_accuracy: 0.5262\n",
            "Epoch 141/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.5549 - accuracy: 0.7750 - val_loss: 1.1827 - val_accuracy: 0.5415\n",
            "Epoch 142/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.5364 - accuracy: 0.7834 - val_loss: 1.2359 - val_accuracy: 0.5568\n",
            "Epoch 143/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.5602 - accuracy: 0.7603 - val_loss: 1.2034 - val_accuracy: 0.5415\n",
            "Epoch 144/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.5489 - accuracy: 0.7804 - val_loss: 1.2311 - val_accuracy: 0.5590\n",
            "Epoch 145/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.5138 - accuracy: 0.7855 - val_loss: 1.2421 - val_accuracy: 0.5437\n",
            "Epoch 146/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.5366 - accuracy: 0.7833 - val_loss: 1.2395 - val_accuracy: 0.5568\n",
            "Epoch 147/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.5280 - accuracy: 0.7842 - val_loss: 1.2377 - val_accuracy: 0.5502\n",
            "Epoch 148/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.5033 - accuracy: 0.7939 - val_loss: 1.2440 - val_accuracy: 0.5590\n",
            "Epoch 149/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.5477 - accuracy: 0.7813 - val_loss: 1.2466 - val_accuracy: 0.5437\n",
            "Epoch 150/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.5347 - accuracy: 0.7769 - val_loss: 1.2985 - val_accuracy: 0.5459\n",
            "Epoch 151/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.5012 - accuracy: 0.8007 - val_loss: 1.2771 - val_accuracy: 0.5437\n",
            "Epoch 152/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.5254 - accuracy: 0.7973 - val_loss: 1.2404 - val_accuracy: 0.5786\n",
            "Epoch 153/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.4894 - accuracy: 0.7981 - val_loss: 1.2764 - val_accuracy: 0.5611\n",
            "Epoch 154/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.5097 - accuracy: 0.7928 - val_loss: 1.3395 - val_accuracy: 0.5480\n",
            "Epoch 155/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.4662 - accuracy: 0.8131 - val_loss: 1.3344 - val_accuracy: 0.5546\n",
            "Epoch 156/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.4833 - accuracy: 0.8079 - val_loss: 1.3532 - val_accuracy: 0.5437\n",
            "Epoch 157/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.4610 - accuracy: 0.8225 - val_loss: 1.3117 - val_accuracy: 0.5459\n",
            "Epoch 158/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.4393 - accuracy: 0.8314 - val_loss: 1.2809 - val_accuracy: 0.5611\n",
            "Epoch 159/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.4692 - accuracy: 0.8076 - val_loss: 1.3098 - val_accuracy: 0.5197\n",
            "Epoch 160/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.4948 - accuracy: 0.7940 - val_loss: 1.3247 - val_accuracy: 0.5415\n",
            "Epoch 161/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.4715 - accuracy: 0.8102 - val_loss: 1.3409 - val_accuracy: 0.5415\n",
            "Epoch 162/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.4591 - accuracy: 0.8209 - val_loss: 1.3869 - val_accuracy: 0.5437\n",
            "Epoch 163/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.4385 - accuracy: 0.8349 - val_loss: 1.3713 - val_accuracy: 0.5175\n",
            "Epoch 164/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.4329 - accuracy: 0.8249 - val_loss: 1.3216 - val_accuracy: 0.5655\n",
            "Epoch 165/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.4356 - accuracy: 0.8274 - val_loss: 1.3591 - val_accuracy: 0.5393\n",
            "Epoch 166/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.4350 - accuracy: 0.8282 - val_loss: 1.4374 - val_accuracy: 0.5240\n",
            "Epoch 167/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.4473 - accuracy: 0.8142 - val_loss: 1.4427 - val_accuracy: 0.5328\n",
            "Epoch 168/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.4345 - accuracy: 0.8208 - val_loss: 1.3952 - val_accuracy: 0.5349\n",
            "Epoch 169/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.4311 - accuracy: 0.8352 - val_loss: 1.4134 - val_accuracy: 0.5393\n",
            "Epoch 170/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.4522 - accuracy: 0.8245 - val_loss: 1.4743 - val_accuracy: 0.5546\n",
            "Epoch 171/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.4117 - accuracy: 0.8262 - val_loss: 1.4694 - val_accuracy: 0.5502\n",
            "Epoch 172/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.4223 - accuracy: 0.8318 - val_loss: 1.5329 - val_accuracy: 0.5371\n",
            "Epoch 173/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.4078 - accuracy: 0.8468 - val_loss: 1.4384 - val_accuracy: 0.5677\n",
            "Epoch 174/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.3875 - accuracy: 0.8529 - val_loss: 1.5486 - val_accuracy: 0.5393\n",
            "Epoch 175/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.4129 - accuracy: 0.8302 - val_loss: 1.4189 - val_accuracy: 0.5633\n",
            "Epoch 176/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.4084 - accuracy: 0.8307 - val_loss: 1.5028 - val_accuracy: 0.5437\n",
            "Epoch 177/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.4116 - accuracy: 0.8426 - val_loss: 1.5441 - val_accuracy: 0.5284\n",
            "Epoch 178/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.3937 - accuracy: 0.8450 - val_loss: 1.4624 - val_accuracy: 0.5590\n",
            "Epoch 179/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.3728 - accuracy: 0.8452 - val_loss: 1.6016 - val_accuracy: 0.5153\n",
            "Epoch 180/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.3947 - accuracy: 0.8431 - val_loss: 1.6144 - val_accuracy: 0.5349\n",
            "Epoch 181/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.4019 - accuracy: 0.8343 - val_loss: 1.6078 - val_accuracy: 0.5371\n",
            "Epoch 182/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.4001 - accuracy: 0.8394 - val_loss: 1.5207 - val_accuracy: 0.5633\n",
            "Epoch 183/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.3864 - accuracy: 0.8483 - val_loss: 1.5459 - val_accuracy: 0.5284\n",
            "Epoch 184/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.3605 - accuracy: 0.8632 - val_loss: 1.4973 - val_accuracy: 0.5459\n",
            "Epoch 185/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.3707 - accuracy: 0.8513 - val_loss: 1.5993 - val_accuracy: 0.5393\n",
            "Epoch 186/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.3383 - accuracy: 0.8685 - val_loss: 1.6512 - val_accuracy: 0.5415\n",
            "Epoch 187/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.3741 - accuracy: 0.8490 - val_loss: 1.5449 - val_accuracy: 0.5568\n",
            "Epoch 188/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.3546 - accuracy: 0.8565 - val_loss: 1.5326 - val_accuracy: 0.5371\n",
            "Epoch 189/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.3381 - accuracy: 0.8736 - val_loss: 1.6057 - val_accuracy: 0.5437\n",
            "Epoch 190/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.3785 - accuracy: 0.8508 - val_loss: 1.6544 - val_accuracy: 0.5328\n",
            "Epoch 191/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.3578 - accuracy: 0.8582 - val_loss: 1.6043 - val_accuracy: 0.5502\n",
            "Epoch 192/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.3277 - accuracy: 0.8696 - val_loss: 1.6201 - val_accuracy: 0.5524\n",
            "Epoch 193/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.3401 - accuracy: 0.8666 - val_loss: 1.6681 - val_accuracy: 0.5131\n",
            "Epoch 194/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.3255 - accuracy: 0.8716 - val_loss: 1.6208 - val_accuracy: 0.5524\n",
            "Epoch 195/200\n",
            "65/65 [==============================] - 0s 2ms/step - loss: 0.3298 - accuracy: 0.8659 - val_loss: 1.7160 - val_accuracy: 0.5349\n",
            "Epoch 196/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.3463 - accuracy: 0.8634 - val_loss: 1.7489 - val_accuracy: 0.5306\n",
            "Epoch 197/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.3103 - accuracy: 0.8787 - val_loss: 1.7659 - val_accuracy: 0.5197\n",
            "Epoch 198/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.3221 - accuracy: 0.8697 - val_loss: 1.7053 - val_accuracy: 0.5459\n",
            "Epoch 199/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.3168 - accuracy: 0.8775 - val_loss: 1.8193 - val_accuracy: 0.5218\n",
            "Epoch 200/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.3020 - accuracy: 0.8820 - val_loss: 1.7419 - val_accuracy: 0.5371\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbGqPW6PjVYg"
      },
      "source": [
        "model.save('/content/drive/MyDrive/Colab Notebooks/SPEECH_EMOTION_Recognition/Nộp bài(chốt hạ)/model_saver/basic_mfcc39_cremad.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WTeZEC0GjVYh"
      },
      "source": [
        "###test_result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-12T05:45:41.629805Z",
          "iopub.execute_input": "2021-06-12T05:45:41.630161Z",
          "iopub.status.idle": "2021-06-12T05:45:41.786756Z",
          "shell.execute_reply.started": "2021-06-12T05:45:41.630121Z",
          "shell.execute_reply": "2021-06-12T05:45:41.785499Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4OnrP0zQjVYi",
        "outputId": "736add26-1e60-4af3-eef0-6545611bb8c5"
      },
      "source": [
        "d = {0: 'happy',\n",
        "     1: 'sad',\n",
        "     2: 'angry',\n",
        "     3: 'fear'}\n",
        "Y_test_pred = np.argmax(model.predict(X_test), axis=-1)\n",
        "Y_test_pred = list(map(lambda x: d[x], Y_test_pred))\n",
        "y_test = np.argmax(y_test, axis=-1)\n",
        "y_test = list(map(lambda x: d[x], y_test))\n",
        "print(classification_report(y_test, Y_test_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.60      0.49      0.54       136\n",
            "        fear       0.50      0.49      0.49       134\n",
            "       happy       0.45      0.50      0.47       120\n",
            "         sad       0.65      0.73      0.69       119\n",
            "\n",
            "    accuracy                           0.55       509\n",
            "   macro avg       0.55      0.55      0.55       509\n",
            "weighted avg       0.55      0.55      0.55       509\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-12T05:45:47.991956Z",
          "iopub.execute_input": "2021-06-12T05:45:47.992400Z",
          "iopub.status.idle": "2021-06-12T05:45:48.358940Z",
          "shell.execute_reply.started": "2021-06-12T05:45:47.992353Z",
          "shell.execute_reply": "2021-06-12T05:45:48.357523Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 483
        },
        "id": "Ohht0FCPjVYk",
        "outputId": "32e413f3-7072-43af-a80e-c6f8c7ff8f51"
      },
      "source": [
        "import scikitplot as skplt\n",
        "\n",
        "skplt.metrics.plot_confusion_matrix(\n",
        "    y_test, \n",
        "    Y_test_pred,\n",
        "    figsize=(8,8))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f11a7376ed0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xhwzq874jVYm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DrgtYxBXziOW"
      },
      "source": [
        "# mfcc_13 + conv1D"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cohS6aj0zl1E"
      },
      "source": [
        "audio_duration = 3\n",
        "sampling_rate = 22050\n",
        "input_length = sampling_rate * audio_duration"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UjCgyCD50B3z"
      },
      "source": [
        "data = {'labels': [],\n",
        "        'features': []}\n",
        "\n",
        "for i in range(len(CREMA_D_df)):\n",
        "  if ((CREMA_D_df['Emotion'][i] == 'HAP') | (CREMA_D_df['Emotion'][i] == 'SAD') | \n",
        "      (CREMA_D_df['Emotion'][i] == 'ANG') | (CREMA_D_df['Emotion'][i] == 'FEA')):\n",
        "    \n",
        "    if CREMA_D_df['Emotion'][i] == 'HAP':\n",
        "      data['labels'].append(0)\n",
        "    elif CREMA_D_df['Emotion'][i] == 'SAD':\n",
        "      data['labels'].append(1)\n",
        "    elif CREMA_D_df['Emotion'][i] == 'ANG':\n",
        "      data['labels'].append(2)\n",
        "    elif CREMA_D_df['Emotion'][i] == 'FEA':\n",
        "      data['labels'].append(3)\n",
        "\n",
        "\n",
        "    signal, sr =  librosa.load(CREMA_D_df['Paths'][i])\n",
        "\n",
        "    if len(signal) > input_length:\n",
        "        signal = signal[0:input_length]\n",
        "    elif  input_length > len(signal):\n",
        "        max_offset = input_length - len(signal)  \n",
        "        signal = np.pad(signal, (0, max_offset), \"constant\")\n",
        "\n",
        "    mfcc = librosa.feature.mfcc(y=signal, sr=sr, n_mfcc=13).T\n",
        "    mfcc = mfcc.reshape(-1,1)\n",
        "    data['features'].append(mfcc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ybUZT_zg0B6o"
      },
      "source": [
        "X = data['features']\n",
        "y = data['labels']\n",
        "\n",
        "y = np.array(y)\n",
        "y = to_categorical(y)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=0)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=0)\n",
        "\n",
        "X_train = np.array(X_train)\n",
        "X_test = np.array(X_test)\n",
        "X_val = np.array(X_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8zTCz7d0B9r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d3ce513-43b7-48e2-c8f2-1ef6f279b9d9"
      },
      "source": [
        "X_train.shape,X_test.shape,y_train.shape,y_test.shape\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((4117, 1690, 1), (509, 1690, 1), (4117, 4), (509, 4))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p1nDyFxm0CAT"
      },
      "source": [
        "\n",
        "# CNN I/P Config\n",
        "num_classes = 4\n",
        "input_shape = X_train.shape[1:]\n",
        "learning_rate = 0.0001\n",
        "decay = 1e-6\n",
        "momentum = 0.9\n",
        "\n",
        "#LSTM Configuration\n",
        "num_lstm = 256"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3MYiyLaG0CDN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b6be8d2-954b-4174-e73a-0ae121370a88"
      },
      "source": [
        "model = Sequential(name='Audio_CNN_1D')\n",
        "\n",
        "# LFLB1\n",
        "model.add(Conv1D(filters=64, kernel_size=(3), strides=1, padding='same', data_format='channels_last',input_shape=input_shape))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('elu'))\n",
        "model.add(MaxPooling1D(pool_size=4, strides=4))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "# LFLB2\n",
        "model.add(Conv1D(filters=64, kernel_size=3, strides=1, padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('elu'))\n",
        "model.add(MaxPooling1D(pool_size=4, strides=4))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# LFLB3\n",
        "model.add(Conv1D(filters=128, kernel_size=3, strides=1, padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('elu'))\n",
        "model.add(MaxPooling1D(pool_size=4, strides=4))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# LFLB4\n",
        "model.add(Conv1D(filters=128, kernel_size=3, strides=1, padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('elu'))\n",
        "model.add(MaxPooling1D(pool_size=4, strides=4))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# LSTM\n",
        "model.add(LSTM(units=num_lstm))\n",
        "\n",
        "# FC\n",
        "model.add(Dense(units=num_classes, activation='softmax'))\n",
        "\n",
        "# Model compilation\n",
        "opt= keras.optimizers.Adam(lr=0.01, beta_1=0.9,  beta_2=0.999, amsgrad=False)\n",
        "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
        "\n",
        "model.summary()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"Audio_CNN_1D\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 1690, 64)          256       \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 1690, 64)          256       \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 1690, 64)          0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D) (None, 422, 64)           0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 422, 64)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 422, 64)           12352     \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 422, 64)           256       \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 422, 64)           0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1 (None, 105, 64)           0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 105, 64)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 105, 128)          24704     \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 105, 128)          512       \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 105, 128)          0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_2 (MaxPooling1 (None, 26, 128)           0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 26, 128)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 26, 128)           49280     \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 26, 128)           512       \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 26, 128)           0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_3 (MaxPooling1 (None, 6, 128)            0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 6, 128)            0         \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 256)               394240    \n",
            "_________________________________________________________________\n",
            "dense_20 (Dense)             (None, 4)                 1028      \n",
            "=================================================================\n",
            "Total params: 483,396\n",
            "Trainable params: 482,628\n",
            "Non-trainable params: 768\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4gFeaJMR0CFu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e1b85bc-b437-4d44-b14b-f942478d6de5"
      },
      "source": [
        "#Train Config\n",
        "\n",
        "batch_size = 16\n",
        "num_epochs = 200\n",
        "\n",
        "# Model Training\n",
        "lr_reduce = ReduceLROnPlateau(monitor='val_loss', factor=0.9, patience=20, min_lr=0.000001)\n",
        "# Please change the model name accordingly.\n",
        "mcp_save = ModelCheckpoint('/content/Audio_1DCNN.h5', save_best_only=True, monitor='val_categorical_accuracy', mode='max')\n",
        "cnnhistory=model.fit(X_train, y_train, batch_size=batch_size, epochs=num_epochs,validation_data=(X_val, y_val), callbacks=[mcp_save, lr_reduce])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "258/258 [==============================] - 45s 130ms/step - loss: 1.3101 - categorical_accuracy: 0.4457 - val_loss: 1.6579 - val_categorical_accuracy: 0.3166\n",
            "Epoch 2/200\n",
            "258/258 [==============================] - 33s 128ms/step - loss: 1.0522 - categorical_accuracy: 0.5384 - val_loss: 1.2154 - val_categorical_accuracy: 0.4651\n",
            "Epoch 3/200\n",
            "258/258 [==============================] - 32s 124ms/step - loss: 1.0399 - categorical_accuracy: 0.5320 - val_loss: 1.0990 - val_categorical_accuracy: 0.4978\n",
            "Epoch 4/200\n",
            "258/258 [==============================] - 32s 124ms/step - loss: 1.0665 - categorical_accuracy: 0.5056 - val_loss: 1.0735 - val_categorical_accuracy: 0.4869\n",
            "Epoch 5/200\n",
            "258/258 [==============================] - 32s 124ms/step - loss: 1.0780 - categorical_accuracy: 0.5106 - val_loss: 1.3035 - val_categorical_accuracy: 0.4585\n",
            "Epoch 6/200\n",
            "258/258 [==============================] - 32s 125ms/step - loss: 1.0684 - categorical_accuracy: 0.5191 - val_loss: 1.2374 - val_categorical_accuracy: 0.4432\n",
            "Epoch 7/200\n",
            "258/258 [==============================] - 32s 125ms/step - loss: 1.0604 - categorical_accuracy: 0.5161 - val_loss: 1.2849 - val_categorical_accuracy: 0.5000\n",
            "Epoch 8/200\n",
            "258/258 [==============================] - 32s 126ms/step - loss: 1.0303 - categorical_accuracy: 0.5414 - val_loss: 1.0668 - val_categorical_accuracy: 0.5066\n",
            "Epoch 9/200\n",
            "258/258 [==============================] - 33s 126ms/step - loss: 1.0172 - categorical_accuracy: 0.5497 - val_loss: 1.2131 - val_categorical_accuracy: 0.4651\n",
            "Epoch 10/200\n",
            "258/258 [==============================] - 32s 124ms/step - loss: 1.0237 - categorical_accuracy: 0.5333 - val_loss: 1.0817 - val_categorical_accuracy: 0.5284\n",
            "Epoch 11/200\n",
            "258/258 [==============================] - 32s 124ms/step - loss: 0.9999 - categorical_accuracy: 0.5633 - val_loss: 1.0994 - val_categorical_accuracy: 0.4913\n",
            "Epoch 12/200\n",
            "258/258 [==============================] - 32s 124ms/step - loss: 1.0248 - categorical_accuracy: 0.5438 - val_loss: 1.1674 - val_categorical_accuracy: 0.4803\n",
            "Epoch 13/200\n",
            "258/258 [==============================] - 32s 123ms/step - loss: 1.0489 - categorical_accuracy: 0.5214 - val_loss: 1.1266 - val_categorical_accuracy: 0.4803\n",
            "Epoch 14/200\n",
            "258/258 [==============================] - 32s 125ms/step - loss: 1.0351 - categorical_accuracy: 0.5388 - val_loss: 1.0546 - val_categorical_accuracy: 0.5262\n",
            "Epoch 15/200\n",
            "258/258 [==============================] - 32s 126ms/step - loss: 1.0257 - categorical_accuracy: 0.5403 - val_loss: 1.0860 - val_categorical_accuracy: 0.5109\n",
            "Epoch 16/200\n",
            "258/258 [==============================] - 33s 126ms/step - loss: 1.0186 - categorical_accuracy: 0.5389 - val_loss: 1.1061 - val_categorical_accuracy: 0.5044\n",
            "Epoch 17/200\n",
            "258/258 [==============================] - 33s 128ms/step - loss: 0.9988 - categorical_accuracy: 0.5485 - val_loss: 1.0846 - val_categorical_accuracy: 0.5044\n",
            "Epoch 18/200\n",
            "258/258 [==============================] - 33s 128ms/step - loss: 1.0270 - categorical_accuracy: 0.5405 - val_loss: 1.1901 - val_categorical_accuracy: 0.4913\n",
            "Epoch 19/200\n",
            "258/258 [==============================] - 33s 128ms/step - loss: 1.0258 - categorical_accuracy: 0.5294 - val_loss: 1.0780 - val_categorical_accuracy: 0.5175\n",
            "Epoch 20/200\n",
            "258/258 [==============================] - 33s 130ms/step - loss: 1.0244 - categorical_accuracy: 0.5288 - val_loss: 1.1753 - val_categorical_accuracy: 0.4869\n",
            "Epoch 21/200\n",
            "258/258 [==============================] - 33s 130ms/step - loss: 1.0295 - categorical_accuracy: 0.5316 - val_loss: 1.0427 - val_categorical_accuracy: 0.5153\n",
            "Epoch 22/200\n",
            "258/258 [==============================] - 34s 130ms/step - loss: 1.0121 - categorical_accuracy: 0.5458 - val_loss: 1.1898 - val_categorical_accuracy: 0.4651\n",
            "Epoch 23/200\n",
            "258/258 [==============================] - 34s 130ms/step - loss: 1.0013 - categorical_accuracy: 0.5526 - val_loss: 1.1579 - val_categorical_accuracy: 0.5000\n",
            "Epoch 24/200\n",
            "258/258 [==============================] - 33s 127ms/step - loss: 1.0031 - categorical_accuracy: 0.5524 - val_loss: 1.1025 - val_categorical_accuracy: 0.4825\n",
            "Epoch 25/200\n",
            "258/258 [==============================] - 33s 128ms/step - loss: 1.0279 - categorical_accuracy: 0.5223 - val_loss: 1.1543 - val_categorical_accuracy: 0.4869\n",
            "Epoch 26/200\n",
            "258/258 [==============================] - 34s 134ms/step - loss: 1.0086 - categorical_accuracy: 0.5444 - val_loss: 1.1272 - val_categorical_accuracy: 0.4891\n",
            "Epoch 27/200\n",
            "258/258 [==============================] - 34s 130ms/step - loss: 0.9908 - categorical_accuracy: 0.5647 - val_loss: 1.1358 - val_categorical_accuracy: 0.4738\n",
            "Epoch 28/200\n",
            "258/258 [==============================] - 33s 128ms/step - loss: 1.0176 - categorical_accuracy: 0.5551 - val_loss: 1.0520 - val_categorical_accuracy: 0.5262\n",
            "Epoch 29/200\n",
            "258/258 [==============================] - 33s 129ms/step - loss: 0.9954 - categorical_accuracy: 0.5611 - val_loss: 1.0827 - val_categorical_accuracy: 0.5087\n",
            "Epoch 30/200\n",
            "258/258 [==============================] - 33s 129ms/step - loss: 1.0362 - categorical_accuracy: 0.5310 - val_loss: 1.0646 - val_categorical_accuracy: 0.5131\n",
            "Epoch 31/200\n",
            "258/258 [==============================] - 33s 128ms/step - loss: 1.0012 - categorical_accuracy: 0.5498 - val_loss: 1.1132 - val_categorical_accuracy: 0.5153\n",
            "Epoch 32/200\n",
            "258/258 [==============================] - 34s 130ms/step - loss: 1.0089 - categorical_accuracy: 0.5457 - val_loss: 1.0816 - val_categorical_accuracy: 0.5349\n",
            "Epoch 33/200\n",
            "258/258 [==============================] - 33s 130ms/step - loss: 1.0017 - categorical_accuracy: 0.5560 - val_loss: 1.0938 - val_categorical_accuracy: 0.5087\n",
            "Epoch 34/200\n",
            "258/258 [==============================] - 33s 129ms/step - loss: 1.0398 - categorical_accuracy: 0.5285 - val_loss: 1.0686 - val_categorical_accuracy: 0.5349\n",
            "Epoch 35/200\n",
            "258/258 [==============================] - 34s 130ms/step - loss: 0.9959 - categorical_accuracy: 0.5316 - val_loss: 1.0872 - val_categorical_accuracy: 0.4563\n",
            "Epoch 36/200\n",
            "258/258 [==============================] - 34s 132ms/step - loss: 1.0213 - categorical_accuracy: 0.5400 - val_loss: 1.0912 - val_categorical_accuracy: 0.5197\n",
            "Epoch 37/200\n",
            "258/258 [==============================] - 34s 131ms/step - loss: 1.0103 - categorical_accuracy: 0.5480 - val_loss: 1.1299 - val_categorical_accuracy: 0.4585\n",
            "Epoch 38/200\n",
            "258/258 [==============================] - 34s 130ms/step - loss: 1.0131 - categorical_accuracy: 0.5357 - val_loss: 1.2243 - val_categorical_accuracy: 0.4782\n",
            "Epoch 39/200\n",
            "258/258 [==============================] - 34s 132ms/step - loss: 1.0097 - categorical_accuracy: 0.5400 - val_loss: 1.0898 - val_categorical_accuracy: 0.5284\n",
            "Epoch 40/200\n",
            "258/258 [==============================] - 33s 129ms/step - loss: 1.0015 - categorical_accuracy: 0.5614 - val_loss: 1.1485 - val_categorical_accuracy: 0.5022\n",
            "Epoch 41/200\n",
            "258/258 [==============================] - 34s 132ms/step - loss: 1.0110 - categorical_accuracy: 0.5484 - val_loss: 1.0551 - val_categorical_accuracy: 0.5066\n",
            "Epoch 42/200\n",
            "258/258 [==============================] - 33s 130ms/step - loss: 0.9957 - categorical_accuracy: 0.5650 - val_loss: 1.0271 - val_categorical_accuracy: 0.5153\n",
            "Epoch 43/200\n",
            "258/258 [==============================] - 34s 130ms/step - loss: 1.0018 - categorical_accuracy: 0.5709 - val_loss: 1.0798 - val_categorical_accuracy: 0.5000\n",
            "Epoch 44/200\n",
            "258/258 [==============================] - 34s 133ms/step - loss: 1.0098 - categorical_accuracy: 0.5641 - val_loss: 1.0540 - val_categorical_accuracy: 0.4934\n",
            "Epoch 45/200\n",
            "258/258 [==============================] - 34s 132ms/step - loss: 1.0008 - categorical_accuracy: 0.5561 - val_loss: 1.0995 - val_categorical_accuracy: 0.5109\n",
            "Epoch 46/200\n",
            "258/258 [==============================] - 34s 133ms/step - loss: 0.9983 - categorical_accuracy: 0.5413 - val_loss: 1.0512 - val_categorical_accuracy: 0.5240\n",
            "Epoch 47/200\n",
            "258/258 [==============================] - 34s 130ms/step - loss: 0.9704 - categorical_accuracy: 0.5715 - val_loss: 1.1657 - val_categorical_accuracy: 0.4716\n",
            "Epoch 48/200\n",
            "258/258 [==============================] - 33s 129ms/step - loss: 0.9979 - categorical_accuracy: 0.5499 - val_loss: 1.0824 - val_categorical_accuracy: 0.5022\n",
            "Epoch 49/200\n",
            "258/258 [==============================] - 34s 131ms/step - loss: 0.9996 - categorical_accuracy: 0.5474 - val_loss: 1.1049 - val_categorical_accuracy: 0.4694\n",
            "Epoch 50/200\n",
            "258/258 [==============================] - 34s 132ms/step - loss: 0.9880 - categorical_accuracy: 0.5706 - val_loss: 1.1827 - val_categorical_accuracy: 0.4651\n",
            "Epoch 51/200\n",
            "258/258 [==============================] - 33s 129ms/step - loss: 0.9697 - categorical_accuracy: 0.5620 - val_loss: 1.0658 - val_categorical_accuracy: 0.5524\n",
            "Epoch 52/200\n",
            "258/258 [==============================] - 33s 128ms/step - loss: 0.9875 - categorical_accuracy: 0.5620 - val_loss: 1.0765 - val_categorical_accuracy: 0.4934\n",
            "Epoch 53/200\n",
            "258/258 [==============================] - 34s 130ms/step - loss: 0.9890 - categorical_accuracy: 0.5537 - val_loss: 1.0377 - val_categorical_accuracy: 0.5109\n",
            "Epoch 54/200\n",
            "258/258 [==============================] - 34s 130ms/step - loss: 0.9705 - categorical_accuracy: 0.5584 - val_loss: 1.0830 - val_categorical_accuracy: 0.4978\n",
            "Epoch 55/200\n",
            "258/258 [==============================] - 34s 130ms/step - loss: 0.9844 - categorical_accuracy: 0.5613 - val_loss: 1.0679 - val_categorical_accuracy: 0.4956\n",
            "Epoch 56/200\n",
            "258/258 [==============================] - 34s 131ms/step - loss: 0.9750 - categorical_accuracy: 0.5617 - val_loss: 1.0537 - val_categorical_accuracy: 0.5087\n",
            "Epoch 57/200\n",
            "258/258 [==============================] - 34s 131ms/step - loss: 0.9777 - categorical_accuracy: 0.5575 - val_loss: 1.0767 - val_categorical_accuracy: 0.4956\n",
            "Epoch 58/200\n",
            "258/258 [==============================] - 33s 128ms/step - loss: 0.9734 - categorical_accuracy: 0.5617 - val_loss: 1.0315 - val_categorical_accuracy: 0.5480\n",
            "Epoch 59/200\n",
            "258/258 [==============================] - 33s 128ms/step - loss: 0.9935 - categorical_accuracy: 0.5581 - val_loss: 1.0247 - val_categorical_accuracy: 0.5502\n",
            "Epoch 60/200\n",
            "258/258 [==============================] - 33s 127ms/step - loss: 0.9750 - categorical_accuracy: 0.5764 - val_loss: 1.2011 - val_categorical_accuracy: 0.4694\n",
            "Epoch 61/200\n",
            "258/258 [==============================] - 33s 126ms/step - loss: 0.9621 - categorical_accuracy: 0.5797 - val_loss: 1.0556 - val_categorical_accuracy: 0.5022\n",
            "Epoch 62/200\n",
            "258/258 [==============================] - 33s 129ms/step - loss: 0.9795 - categorical_accuracy: 0.5568 - val_loss: 1.0637 - val_categorical_accuracy: 0.5240\n",
            "Epoch 63/200\n",
            "258/258 [==============================] - 33s 129ms/step - loss: 0.9941 - categorical_accuracy: 0.5587 - val_loss: 1.0782 - val_categorical_accuracy: 0.4978\n",
            "Epoch 64/200\n",
            "258/258 [==============================] - 34s 133ms/step - loss: 0.9599 - categorical_accuracy: 0.5745 - val_loss: 1.0556 - val_categorical_accuracy: 0.4978\n",
            "Epoch 65/200\n",
            "258/258 [==============================] - 34s 133ms/step - loss: 0.9840 - categorical_accuracy: 0.5603 - val_loss: 1.0649 - val_categorical_accuracy: 0.5415\n",
            "Epoch 66/200\n",
            "258/258 [==============================] - 34s 132ms/step - loss: 0.9949 - categorical_accuracy: 0.5629 - val_loss: 1.0513 - val_categorical_accuracy: 0.5153\n",
            "Epoch 67/200\n",
            "258/258 [==============================] - 34s 134ms/step - loss: 0.9827 - categorical_accuracy: 0.5469 - val_loss: 1.0879 - val_categorical_accuracy: 0.5000\n",
            "Epoch 68/200\n",
            "258/258 [==============================] - 34s 131ms/step - loss: 0.9638 - categorical_accuracy: 0.5715 - val_loss: 1.1974 - val_categorical_accuracy: 0.4279\n",
            "Epoch 69/200\n",
            "258/258 [==============================] - 33s 130ms/step - loss: 0.9708 - categorical_accuracy: 0.5551 - val_loss: 1.1766 - val_categorical_accuracy: 0.4782\n",
            "Epoch 70/200\n",
            "258/258 [==============================] - 35s 134ms/step - loss: 0.9758 - categorical_accuracy: 0.5687 - val_loss: 1.0776 - val_categorical_accuracy: 0.5306\n",
            "Epoch 71/200\n",
            "258/258 [==============================] - 34s 132ms/step - loss: 0.9825 - categorical_accuracy: 0.5757 - val_loss: 1.1873 - val_categorical_accuracy: 0.4672\n",
            "Epoch 72/200\n",
            "258/258 [==============================] - 34s 130ms/step - loss: 0.9794 - categorical_accuracy: 0.5689 - val_loss: 1.0158 - val_categorical_accuracy: 0.5284\n",
            "Epoch 73/200\n",
            "258/258 [==============================] - 33s 130ms/step - loss: 0.9789 - categorical_accuracy: 0.5589 - val_loss: 1.1238 - val_categorical_accuracy: 0.4410\n",
            "Epoch 74/200\n",
            "258/258 [==============================] - 33s 129ms/step - loss: 0.9792 - categorical_accuracy: 0.5614 - val_loss: 1.0552 - val_categorical_accuracy: 0.5349\n",
            "Epoch 75/200\n",
            "258/258 [==============================] - 33s 130ms/step - loss: 0.9417 - categorical_accuracy: 0.5903 - val_loss: 1.1369 - val_categorical_accuracy: 0.4432\n",
            "Epoch 76/200\n",
            "258/258 [==============================] - 35s 135ms/step - loss: 0.9412 - categorical_accuracy: 0.5762 - val_loss: 1.0935 - val_categorical_accuracy: 0.5087\n",
            "Epoch 77/200\n",
            "258/258 [==============================] - 35s 135ms/step - loss: 0.9670 - categorical_accuracy: 0.5773 - val_loss: 1.0478 - val_categorical_accuracy: 0.5131\n",
            "Epoch 78/200\n",
            "258/258 [==============================] - 34s 133ms/step - loss: 0.9803 - categorical_accuracy: 0.5639 - val_loss: 1.0186 - val_categorical_accuracy: 0.5502\n",
            "Epoch 79/200\n",
            "258/258 [==============================] - 34s 131ms/step - loss: 0.9798 - categorical_accuracy: 0.5712 - val_loss: 1.0598 - val_categorical_accuracy: 0.5437\n",
            "Epoch 80/200\n",
            "258/258 [==============================] - 34s 133ms/step - loss: 0.9362 - categorical_accuracy: 0.5913 - val_loss: 1.0036 - val_categorical_accuracy: 0.5568\n",
            "Epoch 81/200\n",
            "258/258 [==============================] - 33s 128ms/step - loss: 0.9835 - categorical_accuracy: 0.5718 - val_loss: 1.1156 - val_categorical_accuracy: 0.4869\n",
            "Epoch 82/200\n",
            "258/258 [==============================] - 34s 131ms/step - loss: 0.9813 - categorical_accuracy: 0.5675 - val_loss: 1.1003 - val_categorical_accuracy: 0.5087\n",
            "Epoch 83/200\n",
            "258/258 [==============================] - 34s 131ms/step - loss: 0.9653 - categorical_accuracy: 0.5653 - val_loss: 1.0929 - val_categorical_accuracy: 0.5175\n",
            "Epoch 84/200\n",
            "258/258 [==============================] - 33s 127ms/step - loss: 0.9571 - categorical_accuracy: 0.5694 - val_loss: 1.0175 - val_categorical_accuracy: 0.5546\n",
            "Epoch 85/200\n",
            "258/258 [==============================] - 33s 128ms/step - loss: 0.9637 - categorical_accuracy: 0.5789 - val_loss: 1.0433 - val_categorical_accuracy: 0.5197\n",
            "Epoch 86/200\n",
            "258/258 [==============================] - 33s 130ms/step - loss: 0.9505 - categorical_accuracy: 0.5713 - val_loss: 1.0110 - val_categorical_accuracy: 0.5546\n",
            "Epoch 87/200\n",
            "258/258 [==============================] - 33s 127ms/step - loss: 0.9767 - categorical_accuracy: 0.5697 - val_loss: 1.0562 - val_categorical_accuracy: 0.5197\n",
            "Epoch 88/200\n",
            "258/258 [==============================] - 33s 127ms/step - loss: 0.9635 - categorical_accuracy: 0.5765 - val_loss: 1.0893 - val_categorical_accuracy: 0.4978\n",
            "Epoch 89/200\n",
            "258/258 [==============================] - 33s 128ms/step - loss: 0.9478 - categorical_accuracy: 0.5765 - val_loss: 1.0497 - val_categorical_accuracy: 0.5131\n",
            "Epoch 90/200\n",
            "258/258 [==============================] - 33s 128ms/step - loss: 0.9805 - categorical_accuracy: 0.5721 - val_loss: 1.1503 - val_categorical_accuracy: 0.4782\n",
            "Epoch 91/200\n",
            "258/258 [==============================] - 34s 132ms/step - loss: 0.9564 - categorical_accuracy: 0.5688 - val_loss: 0.9956 - val_categorical_accuracy: 0.5371\n",
            "Epoch 92/200\n",
            "258/258 [==============================] - 33s 129ms/step - loss: 0.9483 - categorical_accuracy: 0.5655 - val_loss: 1.0270 - val_categorical_accuracy: 0.5131\n",
            "Epoch 93/200\n",
            "258/258 [==============================] - 33s 129ms/step - loss: 0.9416 - categorical_accuracy: 0.5885 - val_loss: 1.0526 - val_categorical_accuracy: 0.4760\n",
            "Epoch 94/200\n",
            "258/258 [==============================] - 34s 133ms/step - loss: 0.9636 - categorical_accuracy: 0.5752 - val_loss: 1.0422 - val_categorical_accuracy: 0.5349\n",
            "Epoch 95/200\n",
            "258/258 [==============================] - 34s 134ms/step - loss: 0.9385 - categorical_accuracy: 0.5718 - val_loss: 0.9930 - val_categorical_accuracy: 0.5633\n",
            "Epoch 96/200\n",
            "258/258 [==============================] - 34s 133ms/step - loss: 0.9605 - categorical_accuracy: 0.5695 - val_loss: 1.0106 - val_categorical_accuracy: 0.5480\n",
            "Epoch 97/200\n",
            "258/258 [==============================] - 34s 133ms/step - loss: 0.9616 - categorical_accuracy: 0.5641 - val_loss: 1.0841 - val_categorical_accuracy: 0.4782\n",
            "Epoch 98/200\n",
            "258/258 [==============================] - 34s 133ms/step - loss: 0.9804 - categorical_accuracy: 0.5636 - val_loss: 1.0793 - val_categorical_accuracy: 0.5262\n",
            "Epoch 99/200\n",
            "258/258 [==============================] - 34s 133ms/step - loss: 0.9874 - categorical_accuracy: 0.5588 - val_loss: 1.0373 - val_categorical_accuracy: 0.5349\n",
            "Epoch 100/200\n",
            "258/258 [==============================] - 34s 133ms/step - loss: 0.9860 - categorical_accuracy: 0.5462 - val_loss: 1.0230 - val_categorical_accuracy: 0.5371\n",
            "Epoch 101/200\n",
            "258/258 [==============================] - 33s 128ms/step - loss: 0.9845 - categorical_accuracy: 0.5757 - val_loss: 1.0767 - val_categorical_accuracy: 0.5197\n",
            "Epoch 102/200\n",
            "258/258 [==============================] - 34s 132ms/step - loss: 0.9694 - categorical_accuracy: 0.5626 - val_loss: 1.1170 - val_categorical_accuracy: 0.5131\n",
            "Epoch 103/200\n",
            "258/258 [==============================] - 34s 132ms/step - loss: 0.9679 - categorical_accuracy: 0.5744 - val_loss: 1.0742 - val_categorical_accuracy: 0.5153\n",
            "Epoch 104/200\n",
            "258/258 [==============================] - 35s 134ms/step - loss: 0.9691 - categorical_accuracy: 0.5799 - val_loss: 1.0003 - val_categorical_accuracy: 0.5502\n",
            "Epoch 105/200\n",
            "258/258 [==============================] - 34s 133ms/step - loss: 0.9737 - categorical_accuracy: 0.5598 - val_loss: 1.0745 - val_categorical_accuracy: 0.4847\n",
            "Epoch 106/200\n",
            "258/258 [==============================] - 34s 133ms/step - loss: 0.9464 - categorical_accuracy: 0.5886 - val_loss: 1.0269 - val_categorical_accuracy: 0.5284\n",
            "Epoch 107/200\n",
            "258/258 [==============================] - 34s 133ms/step - loss: 0.9589 - categorical_accuracy: 0.5744 - val_loss: 1.0830 - val_categorical_accuracy: 0.4978\n",
            "Epoch 108/200\n",
            "258/258 [==============================] - 35s 134ms/step - loss: 0.9647 - categorical_accuracy: 0.5603 - val_loss: 1.0406 - val_categorical_accuracy: 0.5175\n",
            "Epoch 109/200\n",
            "258/258 [==============================] - 35s 135ms/step - loss: 0.9701 - categorical_accuracy: 0.5652 - val_loss: 1.0366 - val_categorical_accuracy: 0.5197\n",
            "Epoch 110/200\n",
            "258/258 [==============================] - 34s 132ms/step - loss: 0.9715 - categorical_accuracy: 0.5658 - val_loss: 1.1127 - val_categorical_accuracy: 0.4913\n",
            "Epoch 111/200\n",
            "258/258 [==============================] - 34s 130ms/step - loss: 0.9430 - categorical_accuracy: 0.5911 - val_loss: 1.0525 - val_categorical_accuracy: 0.4847\n",
            "Epoch 112/200\n",
            "258/258 [==============================] - 34s 130ms/step - loss: 0.9470 - categorical_accuracy: 0.5749 - val_loss: 1.0620 - val_categorical_accuracy: 0.4869\n",
            "Epoch 113/200\n",
            "258/258 [==============================] - 34s 132ms/step - loss: 0.9619 - categorical_accuracy: 0.5688 - val_loss: 1.0958 - val_categorical_accuracy: 0.5175\n",
            "Epoch 114/200\n",
            "258/258 [==============================] - 34s 133ms/step - loss: 0.9586 - categorical_accuracy: 0.5630 - val_loss: 1.0220 - val_categorical_accuracy: 0.5262\n",
            "Epoch 115/200\n",
            "258/258 [==============================] - 34s 131ms/step - loss: 0.9748 - categorical_accuracy: 0.5628 - val_loss: 1.0199 - val_categorical_accuracy: 0.5328\n",
            "Epoch 116/200\n",
            "258/258 [==============================] - 34s 132ms/step - loss: 0.9467 - categorical_accuracy: 0.5675 - val_loss: 1.0060 - val_categorical_accuracy: 0.5502\n",
            "Epoch 117/200\n",
            "258/258 [==============================] - 34s 133ms/step - loss: 0.9229 - categorical_accuracy: 0.5837 - val_loss: 1.0861 - val_categorical_accuracy: 0.5022\n",
            "Epoch 118/200\n",
            "258/258 [==============================] - 34s 134ms/step - loss: 0.9199 - categorical_accuracy: 0.5875 - val_loss: 0.9814 - val_categorical_accuracy: 0.5764\n",
            "Epoch 119/200\n",
            "258/258 [==============================] - 34s 132ms/step - loss: 0.9403 - categorical_accuracy: 0.5900 - val_loss: 1.0971 - val_categorical_accuracy: 0.5109\n",
            "Epoch 120/200\n",
            "258/258 [==============================] - 34s 131ms/step - loss: 0.9352 - categorical_accuracy: 0.5881 - val_loss: 1.1056 - val_categorical_accuracy: 0.4803\n",
            "Epoch 121/200\n",
            "258/258 [==============================] - 34s 133ms/step - loss: 0.9274 - categorical_accuracy: 0.5928 - val_loss: 1.0770 - val_categorical_accuracy: 0.5087\n",
            "Epoch 122/200\n",
            "258/258 [==============================] - 35s 134ms/step - loss: 0.9416 - categorical_accuracy: 0.5808 - val_loss: 1.0408 - val_categorical_accuracy: 0.5066\n",
            "Epoch 123/200\n",
            "258/258 [==============================] - 34s 132ms/step - loss: 0.9461 - categorical_accuracy: 0.5695 - val_loss: 1.0291 - val_categorical_accuracy: 0.5306\n",
            "Epoch 124/200\n",
            "258/258 [==============================] - 35s 134ms/step - loss: 0.9368 - categorical_accuracy: 0.5794 - val_loss: 1.0168 - val_categorical_accuracy: 0.5393\n",
            "Epoch 125/200\n",
            "258/258 [==============================] - 35s 134ms/step - loss: 0.9358 - categorical_accuracy: 0.5912 - val_loss: 1.1806 - val_categorical_accuracy: 0.4476\n",
            "Epoch 126/200\n",
            "258/258 [==============================] - 34s 133ms/step - loss: 0.9467 - categorical_accuracy: 0.5824 - val_loss: 1.0280 - val_categorical_accuracy: 0.5218\n",
            "Epoch 127/200\n",
            "258/258 [==============================] - 35s 134ms/step - loss: 0.9470 - categorical_accuracy: 0.5823 - val_loss: 1.0082 - val_categorical_accuracy: 0.5590\n",
            "Epoch 128/200\n",
            "258/258 [==============================] - 35s 135ms/step - loss: 0.9392 - categorical_accuracy: 0.5896 - val_loss: 1.0776 - val_categorical_accuracy: 0.5153\n",
            "Epoch 129/200\n",
            "258/258 [==============================] - 34s 134ms/step - loss: 0.9372 - categorical_accuracy: 0.5821 - val_loss: 1.0052 - val_categorical_accuracy: 0.5524\n",
            "Epoch 130/200\n",
            "258/258 [==============================] - 34s 134ms/step - loss: 0.9396 - categorical_accuracy: 0.5852 - val_loss: 1.0221 - val_categorical_accuracy: 0.5240\n",
            "Epoch 131/200\n",
            "258/258 [==============================] - 35s 134ms/step - loss: 0.9231 - categorical_accuracy: 0.5802 - val_loss: 0.9527 - val_categorical_accuracy: 0.5808\n",
            "Epoch 132/200\n",
            "258/258 [==============================] - 34s 133ms/step - loss: 0.9266 - categorical_accuracy: 0.5988 - val_loss: 1.0338 - val_categorical_accuracy: 0.5349\n",
            "Epoch 133/200\n",
            "258/258 [==============================] - 35s 134ms/step - loss: 0.9325 - categorical_accuracy: 0.5915 - val_loss: 1.0108 - val_categorical_accuracy: 0.5087\n",
            "Epoch 134/200\n",
            "258/258 [==============================] - 34s 133ms/step - loss: 0.9025 - categorical_accuracy: 0.5890 - val_loss: 1.0116 - val_categorical_accuracy: 0.5109\n",
            "Epoch 135/200\n",
            "258/258 [==============================] - 34s 132ms/step - loss: 0.9406 - categorical_accuracy: 0.5675 - val_loss: 1.0021 - val_categorical_accuracy: 0.5502\n",
            "Epoch 136/200\n",
            "258/258 [==============================] - 34s 133ms/step - loss: 0.9466 - categorical_accuracy: 0.5903 - val_loss: 0.9748 - val_categorical_accuracy: 0.5393\n",
            "Epoch 137/200\n",
            "258/258 [==============================] - 34s 131ms/step - loss: 0.9372 - categorical_accuracy: 0.5819 - val_loss: 1.0394 - val_categorical_accuracy: 0.5328\n",
            "Epoch 138/200\n",
            "258/258 [==============================] - 33s 129ms/step - loss: 0.9578 - categorical_accuracy: 0.5818 - val_loss: 1.0723 - val_categorical_accuracy: 0.5197\n",
            "Epoch 139/200\n",
            "258/258 [==============================] - 33s 129ms/step - loss: 0.9572 - categorical_accuracy: 0.5834 - val_loss: 1.0623 - val_categorical_accuracy: 0.5109\n",
            "Epoch 140/200\n",
            "258/258 [==============================] - 33s 127ms/step - loss: 0.9411 - categorical_accuracy: 0.5826 - val_loss: 1.1952 - val_categorical_accuracy: 0.4410\n",
            "Epoch 141/200\n",
            "258/258 [==============================] - 33s 127ms/step - loss: 0.9219 - categorical_accuracy: 0.5981 - val_loss: 1.0683 - val_categorical_accuracy: 0.5131\n",
            "Epoch 142/200\n",
            "258/258 [==============================] - 33s 129ms/step - loss: 0.9337 - categorical_accuracy: 0.5854 - val_loss: 0.9875 - val_categorical_accuracy: 0.5437\n",
            "Epoch 143/200\n",
            "258/258 [==============================] - 34s 131ms/step - loss: 0.9459 - categorical_accuracy: 0.5904 - val_loss: 1.0711 - val_categorical_accuracy: 0.4913\n",
            "Epoch 144/200\n",
            "258/258 [==============================] - 33s 129ms/step - loss: 0.9456 - categorical_accuracy: 0.5914 - val_loss: 1.1182 - val_categorical_accuracy: 0.4782\n",
            "Epoch 145/200\n",
            "258/258 [==============================] - 33s 128ms/step - loss: 0.9225 - categorical_accuracy: 0.5934 - val_loss: 1.0173 - val_categorical_accuracy: 0.5109\n",
            "Epoch 146/200\n",
            "258/258 [==============================] - 33s 127ms/step - loss: 0.9505 - categorical_accuracy: 0.5750 - val_loss: 1.0277 - val_categorical_accuracy: 0.5437\n",
            "Epoch 147/200\n",
            "258/258 [==============================] - 33s 129ms/step - loss: 0.9505 - categorical_accuracy: 0.5832 - val_loss: 1.0215 - val_categorical_accuracy: 0.5218\n",
            "Epoch 148/200\n",
            "258/258 [==============================] - 34s 131ms/step - loss: 0.9296 - categorical_accuracy: 0.5823 - val_loss: 1.1111 - val_categorical_accuracy: 0.5197\n",
            "Epoch 149/200\n",
            "258/258 [==============================] - 33s 128ms/step - loss: 0.9443 - categorical_accuracy: 0.5836 - val_loss: 1.0919 - val_categorical_accuracy: 0.4651\n",
            "Epoch 150/200\n",
            "258/258 [==============================] - 34s 130ms/step - loss: 0.9712 - categorical_accuracy: 0.5712 - val_loss: 1.1443 - val_categorical_accuracy: 0.4825\n",
            "Epoch 151/200\n",
            "258/258 [==============================] - 33s 128ms/step - loss: 0.9137 - categorical_accuracy: 0.5900 - val_loss: 1.1996 - val_categorical_accuracy: 0.4651\n",
            "Epoch 152/200\n",
            "258/258 [==============================] - 33s 128ms/step - loss: 0.9335 - categorical_accuracy: 0.5752 - val_loss: 1.0617 - val_categorical_accuracy: 0.5262\n",
            "Epoch 153/200\n",
            "258/258 [==============================] - 34s 130ms/step - loss: 0.9250 - categorical_accuracy: 0.5893 - val_loss: 1.0360 - val_categorical_accuracy: 0.5087\n",
            "Epoch 154/200\n",
            "258/258 [==============================] - 34s 130ms/step - loss: 0.9477 - categorical_accuracy: 0.5879 - val_loss: 1.0614 - val_categorical_accuracy: 0.5175\n",
            "Epoch 155/200\n",
            "258/258 [==============================] - 33s 129ms/step - loss: 0.9304 - categorical_accuracy: 0.5873 - val_loss: 1.0258 - val_categorical_accuracy: 0.5437\n",
            "Epoch 156/200\n",
            "258/258 [==============================] - 33s 129ms/step - loss: 0.9379 - categorical_accuracy: 0.5784 - val_loss: 1.0275 - val_categorical_accuracy: 0.5087\n",
            "Epoch 157/200\n",
            "258/258 [==============================] - 33s 128ms/step - loss: 0.9436 - categorical_accuracy: 0.5745 - val_loss: 1.2061 - val_categorical_accuracy: 0.4563\n",
            "Epoch 158/200\n",
            "258/258 [==============================] - 33s 128ms/step - loss: 0.9382 - categorical_accuracy: 0.5930 - val_loss: 1.0508 - val_categorical_accuracy: 0.5306\n",
            "Epoch 159/200\n",
            "258/258 [==============================] - 33s 127ms/step - loss: 0.9681 - categorical_accuracy: 0.5696 - val_loss: 1.0103 - val_categorical_accuracy: 0.5306\n",
            "Epoch 160/200\n",
            "258/258 [==============================] - 33s 128ms/step - loss: 0.9174 - categorical_accuracy: 0.5947 - val_loss: 1.0634 - val_categorical_accuracy: 0.5371\n",
            "Epoch 161/200\n",
            "258/258 [==============================] - 33s 127ms/step - loss: 0.9513 - categorical_accuracy: 0.5836 - val_loss: 1.0935 - val_categorical_accuracy: 0.4913\n",
            "Epoch 162/200\n",
            "258/258 [==============================] - 33s 128ms/step - loss: 0.9357 - categorical_accuracy: 0.5849 - val_loss: 1.2420 - val_categorical_accuracy: 0.4323\n",
            "Epoch 163/200\n",
            "258/258 [==============================] - 33s 128ms/step - loss: 0.9379 - categorical_accuracy: 0.5844 - val_loss: 1.0324 - val_categorical_accuracy: 0.5306\n",
            "Epoch 164/200\n",
            "258/258 [==============================] - 33s 128ms/step - loss: 0.9270 - categorical_accuracy: 0.5914 - val_loss: 0.9840 - val_categorical_accuracy: 0.5546\n",
            "Epoch 165/200\n",
            "258/258 [==============================] - 33s 127ms/step - loss: 0.9283 - categorical_accuracy: 0.5916 - val_loss: 1.1350 - val_categorical_accuracy: 0.5109\n",
            "Epoch 166/200\n",
            "258/258 [==============================] - 34s 133ms/step - loss: 0.9654 - categorical_accuracy: 0.5790 - val_loss: 1.0204 - val_categorical_accuracy: 0.5306\n",
            "Epoch 167/200\n",
            "258/258 [==============================] - 35s 135ms/step - loss: 0.9322 - categorical_accuracy: 0.5796 - val_loss: 1.0735 - val_categorical_accuracy: 0.5349\n",
            "Epoch 168/200\n",
            "258/258 [==============================] - 34s 133ms/step - loss: 0.9254 - categorical_accuracy: 0.5988 - val_loss: 1.1099 - val_categorical_accuracy: 0.4847\n",
            "Epoch 169/200\n",
            "258/258 [==============================] - 35s 134ms/step - loss: 0.9273 - categorical_accuracy: 0.5926 - val_loss: 0.9895 - val_categorical_accuracy: 0.5502\n",
            "Epoch 170/200\n",
            "258/258 [==============================] - 35s 135ms/step - loss: 0.9277 - categorical_accuracy: 0.5892 - val_loss: 1.1312 - val_categorical_accuracy: 0.4934\n",
            "Epoch 171/200\n",
            "258/258 [==============================] - 34s 132ms/step - loss: 0.9307 - categorical_accuracy: 0.5945 - val_loss: 1.1350 - val_categorical_accuracy: 0.4607\n",
            "Epoch 172/200\n",
            "258/258 [==============================] - 34s 130ms/step - loss: 0.9299 - categorical_accuracy: 0.6003 - val_loss: 1.1492 - val_categorical_accuracy: 0.4629\n",
            "Epoch 173/200\n",
            "258/258 [==============================] - 34s 133ms/step - loss: 0.9126 - categorical_accuracy: 0.5975 - val_loss: 1.0966 - val_categorical_accuracy: 0.4869\n",
            "Epoch 174/200\n",
            "258/258 [==============================] - 34s 131ms/step - loss: 0.9066 - categorical_accuracy: 0.6039 - val_loss: 1.0544 - val_categorical_accuracy: 0.5218\n",
            "Epoch 175/200\n",
            "258/258 [==============================] - 34s 132ms/step - loss: 0.9288 - categorical_accuracy: 0.5948 - val_loss: 1.1213 - val_categorical_accuracy: 0.5022\n",
            "Epoch 176/200\n",
            "258/258 [==============================] - 34s 134ms/step - loss: 0.9181 - categorical_accuracy: 0.6003 - val_loss: 1.0393 - val_categorical_accuracy: 0.5153\n",
            "Epoch 177/200\n",
            "258/258 [==============================] - 34s 132ms/step - loss: 0.9139 - categorical_accuracy: 0.6097 - val_loss: 1.0705 - val_categorical_accuracy: 0.5022\n",
            "Epoch 178/200\n",
            "258/258 [==============================] - 33s 129ms/step - loss: 0.9335 - categorical_accuracy: 0.5771 - val_loss: 1.0903 - val_categorical_accuracy: 0.5087\n",
            "Epoch 179/200\n",
            "258/258 [==============================] - 33s 130ms/step - loss: 0.9401 - categorical_accuracy: 0.5687 - val_loss: 1.0569 - val_categorical_accuracy: 0.5218\n",
            "Epoch 180/200\n",
            "258/258 [==============================] - 33s 129ms/step - loss: 0.9081 - categorical_accuracy: 0.5945 - val_loss: 1.0408 - val_categorical_accuracy: 0.5087\n",
            "Epoch 181/200\n",
            "258/258 [==============================] - 33s 129ms/step - loss: 0.8989 - categorical_accuracy: 0.6057 - val_loss: 1.0910 - val_categorical_accuracy: 0.4956\n",
            "Epoch 182/200\n",
            "258/258 [==============================] - 33s 129ms/step - loss: 0.9269 - categorical_accuracy: 0.5918 - val_loss: 1.0558 - val_categorical_accuracy: 0.5153\n",
            "Epoch 183/200\n",
            "258/258 [==============================] - 33s 129ms/step - loss: 0.9209 - categorical_accuracy: 0.5938 - val_loss: 1.0927 - val_categorical_accuracy: 0.5349\n",
            "Epoch 184/200\n",
            "258/258 [==============================] - 33s 129ms/step - loss: 0.9327 - categorical_accuracy: 0.5893 - val_loss: 1.1777 - val_categorical_accuracy: 0.4782\n",
            "Epoch 185/200\n",
            "258/258 [==============================] - 34s 131ms/step - loss: 0.9188 - categorical_accuracy: 0.5946 - val_loss: 1.0893 - val_categorical_accuracy: 0.5022\n",
            "Epoch 186/200\n",
            "258/258 [==============================] - 34s 131ms/step - loss: 0.9409 - categorical_accuracy: 0.5795 - val_loss: 0.9973 - val_categorical_accuracy: 0.5371\n",
            "Epoch 187/200\n",
            "258/258 [==============================] - 34s 132ms/step - loss: 0.9323 - categorical_accuracy: 0.5803 - val_loss: 1.0549 - val_categorical_accuracy: 0.5197\n",
            "Epoch 188/200\n",
            "258/258 [==============================] - 34s 132ms/step - loss: 0.9260 - categorical_accuracy: 0.5922 - val_loss: 1.1069 - val_categorical_accuracy: 0.5066\n",
            "Epoch 189/200\n",
            "258/258 [==============================] - 34s 130ms/step - loss: 0.9291 - categorical_accuracy: 0.5981 - val_loss: 1.0216 - val_categorical_accuracy: 0.5546\n",
            "Epoch 190/200\n",
            "258/258 [==============================] - 34s 132ms/step - loss: 0.9115 - categorical_accuracy: 0.5899 - val_loss: 1.0969 - val_categorical_accuracy: 0.4651\n",
            "Epoch 191/200\n",
            "258/258 [==============================] - 33s 130ms/step - loss: 0.9097 - categorical_accuracy: 0.5913 - val_loss: 1.1595 - val_categorical_accuracy: 0.4716\n",
            "Epoch 192/200\n",
            "258/258 [==============================] - 34s 131ms/step - loss: 0.9121 - categorical_accuracy: 0.5914 - val_loss: 1.0549 - val_categorical_accuracy: 0.5371\n",
            "Epoch 193/200\n",
            "258/258 [==============================] - 34s 130ms/step - loss: 0.9284 - categorical_accuracy: 0.5707 - val_loss: 1.0629 - val_categorical_accuracy: 0.5153\n",
            "Epoch 194/200\n",
            "258/258 [==============================] - 34s 132ms/step - loss: 0.8946 - categorical_accuracy: 0.5922 - val_loss: 1.1544 - val_categorical_accuracy: 0.4629\n",
            "Epoch 195/200\n",
            "258/258 [==============================] - 35s 135ms/step - loss: 0.9140 - categorical_accuracy: 0.5953 - val_loss: 1.0162 - val_categorical_accuracy: 0.5044\n",
            "Epoch 196/200\n",
            "258/258 [==============================] - 35s 135ms/step - loss: 0.9143 - categorical_accuracy: 0.5957 - val_loss: 1.1282 - val_categorical_accuracy: 0.4607\n",
            "Epoch 197/200\n",
            "258/258 [==============================] - 35s 136ms/step - loss: 0.9185 - categorical_accuracy: 0.5953 - val_loss: 0.9844 - val_categorical_accuracy: 0.5459\n",
            "Epoch 198/200\n",
            "258/258 [==============================] - 34s 134ms/step - loss: 0.9001 - categorical_accuracy: 0.5979 - val_loss: 1.1054 - val_categorical_accuracy: 0.4956\n",
            "Epoch 199/200\n",
            "258/258 [==============================] - 35s 134ms/step - loss: 0.9224 - categorical_accuracy: 0.5725 - val_loss: 0.9593 - val_categorical_accuracy: 0.5655\n",
            "Epoch 200/200\n",
            "258/258 [==============================] - 35s 136ms/step - loss: 0.8844 - categorical_accuracy: 0.6173 - val_loss: 1.0794 - val_categorical_accuracy: 0.5109\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8_2j3Pf0CIU"
      },
      "source": [
        "model.save('/content/drive/MyDrive/Colab Notebooks/SPEECH_EMOTION_Recognition/Nộp bài(chốt hạ)/model_saver/conv1D_mfcc13_cremad.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L4jDC7cNsJL1"
      },
      "source": [
        "###test_result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ywGjCaH4sJMK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c15d8fa2-6a65-4090-d906-6d44aa06acc3"
      },
      "source": [
        "d = {0: 'happy',\n",
        "     1: 'sad',\n",
        "     2: 'angry',\n",
        "     3: 'fear'}\n",
        "Y_test_pred = np.argmax(model.predict(X_test), axis=-1)\n",
        "Y_test_pred = list(map(lambda x: d[x], Y_test_pred))\n",
        "y_test = np.argmax(y_test, axis=-1)\n",
        "y_test = list(map(lambda x: d[x], y_test))\n",
        "print(classification_report(y_test, Y_test_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.76      0.54      0.64       136\n",
            "        fear       0.45      0.75      0.56       134\n",
            "       happy       0.49      0.53      0.51       120\n",
            "         sad       0.79      0.39      0.52       119\n",
            "\n",
            "    accuracy                           0.56       509\n",
            "   macro avg       0.62      0.55      0.56       509\n",
            "weighted avg       0.62      0.56      0.56       509\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aGj4vva1sJMP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "outputId": "49267add-73b2-4b2b-b0ba-caba2c881622"
      },
      "source": [
        "import scikitplot as skplt\n",
        "\n",
        "skplt.metrics.plot_confusion_matrix(\n",
        "    y_test, \n",
        "    Y_test_pred,\n",
        "    figsize=(8,8))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f11a69b9b90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zr5UPcz_Knl-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NR2GYIPltbbE"
      },
      "source": [
        "# mfcc_26 + conv1D"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XPB8ykfdtbbp"
      },
      "source": [
        "audio_duration = 3\n",
        "sampling_rate = 22050\n",
        "input_length = sampling_rate * audio_duration"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZsmL8Avtbbq"
      },
      "source": [
        "data = {'labels': [],\n",
        "        'features': []}\n",
        "\n",
        "for i in range(len(CREMA_D_df)):\n",
        "  if ((CREMA_D_df['Emotion'][i] == 'HAP') | (CREMA_D_df['Emotion'][i] == 'SAD') | \n",
        "      (CREMA_D_df['Emotion'][i] == 'ANG') | (CREMA_D_df['Emotion'][i] == 'FEA')):\n",
        "    \n",
        "    if CREMA_D_df['Emotion'][i] == 'HAP':\n",
        "      data['labels'].append(0)\n",
        "    elif CREMA_D_df['Emotion'][i] == 'SAD':\n",
        "      data['labels'].append(1)\n",
        "    elif CREMA_D_df['Emotion'][i] == 'ANG':\n",
        "      data['labels'].append(2)\n",
        "    elif CREMA_D_df['Emotion'][i] == 'FEA':\n",
        "      data['labels'].append(3)\n",
        "\n",
        "\n",
        "    signal, sr =  librosa.load(CREMA_D_df['Paths'][i])\n",
        "\n",
        "    if len(signal) > input_length:\n",
        "        signal = signal[0:input_length]\n",
        "    elif  input_length > len(signal):\n",
        "        max_offset = input_length - len(signal)  \n",
        "        signal = np.pad(signal, (0, max_offset), \"constant\")\n",
        "\n",
        "    mfcc = librosa.feature.mfcc(y=signal, sr=sr, n_mfcc=26).T\n",
        "    mfcc = mfcc.reshape(-1,1)\n",
        "    data['features'].append(mfcc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5SWpoWRmtbbs"
      },
      "source": [
        "X = data['features']\n",
        "y = data['labels']\n",
        "\n",
        "y = np.array(y)\n",
        "y = to_categorical(y)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=0)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=0)\n",
        "\n",
        "X_train = np.array(X_train)\n",
        "X_test = np.array(X_test)\n",
        "X_val = np.array(X_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4zF-hWnCtbbt",
        "outputId": "a0ae3e75-8a34-45c8-faaf-ae0d608a1ff1"
      },
      "source": [
        "X_train.shape,X_test.shape,y_train.shape,y_test.shape\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((4117, 3380, 1), (509, 3380, 1), (4117, 4), (509, 4))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VYhtX3Xtbbt"
      },
      "source": [
        "\n",
        "# CNN I/P Config\n",
        "num_classes = 4\n",
        "input_shape = X_train.shape[1:]\n",
        "learning_rate = 0.0001\n",
        "decay = 1e-6\n",
        "momentum = 0.9\n",
        "\n",
        "#LSTM Configuration\n",
        "num_lstm = 256"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KwULrfdLtbbu",
        "outputId": "945f4dce-e62e-4487-e714-4c8c1eb603e4"
      },
      "source": [
        "model = Sequential(name='Audio_CNN_1D')\n",
        "\n",
        "# LFLB1\n",
        "model.add(Conv1D(filters=64, kernel_size=(3), strides=1, padding='same', data_format='channels_last',input_shape=input_shape))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('elu'))\n",
        "model.add(MaxPooling1D(pool_size=4, strides=4))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "# LFLB2\n",
        "model.add(Conv1D(filters=64, kernel_size=3, strides=1, padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('elu'))\n",
        "model.add(MaxPooling1D(pool_size=4, strides=4))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# LFLB3\n",
        "model.add(Conv1D(filters=128, kernel_size=3, strides=1, padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('elu'))\n",
        "model.add(MaxPooling1D(pool_size=4, strides=4))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# LFLB4\n",
        "model.add(Conv1D(filters=128, kernel_size=3, strides=1, padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('elu'))\n",
        "model.add(MaxPooling1D(pool_size=4, strides=4))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# LSTM\n",
        "model.add(LSTM(units=num_lstm))\n",
        "\n",
        "# FC\n",
        "model.add(Dense(units=num_classes, activation='softmax'))\n",
        "\n",
        "# Model compilation\n",
        "opt= keras.optimizers.Adam(lr=0.01, beta_1=0.9,  beta_2=0.999, amsgrad=False)\n",
        "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
        "\n",
        "model.summary()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"Audio_CNN_1D\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 3380, 64)          256       \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 3380, 64)          256       \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 3380, 64)          0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D) (None, 845, 64)           0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 845, 64)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 845, 64)           12352     \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 845, 64)           256       \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 845, 64)           0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1 (None, 211, 64)           0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 211, 64)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 211, 128)          24704     \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 211, 128)          512       \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 211, 128)          0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_2 (MaxPooling1 (None, 52, 128)           0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 52, 128)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 52, 128)           49280     \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 52, 128)           512       \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 52, 128)           0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_3 (MaxPooling1 (None, 13, 128)           0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 13, 128)           0         \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 256)               394240    \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 4)                 1028      \n",
            "=================================================================\n",
            "Total params: 483,396\n",
            "Trainable params: 482,628\n",
            "Non-trainable params: 768\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Ry8F3bqtbbv",
        "outputId": "a72c1194-602f-456d-9f03-93fb186876fc"
      },
      "source": [
        "#Train Config\n",
        "\n",
        "batch_size = 16\n",
        "num_epochs = 200\n",
        "\n",
        "# Model Training\n",
        "lr_reduce = ReduceLROnPlateau(monitor='val_loss', factor=0.9, patience=20, min_lr=0.000001)\n",
        "# Please change the model name accordingly.\n",
        "mcp_save = ModelCheckpoint('/content/Audio_1DCNN.h5', save_best_only=True, monitor='val_categorical_accuracy', mode='max')\n",
        "cnnhistory=model.fit(X_train, y_train, batch_size=batch_size, epochs=num_epochs,validation_data=(X_val, y_val), callbacks=[mcp_save, lr_reduce])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "258/258 [==============================] - 57s 18ms/step - loss: 1.3544 - categorical_accuracy: 0.4283 - val_loss: 1.9161 - val_categorical_accuracy: 0.2817\n",
            "Epoch 2/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.1245 - categorical_accuracy: 0.4637 - val_loss: 1.9937 - val_categorical_accuracy: 0.3035\n",
            "Epoch 3/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0976 - categorical_accuracy: 0.5172 - val_loss: 1.3214 - val_categorical_accuracy: 0.3908\n",
            "Epoch 4/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.1015 - categorical_accuracy: 0.5070 - val_loss: 1.1510 - val_categorical_accuracy: 0.4760\n",
            "Epoch 5/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0809 - categorical_accuracy: 0.5161 - val_loss: 1.1258 - val_categorical_accuracy: 0.4956\n",
            "Epoch 6/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0821 - categorical_accuracy: 0.5154 - val_loss: 1.3558 - val_categorical_accuracy: 0.4083\n",
            "Epoch 7/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0884 - categorical_accuracy: 0.5027 - val_loss: 1.1356 - val_categorical_accuracy: 0.4956\n",
            "Epoch 8/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.1003 - categorical_accuracy: 0.4890 - val_loss: 1.2591 - val_categorical_accuracy: 0.4782\n",
            "Epoch 9/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0617 - categorical_accuracy: 0.5048 - val_loss: 1.1567 - val_categorical_accuracy: 0.4825\n",
            "Epoch 10/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0729 - categorical_accuracy: 0.5027 - val_loss: 1.2337 - val_categorical_accuracy: 0.4847\n",
            "Epoch 11/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0867 - categorical_accuracy: 0.5153 - val_loss: 1.1389 - val_categorical_accuracy: 0.4913\n",
            "Epoch 12/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0743 - categorical_accuracy: 0.5284 - val_loss: 1.1503 - val_categorical_accuracy: 0.4847\n",
            "Epoch 13/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0572 - categorical_accuracy: 0.5152 - val_loss: 1.0910 - val_categorical_accuracy: 0.5109\n",
            "Epoch 14/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0620 - categorical_accuracy: 0.5169 - val_loss: 1.0987 - val_categorical_accuracy: 0.5066\n",
            "Epoch 15/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0685 - categorical_accuracy: 0.5085 - val_loss: 1.0745 - val_categorical_accuracy: 0.5349\n",
            "Epoch 16/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0405 - categorical_accuracy: 0.5360 - val_loss: 1.0928 - val_categorical_accuracy: 0.5349\n",
            "Epoch 17/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0550 - categorical_accuracy: 0.5249 - val_loss: 1.1636 - val_categorical_accuracy: 0.4694\n",
            "Epoch 18/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0438 - categorical_accuracy: 0.5402 - val_loss: 1.1367 - val_categorical_accuracy: 0.5044\n",
            "Epoch 19/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0299 - categorical_accuracy: 0.5458 - val_loss: 1.0957 - val_categorical_accuracy: 0.5087\n",
            "Epoch 20/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0635 - categorical_accuracy: 0.5281 - val_loss: 1.2444 - val_categorical_accuracy: 0.4520\n",
            "Epoch 21/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0510 - categorical_accuracy: 0.5259 - val_loss: 1.0755 - val_categorical_accuracy: 0.5371\n",
            "Epoch 22/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0475 - categorical_accuracy: 0.5216 - val_loss: 1.1144 - val_categorical_accuracy: 0.5109\n",
            "Epoch 23/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0405 - categorical_accuracy: 0.5310 - val_loss: 1.0967 - val_categorical_accuracy: 0.5087\n",
            "Epoch 24/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0592 - categorical_accuracy: 0.5264 - val_loss: 1.1847 - val_categorical_accuracy: 0.4891\n",
            "Epoch 25/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0666 - categorical_accuracy: 0.5196 - val_loss: 1.1909 - val_categorical_accuracy: 0.4913\n",
            "Epoch 26/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0418 - categorical_accuracy: 0.5129 - val_loss: 1.1874 - val_categorical_accuracy: 0.4389\n",
            "Epoch 27/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0617 - categorical_accuracy: 0.5167 - val_loss: 1.0837 - val_categorical_accuracy: 0.5087\n",
            "Epoch 28/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0477 - categorical_accuracy: 0.5128 - val_loss: 1.0632 - val_categorical_accuracy: 0.4934\n",
            "Epoch 29/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0584 - categorical_accuracy: 0.5157 - val_loss: 1.0548 - val_categorical_accuracy: 0.5109\n",
            "Epoch 30/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0425 - categorical_accuracy: 0.5135 - val_loss: 1.1541 - val_categorical_accuracy: 0.5066\n",
            "Epoch 31/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0260 - categorical_accuracy: 0.5307 - val_loss: 1.0739 - val_categorical_accuracy: 0.5262\n",
            "Epoch 32/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0292 - categorical_accuracy: 0.5180 - val_loss: 1.1167 - val_categorical_accuracy: 0.4891\n",
            "Epoch 33/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0426 - categorical_accuracy: 0.5174 - val_loss: 1.0754 - val_categorical_accuracy: 0.4978\n",
            "Epoch 34/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0279 - categorical_accuracy: 0.5213 - val_loss: 1.1401 - val_categorical_accuracy: 0.4978\n",
            "Epoch 35/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0587 - categorical_accuracy: 0.5323 - val_loss: 1.0972 - val_categorical_accuracy: 0.4978\n",
            "Epoch 36/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0386 - categorical_accuracy: 0.5318 - val_loss: 1.1270 - val_categorical_accuracy: 0.4869\n",
            "Epoch 37/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0398 - categorical_accuracy: 0.5347 - val_loss: 1.0847 - val_categorical_accuracy: 0.4607\n",
            "Epoch 38/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0164 - categorical_accuracy: 0.5446 - val_loss: 1.0823 - val_categorical_accuracy: 0.5153\n",
            "Epoch 39/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 0.9949 - categorical_accuracy: 0.5596 - val_loss: 1.1204 - val_categorical_accuracy: 0.4978\n",
            "Epoch 40/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0259 - categorical_accuracy: 0.5374 - val_loss: 1.1883 - val_categorical_accuracy: 0.5197\n",
            "Epoch 41/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0149 - categorical_accuracy: 0.5386 - val_loss: 1.0934 - val_categorical_accuracy: 0.5218\n",
            "Epoch 42/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0105 - categorical_accuracy: 0.5422 - val_loss: 1.1762 - val_categorical_accuracy: 0.4432\n",
            "Epoch 43/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0235 - categorical_accuracy: 0.5321 - val_loss: 1.0817 - val_categorical_accuracy: 0.4869\n",
            "Epoch 44/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0191 - categorical_accuracy: 0.5391 - val_loss: 1.1601 - val_categorical_accuracy: 0.5022\n",
            "Epoch 45/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0273 - categorical_accuracy: 0.5288 - val_loss: 1.0757 - val_categorical_accuracy: 0.5197\n",
            "Epoch 46/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0535 - categorical_accuracy: 0.5252 - val_loss: 1.1626 - val_categorical_accuracy: 0.4498\n",
            "Epoch 47/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0511 - categorical_accuracy: 0.5161 - val_loss: 1.0942 - val_categorical_accuracy: 0.4913\n",
            "Epoch 48/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0258 - categorical_accuracy: 0.5316 - val_loss: 1.1573 - val_categorical_accuracy: 0.3668\n",
            "Epoch 49/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0263 - categorical_accuracy: 0.5310 - val_loss: 1.1207 - val_categorical_accuracy: 0.4891\n",
            "Epoch 50/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0320 - categorical_accuracy: 0.5327 - val_loss: 1.0924 - val_categorical_accuracy: 0.5153\n",
            "Epoch 51/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0046 - categorical_accuracy: 0.5611 - val_loss: 1.1286 - val_categorical_accuracy: 0.5044\n",
            "Epoch 52/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0304 - categorical_accuracy: 0.5338 - val_loss: 1.0873 - val_categorical_accuracy: 0.5218\n",
            "Epoch 53/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0242 - categorical_accuracy: 0.5361 - val_loss: 1.1511 - val_categorical_accuracy: 0.4301\n",
            "Epoch 54/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0056 - categorical_accuracy: 0.5527 - val_loss: 1.1039 - val_categorical_accuracy: 0.4803\n",
            "Epoch 55/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0396 - categorical_accuracy: 0.5407 - val_loss: 1.0930 - val_categorical_accuracy: 0.4847\n",
            "Epoch 56/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0395 - categorical_accuracy: 0.5335 - val_loss: 1.0954 - val_categorical_accuracy: 0.5022\n",
            "Epoch 57/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0211 - categorical_accuracy: 0.5458 - val_loss: 1.0739 - val_categorical_accuracy: 0.5218\n",
            "Epoch 58/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0236 - categorical_accuracy: 0.5420 - val_loss: 1.2051 - val_categorical_accuracy: 0.4782\n",
            "Epoch 59/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0360 - categorical_accuracy: 0.5313 - val_loss: 1.2001 - val_categorical_accuracy: 0.4236\n",
            "Epoch 60/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0339 - categorical_accuracy: 0.5329 - val_loss: 1.0561 - val_categorical_accuracy: 0.5328\n",
            "Epoch 61/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0044 - categorical_accuracy: 0.5547 - val_loss: 1.0848 - val_categorical_accuracy: 0.4956\n",
            "Epoch 62/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0174 - categorical_accuracy: 0.5367 - val_loss: 1.0615 - val_categorical_accuracy: 0.5437\n",
            "Epoch 63/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 0.9995 - categorical_accuracy: 0.5431 - val_loss: 1.0605 - val_categorical_accuracy: 0.5153\n",
            "Epoch 64/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0164 - categorical_accuracy: 0.5598 - val_loss: 1.1394 - val_categorical_accuracy: 0.4891\n",
            "Epoch 65/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0048 - categorical_accuracy: 0.5375 - val_loss: 1.1433 - val_categorical_accuracy: 0.4913\n",
            "Epoch 66/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0310 - categorical_accuracy: 0.5445 - val_loss: 1.0706 - val_categorical_accuracy: 0.5000\n",
            "Epoch 67/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0051 - categorical_accuracy: 0.5478 - val_loss: 1.0610 - val_categorical_accuracy: 0.5109\n",
            "Epoch 68/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0172 - categorical_accuracy: 0.5460 - val_loss: 1.1117 - val_categorical_accuracy: 0.4891\n",
            "Epoch 69/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 0.9946 - categorical_accuracy: 0.5387 - val_loss: 1.1041 - val_categorical_accuracy: 0.5022\n",
            "Epoch 70/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0121 - categorical_accuracy: 0.5475 - val_loss: 1.1490 - val_categorical_accuracy: 0.4694\n",
            "Epoch 71/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0190 - categorical_accuracy: 0.5432 - val_loss: 1.0838 - val_categorical_accuracy: 0.4716\n",
            "Epoch 72/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 0.9915 - categorical_accuracy: 0.5583 - val_loss: 1.0793 - val_categorical_accuracy: 0.5240\n",
            "Epoch 73/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0022 - categorical_accuracy: 0.5472 - val_loss: 1.0572 - val_categorical_accuracy: 0.5415\n",
            "Epoch 74/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0202 - categorical_accuracy: 0.5447 - val_loss: 1.0659 - val_categorical_accuracy: 0.4782\n",
            "Epoch 75/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0122 - categorical_accuracy: 0.5348 - val_loss: 1.1812 - val_categorical_accuracy: 0.4520\n",
            "Epoch 76/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 0.9960 - categorical_accuracy: 0.5662 - val_loss: 1.1001 - val_categorical_accuracy: 0.4716\n",
            "Epoch 77/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0225 - categorical_accuracy: 0.5424 - val_loss: 1.1730 - val_categorical_accuracy: 0.4498\n",
            "Epoch 78/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 0.9785 - categorical_accuracy: 0.5633 - val_loss: 1.1389 - val_categorical_accuracy: 0.4672\n",
            "Epoch 79/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0070 - categorical_accuracy: 0.5569 - val_loss: 1.0650 - val_categorical_accuracy: 0.5306\n",
            "Epoch 80/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 0.9853 - categorical_accuracy: 0.5607 - val_loss: 1.1657 - val_categorical_accuracy: 0.4847\n",
            "Epoch 81/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0016 - categorical_accuracy: 0.5718 - val_loss: 1.0678 - val_categorical_accuracy: 0.5262\n",
            "Epoch 82/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 0.9789 - categorical_accuracy: 0.5662 - val_loss: 1.0774 - val_categorical_accuracy: 0.5131\n",
            "Epoch 83/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 0.9922 - categorical_accuracy: 0.5563 - val_loss: 1.0703 - val_categorical_accuracy: 0.5000\n",
            "Epoch 84/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 0.9904 - categorical_accuracy: 0.5527 - val_loss: 1.1258 - val_categorical_accuracy: 0.4956\n",
            "Epoch 85/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0102 - categorical_accuracy: 0.5453 - val_loss: 1.1142 - val_categorical_accuracy: 0.4913\n",
            "Epoch 86/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0155 - categorical_accuracy: 0.5383 - val_loss: 1.0565 - val_categorical_accuracy: 0.5175\n",
            "Epoch 87/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0076 - categorical_accuracy: 0.5368 - val_loss: 1.1099 - val_categorical_accuracy: 0.4891\n",
            "Epoch 88/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 0.9991 - categorical_accuracy: 0.5555 - val_loss: 1.1262 - val_categorical_accuracy: 0.4891\n",
            "Epoch 89/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 0.9922 - categorical_accuracy: 0.5618 - val_loss: 1.0682 - val_categorical_accuracy: 0.4978\n",
            "Epoch 90/200\n",
            "258/258 [==============================] - 3s 13ms/step - loss: 0.9904 - categorical_accuracy: 0.5567 - val_loss: 1.1427 - val_categorical_accuracy: 0.4782\n",
            "Epoch 91/200\n",
            "258/258 [==============================] - 3s 13ms/step - loss: 0.9828 - categorical_accuracy: 0.5735 - val_loss: 1.1317 - val_categorical_accuracy: 0.4869\n",
            "Epoch 92/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 0.9950 - categorical_accuracy: 0.5553 - val_loss: 1.0829 - val_categorical_accuracy: 0.5022\n",
            "Epoch 93/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 0.9740 - categorical_accuracy: 0.5635 - val_loss: 1.0734 - val_categorical_accuracy: 0.4956\n",
            "Epoch 94/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 0.9836 - categorical_accuracy: 0.5456 - val_loss: 1.0593 - val_categorical_accuracy: 0.5197\n",
            "Epoch 95/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 0.9870 - categorical_accuracy: 0.5606 - val_loss: 1.1131 - val_categorical_accuracy: 0.5153\n",
            "Epoch 96/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0000 - categorical_accuracy: 0.5563 - val_loss: 1.0561 - val_categorical_accuracy: 0.5153\n",
            "Epoch 97/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 0.9664 - categorical_accuracy: 0.5770 - val_loss: 1.0402 - val_categorical_accuracy: 0.5284\n",
            "Epoch 98/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 0.9930 - categorical_accuracy: 0.5580 - val_loss: 1.0445 - val_categorical_accuracy: 0.5306\n",
            "Epoch 99/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 0.9702 - categorical_accuracy: 0.5744 - val_loss: 1.0407 - val_categorical_accuracy: 0.5153\n",
            "Epoch 100/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 0.9851 - categorical_accuracy: 0.5595 - val_loss: 1.0620 - val_categorical_accuracy: 0.5022\n",
            "Epoch 101/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 0.9653 - categorical_accuracy: 0.5663 - val_loss: 1.1249 - val_categorical_accuracy: 0.4913\n",
            "Epoch 102/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0095 - categorical_accuracy: 0.5481 - val_loss: 1.1615 - val_categorical_accuracy: 0.4127\n",
            "Epoch 103/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 0.9921 - categorical_accuracy: 0.5534 - val_loss: 1.0514 - val_categorical_accuracy: 0.5153\n",
            "Epoch 104/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 0.9509 - categorical_accuracy: 0.5781 - val_loss: 1.0248 - val_categorical_accuracy: 0.5611\n",
            "Epoch 105/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 0.9743 - categorical_accuracy: 0.5566 - val_loss: 1.0968 - val_categorical_accuracy: 0.4891\n",
            "Epoch 106/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 0.9804 - categorical_accuracy: 0.5674 - val_loss: 1.0375 - val_categorical_accuracy: 0.5262\n",
            "Epoch 107/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 0.9717 - categorical_accuracy: 0.5744 - val_loss: 1.0969 - val_categorical_accuracy: 0.4934\n",
            "Epoch 108/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 0.9602 - categorical_accuracy: 0.5790 - val_loss: 1.0856 - val_categorical_accuracy: 0.4803\n",
            "Epoch 109/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 0.9521 - categorical_accuracy: 0.5839 - val_loss: 1.0730 - val_categorical_accuracy: 0.5306\n",
            "Epoch 110/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 0.9678 - categorical_accuracy: 0.5819 - val_loss: 1.0696 - val_categorical_accuracy: 0.5393\n",
            "Epoch 111/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 0.9825 - categorical_accuracy: 0.5607 - val_loss: 1.0358 - val_categorical_accuracy: 0.5437\n",
            "Epoch 112/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 0.9865 - categorical_accuracy: 0.5585 - val_loss: 1.0627 - val_categorical_accuracy: 0.5109\n",
            "Epoch 113/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 0.9537 - categorical_accuracy: 0.5848 - val_loss: 1.0312 - val_categorical_accuracy: 0.5393\n",
            "Epoch 114/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 0.9880 - categorical_accuracy: 0.5641 - val_loss: 1.0777 - val_categorical_accuracy: 0.5284\n",
            "Epoch 115/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 0.9429 - categorical_accuracy: 0.5785 - val_loss: 1.1092 - val_categorical_accuracy: 0.4454\n",
            "Epoch 116/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 0.9923 - categorical_accuracy: 0.5555 - val_loss: 1.0374 - val_categorical_accuracy: 0.5022\n",
            "Epoch 117/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 0.9792 - categorical_accuracy: 0.5715 - val_loss: 1.0830 - val_categorical_accuracy: 0.5109\n",
            "Epoch 118/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 0.9855 - categorical_accuracy: 0.5583 - val_loss: 1.1464 - val_categorical_accuracy: 0.4825\n",
            "Epoch 119/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 0.9738 - categorical_accuracy: 0.5742 - val_loss: 1.1176 - val_categorical_accuracy: 0.4891\n",
            "Epoch 120/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 0.9749 - categorical_accuracy: 0.5718 - val_loss: 1.1475 - val_categorical_accuracy: 0.5284\n",
            "Epoch 121/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 0.9821 - categorical_accuracy: 0.5639 - val_loss: 1.0319 - val_categorical_accuracy: 0.5371\n",
            "Epoch 122/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 0.9921 - categorical_accuracy: 0.5629 - val_loss: 1.0131 - val_categorical_accuracy: 0.5633\n",
            "Epoch 123/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 0.9418 - categorical_accuracy: 0.5906 - val_loss: 1.0727 - val_categorical_accuracy: 0.5153\n",
            "Epoch 124/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 0.9651 - categorical_accuracy: 0.5902 - val_loss: 1.0303 - val_categorical_accuracy: 0.5197\n",
            "Epoch 125/200\n",
            "258/258 [==============================] - 3s 13ms/step - loss: 0.9949 - categorical_accuracy: 0.5640 - val_loss: 1.0613 - val_categorical_accuracy: 0.4978\n",
            "Epoch 126/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0041 - categorical_accuracy: 0.5465 - val_loss: 1.0735 - val_categorical_accuracy: 0.5328\n",
            "Epoch 127/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 0.9550 - categorical_accuracy: 0.5673 - val_loss: 1.0888 - val_categorical_accuracy: 0.5218\n",
            "Epoch 128/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 0.9651 - categorical_accuracy: 0.5797 - val_loss: 1.1453 - val_categorical_accuracy: 0.5306\n",
            "Epoch 129/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 0.9998 - categorical_accuracy: 0.5589 - val_loss: 1.0386 - val_categorical_accuracy: 0.5437\n",
            "Epoch 130/200\n",
            "258/258 [==============================] - 3s 13ms/step - loss: 0.9782 - categorical_accuracy: 0.5805 - val_loss: 1.0707 - val_categorical_accuracy: 0.5262\n",
            "Epoch 131/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 0.9719 - categorical_accuracy: 0.5679 - val_loss: 1.0253 - val_categorical_accuracy: 0.5459\n",
            "Epoch 132/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 0.9887 - categorical_accuracy: 0.5618 - val_loss: 1.0556 - val_categorical_accuracy: 0.5633\n",
            "Epoch 133/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 0.9573 - categorical_accuracy: 0.5784 - val_loss: 1.0741 - val_categorical_accuracy: 0.5131\n",
            "Epoch 134/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 0.9429 - categorical_accuracy: 0.5815 - val_loss: 1.0136 - val_categorical_accuracy: 0.5699\n",
            "Epoch 135/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 0.9633 - categorical_accuracy: 0.5763 - val_loss: 1.1545 - val_categorical_accuracy: 0.5175\n",
            "Epoch 136/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 0.9780 - categorical_accuracy: 0.5713 - val_loss: 1.0349 - val_categorical_accuracy: 0.5524\n",
            "Epoch 137/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 0.9726 - categorical_accuracy: 0.5759 - val_loss: 0.9977 - val_categorical_accuracy: 0.5459\n",
            "Epoch 138/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0091 - categorical_accuracy: 0.5552 - val_loss: 1.0242 - val_categorical_accuracy: 0.5415\n",
            "Epoch 139/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 0.9624 - categorical_accuracy: 0.5744 - val_loss: 1.0306 - val_categorical_accuracy: 0.5568\n",
            "Epoch 140/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 0.9889 - categorical_accuracy: 0.5712 - val_loss: 1.1049 - val_categorical_accuracy: 0.5175\n",
            "Epoch 141/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 0.9952 - categorical_accuracy: 0.5481 - val_loss: 1.0240 - val_categorical_accuracy: 0.5502\n",
            "Epoch 142/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 0.9715 - categorical_accuracy: 0.5650 - val_loss: 1.0609 - val_categorical_accuracy: 0.5087\n",
            "Epoch 143/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 0.9583 - categorical_accuracy: 0.5652 - val_loss: 1.0437 - val_categorical_accuracy: 0.5197\n",
            "Epoch 144/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 0.9700 - categorical_accuracy: 0.5490 - val_loss: 1.0863 - val_categorical_accuracy: 0.5153\n",
            "Epoch 145/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 0.9471 - categorical_accuracy: 0.5753 - val_loss: 1.0838 - val_categorical_accuracy: 0.5153\n",
            "Epoch 146/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 0.9535 - categorical_accuracy: 0.5682 - val_loss: 1.0724 - val_categorical_accuracy: 0.5415\n",
            "Epoch 147/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 0.9693 - categorical_accuracy: 0.5467 - val_loss: 1.0528 - val_categorical_accuracy: 0.5175\n",
            "Epoch 148/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 0.9528 - categorical_accuracy: 0.5689 - val_loss: 1.0225 - val_categorical_accuracy: 0.5262\n",
            "Epoch 149/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 0.9439 - categorical_accuracy: 0.5838 - val_loss: 1.1172 - val_categorical_accuracy: 0.4978\n",
            "Epoch 150/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 0.9400 - categorical_accuracy: 0.5826 - val_loss: 1.0708 - val_categorical_accuracy: 0.5611\n",
            "Epoch 151/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 0.9704 - categorical_accuracy: 0.5662 - val_loss: 1.0543 - val_categorical_accuracy: 0.5328\n",
            "Epoch 152/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 0.9728 - categorical_accuracy: 0.5645 - val_loss: 1.0564 - val_categorical_accuracy: 0.5022\n",
            "Epoch 153/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 0.9723 - categorical_accuracy: 0.5700 - val_loss: 1.0273 - val_categorical_accuracy: 0.5262\n",
            "Epoch 154/200\n",
            "258/258 [==============================] - 3s 13ms/step - loss: 0.9262 - categorical_accuracy: 0.5940 - val_loss: 1.0328 - val_categorical_accuracy: 0.5371\n",
            "Epoch 155/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 0.9646 - categorical_accuracy: 0.5685 - val_loss: 1.0208 - val_categorical_accuracy: 0.5459\n",
            "Epoch 156/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 0.9935 - categorical_accuracy: 0.5602 - val_loss: 1.0173 - val_categorical_accuracy: 0.5721\n",
            "Epoch 157/200\n",
            "258/258 [==============================] - 3s 13ms/step - loss: 0.9504 - categorical_accuracy: 0.5844 - val_loss: 1.0629 - val_categorical_accuracy: 0.5197\n",
            "Epoch 158/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 0.9873 - categorical_accuracy: 0.5565 - val_loss: 1.1055 - val_categorical_accuracy: 0.5284\n",
            "Epoch 159/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 0.9656 - categorical_accuracy: 0.5549 - val_loss: 1.0057 - val_categorical_accuracy: 0.5568\n",
            "Epoch 160/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 0.9497 - categorical_accuracy: 0.5856 - val_loss: 1.0091 - val_categorical_accuracy: 0.5240\n",
            "Epoch 161/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 0.9567 - categorical_accuracy: 0.5684 - val_loss: 1.0113 - val_categorical_accuracy: 0.5459\n",
            "Epoch 162/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 0.9259 - categorical_accuracy: 0.5915 - val_loss: 1.0017 - val_categorical_accuracy: 0.5393\n",
            "Epoch 163/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 0.9241 - categorical_accuracy: 0.5914 - val_loss: 1.0390 - val_categorical_accuracy: 0.5306\n",
            "Epoch 164/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 0.9447 - categorical_accuracy: 0.5882 - val_loss: 1.0559 - val_categorical_accuracy: 0.5437\n",
            "Epoch 165/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 0.9474 - categorical_accuracy: 0.5693 - val_loss: 1.0985 - val_categorical_accuracy: 0.4694\n",
            "Epoch 166/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 0.9406 - categorical_accuracy: 0.5736 - val_loss: 1.0010 - val_categorical_accuracy: 0.5590\n",
            "Epoch 167/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 0.9392 - categorical_accuracy: 0.5834 - val_loss: 1.0394 - val_categorical_accuracy: 0.5175\n",
            "Epoch 168/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 0.9316 - categorical_accuracy: 0.5872 - val_loss: 1.0912 - val_categorical_accuracy: 0.4803\n",
            "Epoch 169/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 0.9607 - categorical_accuracy: 0.5729 - val_loss: 1.0316 - val_categorical_accuracy: 0.5611\n",
            "Epoch 170/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 0.9250 - categorical_accuracy: 0.5918 - val_loss: 1.1377 - val_categorical_accuracy: 0.5000\n",
            "Epoch 171/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 0.9548 - categorical_accuracy: 0.5744 - val_loss: 0.9780 - val_categorical_accuracy: 0.5437\n",
            "Epoch 172/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 0.9507 - categorical_accuracy: 0.5807 - val_loss: 1.0253 - val_categorical_accuracy: 0.5240\n",
            "Epoch 173/200\n",
            "258/258 [==============================] - 3s 13ms/step - loss: 0.9376 - categorical_accuracy: 0.5910 - val_loss: 1.1413 - val_categorical_accuracy: 0.4607\n",
            "Epoch 174/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 0.9461 - categorical_accuracy: 0.5719 - val_loss: 0.9956 - val_categorical_accuracy: 0.5655\n",
            "Epoch 175/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 0.9066 - categorical_accuracy: 0.6014 - val_loss: 1.0418 - val_categorical_accuracy: 0.5109\n",
            "Epoch 176/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 0.9492 - categorical_accuracy: 0.5774 - val_loss: 1.0095 - val_categorical_accuracy: 0.5349\n",
            "Epoch 177/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 0.9324 - categorical_accuracy: 0.5979 - val_loss: 1.0510 - val_categorical_accuracy: 0.5240\n",
            "Epoch 178/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 0.9306 - categorical_accuracy: 0.5947 - val_loss: 1.0221 - val_categorical_accuracy: 0.5502\n",
            "Epoch 179/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 0.9391 - categorical_accuracy: 0.5758 - val_loss: 1.0395 - val_categorical_accuracy: 0.5437\n",
            "Epoch 180/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 0.9341 - categorical_accuracy: 0.5919 - val_loss: 1.0779 - val_categorical_accuracy: 0.5306\n",
            "Epoch 181/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 0.9264 - categorical_accuracy: 0.5953 - val_loss: 1.0196 - val_categorical_accuracy: 0.5480\n",
            "Epoch 182/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 0.9852 - categorical_accuracy: 0.5623 - val_loss: 1.1955 - val_categorical_accuracy: 0.4825\n",
            "Epoch 183/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 0.9450 - categorical_accuracy: 0.5673 - val_loss: 1.1305 - val_categorical_accuracy: 0.5000\n",
            "Epoch 184/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 0.9664 - categorical_accuracy: 0.5722 - val_loss: 1.0297 - val_categorical_accuracy: 0.5371\n",
            "Epoch 185/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 0.9299 - categorical_accuracy: 0.5811 - val_loss: 1.0570 - val_categorical_accuracy: 0.4956\n",
            "Epoch 186/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 0.9751 - categorical_accuracy: 0.5615 - val_loss: 1.0450 - val_categorical_accuracy: 0.5328\n",
            "Epoch 187/200\n",
            "258/258 [==============================] - 3s 13ms/step - loss: 0.8936 - categorical_accuracy: 0.6106 - val_loss: 1.0126 - val_categorical_accuracy: 0.5197\n",
            "Epoch 188/200\n",
            "258/258 [==============================] - 3s 13ms/step - loss: 0.9350 - categorical_accuracy: 0.5952 - val_loss: 1.0883 - val_categorical_accuracy: 0.5328\n",
            "Epoch 189/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 0.9341 - categorical_accuracy: 0.5857 - val_loss: 1.0863 - val_categorical_accuracy: 0.5044\n",
            "Epoch 190/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 0.9224 - categorical_accuracy: 0.6000 - val_loss: 1.0197 - val_categorical_accuracy: 0.5415\n",
            "Epoch 191/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 0.9305 - categorical_accuracy: 0.5885 - val_loss: 0.9498 - val_categorical_accuracy: 0.5699\n",
            "Epoch 192/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 0.9191 - categorical_accuracy: 0.6057 - val_loss: 1.0032 - val_categorical_accuracy: 0.5393\n",
            "Epoch 193/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 0.9337 - categorical_accuracy: 0.5856 - val_loss: 1.0618 - val_categorical_accuracy: 0.5611\n",
            "Epoch 194/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 0.9141 - categorical_accuracy: 0.5935 - val_loss: 1.0343 - val_categorical_accuracy: 0.5590\n",
            "Epoch 195/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 0.9310 - categorical_accuracy: 0.5920 - val_loss: 1.0518 - val_categorical_accuracy: 0.5502\n",
            "Epoch 196/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 0.8987 - categorical_accuracy: 0.6161 - val_loss: 0.9801 - val_categorical_accuracy: 0.5830\n",
            "Epoch 197/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 0.9126 - categorical_accuracy: 0.6013 - val_loss: 1.0274 - val_categorical_accuracy: 0.5393\n",
            "Epoch 198/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 0.9361 - categorical_accuracy: 0.5820 - val_loss: 1.0254 - val_categorical_accuracy: 0.5371\n",
            "Epoch 199/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 0.9284 - categorical_accuracy: 0.5803 - val_loss: 0.9642 - val_categorical_accuracy: 0.5611\n",
            "Epoch 200/200\n",
            "258/258 [==============================] - 3s 13ms/step - loss: 0.9183 - categorical_accuracy: 0.5895 - val_loss: 1.0624 - val_categorical_accuracy: 0.5240\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7XV79oUttbbw"
      },
      "source": [
        "model.save('/content/drive/MyDrive/Colab Notebooks/SPEECH_EMOTION_Recognition/Nộp bài(chốt hạ)/model_saver/conv1D_mfcc26_cremad.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kj8Ywt67tbbx"
      },
      "source": [
        "###test_result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SHUi62F_tbby",
        "outputId": "3761a195-774d-4992-d901-652f6bb9c374"
      },
      "source": [
        "d = {0: 'happy',\n",
        "     1: 'sad',\n",
        "     2: 'angry',\n",
        "     3: 'fear'}\n",
        "Y_test_pred = np.argmax(model.predict(X_test), axis=-1)\n",
        "Y_test_pred = list(map(lambda x: d[x], Y_test_pred))\n",
        "y_test = np.argmax(y_test, axis=-1)\n",
        "y_test = list(map(lambda x: d[x], y_test))\n",
        "print(classification_report(y_test, Y_test_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.83      0.54      0.66       136\n",
            "        fear       0.42      0.66      0.52       134\n",
            "       happy       0.50      0.45      0.48       120\n",
            "         sad       0.65      0.55      0.60       119\n",
            "\n",
            "    accuracy                           0.56       509\n",
            "   macro avg       0.60      0.55      0.56       509\n",
            "weighted avg       0.60      0.56      0.56       509\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 483
        },
        "id": "MQlAlhH9tbbz",
        "outputId": "194605ab-748e-4208-a61e-541ec4119ea9"
      },
      "source": [
        "import scikitplot as skplt\n",
        "\n",
        "skplt.metrics.plot_confusion_matrix(\n",
        "    y_test, \n",
        "    Y_test_pred,\n",
        "    figsize=(8,8))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fa488404590>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fRMgRutjtbb0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LLLeABg0tl-u"
      },
      "source": [
        "# mfcc_39 + conv1D"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2p5D5OGtl_i"
      },
      "source": [
        "audio_duration = 3\n",
        "sampling_rate = 22050\n",
        "input_length = sampling_rate * audio_duration"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1kRZa-Gtl_l"
      },
      "source": [
        "data = {'labels': [],\n",
        "        'features': []}\n",
        "\n",
        "for i in range(len(CREMA_D_df)):\n",
        "  if ((CREMA_D_df['Emotion'][i] == 'HAP') | (CREMA_D_df['Emotion'][i] == 'SAD') | \n",
        "      (CREMA_D_df['Emotion'][i] == 'ANG') | (CREMA_D_df['Emotion'][i] == 'FEA')):\n",
        "    \n",
        "    if CREMA_D_df['Emotion'][i] == 'HAP':\n",
        "      data['labels'].append(0)\n",
        "    elif CREMA_D_df['Emotion'][i] == 'SAD':\n",
        "      data['labels'].append(1)\n",
        "    elif CREMA_D_df['Emotion'][i] == 'ANG':\n",
        "      data['labels'].append(2)\n",
        "    elif CREMA_D_df['Emotion'][i] == 'FEA':\n",
        "      data['labels'].append(3)\n",
        "\n",
        "\n",
        "    signal, sr =  librosa.load(CREMA_D_df['Paths'][i])\n",
        "\n",
        "    if len(signal) > input_length:\n",
        "        signal = signal[0:input_length]\n",
        "    elif  input_length > len(signal):\n",
        "        max_offset = input_length - len(signal)  \n",
        "        signal = np.pad(signal, (0, max_offset), \"constant\")\n",
        "\n",
        "    mfcc = librosa.feature.mfcc(y=signal, sr=sr, n_mfcc=39).T\n",
        "    mfcc = mfcc.reshape(-1,1)\n",
        "    data['features'].append(mfcc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DtTRUui7tl_m"
      },
      "source": [
        "X = data['features']\n",
        "y = data['labels']\n",
        "\n",
        "y = np.array(y)\n",
        "y = to_categorical(y)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=0)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=0)\n",
        "\n",
        "X_train = np.array(X_train)\n",
        "X_test = np.array(X_test)\n",
        "X_val = np.array(X_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BGzMR_estl_o",
        "outputId": "2630b5b3-ace8-4a17-d8fa-ccb62888181e"
      },
      "source": [
        "X_train.shape,X_test.shape,y_train.shape,y_test.shape\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((4117, 5070, 1), (509, 5070, 1), (4117, 4), (509, 4))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OgtN8lmxtl_p"
      },
      "source": [
        "\n",
        "# CNN I/P Config\n",
        "num_classes = 4\n",
        "input_shape = X_train.shape[1:]\n",
        "learning_rate = 0.0001\n",
        "decay = 1e-6\n",
        "momentum = 0.9\n",
        "\n",
        "#LSTM Configuration\n",
        "num_lstm = 256"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yp-yuU1ftl_q",
        "outputId": "1e458943-59b0-43f2-dba8-d4826eecf70f"
      },
      "source": [
        "model = Sequential(name='Audio_CNN_1D')\n",
        "\n",
        "# LFLB1\n",
        "model.add(Conv1D(filters=64, kernel_size=(3), strides=1, padding='same', data_format='channels_last',input_shape=input_shape))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('elu'))\n",
        "model.add(MaxPooling1D(pool_size=4, strides=4))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "# LFLB2\n",
        "model.add(Conv1D(filters=64, kernel_size=3, strides=1, padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('elu'))\n",
        "model.add(MaxPooling1D(pool_size=4, strides=4))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# LFLB3\n",
        "model.add(Conv1D(filters=128, kernel_size=3, strides=1, padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('elu'))\n",
        "model.add(MaxPooling1D(pool_size=4, strides=4))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# LFLB4\n",
        "model.add(Conv1D(filters=128, kernel_size=3, strides=1, padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('elu'))\n",
        "model.add(MaxPooling1D(pool_size=4, strides=4))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# LSTM\n",
        "model.add(LSTM(units=num_lstm))\n",
        "\n",
        "# FC\n",
        "model.add(Dense(units=num_classes, activation='softmax'))\n",
        "\n",
        "# Model compilation\n",
        "opt= keras.optimizers.Adam(lr=0.01, beta_1=0.9,  beta_2=0.999, amsgrad=False)\n",
        "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
        "\n",
        "model.summary()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"Audio_CNN_1D\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_4 (Conv1D)            (None, 5070, 64)          256       \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 5070, 64)          256       \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 5070, 64)          0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_4 (MaxPooling1 (None, 1267, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 1267, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv1d_5 (Conv1D)            (None, 1267, 64)          12352     \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 1267, 64)          256       \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 1267, 64)          0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_5 (MaxPooling1 (None, 316, 64)           0         \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 316, 64)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_6 (Conv1D)            (None, 316, 128)          24704     \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 316, 128)          512       \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 316, 128)          0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_6 (MaxPooling1 (None, 79, 128)           0         \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 79, 128)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_7 (Conv1D)            (None, 79, 128)           49280     \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 79, 128)           512       \n",
            "_________________________________________________________________\n",
            "activation_7 (Activation)    (None, 79, 128)           0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_7 (MaxPooling1 (None, 19, 128)           0         \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 19, 128)           0         \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 256)               394240    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 4)                 1028      \n",
            "=================================================================\n",
            "Total params: 483,396\n",
            "Trainable params: 482,628\n",
            "Non-trainable params: 768\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gWa861hStl_r",
        "outputId": "6ed370bd-03e4-40ef-eed1-285634fc90f4"
      },
      "source": [
        "#Train Config\n",
        "\n",
        "batch_size = 16\n",
        "num_epochs = 200\n",
        "\n",
        "# Model Training\n",
        "lr_reduce = ReduceLROnPlateau(monitor='val_loss', factor=0.9, patience=20, min_lr=0.000001)\n",
        "# Please change the model name accordingly.\n",
        "mcp_save = ModelCheckpoint('/content/Audio_1DCNN.h5', save_best_only=True, monitor='val_categorical_accuracy', mode='max')\n",
        "cnnhistory=model.fit(X_train, y_train, batch_size=batch_size, epochs=num_epochs,validation_data=(X_val, y_val), callbacks=[mcp_save, lr_reduce])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "258/258 [==============================] - 9s 20ms/step - loss: 1.4048 - categorical_accuracy: 0.4170 - val_loss: 1.6584 - val_categorical_accuracy: 0.2707\n",
            "Epoch 2/200\n",
            "258/258 [==============================] - 4s 15ms/step - loss: 1.1258 - categorical_accuracy: 0.4800 - val_loss: 1.6398 - val_categorical_accuracy: 0.2052\n",
            "Epoch 3/200\n",
            "258/258 [==============================] - 4s 15ms/step - loss: 1.1063 - categorical_accuracy: 0.4961 - val_loss: 1.4347 - val_categorical_accuracy: 0.2729\n",
            "Epoch 4/200\n",
            "258/258 [==============================] - 4s 16ms/step - loss: 1.0883 - categorical_accuracy: 0.4932 - val_loss: 1.2630 - val_categorical_accuracy: 0.3734\n",
            "Epoch 5/200\n",
            "258/258 [==============================] - 4s 15ms/step - loss: 1.1365 - categorical_accuracy: 0.4715 - val_loss: 1.1851 - val_categorical_accuracy: 0.4782\n",
            "Epoch 6/200\n",
            "258/258 [==============================] - 4s 15ms/step - loss: 1.1395 - categorical_accuracy: 0.4656 - val_loss: 1.2200 - val_categorical_accuracy: 0.4585\n",
            "Epoch 7/200\n",
            "258/258 [==============================] - 4s 15ms/step - loss: 1.1146 - categorical_accuracy: 0.5055 - val_loss: 1.3473 - val_categorical_accuracy: 0.4083\n",
            "Epoch 8/200\n",
            "258/258 [==============================] - 4s 15ms/step - loss: 1.1103 - categorical_accuracy: 0.4944 - val_loss: 1.3021 - val_categorical_accuracy: 0.4389\n",
            "Epoch 9/200\n",
            "258/258 [==============================] - 4s 16ms/step - loss: 1.1028 - categorical_accuracy: 0.5068 - val_loss: 1.1484 - val_categorical_accuracy: 0.4891\n",
            "Epoch 10/200\n",
            "258/258 [==============================] - 4s 15ms/step - loss: 1.1077 - categorical_accuracy: 0.4788 - val_loss: 1.1618 - val_categorical_accuracy: 0.4738\n",
            "Epoch 11/200\n",
            "258/258 [==============================] - 4s 15ms/step - loss: 1.0766 - categorical_accuracy: 0.5012 - val_loss: 1.2115 - val_categorical_accuracy: 0.4694\n",
            "Epoch 12/200\n",
            "258/258 [==============================] - 4s 15ms/step - loss: 1.1130 - categorical_accuracy: 0.4836 - val_loss: 1.1010 - val_categorical_accuracy: 0.5066\n",
            "Epoch 13/200\n",
            "258/258 [==============================] - 4s 15ms/step - loss: 1.0450 - categorical_accuracy: 0.5208 - val_loss: 1.1984 - val_categorical_accuracy: 0.4847\n",
            "Epoch 14/200\n",
            "258/258 [==============================] - 4s 16ms/step - loss: 1.0904 - categorical_accuracy: 0.5145 - val_loss: 1.1697 - val_categorical_accuracy: 0.3668\n",
            "Epoch 15/200\n",
            "258/258 [==============================] - 4s 15ms/step - loss: 1.0939 - categorical_accuracy: 0.4886 - val_loss: 1.1048 - val_categorical_accuracy: 0.5109\n",
            "Epoch 16/200\n",
            "258/258 [==============================] - 4s 16ms/step - loss: 1.0753 - categorical_accuracy: 0.5165 - val_loss: 1.1213 - val_categorical_accuracy: 0.5153\n",
            "Epoch 17/200\n",
            "258/258 [==============================] - 4s 15ms/step - loss: 1.0959 - categorical_accuracy: 0.4953 - val_loss: 1.0894 - val_categorical_accuracy: 0.4891\n",
            "Epoch 18/200\n",
            "258/258 [==============================] - 4s 15ms/step - loss: 1.0718 - categorical_accuracy: 0.5228 - val_loss: 1.0998 - val_categorical_accuracy: 0.5153\n",
            "Epoch 19/200\n",
            "258/258 [==============================] - 4s 15ms/step - loss: 1.0809 - categorical_accuracy: 0.5076 - val_loss: 1.1070 - val_categorical_accuracy: 0.5000\n",
            "Epoch 20/200\n",
            "258/258 [==============================] - 4s 15ms/step - loss: 1.0592 - categorical_accuracy: 0.5042 - val_loss: 1.1085 - val_categorical_accuracy: 0.4956\n",
            "Epoch 21/200\n",
            "258/258 [==============================] - 4s 15ms/step - loss: 1.0667 - categorical_accuracy: 0.5226 - val_loss: 1.1099 - val_categorical_accuracy: 0.5131\n",
            "Epoch 22/200\n",
            "258/258 [==============================] - 4s 15ms/step - loss: 1.0680 - categorical_accuracy: 0.5249 - val_loss: 1.1365 - val_categorical_accuracy: 0.4913\n",
            "Epoch 23/200\n",
            "258/258 [==============================] - 4s 15ms/step - loss: 1.0578 - categorical_accuracy: 0.5249 - val_loss: 1.1097 - val_categorical_accuracy: 0.5175\n",
            "Epoch 24/200\n",
            "258/258 [==============================] - 4s 16ms/step - loss: 1.0657 - categorical_accuracy: 0.5137 - val_loss: 1.0909 - val_categorical_accuracy: 0.4694\n",
            "Epoch 25/200\n",
            "258/258 [==============================] - 4s 15ms/step - loss: 1.0590 - categorical_accuracy: 0.5139 - val_loss: 1.0896 - val_categorical_accuracy: 0.5109\n",
            "Epoch 26/200\n",
            "258/258 [==============================] - 4s 15ms/step - loss: 1.0692 - categorical_accuracy: 0.5208 - val_loss: 1.0923 - val_categorical_accuracy: 0.5109\n",
            "Epoch 27/200\n",
            "258/258 [==============================] - 4s 15ms/step - loss: 1.0622 - categorical_accuracy: 0.5112 - val_loss: 1.1009 - val_categorical_accuracy: 0.5000\n",
            "Epoch 28/200\n",
            "258/258 [==============================] - 4s 16ms/step - loss: 1.0587 - categorical_accuracy: 0.5218 - val_loss: 1.1159 - val_categorical_accuracy: 0.4607\n",
            "Epoch 29/200\n",
            "258/258 [==============================] - 4s 15ms/step - loss: 1.0640 - categorical_accuracy: 0.4896 - val_loss: 1.1089 - val_categorical_accuracy: 0.4956\n",
            "Epoch 30/200\n",
            "258/258 [==============================] - 4s 15ms/step - loss: 1.0752 - categorical_accuracy: 0.5094 - val_loss: 1.1702 - val_categorical_accuracy: 0.4738\n",
            "Epoch 31/200\n",
            "258/258 [==============================] - 4s 15ms/step - loss: 1.0788 - categorical_accuracy: 0.5011 - val_loss: 1.1205 - val_categorical_accuracy: 0.4891\n",
            "Epoch 32/200\n",
            "258/258 [==============================] - 4s 15ms/step - loss: 1.0626 - categorical_accuracy: 0.5054 - val_loss: 1.1008 - val_categorical_accuracy: 0.4956\n",
            "Epoch 33/200\n",
            "258/258 [==============================] - 4s 15ms/step - loss: 1.0380 - categorical_accuracy: 0.5183 - val_loss: 1.1490 - val_categorical_accuracy: 0.4345\n",
            "Epoch 34/200\n",
            "258/258 [==============================] - 4s 15ms/step - loss: 1.0695 - categorical_accuracy: 0.5091 - val_loss: 1.1091 - val_categorical_accuracy: 0.5000\n",
            "Epoch 35/200\n",
            "258/258 [==============================] - 4s 15ms/step - loss: 1.0294 - categorical_accuracy: 0.5351 - val_loss: 1.1004 - val_categorical_accuracy: 0.5175\n",
            "Epoch 36/200\n",
            "258/258 [==============================] - 4s 15ms/step - loss: 1.0365 - categorical_accuracy: 0.5310 - val_loss: 1.1464 - val_categorical_accuracy: 0.4934\n",
            "Epoch 37/200\n",
            "258/258 [==============================] - 4s 15ms/step - loss: 1.0585 - categorical_accuracy: 0.5087 - val_loss: 1.1317 - val_categorical_accuracy: 0.4913\n",
            "Epoch 38/200\n",
            "258/258 [==============================] - 4s 15ms/step - loss: 1.0367 - categorical_accuracy: 0.5191 - val_loss: 1.1169 - val_categorical_accuracy: 0.4934\n",
            "Epoch 39/200\n",
            "258/258 [==============================] - 4s 15ms/step - loss: 1.0616 - categorical_accuracy: 0.5153 - val_loss: 1.1342 - val_categorical_accuracy: 0.5000\n",
            "Epoch 40/200\n",
            "258/258 [==============================] - 4s 15ms/step - loss: 1.0619 - categorical_accuracy: 0.4998 - val_loss: 1.1261 - val_categorical_accuracy: 0.4956\n",
            "Epoch 41/200\n",
            "258/258 [==============================] - 4s 15ms/step - loss: 1.0505 - categorical_accuracy: 0.5054 - val_loss: 1.1142 - val_categorical_accuracy: 0.4782\n",
            "Epoch 42/200\n",
            "258/258 [==============================] - 4s 15ms/step - loss: 1.0582 - categorical_accuracy: 0.5113 - val_loss: 1.1118 - val_categorical_accuracy: 0.4978\n",
            "Epoch 43/200\n",
            "258/258 [==============================] - 4s 15ms/step - loss: 1.0517 - categorical_accuracy: 0.5160 - val_loss: 1.1411 - val_categorical_accuracy: 0.4825\n",
            "Epoch 44/200\n",
            "258/258 [==============================] - 4s 16ms/step - loss: 1.0540 - categorical_accuracy: 0.5172 - val_loss: 1.1013 - val_categorical_accuracy: 0.4956\n",
            "Epoch 45/200\n",
            "258/258 [==============================] - 4s 15ms/step - loss: 1.0395 - categorical_accuracy: 0.5166 - val_loss: 1.1553 - val_categorical_accuracy: 0.4825\n",
            "Epoch 46/200\n",
            "258/258 [==============================] - 4s 15ms/step - loss: 1.0660 - categorical_accuracy: 0.5154 - val_loss: 1.1321 - val_categorical_accuracy: 0.5153\n",
            "Epoch 47/200\n",
            "258/258 [==============================] - 4s 15ms/step - loss: 1.0342 - categorical_accuracy: 0.5367 - val_loss: 1.0880 - val_categorical_accuracy: 0.4956\n",
            "Epoch 48/200\n",
            "258/258 [==============================] - 4s 15ms/step - loss: 1.0279 - categorical_accuracy: 0.5441 - val_loss: 1.0965 - val_categorical_accuracy: 0.5109\n",
            "Epoch 49/200\n",
            "258/258 [==============================] - 4s 16ms/step - loss: 1.0458 - categorical_accuracy: 0.5265 - val_loss: 1.1256 - val_categorical_accuracy: 0.4956\n",
            "Epoch 50/200\n",
            "258/258 [==============================] - 4s 15ms/step - loss: 1.0773 - categorical_accuracy: 0.5281 - val_loss: 1.1153 - val_categorical_accuracy: 0.4891\n",
            "Epoch 51/200\n",
            "258/258 [==============================] - 4s 15ms/step - loss: 1.0404 - categorical_accuracy: 0.5332 - val_loss: 1.0874 - val_categorical_accuracy: 0.4934\n",
            "Epoch 52/200\n",
            "258/258 [==============================] - 4s 16ms/step - loss: 1.0978 - categorical_accuracy: 0.4978 - val_loss: 1.1072 - val_categorical_accuracy: 0.4803\n",
            "Epoch 53/200\n",
            "258/258 [==============================] - 4s 15ms/step - loss: 1.0510 - categorical_accuracy: 0.5214 - val_loss: 1.1176 - val_categorical_accuracy: 0.4956\n",
            "Epoch 54/200\n",
            "258/258 [==============================] - 4s 15ms/step - loss: 1.0461 - categorical_accuracy: 0.5208 - val_loss: 1.0805 - val_categorical_accuracy: 0.5153\n",
            "Epoch 55/200\n",
            "258/258 [==============================] - 4s 15ms/step - loss: 1.0352 - categorical_accuracy: 0.5328 - val_loss: 1.0713 - val_categorical_accuracy: 0.5262\n",
            "Epoch 56/200\n",
            "258/258 [==============================] - 4s 15ms/step - loss: 1.0209 - categorical_accuracy: 0.5399 - val_loss: 1.0717 - val_categorical_accuracy: 0.5109\n",
            "Epoch 57/200\n",
            "258/258 [==============================] - 4s 16ms/step - loss: 1.0689 - categorical_accuracy: 0.4934 - val_loss: 1.1515 - val_categorical_accuracy: 0.5044\n",
            "Epoch 58/200\n",
            "258/258 [==============================] - 4s 15ms/step - loss: 1.0540 - categorical_accuracy: 0.5184 - val_loss: 1.1064 - val_categorical_accuracy: 0.5022\n",
            "Epoch 59/200\n",
            "258/258 [==============================] - 4s 15ms/step - loss: 1.0659 - categorical_accuracy: 0.5121 - val_loss: 1.0820 - val_categorical_accuracy: 0.5153\n",
            "Epoch 60/200\n",
            "258/258 [==============================] - 4s 16ms/step - loss: 1.0559 - categorical_accuracy: 0.5274 - val_loss: 1.1325 - val_categorical_accuracy: 0.5066\n",
            "Epoch 61/200\n",
            "258/258 [==============================] - 4s 16ms/step - loss: 1.0431 - categorical_accuracy: 0.5146 - val_loss: 1.1022 - val_categorical_accuracy: 0.5197\n",
            "Epoch 62/200\n",
            "258/258 [==============================] - 4s 15ms/step - loss: 1.0315 - categorical_accuracy: 0.5289 - val_loss: 1.0762 - val_categorical_accuracy: 0.5240\n",
            "Epoch 63/200\n",
            "258/258 [==============================] - 4s 15ms/step - loss: 1.0024 - categorical_accuracy: 0.5571 - val_loss: 1.0615 - val_categorical_accuracy: 0.5306\n",
            "Epoch 64/200\n",
            "258/258 [==============================] - 4s 15ms/step - loss: 1.0371 - categorical_accuracy: 0.5292 - val_loss: 1.0663 - val_categorical_accuracy: 0.4869\n",
            "Epoch 65/200\n",
            "258/258 [==============================] - 4s 15ms/step - loss: 1.0175 - categorical_accuracy: 0.5443 - val_loss: 1.0716 - val_categorical_accuracy: 0.5087\n",
            "Epoch 66/200\n",
            "258/258 [==============================] - 4s 15ms/step - loss: 1.0158 - categorical_accuracy: 0.5446 - val_loss: 1.0908 - val_categorical_accuracy: 0.5109\n",
            "Epoch 67/200\n",
            "258/258 [==============================] - 4s 15ms/step - loss: 1.0591 - categorical_accuracy: 0.5239 - val_loss: 1.1535 - val_categorical_accuracy: 0.4105\n",
            "Epoch 68/200\n",
            "258/258 [==============================] - 4s 15ms/step - loss: 1.0369 - categorical_accuracy: 0.5142 - val_loss: 1.1266 - val_categorical_accuracy: 0.5109\n",
            "Epoch 69/200\n",
            "258/258 [==============================] - 4s 15ms/step - loss: 1.0130 - categorical_accuracy: 0.5463 - val_loss: 1.1558 - val_categorical_accuracy: 0.4891\n",
            "Epoch 70/200\n",
            "258/258 [==============================] - 4s 15ms/step - loss: 1.0351 - categorical_accuracy: 0.5422 - val_loss: 1.0690 - val_categorical_accuracy: 0.4869\n",
            "Epoch 71/200\n",
            "258/258 [==============================] - 4s 16ms/step - loss: 1.0381 - categorical_accuracy: 0.5189 - val_loss: 1.0904 - val_categorical_accuracy: 0.5066\n",
            "Epoch 72/200\n",
            "258/258 [==============================] - 4s 15ms/step - loss: 1.0518 - categorical_accuracy: 0.5208 - val_loss: 1.0261 - val_categorical_accuracy: 0.5393\n",
            "Epoch 73/200\n",
            "258/258 [==============================] - 4s 15ms/step - loss: 1.0151 - categorical_accuracy: 0.5204 - val_loss: 1.0660 - val_categorical_accuracy: 0.5153\n",
            "Epoch 74/200\n",
            "258/258 [==============================] - 4s 16ms/step - loss: 1.0476 - categorical_accuracy: 0.5098 - val_loss: 1.0605 - val_categorical_accuracy: 0.5349\n",
            "Epoch 75/200\n",
            "258/258 [==============================] - 4s 15ms/step - loss: 1.0240 - categorical_accuracy: 0.5247 - val_loss: 1.0599 - val_categorical_accuracy: 0.5197\n",
            "Epoch 76/200\n",
            "258/258 [==============================] - 4s 15ms/step - loss: 1.0799 - categorical_accuracy: 0.5114 - val_loss: 1.0662 - val_categorical_accuracy: 0.5328\n",
            "Epoch 77/200\n",
            "258/258 [==============================] - 4s 16ms/step - loss: 1.0466 - categorical_accuracy: 0.5405 - val_loss: 1.0898 - val_categorical_accuracy: 0.5066\n",
            "Epoch 78/200\n",
            "258/258 [==============================] - 4s 15ms/step - loss: 1.0258 - categorical_accuracy: 0.5362 - val_loss: 1.0695 - val_categorical_accuracy: 0.5109\n",
            "Epoch 79/200\n",
            "258/258 [==============================] - 4s 15ms/step - loss: 1.0349 - categorical_accuracy: 0.5190 - val_loss: 1.0413 - val_categorical_accuracy: 0.5197\n",
            "Epoch 80/200\n",
            "258/258 [==============================] - 4s 15ms/step - loss: 1.0224 - categorical_accuracy: 0.5345 - val_loss: 1.0586 - val_categorical_accuracy: 0.5262\n",
            "Epoch 81/200\n",
            "258/258 [==============================] - 4s 15ms/step - loss: 1.0390 - categorical_accuracy: 0.5356 - val_loss: 1.0698 - val_categorical_accuracy: 0.4891\n",
            "Epoch 82/200\n",
            "258/258 [==============================] - 4s 15ms/step - loss: 1.0215 - categorical_accuracy: 0.5429 - val_loss: 1.0966 - val_categorical_accuracy: 0.5153\n",
            "Epoch 83/200\n",
            "258/258 [==============================] - 4s 16ms/step - loss: 1.0251 - categorical_accuracy: 0.5323 - val_loss: 1.0983 - val_categorical_accuracy: 0.5197\n",
            "Epoch 84/200\n",
            "258/258 [==============================] - 4s 15ms/step - loss: 1.0308 - categorical_accuracy: 0.5405 - val_loss: 1.0866 - val_categorical_accuracy: 0.5109\n",
            "Epoch 85/200\n",
            "258/258 [==============================] - 4s 15ms/step - loss: 1.0427 - categorical_accuracy: 0.5252 - val_loss: 1.1209 - val_categorical_accuracy: 0.4672\n",
            "Epoch 86/200\n",
            "258/258 [==============================] - 4s 16ms/step - loss: 1.0537 - categorical_accuracy: 0.5238 - val_loss: 1.0991 - val_categorical_accuracy: 0.5109\n",
            "Epoch 87/200\n",
            "258/258 [==============================] - 4s 15ms/step - loss: 1.0727 - categorical_accuracy: 0.5068 - val_loss: 1.0992 - val_categorical_accuracy: 0.4825\n",
            "Epoch 88/200\n",
            "258/258 [==============================] - 4s 15ms/step - loss: 1.0461 - categorical_accuracy: 0.5407 - val_loss: 1.2731 - val_categorical_accuracy: 0.4803\n",
            "Epoch 89/200\n",
            "258/258 [==============================] - 4s 15ms/step - loss: 1.0866 - categorical_accuracy: 0.5059 - val_loss: 1.0611 - val_categorical_accuracy: 0.5175\n",
            "Epoch 90/200\n",
            "258/258 [==============================] - 4s 15ms/step - loss: 1.0539 - categorical_accuracy: 0.5203 - val_loss: 1.0786 - val_categorical_accuracy: 0.5000\n",
            "Epoch 91/200\n",
            "258/258 [==============================] - 4s 16ms/step - loss: 1.0403 - categorical_accuracy: 0.5286 - val_loss: 1.0958 - val_categorical_accuracy: 0.4869\n",
            "Epoch 92/200\n",
            "258/258 [==============================] - 4s 15ms/step - loss: 1.0438 - categorical_accuracy: 0.5303 - val_loss: 1.1295 - val_categorical_accuracy: 0.4913\n",
            "Epoch 93/200\n",
            "258/258 [==============================] - 4s 15ms/step - loss: 1.0550 - categorical_accuracy: 0.5207 - val_loss: 1.1189 - val_categorical_accuracy: 0.4847\n",
            "Epoch 94/200\n",
            "258/258 [==============================] - 4s 15ms/step - loss: 1.0366 - categorical_accuracy: 0.5264 - val_loss: 1.0814 - val_categorical_accuracy: 0.5153\n",
            "Epoch 95/200\n",
            "258/258 [==============================] - 4s 16ms/step - loss: 1.0373 - categorical_accuracy: 0.5268 - val_loss: 1.0809 - val_categorical_accuracy: 0.4978\n",
            "Epoch 96/200\n",
            "258/258 [==============================] - 4s 15ms/step - loss: 1.0275 - categorical_accuracy: 0.5384 - val_loss: 1.0977 - val_categorical_accuracy: 0.5087\n",
            "Epoch 97/200\n",
            "258/258 [==============================] - 4s 16ms/step - loss: 1.0352 - categorical_accuracy: 0.5393 - val_loss: 1.1323 - val_categorical_accuracy: 0.4978\n",
            "Epoch 98/200\n",
            "258/258 [==============================] - 4s 16ms/step - loss: 1.0464 - categorical_accuracy: 0.5218 - val_loss: 1.0642 - val_categorical_accuracy: 0.5044\n",
            "Epoch 99/200\n",
            "258/258 [==============================] - 4s 15ms/step - loss: 1.0215 - categorical_accuracy: 0.5352 - val_loss: 1.0949 - val_categorical_accuracy: 0.5175\n",
            "Epoch 100/200\n",
            "258/258 [==============================] - 4s 15ms/step - loss: 1.0412 - categorical_accuracy: 0.5186 - val_loss: 1.1187 - val_categorical_accuracy: 0.4563\n",
            "Epoch 101/200\n",
            "258/258 [==============================] - 4s 15ms/step - loss: 1.0320 - categorical_accuracy: 0.5350 - val_loss: 1.1106 - val_categorical_accuracy: 0.4913\n",
            "Epoch 102/200\n",
            "258/258 [==============================] - 4s 15ms/step - loss: 1.0283 - categorical_accuracy: 0.5426 - val_loss: 1.1018 - val_categorical_accuracy: 0.5109\n",
            "Epoch 103/200\n",
            "258/258 [==============================] - 4s 15ms/step - loss: 1.0209 - categorical_accuracy: 0.5287 - val_loss: 1.1152 - val_categorical_accuracy: 0.4825\n",
            "Epoch 104/200\n",
            "258/258 [==============================] - 4s 15ms/step - loss: 1.0300 - categorical_accuracy: 0.5440 - val_loss: 1.0690 - val_categorical_accuracy: 0.4891\n",
            "Epoch 105/200\n",
            "258/258 [==============================] - 4s 15ms/step - loss: 1.0293 - categorical_accuracy: 0.5253 - val_loss: 1.1076 - val_categorical_accuracy: 0.4956\n",
            "Epoch 106/200\n",
            "258/258 [==============================] - 4s 15ms/step - loss: 1.0347 - categorical_accuracy: 0.5342 - val_loss: 1.1133 - val_categorical_accuracy: 0.4782\n",
            "Epoch 107/200\n",
            "258/258 [==============================] - 4s 15ms/step - loss: 1.0477 - categorical_accuracy: 0.5246 - val_loss: 1.0880 - val_categorical_accuracy: 0.5022\n",
            "Epoch 108/200\n",
            "258/258 [==============================] - 4s 15ms/step - loss: 1.0309 - categorical_accuracy: 0.5449 - val_loss: 1.1797 - val_categorical_accuracy: 0.4410\n",
            "Epoch 109/200\n",
            "258/258 [==============================] - 4s 15ms/step - loss: 1.0307 - categorical_accuracy: 0.5270 - val_loss: 1.1149 - val_categorical_accuracy: 0.5066\n",
            "Epoch 110/200\n",
            "258/258 [==============================] - 4s 15ms/step - loss: 1.0412 - categorical_accuracy: 0.5353 - val_loss: 1.1413 - val_categorical_accuracy: 0.5087\n",
            "Epoch 111/200\n",
            "258/258 [==============================] - 4s 16ms/step - loss: 1.0283 - categorical_accuracy: 0.5375 - val_loss: 1.0701 - val_categorical_accuracy: 0.5175\n",
            "Epoch 112/200\n",
            "258/258 [==============================] - 4s 15ms/step - loss: 1.0323 - categorical_accuracy: 0.5185 - val_loss: 1.0870 - val_categorical_accuracy: 0.4934\n",
            "Epoch 113/200\n",
            "258/258 [==============================] - 4s 16ms/step - loss: 1.0051 - categorical_accuracy: 0.5452 - val_loss: 1.0681 - val_categorical_accuracy: 0.5131\n",
            "Epoch 114/200\n",
            "258/258 [==============================] - 4s 16ms/step - loss: 1.0212 - categorical_accuracy: 0.5369 - val_loss: 1.1821 - val_categorical_accuracy: 0.4934\n",
            "Epoch 115/200\n",
            "258/258 [==============================] - 4s 15ms/step - loss: 1.0453 - categorical_accuracy: 0.5227 - val_loss: 1.1370 - val_categorical_accuracy: 0.4913\n",
            "Epoch 116/200\n",
            "258/258 [==============================] - 4s 15ms/step - loss: 1.0225 - categorical_accuracy: 0.5341 - val_loss: 1.1170 - val_categorical_accuracy: 0.5066\n",
            "Epoch 117/200\n",
            "258/258 [==============================] - 4s 15ms/step - loss: 1.0265 - categorical_accuracy: 0.5327 - val_loss: 1.0698 - val_categorical_accuracy: 0.5306\n",
            "Epoch 118/200\n",
            "258/258 [==============================] - 4s 15ms/step - loss: 1.0406 - categorical_accuracy: 0.5280 - val_loss: 1.0869 - val_categorical_accuracy: 0.5131\n",
            "Epoch 119/200\n",
            "258/258 [==============================] - 4s 15ms/step - loss: 1.0163 - categorical_accuracy: 0.5316 - val_loss: 1.0886 - val_categorical_accuracy: 0.5153\n",
            "Epoch 120/200\n",
            "258/258 [==============================] - 4s 15ms/step - loss: 1.0196 - categorical_accuracy: 0.5335 - val_loss: 1.0878 - val_categorical_accuracy: 0.5371\n",
            "Epoch 121/200\n",
            "258/258 [==============================] - 4s 15ms/step - loss: 0.9961 - categorical_accuracy: 0.5576 - val_loss: 1.0887 - val_categorical_accuracy: 0.5175\n",
            "Epoch 122/200\n",
            "258/258 [==============================] - 4s 15ms/step - loss: 1.0114 - categorical_accuracy: 0.5453 - val_loss: 1.0972 - val_categorical_accuracy: 0.4978\n",
            "Epoch 123/200\n",
            "258/258 [==============================] - 4s 15ms/step - loss: 1.0133 - categorical_accuracy: 0.5449 - val_loss: 1.0832 - val_categorical_accuracy: 0.4869\n",
            "Epoch 124/200\n",
            "258/258 [==============================] - 4s 15ms/step - loss: 0.9796 - categorical_accuracy: 0.5599 - val_loss: 1.0648 - val_categorical_accuracy: 0.4913\n",
            "Epoch 125/200\n",
            "258/258 [==============================] - 4s 15ms/step - loss: 1.0004 - categorical_accuracy: 0.5603 - val_loss: 1.0701 - val_categorical_accuracy: 0.5044\n",
            "Epoch 126/200\n",
            "258/258 [==============================] - 4s 15ms/step - loss: 1.0100 - categorical_accuracy: 0.5518 - val_loss: 1.0678 - val_categorical_accuracy: 0.5197\n",
            "Epoch 127/200\n",
            "258/258 [==============================] - 4s 15ms/step - loss: 1.0192 - categorical_accuracy: 0.5331 - val_loss: 1.0675 - val_categorical_accuracy: 0.5175\n",
            "Epoch 128/200\n",
            "258/258 [==============================] - 4s 15ms/step - loss: 1.0282 - categorical_accuracy: 0.5373 - val_loss: 1.0757 - val_categorical_accuracy: 0.5349\n",
            "Epoch 129/200\n",
            "258/258 [==============================] - 4s 15ms/step - loss: 0.9958 - categorical_accuracy: 0.5478 - val_loss: 1.0941 - val_categorical_accuracy: 0.5022\n",
            "Epoch 130/200\n",
            "258/258 [==============================] - 4s 16ms/step - loss: 1.0209 - categorical_accuracy: 0.5546 - val_loss: 1.0476 - val_categorical_accuracy: 0.5240\n",
            "Epoch 131/200\n",
            "258/258 [==============================] - 4s 15ms/step - loss: 1.0287 - categorical_accuracy: 0.5426 - val_loss: 1.0930 - val_categorical_accuracy: 0.5000\n",
            "Epoch 132/200\n",
            "258/258 [==============================] - 4s 16ms/step - loss: 1.0071 - categorical_accuracy: 0.5538 - val_loss: 1.1091 - val_categorical_accuracy: 0.4803\n",
            "Epoch 133/200\n",
            "258/258 [==============================] - 4s 16ms/step - loss: 1.0275 - categorical_accuracy: 0.5327 - val_loss: 1.0922 - val_categorical_accuracy: 0.5153\n",
            "Epoch 134/200\n",
            "258/258 [==============================] - 4s 15ms/step - loss: 0.9688 - categorical_accuracy: 0.5692 - val_loss: 1.0708 - val_categorical_accuracy: 0.5306\n",
            "Epoch 135/200\n",
            "258/258 [==============================] - 4s 15ms/step - loss: 0.9907 - categorical_accuracy: 0.5606 - val_loss: 1.0867 - val_categorical_accuracy: 0.5262\n",
            "Epoch 136/200\n",
            "258/258 [==============================] - 4s 16ms/step - loss: 1.0124 - categorical_accuracy: 0.5442 - val_loss: 1.0788 - val_categorical_accuracy: 0.5109\n",
            "Epoch 137/200\n",
            "258/258 [==============================] - 4s 15ms/step - loss: 0.9961 - categorical_accuracy: 0.5486 - val_loss: 1.0830 - val_categorical_accuracy: 0.5306\n",
            "Epoch 138/200\n",
            "258/258 [==============================] - 4s 15ms/step - loss: 1.0116 - categorical_accuracy: 0.5399 - val_loss: 1.1085 - val_categorical_accuracy: 0.5109\n",
            "Epoch 139/200\n",
            "258/258 [==============================] - 4s 15ms/step - loss: 0.9957 - categorical_accuracy: 0.5490 - val_loss: 1.0658 - val_categorical_accuracy: 0.5218\n",
            "Epoch 140/200\n",
            "258/258 [==============================] - 4s 16ms/step - loss: 1.0049 - categorical_accuracy: 0.5436 - val_loss: 1.1075 - val_categorical_accuracy: 0.5087\n",
            "Epoch 141/200\n",
            "258/258 [==============================] - 4s 15ms/step - loss: 1.0121 - categorical_accuracy: 0.5315 - val_loss: 1.0643 - val_categorical_accuracy: 0.5240\n",
            "Epoch 142/200\n",
            "258/258 [==============================] - 4s 15ms/step - loss: 0.9993 - categorical_accuracy: 0.5636 - val_loss: 1.0959 - val_categorical_accuracy: 0.4956\n",
            "Epoch 143/200\n",
            "258/258 [==============================] - 4s 15ms/step - loss: 0.9841 - categorical_accuracy: 0.5646 - val_loss: 1.0977 - val_categorical_accuracy: 0.4869\n",
            "Epoch 144/200\n",
            "258/258 [==============================] - 4s 16ms/step - loss: 0.9985 - categorical_accuracy: 0.5502 - val_loss: 1.0627 - val_categorical_accuracy: 0.5284\n",
            "Epoch 145/200\n",
            "258/258 [==============================] - 4s 16ms/step - loss: 0.9916 - categorical_accuracy: 0.5578 - val_loss: 1.0719 - val_categorical_accuracy: 0.5153\n",
            "Epoch 146/200\n",
            "258/258 [==============================] - 4s 15ms/step - loss: 0.9820 - categorical_accuracy: 0.5547 - val_loss: 1.0811 - val_categorical_accuracy: 0.5175\n",
            "Epoch 147/200\n",
            "258/258 [==============================] - 4s 15ms/step - loss: 0.9788 - categorical_accuracy: 0.5614 - val_loss: 1.1115 - val_categorical_accuracy: 0.4913\n",
            "Epoch 148/200\n",
            "258/258 [==============================] - 4s 16ms/step - loss: 0.9788 - categorical_accuracy: 0.5535 - val_loss: 1.0544 - val_categorical_accuracy: 0.5284\n",
            "Epoch 149/200\n",
            "258/258 [==============================] - 4s 15ms/step - loss: 0.9796 - categorical_accuracy: 0.5588 - val_loss: 1.0786 - val_categorical_accuracy: 0.5240\n",
            "Epoch 150/200\n",
            "258/258 [==============================] - 4s 15ms/step - loss: 1.0233 - categorical_accuracy: 0.5235 - val_loss: 1.0493 - val_categorical_accuracy: 0.5306\n",
            "Epoch 151/200\n",
            "258/258 [==============================] - 4s 16ms/step - loss: 1.0194 - categorical_accuracy: 0.5334 - val_loss: 1.0595 - val_categorical_accuracy: 0.5087\n",
            "Epoch 152/200\n",
            "258/258 [==============================] - 4s 15ms/step - loss: 0.9996 - categorical_accuracy: 0.5482 - val_loss: 1.1307 - val_categorical_accuracy: 0.4629\n",
            "Epoch 153/200\n",
            "258/258 [==============================] - 4s 16ms/step - loss: 1.0160 - categorical_accuracy: 0.5324 - val_loss: 1.0565 - val_categorical_accuracy: 0.5262\n",
            "Epoch 154/200\n",
            "258/258 [==============================] - 4s 16ms/step - loss: 0.9982 - categorical_accuracy: 0.5514 - val_loss: 1.0502 - val_categorical_accuracy: 0.5087\n",
            "Epoch 155/200\n",
            "258/258 [==============================] - 4s 15ms/step - loss: 1.0128 - categorical_accuracy: 0.5464 - val_loss: 1.0619 - val_categorical_accuracy: 0.5328\n",
            "Epoch 156/200\n",
            "258/258 [==============================] - 4s 16ms/step - loss: 1.0320 - categorical_accuracy: 0.5405 - val_loss: 1.0807 - val_categorical_accuracy: 0.4978\n",
            "Epoch 157/200\n",
            "258/258 [==============================] - 4s 15ms/step - loss: 0.9830 - categorical_accuracy: 0.5579 - val_loss: 1.0554 - val_categorical_accuracy: 0.5175\n",
            "Epoch 158/200\n",
            "258/258 [==============================] - 4s 16ms/step - loss: 1.0021 - categorical_accuracy: 0.5403 - val_loss: 1.0852 - val_categorical_accuracy: 0.4978\n",
            "Epoch 159/200\n",
            "258/258 [==============================] - 4s 16ms/step - loss: 0.9835 - categorical_accuracy: 0.5553 - val_loss: 1.0728 - val_categorical_accuracy: 0.4869\n",
            "Epoch 160/200\n",
            "258/258 [==============================] - 4s 16ms/step - loss: 1.0091 - categorical_accuracy: 0.5312 - val_loss: 1.0631 - val_categorical_accuracy: 0.5000\n",
            "Epoch 161/200\n",
            "258/258 [==============================] - 4s 16ms/step - loss: 0.9915 - categorical_accuracy: 0.5588 - val_loss: 1.0468 - val_categorical_accuracy: 0.5262\n",
            "Epoch 162/200\n",
            "258/258 [==============================] - 4s 16ms/step - loss: 1.0050 - categorical_accuracy: 0.5313 - val_loss: 1.0971 - val_categorical_accuracy: 0.5306\n",
            "Epoch 163/200\n",
            "258/258 [==============================] - 4s 16ms/step - loss: 0.9864 - categorical_accuracy: 0.5717 - val_loss: 1.0655 - val_categorical_accuracy: 0.5175\n",
            "Epoch 164/200\n",
            "258/258 [==============================] - 4s 16ms/step - loss: 0.9731 - categorical_accuracy: 0.5686 - val_loss: 1.0334 - val_categorical_accuracy: 0.5284\n",
            "Epoch 165/200\n",
            "258/258 [==============================] - 4s 16ms/step - loss: 0.9788 - categorical_accuracy: 0.5683 - val_loss: 1.0496 - val_categorical_accuracy: 0.5437\n",
            "Epoch 166/200\n",
            "258/258 [==============================] - 4s 15ms/step - loss: 0.9994 - categorical_accuracy: 0.5534 - val_loss: 1.0542 - val_categorical_accuracy: 0.5109\n",
            "Epoch 167/200\n",
            "258/258 [==============================] - 4s 16ms/step - loss: 1.0028 - categorical_accuracy: 0.5371 - val_loss: 1.0494 - val_categorical_accuracy: 0.5240\n",
            "Epoch 168/200\n",
            "258/258 [==============================] - 4s 16ms/step - loss: 0.9970 - categorical_accuracy: 0.5575 - val_loss: 1.0947 - val_categorical_accuracy: 0.5044\n",
            "Epoch 169/200\n",
            "258/258 [==============================] - 4s 16ms/step - loss: 0.9744 - categorical_accuracy: 0.5700 - val_loss: 1.1491 - val_categorical_accuracy: 0.4913\n",
            "Epoch 170/200\n",
            "258/258 [==============================] - 4s 15ms/step - loss: 0.9968 - categorical_accuracy: 0.5535 - val_loss: 1.0783 - val_categorical_accuracy: 0.5306\n",
            "Epoch 171/200\n",
            "258/258 [==============================] - 4s 16ms/step - loss: 0.9794 - categorical_accuracy: 0.5634 - val_loss: 1.0694 - val_categorical_accuracy: 0.5197\n",
            "Epoch 172/200\n",
            "258/258 [==============================] - 4s 16ms/step - loss: 0.9972 - categorical_accuracy: 0.5604 - val_loss: 1.1000 - val_categorical_accuracy: 0.5153\n",
            "Epoch 173/200\n",
            "258/258 [==============================] - 4s 16ms/step - loss: 0.9899 - categorical_accuracy: 0.5569 - val_loss: 1.0773 - val_categorical_accuracy: 0.5044\n",
            "Epoch 174/200\n",
            "258/258 [==============================] - 4s 15ms/step - loss: 0.9798 - categorical_accuracy: 0.5581 - val_loss: 1.0213 - val_categorical_accuracy: 0.5349\n",
            "Epoch 175/200\n",
            "258/258 [==============================] - 4s 15ms/step - loss: 0.9956 - categorical_accuracy: 0.5497 - val_loss: 1.0395 - val_categorical_accuracy: 0.5568\n",
            "Epoch 176/200\n",
            "258/258 [==============================] - 4s 15ms/step - loss: 0.9779 - categorical_accuracy: 0.5620 - val_loss: 1.0599 - val_categorical_accuracy: 0.5240\n",
            "Epoch 177/200\n",
            "258/258 [==============================] - 4s 15ms/step - loss: 0.9645 - categorical_accuracy: 0.5730 - val_loss: 1.0461 - val_categorical_accuracy: 0.5197\n",
            "Epoch 178/200\n",
            "258/258 [==============================] - 4s 15ms/step - loss: 0.9874 - categorical_accuracy: 0.5634 - val_loss: 1.0425 - val_categorical_accuracy: 0.5284\n",
            "Epoch 179/200\n",
            "258/258 [==============================] - 4s 15ms/step - loss: 1.0052 - categorical_accuracy: 0.5585 - val_loss: 1.0529 - val_categorical_accuracy: 0.5131\n",
            "Epoch 180/200\n",
            "258/258 [==============================] - 4s 16ms/step - loss: 0.9940 - categorical_accuracy: 0.5615 - val_loss: 1.1242 - val_categorical_accuracy: 0.4825\n",
            "Epoch 181/200\n",
            "258/258 [==============================] - 4s 16ms/step - loss: 0.9804 - categorical_accuracy: 0.5647 - val_loss: 1.0615 - val_categorical_accuracy: 0.5175\n",
            "Epoch 182/200\n",
            "258/258 [==============================] - 4s 15ms/step - loss: 0.9767 - categorical_accuracy: 0.5600 - val_loss: 1.0964 - val_categorical_accuracy: 0.5044\n",
            "Epoch 183/200\n",
            "258/258 [==============================] - 4s 16ms/step - loss: 0.9843 - categorical_accuracy: 0.5645 - val_loss: 1.0511 - val_categorical_accuracy: 0.5131\n",
            "Epoch 184/200\n",
            "258/258 [==============================] - 4s 16ms/step - loss: 0.9495 - categorical_accuracy: 0.5806 - val_loss: 1.0687 - val_categorical_accuracy: 0.5328\n",
            "Epoch 185/200\n",
            "258/258 [==============================] - 4s 16ms/step - loss: 0.9594 - categorical_accuracy: 0.5719 - val_loss: 1.0641 - val_categorical_accuracy: 0.5284\n",
            "Epoch 186/200\n",
            "258/258 [==============================] - 4s 16ms/step - loss: 0.9735 - categorical_accuracy: 0.5666 - val_loss: 1.0537 - val_categorical_accuracy: 0.5131\n",
            "Epoch 187/200\n",
            "258/258 [==============================] - 4s 15ms/step - loss: 0.9485 - categorical_accuracy: 0.5774 - val_loss: 1.0480 - val_categorical_accuracy: 0.5415\n",
            "Epoch 188/200\n",
            "258/258 [==============================] - 4s 16ms/step - loss: 0.9678 - categorical_accuracy: 0.5677 - val_loss: 1.0706 - val_categorical_accuracy: 0.5044\n",
            "Epoch 189/200\n",
            "258/258 [==============================] - 4s 16ms/step - loss: 0.9921 - categorical_accuracy: 0.5535 - val_loss: 1.0752 - val_categorical_accuracy: 0.5109\n",
            "Epoch 190/200\n",
            "258/258 [==============================] - 4s 16ms/step - loss: 0.9551 - categorical_accuracy: 0.5872 - val_loss: 1.0692 - val_categorical_accuracy: 0.5328\n",
            "Epoch 191/200\n",
            "258/258 [==============================] - 4s 16ms/step - loss: 0.9639 - categorical_accuracy: 0.5722 - val_loss: 1.0752 - val_categorical_accuracy: 0.5197\n",
            "Epoch 192/200\n",
            "258/258 [==============================] - 4s 16ms/step - loss: 0.9750 - categorical_accuracy: 0.5516 - val_loss: 1.0568 - val_categorical_accuracy: 0.5197\n",
            "Epoch 193/200\n",
            "258/258 [==============================] - 4s 16ms/step - loss: 0.9810 - categorical_accuracy: 0.5486 - val_loss: 1.0518 - val_categorical_accuracy: 0.5175\n",
            "Epoch 194/200\n",
            "258/258 [==============================] - 4s 16ms/step - loss: 0.9763 - categorical_accuracy: 0.5662 - val_loss: 1.0405 - val_categorical_accuracy: 0.5262\n",
            "Epoch 195/200\n",
            "258/258 [==============================] - 4s 15ms/step - loss: 0.9820 - categorical_accuracy: 0.5623 - val_loss: 1.0678 - val_categorical_accuracy: 0.5218\n",
            "Epoch 196/200\n",
            "258/258 [==============================] - 4s 16ms/step - loss: 0.9674 - categorical_accuracy: 0.5775 - val_loss: 1.0359 - val_categorical_accuracy: 0.5240\n",
            "Epoch 197/200\n",
            "258/258 [==============================] - 4s 16ms/step - loss: 0.9718 - categorical_accuracy: 0.5664 - val_loss: 1.0517 - val_categorical_accuracy: 0.5131\n",
            "Epoch 198/200\n",
            "258/258 [==============================] - 4s 16ms/step - loss: 0.9935 - categorical_accuracy: 0.5485 - val_loss: 1.0322 - val_categorical_accuracy: 0.5175\n",
            "Epoch 199/200\n",
            "258/258 [==============================] - 4s 16ms/step - loss: 0.9937 - categorical_accuracy: 0.5480 - val_loss: 1.0874 - val_categorical_accuracy: 0.4956\n",
            "Epoch 200/200\n",
            "258/258 [==============================] - 4s 16ms/step - loss: 0.9777 - categorical_accuracy: 0.5498 - val_loss: 1.0649 - val_categorical_accuracy: 0.5240\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLR1ErfJtl_u"
      },
      "source": [
        "model.save('/content/drive/MyDrive/Colab Notebooks/SPEECH_EMOTION_Recognition/Nộp bài(chốt hạ)/model_saver/conv1D_mfcc39_cremad.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_BPApCAktl_v"
      },
      "source": [
        "###test_result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QIA-4r7Itl_z",
        "outputId": "524afb0f-5327-4632-8d31-372e79380af5"
      },
      "source": [
        "d = {0: 'happy',\n",
        "     1: 'sad',\n",
        "     2: 'angry',\n",
        "     3: 'fear'}\n",
        "Y_test_pred = np.argmax(model.predict(X_test), axis=-1)\n",
        "Y_test_pred = list(map(lambda x: d[x], Y_test_pred))\n",
        "y_test = np.argmax(y_test, axis=-1)\n",
        "y_test = list(map(lambda x: d[x], y_test))\n",
        "print(classification_report(y_test, Y_test_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.67      0.60      0.63       136\n",
            "        fear       0.42      0.44      0.43       134\n",
            "       happy       0.49      0.53      0.51       120\n",
            "         sad       0.66      0.66      0.66       119\n",
            "\n",
            "    accuracy                           0.55       509\n",
            "   macro avg       0.56      0.56      0.56       509\n",
            "weighted avg       0.56      0.55      0.56       509\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 483
        },
        "id": "I0UmO3Fntl_1",
        "outputId": "3955e94b-76a6-4b4f-f1af-efccb91dd66e"
      },
      "source": [
        "import scikitplot as skplt\n",
        "\n",
        "skplt.metrics.plot_confusion_matrix(\n",
        "    y_test, \n",
        "    Y_test_pred,\n",
        "    figsize=(8,8))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fa3b6165110>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h6l5qGTKtl_3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8JPwepBQ2ndF"
      },
      "source": [
        "# mfcc_13 + conv2D:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wmPx3AB62ndc"
      },
      "source": [
        "audio_duration = 3\n",
        "sampling_rate = 22050\n",
        "input_length = sampling_rate * audio_duration"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJyazlkFuJXs"
      },
      "source": [
        "data = {'labels': [],\n",
        "        'features': []}\n",
        "\n",
        "for i in range(len(CREMA_D_df)):\n",
        "  if ((CREMA_D_df['Emotion'][i] == 'HAP') | (CREMA_D_df['Emotion'][i] == 'SAD') | \n",
        "      (CREMA_D_df['Emotion'][i] == 'ANG') | (CREMA_D_df['Emotion'][i] == 'FEA')):\n",
        "    \n",
        "    if CREMA_D_df['Emotion'][i] == 'HAP':\n",
        "      data['labels'].append(0)\n",
        "    elif CREMA_D_df['Emotion'][i] == 'SAD':\n",
        "      data['labels'].append(1)\n",
        "    elif CREMA_D_df['Emotion'][i] == 'ANG':\n",
        "      data['labels'].append(2)\n",
        "    elif CREMA_D_df['Emotion'][i] == 'FEA':\n",
        "      data['labels'].append(3)\n",
        "\n",
        "\n",
        "    signal, sr =  librosa.load(CREMA_D_df['Paths'][i])\n",
        "\n",
        "    if len(signal) > input_length:\n",
        "        signal = signal[0:input_length]\n",
        "    elif  input_length > len(signal):\n",
        "        max_offset = input_length - len(signal)  \n",
        "        signal = np.pad(signal, (0, max_offset), \"constant\")\n",
        "\n",
        "    mfcc = librosa.feature.mfcc(y=signal, sr=sr, n_mfcc=13).T\n",
        "    mfcc = np.expand_dims(mfcc, axis=-1)\n",
        "    data['features'].append(mfcc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahakomyG2nde"
      },
      "source": [
        "X = data['features']\n",
        "y = data['labels']\n",
        "\n",
        "y = np.array(y)\n",
        "y = to_categorical(y)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=0)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=0)\n",
        "\n",
        "X_train = np.array(X_train)\n",
        "X_test = np.array(X_test)\n",
        "X_val = np.array(X_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xaP08C9C2nde",
        "outputId": "ad42f5ba-9785-4ba5-c8c0-802cecc33288"
      },
      "source": [
        "X_train.shape,X_test.shape,y_train.shape,y_test.shape\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((4117, 130, 13, 1), (509, 130, 13, 1), (4117, 4), (509, 4))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UsHxeSsK2ndf"
      },
      "source": [
        "# CNN I/P Config\n",
        "num_classes = 4\n",
        "input_shape = X_train.shape[1:]\n",
        "learning_rate = 0.0001\n",
        "decay = 1e-6\n",
        "momentum = 0.9"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0RqouXuA2ndg",
        "outputId": "64b433d0-dbfc-4072-901c-093659d0c56c"
      },
      "source": [
        "model = Sequential(name='Audio_CNN_2D')\n",
        "\n",
        "# LFLB1\n",
        "model.add(Conv2D(filters=64, kernel_size=(3,3), strides=(1,1), padding='same',input_shape=input_shape))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Conv2D(filters=64, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(4,4), strides=(4,4)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(units=num_classes, activation='softmax'))\n",
        "\n",
        "# Model compilation\n",
        "opt = optimizers.SGD(lr=learning_rate, decay=decay, momentum=momentum, nesterov=True)\n",
        "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"Audio_CNN_2D\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 130, 13, 64)       640       \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 130, 13, 64)       256       \n",
            "_________________________________________________________________\n",
            "activation_8 (Activation)    (None, 130, 13, 64)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 65, 6, 64)         0         \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 65, 6, 64)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 65, 6, 64)         36928     \n",
            "_________________________________________________________________\n",
            "batch_normalization_9 (Batch (None, 65, 6, 64)         256       \n",
            "_________________________________________________________________\n",
            "activation_9 (Activation)    (None, 65, 6, 64)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 16, 1, 64)         0         \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 16, 1, 64)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 4)                 4100      \n",
            "=================================================================\n",
            "Total params: 42,180\n",
            "Trainable params: 41,924\n",
            "Non-trainable params: 256\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2_85mCVM2ndg",
        "outputId": "1ff0ede5-a19f-4a85-def8-229bb8e843ce"
      },
      "source": [
        "#Train Config\n",
        "\n",
        "batch_size = 16\n",
        "num_epochs = 200\n",
        "\n",
        "# Model Training\n",
        "lr_reduce = ReduceLROnPlateau(monitor='val_loss', factor=0.9, patience=20, min_lr=0.000001)\n",
        "# Please change the model name accordingly.\n",
        "mcp_save = ModelCheckpoint('/content/Modelfull_2_1.h5', save_best_only=True, monitor='val_categorical_accuracy', mode='max')\n",
        "cnnhistory=model.fit(X_train, y_train, batch_size=batch_size, epochs=num_epochs,validation_data=(X_val, y_val), callbacks=[mcp_save, lr_reduce])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "258/258 [==============================] - 4s 6ms/step - loss: 2.5078 - categorical_accuracy: 0.2934 - val_loss: 1.7122 - val_categorical_accuracy: 0.2904\n",
            "Epoch 2/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 1.8384 - categorical_accuracy: 0.3787 - val_loss: 1.3824 - val_categorical_accuracy: 0.3930\n",
            "Epoch 3/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 1.6142 - categorical_accuracy: 0.4001 - val_loss: 1.2159 - val_categorical_accuracy: 0.4170\n",
            "Epoch 4/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 1.4596 - categorical_accuracy: 0.4218 - val_loss: 1.1130 - val_categorical_accuracy: 0.4934\n",
            "Epoch 5/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 1.3869 - categorical_accuracy: 0.4313 - val_loss: 1.1165 - val_categorical_accuracy: 0.4672\n",
            "Epoch 6/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 1.3108 - categorical_accuracy: 0.4470 - val_loss: 1.1289 - val_categorical_accuracy: 0.4782\n",
            "Epoch 7/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 1.2821 - categorical_accuracy: 0.4542 - val_loss: 1.1045 - val_categorical_accuracy: 0.4934\n",
            "Epoch 8/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 1.2644 - categorical_accuracy: 0.4568 - val_loss: 1.1097 - val_categorical_accuracy: 0.4934\n",
            "Epoch 9/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 1.1984 - categorical_accuracy: 0.4737 - val_loss: 1.0804 - val_categorical_accuracy: 0.4934\n",
            "Epoch 10/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 1.2052 - categorical_accuracy: 0.4724 - val_loss: 1.0895 - val_categorical_accuracy: 0.4738\n",
            "Epoch 11/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 1.1814 - categorical_accuracy: 0.4721 - val_loss: 1.0951 - val_categorical_accuracy: 0.5262\n",
            "Epoch 12/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 1.1870 - categorical_accuracy: 0.4675 - val_loss: 1.0889 - val_categorical_accuracy: 0.5022\n",
            "Epoch 13/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 1.1368 - categorical_accuracy: 0.4884 - val_loss: 1.1060 - val_categorical_accuracy: 0.4847\n",
            "Epoch 14/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 1.1457 - categorical_accuracy: 0.4812 - val_loss: 1.0996 - val_categorical_accuracy: 0.5349\n",
            "Epoch 15/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 1.1279 - categorical_accuracy: 0.4993 - val_loss: 1.0984 - val_categorical_accuracy: 0.4956\n",
            "Epoch 16/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 1.1150 - categorical_accuracy: 0.4940 - val_loss: 1.1009 - val_categorical_accuracy: 0.5218\n",
            "Epoch 17/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 1.1090 - categorical_accuracy: 0.5099 - val_loss: 1.0992 - val_categorical_accuracy: 0.4694\n",
            "Epoch 18/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 1.1173 - categorical_accuracy: 0.4940 - val_loss: 1.0662 - val_categorical_accuracy: 0.5349\n",
            "Epoch 19/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 1.1339 - categorical_accuracy: 0.4900 - val_loss: 1.1013 - val_categorical_accuracy: 0.5284\n",
            "Epoch 20/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 1.0978 - categorical_accuracy: 0.5223 - val_loss: 1.0842 - val_categorical_accuracy: 0.5000\n",
            "Epoch 21/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 1.0870 - categorical_accuracy: 0.5128 - val_loss: 1.1110 - val_categorical_accuracy: 0.4782\n",
            "Epoch 22/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 1.0771 - categorical_accuracy: 0.5111 - val_loss: 1.0900 - val_categorical_accuracy: 0.5218\n",
            "Epoch 23/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 1.0929 - categorical_accuracy: 0.5247 - val_loss: 1.0987 - val_categorical_accuracy: 0.5175\n",
            "Epoch 24/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 1.1006 - categorical_accuracy: 0.5163 - val_loss: 1.0716 - val_categorical_accuracy: 0.5218\n",
            "Epoch 25/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 1.0920 - categorical_accuracy: 0.5299 - val_loss: 1.0709 - val_categorical_accuracy: 0.5349\n",
            "Epoch 26/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 1.0880 - categorical_accuracy: 0.5128 - val_loss: 1.0596 - val_categorical_accuracy: 0.5502\n",
            "Epoch 27/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 1.0938 - categorical_accuracy: 0.5197 - val_loss: 1.0687 - val_categorical_accuracy: 0.5197\n",
            "Epoch 28/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 1.0966 - categorical_accuracy: 0.4996 - val_loss: 1.0721 - val_categorical_accuracy: 0.4978\n",
            "Epoch 29/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 1.0735 - categorical_accuracy: 0.5247 - val_loss: 1.0581 - val_categorical_accuracy: 0.5393\n",
            "Epoch 30/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 1.0535 - categorical_accuracy: 0.5413 - val_loss: 1.0916 - val_categorical_accuracy: 0.5044\n",
            "Epoch 31/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 1.0561 - categorical_accuracy: 0.5389 - val_loss: 1.0407 - val_categorical_accuracy: 0.5262\n",
            "Epoch 32/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 1.0487 - categorical_accuracy: 0.5355 - val_loss: 1.0466 - val_categorical_accuracy: 0.5306\n",
            "Epoch 33/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 1.0487 - categorical_accuracy: 0.5293 - val_loss: 1.0573 - val_categorical_accuracy: 0.5655\n",
            "Epoch 34/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 1.0548 - categorical_accuracy: 0.5265 - val_loss: 1.0686 - val_categorical_accuracy: 0.5153\n",
            "Epoch 35/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 1.0621 - categorical_accuracy: 0.5257 - val_loss: 1.0584 - val_categorical_accuracy: 0.5415\n",
            "Epoch 36/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 1.0528 - categorical_accuracy: 0.5346 - val_loss: 1.0510 - val_categorical_accuracy: 0.5393\n",
            "Epoch 37/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 1.0362 - categorical_accuracy: 0.5341 - val_loss: 1.0729 - val_categorical_accuracy: 0.5262\n",
            "Epoch 38/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 1.0560 - categorical_accuracy: 0.5351 - val_loss: 1.0412 - val_categorical_accuracy: 0.5568\n",
            "Epoch 39/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 1.0332 - categorical_accuracy: 0.5409 - val_loss: 1.0583 - val_categorical_accuracy: 0.5153\n",
            "Epoch 40/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 1.0299 - categorical_accuracy: 0.5338 - val_loss: 1.0397 - val_categorical_accuracy: 0.5437\n",
            "Epoch 41/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 1.0532 - categorical_accuracy: 0.5298 - val_loss: 1.0349 - val_categorical_accuracy: 0.5524\n",
            "Epoch 42/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 1.0302 - categorical_accuracy: 0.5304 - val_loss: 1.0243 - val_categorical_accuracy: 0.5480\n",
            "Epoch 43/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 1.0300 - categorical_accuracy: 0.5530 - val_loss: 1.0802 - val_categorical_accuracy: 0.5044\n",
            "Epoch 44/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 1.0120 - categorical_accuracy: 0.5353 - val_loss: 1.0244 - val_categorical_accuracy: 0.5502\n",
            "Epoch 45/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 1.0558 - categorical_accuracy: 0.5291 - val_loss: 1.0338 - val_categorical_accuracy: 0.5480\n",
            "Epoch 46/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 1.0387 - categorical_accuracy: 0.5463 - val_loss: 1.0414 - val_categorical_accuracy: 0.5328\n",
            "Epoch 47/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 1.0141 - categorical_accuracy: 0.5303 - val_loss: 1.0412 - val_categorical_accuracy: 0.5437\n",
            "Epoch 48/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 1.0339 - categorical_accuracy: 0.5423 - val_loss: 1.0497 - val_categorical_accuracy: 0.5459\n",
            "Epoch 49/200\n",
            "258/258 [==============================] - 1s 5ms/step - loss: 1.0420 - categorical_accuracy: 0.5343 - val_loss: 1.0418 - val_categorical_accuracy: 0.5568\n",
            "Epoch 50/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 1.0338 - categorical_accuracy: 0.5453 - val_loss: 1.0382 - val_categorical_accuracy: 0.5197\n",
            "Epoch 51/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 1.0228 - categorical_accuracy: 0.5458 - val_loss: 1.0884 - val_categorical_accuracy: 0.5109\n",
            "Epoch 52/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.9936 - categorical_accuracy: 0.5708 - val_loss: 1.0534 - val_categorical_accuracy: 0.5437\n",
            "Epoch 53/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 1.0284 - categorical_accuracy: 0.5289 - val_loss: 1.0294 - val_categorical_accuracy: 0.5437\n",
            "Epoch 54/200\n",
            "258/258 [==============================] - 1s 5ms/step - loss: 1.0362 - categorical_accuracy: 0.5356 - val_loss: 1.0132 - val_categorical_accuracy: 0.5371\n",
            "Epoch 55/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 1.0241 - categorical_accuracy: 0.5588 - val_loss: 1.0273 - val_categorical_accuracy: 0.5568\n",
            "Epoch 56/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.9985 - categorical_accuracy: 0.5539 - val_loss: 1.0364 - val_categorical_accuracy: 0.5284\n",
            "Epoch 57/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 1.0265 - categorical_accuracy: 0.5440 - val_loss: 1.0296 - val_categorical_accuracy: 0.5590\n",
            "Epoch 58/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.9909 - categorical_accuracy: 0.5657 - val_loss: 1.0453 - val_categorical_accuracy: 0.5524\n",
            "Epoch 59/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 1.0306 - categorical_accuracy: 0.5322 - val_loss: 1.0268 - val_categorical_accuracy: 0.5611\n",
            "Epoch 60/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.9980 - categorical_accuracy: 0.5585 - val_loss: 1.0113 - val_categorical_accuracy: 0.5349\n",
            "Epoch 61/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 1.0126 - categorical_accuracy: 0.5438 - val_loss: 1.0693 - val_categorical_accuracy: 0.5393\n",
            "Epoch 62/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 1.0121 - categorical_accuracy: 0.5477 - val_loss: 1.0263 - val_categorical_accuracy: 0.5415\n",
            "Epoch 63/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 1.0063 - categorical_accuracy: 0.5574 - val_loss: 1.0609 - val_categorical_accuracy: 0.5393\n",
            "Epoch 64/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 1.0009 - categorical_accuracy: 0.5551 - val_loss: 1.0107 - val_categorical_accuracy: 0.5131\n",
            "Epoch 65/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.9714 - categorical_accuracy: 0.5675 - val_loss: 1.0621 - val_categorical_accuracy: 0.4694\n",
            "Epoch 66/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 1.0165 - categorical_accuracy: 0.5502 - val_loss: 1.0384 - val_categorical_accuracy: 0.5415\n",
            "Epoch 67/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 1.0080 - categorical_accuracy: 0.5361 - val_loss: 1.0188 - val_categorical_accuracy: 0.5590\n",
            "Epoch 68/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.9881 - categorical_accuracy: 0.5551 - val_loss: 1.0336 - val_categorical_accuracy: 0.5546\n",
            "Epoch 69/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.9774 - categorical_accuracy: 0.5658 - val_loss: 1.0482 - val_categorical_accuracy: 0.5611\n",
            "Epoch 70/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.9880 - categorical_accuracy: 0.5614 - val_loss: 1.0125 - val_categorical_accuracy: 0.5546\n",
            "Epoch 71/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.9832 - categorical_accuracy: 0.5587 - val_loss: 1.0499 - val_categorical_accuracy: 0.5459\n",
            "Epoch 72/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.9871 - categorical_accuracy: 0.5538 - val_loss: 1.0072 - val_categorical_accuracy: 0.5633\n",
            "Epoch 73/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.9935 - categorical_accuracy: 0.5650 - val_loss: 0.9875 - val_categorical_accuracy: 0.5415\n",
            "Epoch 74/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.9840 - categorical_accuracy: 0.5621 - val_loss: 1.0214 - val_categorical_accuracy: 0.5524\n",
            "Epoch 75/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 1.0077 - categorical_accuracy: 0.5577 - val_loss: 1.0227 - val_categorical_accuracy: 0.5415\n",
            "Epoch 76/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.9740 - categorical_accuracy: 0.5707 - val_loss: 0.9838 - val_categorical_accuracy: 0.5502\n",
            "Epoch 77/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.9710 - categorical_accuracy: 0.5777 - val_loss: 0.9877 - val_categorical_accuracy: 0.5546\n",
            "Epoch 78/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.9843 - categorical_accuracy: 0.5628 - val_loss: 0.9997 - val_categorical_accuracy: 0.5328\n",
            "Epoch 79/200\n",
            "258/258 [==============================] - 1s 5ms/step - loss: 1.0146 - categorical_accuracy: 0.5410 - val_loss: 1.0090 - val_categorical_accuracy: 0.5633\n",
            "Epoch 80/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.9784 - categorical_accuracy: 0.5741 - val_loss: 0.9900 - val_categorical_accuracy: 0.5437\n",
            "Epoch 81/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.9858 - categorical_accuracy: 0.5732 - val_loss: 1.0275 - val_categorical_accuracy: 0.5393\n",
            "Epoch 82/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.9948 - categorical_accuracy: 0.5659 - val_loss: 0.9881 - val_categorical_accuracy: 0.5415\n",
            "Epoch 83/200\n",
            "258/258 [==============================] - 1s 5ms/step - loss: 0.9522 - categorical_accuracy: 0.5704 - val_loss: 1.0153 - val_categorical_accuracy: 0.5480\n",
            "Epoch 84/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.9918 - categorical_accuracy: 0.5661 - val_loss: 0.9938 - val_categorical_accuracy: 0.5480\n",
            "Epoch 85/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.9806 - categorical_accuracy: 0.5690 - val_loss: 0.9718 - val_categorical_accuracy: 0.5546\n",
            "Epoch 86/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.9832 - categorical_accuracy: 0.5479 - val_loss: 1.0069 - val_categorical_accuracy: 0.5066\n",
            "Epoch 87/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.9867 - categorical_accuracy: 0.5685 - val_loss: 0.9904 - val_categorical_accuracy: 0.5371\n",
            "Epoch 88/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.9573 - categorical_accuracy: 0.5772 - val_loss: 1.0409 - val_categorical_accuracy: 0.5197\n",
            "Epoch 89/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.9918 - categorical_accuracy: 0.5609 - val_loss: 1.0150 - val_categorical_accuracy: 0.5218\n",
            "Epoch 90/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.9610 - categorical_accuracy: 0.5705 - val_loss: 0.9976 - val_categorical_accuracy: 0.5437\n",
            "Epoch 91/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.9865 - categorical_accuracy: 0.5642 - val_loss: 1.0801 - val_categorical_accuracy: 0.4738\n",
            "Epoch 92/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.9703 - categorical_accuracy: 0.5607 - val_loss: 0.9988 - val_categorical_accuracy: 0.5066\n",
            "Epoch 93/200\n",
            "258/258 [==============================] - 1s 5ms/step - loss: 0.9519 - categorical_accuracy: 0.5738 - val_loss: 1.0105 - val_categorical_accuracy: 0.5568\n",
            "Epoch 94/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.9554 - categorical_accuracy: 0.5766 - val_loss: 1.0031 - val_categorical_accuracy: 0.5546\n",
            "Epoch 95/200\n",
            "258/258 [==============================] - 1s 5ms/step - loss: 0.9795 - categorical_accuracy: 0.5613 - val_loss: 0.9691 - val_categorical_accuracy: 0.5633\n",
            "Epoch 96/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.9700 - categorical_accuracy: 0.5672 - val_loss: 0.9788 - val_categorical_accuracy: 0.5502\n",
            "Epoch 97/200\n",
            "258/258 [==============================] - 1s 5ms/step - loss: 0.9896 - categorical_accuracy: 0.5642 - val_loss: 1.0016 - val_categorical_accuracy: 0.5306\n",
            "Epoch 98/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.9696 - categorical_accuracy: 0.5720 - val_loss: 1.0105 - val_categorical_accuracy: 0.5393\n",
            "Epoch 99/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.9717 - categorical_accuracy: 0.5594 - val_loss: 0.9817 - val_categorical_accuracy: 0.5415\n",
            "Epoch 100/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.9834 - categorical_accuracy: 0.5682 - val_loss: 1.0204 - val_categorical_accuracy: 0.5568\n",
            "Epoch 101/200\n",
            "258/258 [==============================] - 1s 5ms/step - loss: 0.9715 - categorical_accuracy: 0.5687 - val_loss: 0.9876 - val_categorical_accuracy: 0.5655\n",
            "Epoch 102/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.9563 - categorical_accuracy: 0.5591 - val_loss: 1.0383 - val_categorical_accuracy: 0.5218\n",
            "Epoch 103/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 1.0063 - categorical_accuracy: 0.5518 - val_loss: 0.9972 - val_categorical_accuracy: 0.5306\n",
            "Epoch 104/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.9492 - categorical_accuracy: 0.5779 - val_loss: 0.9678 - val_categorical_accuracy: 0.5459\n",
            "Epoch 105/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.9633 - categorical_accuracy: 0.5701 - val_loss: 0.9715 - val_categorical_accuracy: 0.5502\n",
            "Epoch 106/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.9736 - categorical_accuracy: 0.5803 - val_loss: 0.9813 - val_categorical_accuracy: 0.5306\n",
            "Epoch 107/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.9625 - categorical_accuracy: 0.5671 - val_loss: 0.9910 - val_categorical_accuracy: 0.5546\n",
            "Epoch 108/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.9624 - categorical_accuracy: 0.5688 - val_loss: 0.9857 - val_categorical_accuracy: 0.5349\n",
            "Epoch 109/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.9537 - categorical_accuracy: 0.5707 - val_loss: 0.9756 - val_categorical_accuracy: 0.5175\n",
            "Epoch 110/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.9357 - categorical_accuracy: 0.5887 - val_loss: 1.0153 - val_categorical_accuracy: 0.5437\n",
            "Epoch 111/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.9582 - categorical_accuracy: 0.5701 - val_loss: 1.0391 - val_categorical_accuracy: 0.4956\n",
            "Epoch 112/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.9365 - categorical_accuracy: 0.5875 - val_loss: 0.9735 - val_categorical_accuracy: 0.5393\n",
            "Epoch 113/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.9560 - categorical_accuracy: 0.5706 - val_loss: 0.9720 - val_categorical_accuracy: 0.5546\n",
            "Epoch 114/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.9377 - categorical_accuracy: 0.5902 - val_loss: 0.9829 - val_categorical_accuracy: 0.5371\n",
            "Epoch 115/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.9268 - categorical_accuracy: 0.5944 - val_loss: 0.9727 - val_categorical_accuracy: 0.5415\n",
            "Epoch 116/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.9476 - categorical_accuracy: 0.5704 - val_loss: 0.9979 - val_categorical_accuracy: 0.5328\n",
            "Epoch 117/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.9598 - categorical_accuracy: 0.5726 - val_loss: 1.0019 - val_categorical_accuracy: 0.5393\n",
            "Epoch 118/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.9660 - categorical_accuracy: 0.5819 - val_loss: 0.9848 - val_categorical_accuracy: 0.5349\n",
            "Epoch 119/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.9329 - categorical_accuracy: 0.5850 - val_loss: 0.9848 - val_categorical_accuracy: 0.5524\n",
            "Epoch 120/200\n",
            "258/258 [==============================] - 1s 5ms/step - loss: 0.9676 - categorical_accuracy: 0.5713 - val_loss: 1.0279 - val_categorical_accuracy: 0.5306\n",
            "Epoch 121/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.9692 - categorical_accuracy: 0.5723 - val_loss: 0.9625 - val_categorical_accuracy: 0.5415\n",
            "Epoch 122/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.9500 - categorical_accuracy: 0.5703 - val_loss: 0.9875 - val_categorical_accuracy: 0.5393\n",
            "Epoch 123/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.9608 - categorical_accuracy: 0.5790 - val_loss: 0.9763 - val_categorical_accuracy: 0.5349\n",
            "Epoch 124/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.9437 - categorical_accuracy: 0.5811 - val_loss: 0.9611 - val_categorical_accuracy: 0.5524\n",
            "Epoch 125/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.9375 - categorical_accuracy: 0.5752 - val_loss: 1.0096 - val_categorical_accuracy: 0.5371\n",
            "Epoch 126/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.9400 - categorical_accuracy: 0.5901 - val_loss: 1.0259 - val_categorical_accuracy: 0.5044\n",
            "Epoch 127/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.9581 - categorical_accuracy: 0.5700 - val_loss: 0.9779 - val_categorical_accuracy: 0.5786\n",
            "Epoch 128/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.9632 - categorical_accuracy: 0.5747 - val_loss: 0.9772 - val_categorical_accuracy: 0.5459\n",
            "Epoch 129/200\n",
            "258/258 [==============================] - 1s 5ms/step - loss: 0.9350 - categorical_accuracy: 0.5797 - val_loss: 0.9755 - val_categorical_accuracy: 0.5590\n",
            "Epoch 130/200\n",
            "258/258 [==============================] - 1s 5ms/step - loss: 0.9414 - categorical_accuracy: 0.5783 - val_loss: 0.9936 - val_categorical_accuracy: 0.5175\n",
            "Epoch 131/200\n",
            "258/258 [==============================] - 1s 5ms/step - loss: 0.9563 - categorical_accuracy: 0.5729 - val_loss: 0.9637 - val_categorical_accuracy: 0.5655\n",
            "Epoch 132/200\n",
            "258/258 [==============================] - 1s 5ms/step - loss: 0.9375 - categorical_accuracy: 0.5835 - val_loss: 1.0359 - val_categorical_accuracy: 0.5109\n",
            "Epoch 133/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.9271 - categorical_accuracy: 0.5965 - val_loss: 0.9633 - val_categorical_accuracy: 0.5459\n",
            "Epoch 134/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.9278 - categorical_accuracy: 0.5856 - val_loss: 0.9505 - val_categorical_accuracy: 0.5611\n",
            "Epoch 135/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.9543 - categorical_accuracy: 0.5782 - val_loss: 0.9921 - val_categorical_accuracy: 0.5393\n",
            "Epoch 136/200\n",
            "258/258 [==============================] - 1s 5ms/step - loss: 0.9349 - categorical_accuracy: 0.5901 - val_loss: 0.9800 - val_categorical_accuracy: 0.5349\n",
            "Epoch 137/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.9420 - categorical_accuracy: 0.5821 - val_loss: 0.9809 - val_categorical_accuracy: 0.5371\n",
            "Epoch 138/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.9525 - categorical_accuracy: 0.5778 - val_loss: 0.9795 - val_categorical_accuracy: 0.5415\n",
            "Epoch 139/200\n",
            "258/258 [==============================] - 1s 5ms/step - loss: 0.9418 - categorical_accuracy: 0.5885 - val_loss: 0.9583 - val_categorical_accuracy: 0.5459\n",
            "Epoch 140/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.9366 - categorical_accuracy: 0.5897 - val_loss: 0.9763 - val_categorical_accuracy: 0.5328\n",
            "Epoch 141/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.9463 - categorical_accuracy: 0.5760 - val_loss: 0.9585 - val_categorical_accuracy: 0.5437\n",
            "Epoch 142/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.9417 - categorical_accuracy: 0.5914 - val_loss: 0.9632 - val_categorical_accuracy: 0.5568\n",
            "Epoch 143/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.9453 - categorical_accuracy: 0.5805 - val_loss: 0.9597 - val_categorical_accuracy: 0.5459\n",
            "Epoch 144/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.9138 - categorical_accuracy: 0.6033 - val_loss: 0.9684 - val_categorical_accuracy: 0.5633\n",
            "Epoch 145/200\n",
            "258/258 [==============================] - 1s 5ms/step - loss: 0.9402 - categorical_accuracy: 0.5808 - val_loss: 0.9626 - val_categorical_accuracy: 0.5742\n",
            "Epoch 146/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.9542 - categorical_accuracy: 0.5654 - val_loss: 0.9614 - val_categorical_accuracy: 0.5655\n",
            "Epoch 147/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.9373 - categorical_accuracy: 0.5847 - val_loss: 0.9578 - val_categorical_accuracy: 0.5590\n",
            "Epoch 148/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.9474 - categorical_accuracy: 0.5782 - val_loss: 0.9469 - val_categorical_accuracy: 0.5546\n",
            "Epoch 149/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.9170 - categorical_accuracy: 0.5984 - val_loss: 1.0102 - val_categorical_accuracy: 0.5306\n",
            "Epoch 150/200\n",
            "258/258 [==============================] - 1s 5ms/step - loss: 0.9383 - categorical_accuracy: 0.5824 - val_loss: 0.9548 - val_categorical_accuracy: 0.5480\n",
            "Epoch 151/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.9326 - categorical_accuracy: 0.5947 - val_loss: 0.9485 - val_categorical_accuracy: 0.5699\n",
            "Epoch 152/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.9189 - categorical_accuracy: 0.6159 - val_loss: 0.9951 - val_categorical_accuracy: 0.5371\n",
            "Epoch 153/200\n",
            "258/258 [==============================] - 1s 5ms/step - loss: 0.9381 - categorical_accuracy: 0.5858 - val_loss: 0.9453 - val_categorical_accuracy: 0.5655\n",
            "Epoch 154/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.9233 - categorical_accuracy: 0.5764 - val_loss: 0.9638 - val_categorical_accuracy: 0.5611\n",
            "Epoch 155/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.9266 - categorical_accuracy: 0.5959 - val_loss: 0.9667 - val_categorical_accuracy: 0.5677\n",
            "Epoch 156/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.9395 - categorical_accuracy: 0.5858 - val_loss: 0.9408 - val_categorical_accuracy: 0.5677\n",
            "Epoch 157/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.9206 - categorical_accuracy: 0.5976 - val_loss: 0.9500 - val_categorical_accuracy: 0.5699\n",
            "Epoch 158/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.9247 - categorical_accuracy: 0.5976 - val_loss: 0.9458 - val_categorical_accuracy: 0.5590\n",
            "Epoch 159/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.9168 - categorical_accuracy: 0.6017 - val_loss: 0.9793 - val_categorical_accuracy: 0.5306\n",
            "Epoch 160/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.9288 - categorical_accuracy: 0.6015 - val_loss: 0.9787 - val_categorical_accuracy: 0.5371\n",
            "Epoch 161/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.9467 - categorical_accuracy: 0.5748 - val_loss: 0.9870 - val_categorical_accuracy: 0.5218\n",
            "Epoch 162/200\n",
            "258/258 [==============================] - 1s 5ms/step - loss: 0.9235 - categorical_accuracy: 0.5846 - val_loss: 0.9433 - val_categorical_accuracy: 0.5873\n",
            "Epoch 163/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.9244 - categorical_accuracy: 0.5809 - val_loss: 0.9762 - val_categorical_accuracy: 0.5546\n",
            "Epoch 164/200\n",
            "258/258 [==============================] - 1s 5ms/step - loss: 0.9401 - categorical_accuracy: 0.5832 - val_loss: 0.9550 - val_categorical_accuracy: 0.5502\n",
            "Epoch 165/200\n",
            "258/258 [==============================] - 1s 5ms/step - loss: 0.9380 - categorical_accuracy: 0.5843 - val_loss: 0.9808 - val_categorical_accuracy: 0.5262\n",
            "Epoch 166/200\n",
            "258/258 [==============================] - 1s 5ms/step - loss: 0.9507 - categorical_accuracy: 0.5830 - val_loss: 0.9446 - val_categorical_accuracy: 0.5633\n",
            "Epoch 167/200\n",
            "258/258 [==============================] - 1s 5ms/step - loss: 0.9216 - categorical_accuracy: 0.5845 - val_loss: 0.9442 - val_categorical_accuracy: 0.5786\n",
            "Epoch 168/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.9159 - categorical_accuracy: 0.6102 - val_loss: 0.9408 - val_categorical_accuracy: 0.5699\n",
            "Epoch 169/200\n",
            "258/258 [==============================] - 1s 5ms/step - loss: 0.9049 - categorical_accuracy: 0.5888 - val_loss: 0.9799 - val_categorical_accuracy: 0.5480\n",
            "Epoch 170/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.9113 - categorical_accuracy: 0.5918 - val_loss: 0.9412 - val_categorical_accuracy: 0.5699\n",
            "Epoch 171/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.9384 - categorical_accuracy: 0.5876 - val_loss: 0.9317 - val_categorical_accuracy: 0.5742\n",
            "Epoch 172/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.8955 - categorical_accuracy: 0.6095 - val_loss: 0.9398 - val_categorical_accuracy: 0.5677\n",
            "Epoch 173/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.9225 - categorical_accuracy: 0.5904 - val_loss: 0.9647 - val_categorical_accuracy: 0.5371\n",
            "Epoch 174/200\n",
            "258/258 [==============================] - 1s 5ms/step - loss: 0.9437 - categorical_accuracy: 0.5874 - val_loss: 0.9467 - val_categorical_accuracy: 0.5655\n",
            "Epoch 175/200\n",
            "258/258 [==============================] - 1s 5ms/step - loss: 0.9273 - categorical_accuracy: 0.5961 - val_loss: 0.9358 - val_categorical_accuracy: 0.5808\n",
            "Epoch 176/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.9254 - categorical_accuracy: 0.5819 - val_loss: 0.9371 - val_categorical_accuracy: 0.5721\n",
            "Epoch 177/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.9128 - categorical_accuracy: 0.5863 - val_loss: 0.9562 - val_categorical_accuracy: 0.5480\n",
            "Epoch 178/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.9276 - categorical_accuracy: 0.5851 - val_loss: 0.9915 - val_categorical_accuracy: 0.5459\n",
            "Epoch 179/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.9307 - categorical_accuracy: 0.5977 - val_loss: 0.9463 - val_categorical_accuracy: 0.5852\n",
            "Epoch 180/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.9153 - categorical_accuracy: 0.6005 - val_loss: 0.9463 - val_categorical_accuracy: 0.5742\n",
            "Epoch 181/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.9244 - categorical_accuracy: 0.5870 - val_loss: 0.9350 - val_categorical_accuracy: 0.5852\n",
            "Epoch 182/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.9233 - categorical_accuracy: 0.6089 - val_loss: 0.9294 - val_categorical_accuracy: 0.5764\n",
            "Epoch 183/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.9125 - categorical_accuracy: 0.5941 - val_loss: 0.9273 - val_categorical_accuracy: 0.5677\n",
            "Epoch 184/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.9348 - categorical_accuracy: 0.5838 - val_loss: 0.9394 - val_categorical_accuracy: 0.5786\n",
            "Epoch 185/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.9222 - categorical_accuracy: 0.5954 - val_loss: 0.9520 - val_categorical_accuracy: 0.5546\n",
            "Epoch 186/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.9182 - categorical_accuracy: 0.5926 - val_loss: 0.9373 - val_categorical_accuracy: 0.5895\n",
            "Epoch 187/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.9126 - categorical_accuracy: 0.6025 - val_loss: 0.9251 - val_categorical_accuracy: 0.5721\n",
            "Epoch 188/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.9472 - categorical_accuracy: 0.5778 - val_loss: 0.9822 - val_categorical_accuracy: 0.5524\n",
            "Epoch 189/200\n",
            "258/258 [==============================] - 1s 5ms/step - loss: 0.9006 - categorical_accuracy: 0.6053 - val_loss: 0.9378 - val_categorical_accuracy: 0.5830\n",
            "Epoch 190/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.9236 - categorical_accuracy: 0.5949 - val_loss: 0.9764 - val_categorical_accuracy: 0.5371\n",
            "Epoch 191/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.9173 - categorical_accuracy: 0.6037 - val_loss: 0.9627 - val_categorical_accuracy: 0.5502\n",
            "Epoch 192/200\n",
            "258/258 [==============================] - 1s 5ms/step - loss: 0.9097 - categorical_accuracy: 0.6074 - val_loss: 0.9372 - val_categorical_accuracy: 0.5764\n",
            "Epoch 193/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.9287 - categorical_accuracy: 0.5915 - val_loss: 0.9287 - val_categorical_accuracy: 0.5808\n",
            "Epoch 194/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.9212 - categorical_accuracy: 0.5830 - val_loss: 0.9294 - val_categorical_accuracy: 0.5764\n",
            "Epoch 195/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.9228 - categorical_accuracy: 0.5943 - val_loss: 0.9691 - val_categorical_accuracy: 0.5437\n",
            "Epoch 196/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.9145 - categorical_accuracy: 0.5842 - val_loss: 0.9502 - val_categorical_accuracy: 0.5590\n",
            "Epoch 197/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.9176 - categorical_accuracy: 0.5885 - val_loss: 0.9707 - val_categorical_accuracy: 0.5175\n",
            "Epoch 198/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.9043 - categorical_accuracy: 0.5969 - val_loss: 0.9295 - val_categorical_accuracy: 0.5917\n",
            "Epoch 199/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.9099 - categorical_accuracy: 0.5969 - val_loss: 0.9337 - val_categorical_accuracy: 0.5764\n",
            "Epoch 200/200\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.9169 - categorical_accuracy: 0.5970 - val_loss: 0.9454 - val_categorical_accuracy: 0.5480\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "phONxCpg2ndh"
      },
      "source": [
        "model.save('/content/drive/MyDrive/Colab Notebooks/SPEECH_EMOTION_Recognition/Nộp bài(chốt hạ)/model_saver/conv2D_mfcc13_cremad.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HjbGkNOG2ndi"
      },
      "source": [
        "###test_result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a80Gcu9H2ndi",
        "outputId": "40671c98-5197-453a-9d2a-b70e15515295"
      },
      "source": [
        "d = {0: 'happy',\n",
        "     1: 'sad',\n",
        "     2: 'angry',\n",
        "     3: 'fear'}\n",
        "Y_test_pred = np.argmax(model.predict(X_test), axis=-1)\n",
        "Y_test_pred = list(map(lambda x: d[x], Y_test_pred))\n",
        "y_test = np.argmax(y_test, axis=-1)\n",
        "y_test = list(map(lambda x: d[x], y_test))\n",
        "print(classification_report(y_test, Y_test_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.58      0.81      0.67       136\n",
            "        fear       0.52      0.55      0.54       134\n",
            "       happy       0.57      0.36      0.44       120\n",
            "         sad       0.68      0.58      0.63       119\n",
            "\n",
            "    accuracy                           0.58       509\n",
            "   macro avg       0.59      0.57      0.57       509\n",
            "weighted avg       0.58      0.58      0.57       509\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 483
        },
        "id": "9Y0mQ9rM2ndj",
        "outputId": "99e5dd1c-87e4-45b7-8016-1957b5e04aa4"
      },
      "source": [
        "import scikitplot as skplt\n",
        "\n",
        "skplt.metrics.plot_confusion_matrix(\n",
        "    y_test, \n",
        "    Y_test_pred,\n",
        "    figsize=(8,8))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fa4901c8990>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNZony_t2ndk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZBa191VcuvUo"
      },
      "source": [
        "# mfcc_26 + conv2D:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zAS4cJuDuvU-"
      },
      "source": [
        "audio_duration = 3\n",
        "sampling_rate = 22050\n",
        "input_length = sampling_rate * audio_duration"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPlZio_4uvVB"
      },
      "source": [
        "data = {'labels': [],\n",
        "        'features': []}\n",
        "\n",
        "for i in range(len(CREMA_D_df)):\n",
        "  if ((CREMA_D_df['Emotion'][i] == 'HAP') | (CREMA_D_df['Emotion'][i] == 'SAD') | \n",
        "      (CREMA_D_df['Emotion'][i] == 'ANG') | (CREMA_D_df['Emotion'][i] == 'FEA')):\n",
        "    \n",
        "    if CREMA_D_df['Emotion'][i] == 'HAP':\n",
        "      data['labels'].append(0)\n",
        "    elif CREMA_D_df['Emotion'][i] == 'SAD':\n",
        "      data['labels'].append(1)\n",
        "    elif CREMA_D_df['Emotion'][i] == 'ANG':\n",
        "      data['labels'].append(2)\n",
        "    elif CREMA_D_df['Emotion'][i] == 'FEA':\n",
        "      data['labels'].append(3)\n",
        "\n",
        "\n",
        "    signal, sr =  librosa.load(CREMA_D_df['Paths'][i])\n",
        "\n",
        "    if len(signal) > input_length:\n",
        "        signal = signal[0:input_length]\n",
        "    elif  input_length > len(signal):\n",
        "        max_offset = input_length - len(signal)  \n",
        "        signal = np.pad(signal, (0, max_offset), \"constant\")\n",
        "\n",
        "    mfcc = librosa.feature.mfcc(y=signal, sr=sr, n_mfcc=26).T\n",
        "    mfcc = np.expand_dims(mfcc, axis=-1)\n",
        "    data['features'].append(mfcc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_BWRUMEmuvVC"
      },
      "source": [
        "X = data['features']\n",
        "y = data['labels']\n",
        "\n",
        "y = np.array(y)\n",
        "y = to_categorical(y)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=0)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=0)\n",
        "\n",
        "X_train = np.array(X_train)\n",
        "X_test = np.array(X_test)\n",
        "X_val = np.array(X_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DewWUvqsuvVE",
        "outputId": "326f360f-b2a4-4d88-d45b-3b0af5a67e60"
      },
      "source": [
        "X_train.shape,X_test.shape,y_train.shape,y_test.shape\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((4117, 130, 26, 1), (509, 130, 26, 1), (4117, 4), (509, 4))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "US0L6jmMuvVI"
      },
      "source": [
        "# CNN I/P Config\n",
        "num_classes = 4\n",
        "input_shape = X_train.shape[1:]\n",
        "learning_rate = 0.0001\n",
        "decay = 1e-6\n",
        "momentum = 0.9"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UAYyhkkIuvVK",
        "outputId": "35860191-a44e-49aa-d152-ae43d0a730e0"
      },
      "source": [
        "model = Sequential(name='Audio_CNN_2D')\n",
        "\n",
        "# LFLB1\n",
        "model.add(Conv2D(filters=64, kernel_size=(3,3), strides=(1,1), padding='same',input_shape=input_shape))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Conv2D(filters=64, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(4,4), strides=(4,4)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(units=num_classes, activation='softmax'))\n",
        "\n",
        "# Model compilation\n",
        "opt = optimizers.SGD(lr=learning_rate, decay=decay, momentum=momentum, nesterov=True)\n",
        "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"Audio_CNN_2D\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_2 (Conv2D)            (None, 130, 26, 64)       640       \n",
            "_________________________________________________________________\n",
            "batch_normalization_10 (Batc (None, 130, 26, 64)       256       \n",
            "_________________________________________________________________\n",
            "activation_10 (Activation)   (None, 130, 26, 64)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 65, 13, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 65, 13, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 65, 13, 64)        36928     \n",
            "_________________________________________________________________\n",
            "batch_normalization_11 (Batc (None, 65, 13, 64)        256       \n",
            "_________________________________________________________________\n",
            "activation_11 (Activation)   (None, 65, 13, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 16, 3, 64)         0         \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 16, 3, 64)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 3072)              0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 4)                 12292     \n",
            "=================================================================\n",
            "Total params: 50,372\n",
            "Trainable params: 50,116\n",
            "Non-trainable params: 256\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2J81f_lLuvVM",
        "outputId": "18959d0c-dbcf-403e-f9a8-fb540aa52b29"
      },
      "source": [
        "#Train Config\n",
        "\n",
        "batch_size = 16\n",
        "num_epochs = 200\n",
        "\n",
        "# Model Training\n",
        "lr_reduce = ReduceLROnPlateau(monitor='val_loss', factor=0.9, patience=20, min_lr=0.000001)\n",
        "# Please change the model name accordingly.\n",
        "mcp_save = ModelCheckpoint('/content/Modelfull_2_1.h5', save_best_only=True, monitor='val_categorical_accuracy', mode='max')\n",
        "cnnhistory=model.fit(X_train, y_train, batch_size=batch_size, epochs=num_epochs,validation_data=(X_val, y_val), callbacks=[mcp_save, lr_reduce])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "258/258 [==============================] - 4s 9ms/step - loss: 2.2322 - categorical_accuracy: 0.2838 - val_loss: 1.2963 - val_categorical_accuracy: 0.3974\n",
            "Epoch 2/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 1.5000 - categorical_accuracy: 0.4127 - val_loss: 1.1697 - val_categorical_accuracy: 0.4716\n",
            "Epoch 3/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 1.3162 - categorical_accuracy: 0.4406 - val_loss: 1.1158 - val_categorical_accuracy: 0.5000\n",
            "Epoch 4/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 1.2327 - categorical_accuracy: 0.4597 - val_loss: 1.1566 - val_categorical_accuracy: 0.4389\n",
            "Epoch 5/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 1.1901 - categorical_accuracy: 0.4738 - val_loss: 1.1058 - val_categorical_accuracy: 0.4607\n",
            "Epoch 6/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 1.1549 - categorical_accuracy: 0.4927 - val_loss: 1.1149 - val_categorical_accuracy: 0.4345\n",
            "Epoch 7/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 1.1465 - categorical_accuracy: 0.4936 - val_loss: 1.0809 - val_categorical_accuracy: 0.5087\n",
            "Epoch 8/200\n",
            "258/258 [==============================] - 1s 6ms/step - loss: 1.1191 - categorical_accuracy: 0.4986 - val_loss: 1.1165 - val_categorical_accuracy: 0.4585\n",
            "Epoch 9/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 1.1318 - categorical_accuracy: 0.4958 - val_loss: 1.0984 - val_categorical_accuracy: 0.4978\n",
            "Epoch 10/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 1.0980 - categorical_accuracy: 0.5103 - val_loss: 1.2044 - val_categorical_accuracy: 0.3646\n",
            "Epoch 11/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 1.1047 - categorical_accuracy: 0.4939 - val_loss: 1.1196 - val_categorical_accuracy: 0.4498\n",
            "Epoch 12/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 1.1102 - categorical_accuracy: 0.5042 - val_loss: 1.1634 - val_categorical_accuracy: 0.4389\n",
            "Epoch 13/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 1.0545 - categorical_accuracy: 0.5379 - val_loss: 1.1125 - val_categorical_accuracy: 0.4345\n",
            "Epoch 14/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 1.0726 - categorical_accuracy: 0.5258 - val_loss: 1.1642 - val_categorical_accuracy: 0.4148\n",
            "Epoch 15/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 1.0450 - categorical_accuracy: 0.5292 - val_loss: 1.1921 - val_categorical_accuracy: 0.3996\n",
            "Epoch 16/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 1.0468 - categorical_accuracy: 0.5253 - val_loss: 1.1199 - val_categorical_accuracy: 0.4476\n",
            "Epoch 17/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 1.0543 - categorical_accuracy: 0.5319 - val_loss: 1.1539 - val_categorical_accuracy: 0.4607\n",
            "Epoch 18/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 1.0572 - categorical_accuracy: 0.5278 - val_loss: 1.1028 - val_categorical_accuracy: 0.4345\n",
            "Epoch 19/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 1.0509 - categorical_accuracy: 0.5310 - val_loss: 1.1761 - val_categorical_accuracy: 0.4192\n",
            "Epoch 20/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 1.0255 - categorical_accuracy: 0.5425 - val_loss: 1.1625 - val_categorical_accuracy: 0.4258\n",
            "Epoch 21/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 1.0538 - categorical_accuracy: 0.5341 - val_loss: 1.1313 - val_categorical_accuracy: 0.4214\n",
            "Epoch 22/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.9911 - categorical_accuracy: 0.5575 - val_loss: 1.2314 - val_categorical_accuracy: 0.4105\n",
            "Epoch 23/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 1.0114 - categorical_accuracy: 0.5536 - val_loss: 1.2164 - val_categorical_accuracy: 0.4541\n",
            "Epoch 24/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.9997 - categorical_accuracy: 0.5457 - val_loss: 1.2453 - val_categorical_accuracy: 0.4192\n",
            "Epoch 25/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 1.0510 - categorical_accuracy: 0.5285 - val_loss: 1.2185 - val_categorical_accuracy: 0.4192\n",
            "Epoch 26/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 1.0290 - categorical_accuracy: 0.5452 - val_loss: 1.1009 - val_categorical_accuracy: 0.4520\n",
            "Epoch 27/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 1.0240 - categorical_accuracy: 0.5527 - val_loss: 1.0795 - val_categorical_accuracy: 0.4716\n",
            "Epoch 28/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 1.0137 - categorical_accuracy: 0.5354 - val_loss: 1.2933 - val_categorical_accuracy: 0.4039\n",
            "Epoch 29/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.9994 - categorical_accuracy: 0.5522 - val_loss: 1.1188 - val_categorical_accuracy: 0.4389\n",
            "Epoch 30/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.9889 - categorical_accuracy: 0.5533 - val_loss: 1.1683 - val_categorical_accuracy: 0.4148\n",
            "Epoch 31/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.9938 - categorical_accuracy: 0.5527 - val_loss: 1.1723 - val_categorical_accuracy: 0.3996\n",
            "Epoch 32/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 1.0021 - categorical_accuracy: 0.5437 - val_loss: 1.0961 - val_categorical_accuracy: 0.4389\n",
            "Epoch 33/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 1.0056 - categorical_accuracy: 0.5543 - val_loss: 1.1330 - val_categorical_accuracy: 0.4170\n",
            "Epoch 34/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.9899 - categorical_accuracy: 0.5511 - val_loss: 1.1913 - val_categorical_accuracy: 0.4236\n",
            "Epoch 35/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.9952 - categorical_accuracy: 0.5672 - val_loss: 1.1269 - val_categorical_accuracy: 0.4410\n",
            "Epoch 36/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.9746 - categorical_accuracy: 0.5669 - val_loss: 1.1268 - val_categorical_accuracy: 0.4214\n",
            "Epoch 37/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.9741 - categorical_accuracy: 0.5717 - val_loss: 1.0869 - val_categorical_accuracy: 0.4498\n",
            "Epoch 38/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.9785 - categorical_accuracy: 0.5765 - val_loss: 1.1117 - val_categorical_accuracy: 0.4498\n",
            "Epoch 39/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.9797 - categorical_accuracy: 0.5704 - val_loss: 1.1157 - val_categorical_accuracy: 0.4301\n",
            "Epoch 40/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.9703 - categorical_accuracy: 0.5632 - val_loss: 1.1965 - val_categorical_accuracy: 0.4127\n",
            "Epoch 41/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.9969 - categorical_accuracy: 0.5611 - val_loss: 1.1009 - val_categorical_accuracy: 0.4432\n",
            "Epoch 42/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.9926 - categorical_accuracy: 0.5589 - val_loss: 1.0731 - val_categorical_accuracy: 0.4672\n",
            "Epoch 43/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.9604 - categorical_accuracy: 0.5713 - val_loss: 1.2238 - val_categorical_accuracy: 0.4061\n",
            "Epoch 44/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.9697 - categorical_accuracy: 0.5569 - val_loss: 1.1221 - val_categorical_accuracy: 0.4214\n",
            "Epoch 45/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.9687 - categorical_accuracy: 0.5732 - val_loss: 1.0926 - val_categorical_accuracy: 0.4476\n",
            "Epoch 46/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.9513 - categorical_accuracy: 0.5795 - val_loss: 1.0372 - val_categorical_accuracy: 0.4825\n",
            "Epoch 47/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.9643 - categorical_accuracy: 0.5706 - val_loss: 1.1080 - val_categorical_accuracy: 0.4258\n",
            "Epoch 48/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.9549 - categorical_accuracy: 0.5772 - val_loss: 1.0837 - val_categorical_accuracy: 0.4498\n",
            "Epoch 49/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.9410 - categorical_accuracy: 0.5686 - val_loss: 1.1809 - val_categorical_accuracy: 0.4127\n",
            "Epoch 50/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.9570 - categorical_accuracy: 0.5744 - val_loss: 1.0829 - val_categorical_accuracy: 0.4476\n",
            "Epoch 51/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.9367 - categorical_accuracy: 0.5811 - val_loss: 1.1191 - val_categorical_accuracy: 0.4432\n",
            "Epoch 52/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.9562 - categorical_accuracy: 0.5837 - val_loss: 1.1598 - val_categorical_accuracy: 0.4127\n",
            "Epoch 53/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.9535 - categorical_accuracy: 0.5772 - val_loss: 1.0907 - val_categorical_accuracy: 0.4454\n",
            "Epoch 54/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.9618 - categorical_accuracy: 0.5583 - val_loss: 1.1441 - val_categorical_accuracy: 0.4323\n",
            "Epoch 55/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.9479 - categorical_accuracy: 0.5787 - val_loss: 1.1303 - val_categorical_accuracy: 0.4301\n",
            "Epoch 56/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.9364 - categorical_accuracy: 0.5953 - val_loss: 1.1126 - val_categorical_accuracy: 0.4432\n",
            "Epoch 57/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.9171 - categorical_accuracy: 0.5863 - val_loss: 1.0794 - val_categorical_accuracy: 0.4476\n",
            "Epoch 58/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.9396 - categorical_accuracy: 0.5849 - val_loss: 1.0696 - val_categorical_accuracy: 0.4563\n",
            "Epoch 59/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.9504 - categorical_accuracy: 0.5813 - val_loss: 1.0590 - val_categorical_accuracy: 0.4651\n",
            "Epoch 60/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.9514 - categorical_accuracy: 0.5869 - val_loss: 1.0530 - val_categorical_accuracy: 0.4629\n",
            "Epoch 61/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.9475 - categorical_accuracy: 0.5885 - val_loss: 1.0918 - val_categorical_accuracy: 0.4454\n",
            "Epoch 62/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.9550 - categorical_accuracy: 0.5868 - val_loss: 1.0337 - val_categorical_accuracy: 0.4782\n",
            "Epoch 63/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.9317 - categorical_accuracy: 0.5925 - val_loss: 1.1104 - val_categorical_accuracy: 0.4367\n",
            "Epoch 64/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.9020 - categorical_accuracy: 0.6032 - val_loss: 1.1091 - val_categorical_accuracy: 0.4389\n",
            "Epoch 65/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.9383 - categorical_accuracy: 0.5923 - val_loss: 1.1066 - val_categorical_accuracy: 0.4410\n",
            "Epoch 66/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.9613 - categorical_accuracy: 0.5761 - val_loss: 1.1235 - val_categorical_accuracy: 0.4367\n",
            "Epoch 67/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.9288 - categorical_accuracy: 0.5832 - val_loss: 1.0576 - val_categorical_accuracy: 0.4738\n",
            "Epoch 68/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.9327 - categorical_accuracy: 0.5916 - val_loss: 1.0993 - val_categorical_accuracy: 0.4367\n",
            "Epoch 69/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.9418 - categorical_accuracy: 0.5838 - val_loss: 1.0597 - val_categorical_accuracy: 0.4782\n",
            "Epoch 70/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.9253 - categorical_accuracy: 0.5778 - val_loss: 1.0773 - val_categorical_accuracy: 0.4498\n",
            "Epoch 71/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.9308 - categorical_accuracy: 0.5823 - val_loss: 1.0298 - val_categorical_accuracy: 0.4716\n",
            "Epoch 72/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.9422 - categorical_accuracy: 0.5818 - val_loss: 1.0386 - val_categorical_accuracy: 0.4825\n",
            "Epoch 73/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.8866 - categorical_accuracy: 0.6130 - val_loss: 1.0113 - val_categorical_accuracy: 0.4934\n",
            "Epoch 74/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.9175 - categorical_accuracy: 0.5933 - val_loss: 1.0674 - val_categorical_accuracy: 0.4694\n",
            "Epoch 75/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.9243 - categorical_accuracy: 0.5833 - val_loss: 1.0876 - val_categorical_accuracy: 0.4410\n",
            "Epoch 76/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.9159 - categorical_accuracy: 0.5957 - val_loss: 1.0727 - val_categorical_accuracy: 0.4563\n",
            "Epoch 77/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.9140 - categorical_accuracy: 0.6011 - val_loss: 1.0032 - val_categorical_accuracy: 0.5087\n",
            "Epoch 78/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.9174 - categorical_accuracy: 0.5931 - val_loss: 0.9950 - val_categorical_accuracy: 0.5131\n",
            "Epoch 79/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.9240 - categorical_accuracy: 0.5923 - val_loss: 1.0418 - val_categorical_accuracy: 0.4738\n",
            "Epoch 80/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.9211 - categorical_accuracy: 0.5802 - val_loss: 1.0485 - val_categorical_accuracy: 0.4585\n",
            "Epoch 81/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.9134 - categorical_accuracy: 0.5925 - val_loss: 1.0283 - val_categorical_accuracy: 0.4891\n",
            "Epoch 82/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.9044 - categorical_accuracy: 0.6060 - val_loss: 0.9806 - val_categorical_accuracy: 0.5655\n",
            "Epoch 83/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.9310 - categorical_accuracy: 0.5970 - val_loss: 1.0412 - val_categorical_accuracy: 0.4672\n",
            "Epoch 84/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.9033 - categorical_accuracy: 0.6091 - val_loss: 1.0077 - val_categorical_accuracy: 0.5000\n",
            "Epoch 85/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.9146 - categorical_accuracy: 0.6137 - val_loss: 0.9725 - val_categorical_accuracy: 0.5306\n",
            "Epoch 86/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.9165 - categorical_accuracy: 0.5968 - val_loss: 1.0271 - val_categorical_accuracy: 0.4825\n",
            "Epoch 87/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.9022 - categorical_accuracy: 0.5926 - val_loss: 1.0419 - val_categorical_accuracy: 0.4847\n",
            "Epoch 88/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.9120 - categorical_accuracy: 0.5965 - val_loss: 0.9891 - val_categorical_accuracy: 0.5284\n",
            "Epoch 89/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.9131 - categorical_accuracy: 0.5946 - val_loss: 0.9777 - val_categorical_accuracy: 0.5349\n",
            "Epoch 90/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.9052 - categorical_accuracy: 0.6076 - val_loss: 1.1188 - val_categorical_accuracy: 0.4279\n",
            "Epoch 91/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.9239 - categorical_accuracy: 0.5990 - val_loss: 1.0619 - val_categorical_accuracy: 0.4541\n",
            "Epoch 92/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.9058 - categorical_accuracy: 0.6018 - val_loss: 1.0399 - val_categorical_accuracy: 0.4803\n",
            "Epoch 93/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.9050 - categorical_accuracy: 0.5987 - val_loss: 0.9887 - val_categorical_accuracy: 0.5131\n",
            "Epoch 94/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.9017 - categorical_accuracy: 0.6003 - val_loss: 1.0488 - val_categorical_accuracy: 0.4738\n",
            "Epoch 95/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.8983 - categorical_accuracy: 0.6040 - val_loss: 1.0255 - val_categorical_accuracy: 0.4716\n",
            "Epoch 96/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.9106 - categorical_accuracy: 0.5978 - val_loss: 1.0194 - val_categorical_accuracy: 0.4825\n",
            "Epoch 97/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.9005 - categorical_accuracy: 0.6035 - val_loss: 1.0111 - val_categorical_accuracy: 0.5218\n",
            "Epoch 98/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.8882 - categorical_accuracy: 0.6103 - val_loss: 1.0251 - val_categorical_accuracy: 0.4956\n",
            "Epoch 99/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.9004 - categorical_accuracy: 0.5983 - val_loss: 1.0040 - val_categorical_accuracy: 0.5218\n",
            "Epoch 100/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.9150 - categorical_accuracy: 0.6016 - val_loss: 0.9927 - val_categorical_accuracy: 0.5371\n",
            "Epoch 101/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.8802 - categorical_accuracy: 0.6242 - val_loss: 1.0113 - val_categorical_accuracy: 0.5044\n",
            "Epoch 102/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.9137 - categorical_accuracy: 0.6083 - val_loss: 0.9827 - val_categorical_accuracy: 0.5087\n",
            "Epoch 103/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.8841 - categorical_accuracy: 0.6076 - val_loss: 1.0138 - val_categorical_accuracy: 0.4913\n",
            "Epoch 104/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.8869 - categorical_accuracy: 0.6048 - val_loss: 1.0213 - val_categorical_accuracy: 0.4760\n",
            "Epoch 105/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.8665 - categorical_accuracy: 0.6236 - val_loss: 1.0756 - val_categorical_accuracy: 0.4498\n",
            "Epoch 106/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.9033 - categorical_accuracy: 0.6028 - val_loss: 1.0387 - val_categorical_accuracy: 0.4782\n",
            "Epoch 107/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.9062 - categorical_accuracy: 0.6137 - val_loss: 0.9764 - val_categorical_accuracy: 0.5240\n",
            "Epoch 108/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.8662 - categorical_accuracy: 0.6202 - val_loss: 1.0036 - val_categorical_accuracy: 0.5000\n",
            "Epoch 109/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.8903 - categorical_accuracy: 0.6028 - val_loss: 1.0078 - val_categorical_accuracy: 0.5044\n",
            "Epoch 110/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.8824 - categorical_accuracy: 0.6084 - val_loss: 0.9806 - val_categorical_accuracy: 0.5328\n",
            "Epoch 111/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.8869 - categorical_accuracy: 0.6118 - val_loss: 0.9583 - val_categorical_accuracy: 0.5611\n",
            "Epoch 112/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.8958 - categorical_accuracy: 0.6029 - val_loss: 0.9827 - val_categorical_accuracy: 0.5218\n",
            "Epoch 113/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.8641 - categorical_accuracy: 0.6187 - val_loss: 0.9633 - val_categorical_accuracy: 0.5306\n",
            "Epoch 114/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.8786 - categorical_accuracy: 0.6295 - val_loss: 0.9871 - val_categorical_accuracy: 0.4956\n",
            "Epoch 115/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.8700 - categorical_accuracy: 0.6227 - val_loss: 0.9884 - val_categorical_accuracy: 0.5153\n",
            "Epoch 116/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.8920 - categorical_accuracy: 0.6201 - val_loss: 0.9832 - val_categorical_accuracy: 0.5284\n",
            "Epoch 117/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.8661 - categorical_accuracy: 0.6157 - val_loss: 1.0508 - val_categorical_accuracy: 0.4672\n",
            "Epoch 118/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.9028 - categorical_accuracy: 0.6058 - val_loss: 1.0428 - val_categorical_accuracy: 0.4782\n",
            "Epoch 119/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.9004 - categorical_accuracy: 0.6037 - val_loss: 1.0314 - val_categorical_accuracy: 0.4956\n",
            "Epoch 120/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.8739 - categorical_accuracy: 0.6196 - val_loss: 1.0245 - val_categorical_accuracy: 0.4978\n",
            "Epoch 121/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.8549 - categorical_accuracy: 0.6158 - val_loss: 0.9951 - val_categorical_accuracy: 0.4956\n",
            "Epoch 122/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.8849 - categorical_accuracy: 0.6111 - val_loss: 1.0008 - val_categorical_accuracy: 0.5153\n",
            "Epoch 123/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.8799 - categorical_accuracy: 0.6032 - val_loss: 0.9783 - val_categorical_accuracy: 0.5240\n",
            "Epoch 124/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.8813 - categorical_accuracy: 0.6177 - val_loss: 0.9600 - val_categorical_accuracy: 0.5328\n",
            "Epoch 125/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.8708 - categorical_accuracy: 0.6282 - val_loss: 1.0054 - val_categorical_accuracy: 0.4978\n",
            "Epoch 126/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.8711 - categorical_accuracy: 0.6122 - val_loss: 1.0089 - val_categorical_accuracy: 0.5000\n",
            "Epoch 127/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.8508 - categorical_accuracy: 0.6319 - val_loss: 0.9929 - val_categorical_accuracy: 0.5153\n",
            "Epoch 128/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.8676 - categorical_accuracy: 0.6189 - val_loss: 0.9920 - val_categorical_accuracy: 0.5109\n",
            "Epoch 129/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.8688 - categorical_accuracy: 0.6223 - val_loss: 0.9591 - val_categorical_accuracy: 0.5437\n",
            "Epoch 130/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.8871 - categorical_accuracy: 0.6118 - val_loss: 0.9825 - val_categorical_accuracy: 0.5131\n",
            "Epoch 131/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.8728 - categorical_accuracy: 0.6173 - val_loss: 0.9580 - val_categorical_accuracy: 0.5437\n",
            "Epoch 132/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.8713 - categorical_accuracy: 0.6185 - val_loss: 0.9947 - val_categorical_accuracy: 0.5044\n",
            "Epoch 133/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.8640 - categorical_accuracy: 0.6285 - val_loss: 0.9687 - val_categorical_accuracy: 0.5175\n",
            "Epoch 134/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.8696 - categorical_accuracy: 0.6195 - val_loss: 0.9883 - val_categorical_accuracy: 0.5153\n",
            "Epoch 135/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.8573 - categorical_accuracy: 0.6101 - val_loss: 0.9780 - val_categorical_accuracy: 0.5306\n",
            "Epoch 136/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.8692 - categorical_accuracy: 0.6154 - val_loss: 1.0020 - val_categorical_accuracy: 0.5109\n",
            "Epoch 137/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.8520 - categorical_accuracy: 0.6339 - val_loss: 0.9704 - val_categorical_accuracy: 0.5437\n",
            "Epoch 138/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.8869 - categorical_accuracy: 0.6131 - val_loss: 0.9626 - val_categorical_accuracy: 0.5524\n",
            "Epoch 139/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.8754 - categorical_accuracy: 0.6247 - val_loss: 0.9637 - val_categorical_accuracy: 0.5393\n",
            "Epoch 140/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.8542 - categorical_accuracy: 0.6275 - val_loss: 1.0017 - val_categorical_accuracy: 0.5131\n",
            "Epoch 141/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.8796 - categorical_accuracy: 0.6211 - val_loss: 0.9957 - val_categorical_accuracy: 0.5240\n",
            "Epoch 142/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.8537 - categorical_accuracy: 0.6216 - val_loss: 0.9520 - val_categorical_accuracy: 0.5633\n",
            "Epoch 143/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.8520 - categorical_accuracy: 0.6236 - val_loss: 0.9649 - val_categorical_accuracy: 0.5371\n",
            "Epoch 144/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.8708 - categorical_accuracy: 0.6287 - val_loss: 0.9361 - val_categorical_accuracy: 0.5677\n",
            "Epoch 145/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.8589 - categorical_accuracy: 0.6282 - val_loss: 0.9393 - val_categorical_accuracy: 0.5611\n",
            "Epoch 146/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.8486 - categorical_accuracy: 0.6327 - val_loss: 0.9732 - val_categorical_accuracy: 0.5284\n",
            "Epoch 147/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.8898 - categorical_accuracy: 0.6173 - val_loss: 0.9672 - val_categorical_accuracy: 0.5328\n",
            "Epoch 148/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.8422 - categorical_accuracy: 0.6273 - val_loss: 0.9954 - val_categorical_accuracy: 0.5000\n",
            "Epoch 149/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.8432 - categorical_accuracy: 0.6324 - val_loss: 0.9179 - val_categorical_accuracy: 0.5764\n",
            "Epoch 150/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.8388 - categorical_accuracy: 0.6473 - val_loss: 0.9251 - val_categorical_accuracy: 0.5939\n",
            "Epoch 151/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.8651 - categorical_accuracy: 0.6246 - val_loss: 0.9804 - val_categorical_accuracy: 0.5328\n",
            "Epoch 152/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.8320 - categorical_accuracy: 0.6469 - val_loss: 0.9993 - val_categorical_accuracy: 0.5175\n",
            "Epoch 153/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.8507 - categorical_accuracy: 0.6313 - val_loss: 0.9502 - val_categorical_accuracy: 0.5459\n",
            "Epoch 154/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.8485 - categorical_accuracy: 0.6302 - val_loss: 0.9283 - val_categorical_accuracy: 0.5655\n",
            "Epoch 155/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.8729 - categorical_accuracy: 0.6144 - val_loss: 0.9352 - val_categorical_accuracy: 0.5546\n",
            "Epoch 156/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.8621 - categorical_accuracy: 0.6186 - val_loss: 0.9350 - val_categorical_accuracy: 0.5546\n",
            "Epoch 157/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.8540 - categorical_accuracy: 0.6382 - val_loss: 0.9848 - val_categorical_accuracy: 0.5175\n",
            "Epoch 158/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.8736 - categorical_accuracy: 0.6256 - val_loss: 0.9428 - val_categorical_accuracy: 0.5502\n",
            "Epoch 159/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.8675 - categorical_accuracy: 0.6228 - val_loss: 0.9192 - val_categorical_accuracy: 0.5677\n",
            "Epoch 160/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.8506 - categorical_accuracy: 0.6427 - val_loss: 0.8938 - val_categorical_accuracy: 0.6179\n",
            "Epoch 161/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.8557 - categorical_accuracy: 0.6358 - val_loss: 1.0288 - val_categorical_accuracy: 0.4934\n",
            "Epoch 162/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.8346 - categorical_accuracy: 0.6393 - val_loss: 0.9543 - val_categorical_accuracy: 0.5611\n",
            "Epoch 163/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.8635 - categorical_accuracy: 0.6285 - val_loss: 0.9453 - val_categorical_accuracy: 0.5437\n",
            "Epoch 164/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.8322 - categorical_accuracy: 0.6431 - val_loss: 0.9831 - val_categorical_accuracy: 0.5175\n",
            "Epoch 165/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.8535 - categorical_accuracy: 0.6245 - val_loss: 0.9806 - val_categorical_accuracy: 0.5153\n",
            "Epoch 166/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.8624 - categorical_accuracy: 0.6300 - val_loss: 0.9278 - val_categorical_accuracy: 0.5742\n",
            "Epoch 167/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.8373 - categorical_accuracy: 0.6336 - val_loss: 0.9507 - val_categorical_accuracy: 0.5524\n",
            "Epoch 168/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.8436 - categorical_accuracy: 0.6307 - val_loss: 0.9125 - val_categorical_accuracy: 0.5764\n",
            "Epoch 169/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.8639 - categorical_accuracy: 0.6235 - val_loss: 0.9324 - val_categorical_accuracy: 0.5721\n",
            "Epoch 170/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.8404 - categorical_accuracy: 0.6402 - val_loss: 0.9323 - val_categorical_accuracy: 0.5786\n",
            "Epoch 171/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.8274 - categorical_accuracy: 0.6483 - val_loss: 0.9187 - val_categorical_accuracy: 0.5742\n",
            "Epoch 172/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.8438 - categorical_accuracy: 0.6369 - val_loss: 0.9261 - val_categorical_accuracy: 0.5721\n",
            "Epoch 173/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.8373 - categorical_accuracy: 0.6449 - val_loss: 0.9049 - val_categorical_accuracy: 0.5830\n",
            "Epoch 174/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.8327 - categorical_accuracy: 0.6415 - val_loss: 0.9657 - val_categorical_accuracy: 0.5349\n",
            "Epoch 175/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.8329 - categorical_accuracy: 0.6337 - val_loss: 0.9680 - val_categorical_accuracy: 0.5306\n",
            "Epoch 176/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.8558 - categorical_accuracy: 0.6139 - val_loss: 0.9298 - val_categorical_accuracy: 0.5742\n",
            "Epoch 177/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.8493 - categorical_accuracy: 0.6327 - val_loss: 0.9225 - val_categorical_accuracy: 0.5764\n",
            "Epoch 178/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.8213 - categorical_accuracy: 0.6487 - val_loss: 0.9439 - val_categorical_accuracy: 0.5590\n",
            "Epoch 179/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.8433 - categorical_accuracy: 0.6357 - val_loss: 0.9115 - val_categorical_accuracy: 0.5721\n",
            "Epoch 180/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.8390 - categorical_accuracy: 0.6487 - val_loss: 0.9079 - val_categorical_accuracy: 0.5699\n",
            "Epoch 181/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.8328 - categorical_accuracy: 0.6366 - val_loss: 0.9322 - val_categorical_accuracy: 0.5655\n",
            "Epoch 182/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.8398 - categorical_accuracy: 0.6336 - val_loss: 0.9519 - val_categorical_accuracy: 0.5371\n",
            "Epoch 183/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.8378 - categorical_accuracy: 0.6360 - val_loss: 1.0220 - val_categorical_accuracy: 0.5131\n",
            "Epoch 184/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.8323 - categorical_accuracy: 0.6407 - val_loss: 0.9561 - val_categorical_accuracy: 0.5459\n",
            "Epoch 185/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.8072 - categorical_accuracy: 0.6519 - val_loss: 0.9570 - val_categorical_accuracy: 0.5415\n",
            "Epoch 186/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.8385 - categorical_accuracy: 0.6401 - val_loss: 0.9623 - val_categorical_accuracy: 0.5568\n",
            "Epoch 187/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.8222 - categorical_accuracy: 0.6524 - val_loss: 0.9235 - val_categorical_accuracy: 0.5721\n",
            "Epoch 188/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.8496 - categorical_accuracy: 0.6247 - val_loss: 0.9450 - val_categorical_accuracy: 0.5524\n",
            "Epoch 189/200\n",
            "258/258 [==============================] - 2s 7ms/step - loss: 0.8510 - categorical_accuracy: 0.6412 - val_loss: 0.9191 - val_categorical_accuracy: 0.5677\n",
            "Epoch 190/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.8196 - categorical_accuracy: 0.6448 - val_loss: 0.9398 - val_categorical_accuracy: 0.5568\n",
            "Epoch 191/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.8319 - categorical_accuracy: 0.6453 - val_loss: 0.9734 - val_categorical_accuracy: 0.5349\n",
            "Epoch 192/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.8395 - categorical_accuracy: 0.6464 - val_loss: 0.8929 - val_categorical_accuracy: 0.6135\n",
            "Epoch 193/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.8287 - categorical_accuracy: 0.6339 - val_loss: 0.9320 - val_categorical_accuracy: 0.5590\n",
            "Epoch 194/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.8296 - categorical_accuracy: 0.6484 - val_loss: 0.9208 - val_categorical_accuracy: 0.5808\n",
            "Epoch 195/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.8318 - categorical_accuracy: 0.6334 - val_loss: 0.9085 - val_categorical_accuracy: 0.6004\n",
            "Epoch 196/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.8281 - categorical_accuracy: 0.6448 - val_loss: 0.9298 - val_categorical_accuracy: 0.5786\n",
            "Epoch 197/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.8180 - categorical_accuracy: 0.6588 - val_loss: 0.9313 - val_categorical_accuracy: 0.5786\n",
            "Epoch 198/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.8471 - categorical_accuracy: 0.6329 - val_loss: 0.9046 - val_categorical_accuracy: 0.5830\n",
            "Epoch 199/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.8427 - categorical_accuracy: 0.6400 - val_loss: 0.9502 - val_categorical_accuracy: 0.5524\n",
            "Epoch 200/200\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.8295 - categorical_accuracy: 0.6347 - val_loss: 0.8925 - val_categorical_accuracy: 0.5852\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZvrlt7DuvVN"
      },
      "source": [
        "model.save('/content/drive/MyDrive/Colab Notebooks/SPEECH_EMOTION_Recognition/Nộp bài(chốt hạ)/model_saver/conv2D_mfcc26_cremad.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5hwbtZmeuvVP"
      },
      "source": [
        "###test_result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AT-mWFp7uvVQ",
        "outputId": "2d6b2810-95ef-4e00-d81b-0841e393b884"
      },
      "source": [
        "d = {0: 'happy',\n",
        "     1: 'sad',\n",
        "     2: 'angry',\n",
        "     3: 'fear'}\n",
        "Y_test_pred = np.argmax(model.predict(X_test), axis=-1)\n",
        "Y_test_pred = list(map(lambda x: d[x], Y_test_pred))\n",
        "y_test = np.argmax(y_test, axis=-1)\n",
        "y_test = list(map(lambda x: d[x], y_test))\n",
        "print(classification_report(y_test, Y_test_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.72      0.72      0.72       136\n",
            "        fear       0.56      0.50      0.53       134\n",
            "       happy       0.60      0.62      0.61       120\n",
            "         sad       0.67      0.71      0.69       119\n",
            "\n",
            "    accuracy                           0.64       509\n",
            "   macro avg       0.64      0.64      0.64       509\n",
            "weighted avg       0.64      0.64      0.64       509\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 483
        },
        "id": "m0Gg7oOEuvVS",
        "outputId": "1a88da5c-5ef2-4f19-c830-926c7ac25b58"
      },
      "source": [
        "import scikitplot as skplt\n",
        "\n",
        "skplt.metrics.plot_confusion_matrix(\n",
        "    y_test, \n",
        "    Y_test_pred,\n",
        "    figsize=(8,8))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fa46c14db10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1UXXf0vGuvVT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8jZBJ97Bu6Jw"
      },
      "source": [
        "# mfcc_39 + conv2D:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6gYzFTPu6Jx"
      },
      "source": [
        "audio_duration = 3\n",
        "sampling_rate = 22050\n",
        "input_length = sampling_rate * audio_duration"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFAtVZnJu6Jy"
      },
      "source": [
        "data = {'labels': [],\n",
        "        'features': []}\n",
        "\n",
        "for i in range(len(CREMA_D_df)):\n",
        "  if ((CREMA_D_df['Emotion'][i] == 'HAP') | (CREMA_D_df['Emotion'][i] == 'SAD') | \n",
        "      (CREMA_D_df['Emotion'][i] == 'ANG') | (CREMA_D_df['Emotion'][i] == 'FEA')):\n",
        "    \n",
        "    if CREMA_D_df['Emotion'][i] == 'HAP':\n",
        "      data['labels'].append(0)\n",
        "    elif CREMA_D_df['Emotion'][i] == 'SAD':\n",
        "      data['labels'].append(1)\n",
        "    elif CREMA_D_df['Emotion'][i] == 'ANG':\n",
        "      data['labels'].append(2)\n",
        "    elif CREMA_D_df['Emotion'][i] == 'FEA':\n",
        "      data['labels'].append(3)\n",
        "\n",
        "\n",
        "    signal, sr =  librosa.load(CREMA_D_df['Paths'][i])\n",
        "\n",
        "    if len(signal) > input_length:\n",
        "        signal = signal[0:input_length]\n",
        "    elif  input_length > len(signal):\n",
        "        max_offset = input_length - len(signal)  \n",
        "        signal = np.pad(signal, (0, max_offset), \"constant\")\n",
        "\n",
        "    mfcc = librosa.feature.mfcc(y=signal, sr=sr, n_mfcc=39).T\n",
        "    mfcc = np.expand_dims(mfcc, axis=-1)\n",
        "    data['features'].append(mfcc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sHQNXG_Eu6Jz"
      },
      "source": [
        "X = data['features']\n",
        "y = data['labels']\n",
        "\n",
        "y = np.array(y)\n",
        "y = to_categorical(y)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=0)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=0)\n",
        "\n",
        "X_train = np.array(X_train)\n",
        "X_test = np.array(X_test)\n",
        "X_val = np.array(X_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WgBirwMHu6J0",
        "outputId": "1b969b63-ee3d-4bac-d032-43ee1a82c311"
      },
      "source": [
        "X_train.shape,X_test.shape,y_train.shape,y_test.shape\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((4117, 130, 39, 1), (509, 130, 39, 1), (4117, 4), (509, 4))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6gDYbVnXu6J2"
      },
      "source": [
        "# CNN I/P Config\n",
        "num_classes = 4\n",
        "input_shape = X_train.shape[1:]\n",
        "learning_rate = 0.0001\n",
        "decay = 1e-6\n",
        "momentum = 0.9"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jV3fKa0-u6J3",
        "outputId": "34c0c845-18ce-4f3f-a447-7f726bc964c9"
      },
      "source": [
        "model = Sequential(name='Audio_CNN_2D')\n",
        "\n",
        "# LFLB1\n",
        "model.add(Conv2D(filters=64, kernel_size=(3,3), strides=(1,1), padding='same',input_shape=input_shape))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Conv2D(filters=64, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(4,4), strides=(4,4)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(units=num_classes, activation='softmax'))\n",
        "\n",
        "# Model compilation\n",
        "opt = optimizers.SGD(lr=learning_rate, decay=decay, momentum=momentum, nesterov=True)\n",
        "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"Audio_CNN_2D\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_4 (Conv2D)            (None, 130, 39, 64)       640       \n",
            "_________________________________________________________________\n",
            "batch_normalization_12 (Batc (None, 130, 39, 64)       256       \n",
            "_________________________________________________________________\n",
            "activation_12 (Activation)   (None, 130, 39, 64)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 65, 19, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_12 (Dropout)         (None, 65, 19, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 65, 19, 64)        36928     \n",
            "_________________________________________________________________\n",
            "batch_normalization_13 (Batc (None, 65, 19, 64)        256       \n",
            "_________________________________________________________________\n",
            "activation_13 (Activation)   (None, 65, 19, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 16, 4, 64)         0         \n",
            "_________________________________________________________________\n",
            "dropout_13 (Dropout)         (None, 16, 4, 64)         0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 4)                 16388     \n",
            "=================================================================\n",
            "Total params: 54,468\n",
            "Trainable params: 54,212\n",
            "Non-trainable params: 256\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NxvemNQPu6J4",
        "outputId": "b8eb93ea-c86b-48cd-d1ff-b449938aaa2b"
      },
      "source": [
        "#Train Config\n",
        "\n",
        "batch_size = 16\n",
        "num_epochs = 200\n",
        "\n",
        "# Model Training\n",
        "lr_reduce = ReduceLROnPlateau(monitor='val_loss', factor=0.9, patience=20, min_lr=0.000001)\n",
        "# Please change the model name accordingly.\n",
        "mcp_save = ModelCheckpoint('/content/Modelfull_2_1.h5', save_best_only=True, monitor='val_categorical_accuracy', mode='max')\n",
        "cnnhistory=model.fit(X_train, y_train, batch_size=batch_size, epochs=num_epochs,validation_data=(X_val, y_val), callbacks=[mcp_save, lr_reduce])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "258/258 [==============================] - 4s 10ms/step - loss: 2.2613 - categorical_accuracy: 0.3076 - val_loss: 1.3784 - val_categorical_accuracy: 0.3974\n",
            "Epoch 2/200\n",
            "258/258 [==============================] - 2s 7ms/step - loss: 1.5011 - categorical_accuracy: 0.4073 - val_loss: 1.2650 - val_categorical_accuracy: 0.4105\n",
            "Epoch 3/200\n",
            "258/258 [==============================] - 2s 7ms/step - loss: 1.3009 - categorical_accuracy: 0.4525 - val_loss: 1.2170 - val_categorical_accuracy: 0.4367\n",
            "Epoch 4/200\n",
            "258/258 [==============================] - 2s 7ms/step - loss: 1.2123 - categorical_accuracy: 0.4789 - val_loss: 1.1826 - val_categorical_accuracy: 0.3821\n",
            "Epoch 5/200\n",
            "258/258 [==============================] - 2s 7ms/step - loss: 1.1489 - categorical_accuracy: 0.4870 - val_loss: 1.1042 - val_categorical_accuracy: 0.4629\n",
            "Epoch 6/200\n",
            "258/258 [==============================] - 2s 7ms/step - loss: 1.1622 - categorical_accuracy: 0.4981 - val_loss: 1.1691 - val_categorical_accuracy: 0.4105\n",
            "Epoch 7/200\n",
            "258/258 [==============================] - 2s 7ms/step - loss: 1.1254 - categorical_accuracy: 0.5109 - val_loss: 1.1502 - val_categorical_accuracy: 0.4345\n",
            "Epoch 8/200\n",
            "258/258 [==============================] - 2s 7ms/step - loss: 1.1142 - categorical_accuracy: 0.4928 - val_loss: 1.1283 - val_categorical_accuracy: 0.4214\n",
            "Epoch 9/200\n",
            "258/258 [==============================] - 2s 7ms/step - loss: 1.1317 - categorical_accuracy: 0.5012 - val_loss: 1.1221 - val_categorical_accuracy: 0.4476\n",
            "Epoch 10/200\n",
            "258/258 [==============================] - 2s 7ms/step - loss: 1.0777 - categorical_accuracy: 0.5330 - val_loss: 1.2148 - val_categorical_accuracy: 0.3930\n",
            "Epoch 11/200\n",
            "258/258 [==============================] - 2s 7ms/step - loss: 1.0729 - categorical_accuracy: 0.5278 - val_loss: 1.1464 - val_categorical_accuracy: 0.4520\n",
            "Epoch 12/200\n",
            "258/258 [==============================] - 2s 7ms/step - loss: 1.0724 - categorical_accuracy: 0.5382 - val_loss: 1.1182 - val_categorical_accuracy: 0.4760\n",
            "Epoch 13/200\n",
            "258/258 [==============================] - 2s 7ms/step - loss: 1.0538 - categorical_accuracy: 0.5441 - val_loss: 1.1757 - val_categorical_accuracy: 0.4410\n",
            "Epoch 14/200\n",
            "258/258 [==============================] - 2s 7ms/step - loss: 1.0806 - categorical_accuracy: 0.5201 - val_loss: 1.1177 - val_categorical_accuracy: 0.4367\n",
            "Epoch 15/200\n",
            "258/258 [==============================] - 2s 7ms/step - loss: 1.0591 - categorical_accuracy: 0.5259 - val_loss: 1.1218 - val_categorical_accuracy: 0.4410\n",
            "Epoch 16/200\n",
            "258/258 [==============================] - 2s 7ms/step - loss: 1.0453 - categorical_accuracy: 0.5452 - val_loss: 1.1047 - val_categorical_accuracy: 0.4782\n",
            "Epoch 17/200\n",
            "258/258 [==============================] - 2s 7ms/step - loss: 1.0430 - categorical_accuracy: 0.5328 - val_loss: 1.1199 - val_categorical_accuracy: 0.4738\n",
            "Epoch 18/200\n",
            "258/258 [==============================] - 2s 7ms/step - loss: 1.0415 - categorical_accuracy: 0.5357 - val_loss: 1.3665 - val_categorical_accuracy: 0.4017\n",
            "Epoch 19/200\n",
            "258/258 [==============================] - 2s 7ms/step - loss: 1.0355 - categorical_accuracy: 0.5447 - val_loss: 1.1683 - val_categorical_accuracy: 0.4170\n",
            "Epoch 20/200\n",
            "258/258 [==============================] - 2s 7ms/step - loss: 1.0510 - categorical_accuracy: 0.5336 - val_loss: 1.1181 - val_categorical_accuracy: 0.4716\n",
            "Epoch 21/200\n",
            "258/258 [==============================] - 2s 7ms/step - loss: 1.0087 - categorical_accuracy: 0.5500 - val_loss: 1.1651 - val_categorical_accuracy: 0.4279\n",
            "Epoch 22/200\n",
            "258/258 [==============================] - 2s 7ms/step - loss: 1.0161 - categorical_accuracy: 0.5481 - val_loss: 1.1090 - val_categorical_accuracy: 0.4825\n",
            "Epoch 23/200\n",
            "258/258 [==============================] - 2s 7ms/step - loss: 1.0049 - categorical_accuracy: 0.5637 - val_loss: 1.1493 - val_categorical_accuracy: 0.3996\n",
            "Epoch 24/200\n",
            "258/258 [==============================] - 2s 7ms/step - loss: 1.0277 - categorical_accuracy: 0.5365 - val_loss: 1.2485 - val_categorical_accuracy: 0.4345\n",
            "Epoch 25/200\n",
            "258/258 [==============================] - 2s 7ms/step - loss: 1.0071 - categorical_accuracy: 0.5533 - val_loss: 1.2557 - val_categorical_accuracy: 0.4039\n",
            "Epoch 26/200\n",
            "258/258 [==============================] - 2s 7ms/step - loss: 0.9917 - categorical_accuracy: 0.5527 - val_loss: 1.1685 - val_categorical_accuracy: 0.4170\n",
            "Epoch 27/200\n",
            "258/258 [==============================] - 2s 7ms/step - loss: 1.0079 - categorical_accuracy: 0.5513 - val_loss: 1.1207 - val_categorical_accuracy: 0.4520\n",
            "Epoch 28/200\n",
            "258/258 [==============================] - 2s 7ms/step - loss: 1.0047 - categorical_accuracy: 0.5566 - val_loss: 1.1450 - val_categorical_accuracy: 0.4520\n",
            "Epoch 29/200\n",
            "258/258 [==============================] - 2s 7ms/step - loss: 0.9937 - categorical_accuracy: 0.5561 - val_loss: 1.2362 - val_categorical_accuracy: 0.4236\n",
            "Epoch 30/200\n",
            "258/258 [==============================] - 2s 7ms/step - loss: 1.0096 - categorical_accuracy: 0.5472 - val_loss: 1.1270 - val_categorical_accuracy: 0.4651\n",
            "Epoch 31/200\n",
            "258/258 [==============================] - 2s 7ms/step - loss: 0.9726 - categorical_accuracy: 0.5691 - val_loss: 1.1989 - val_categorical_accuracy: 0.4410\n",
            "Epoch 32/200\n",
            "258/258 [==============================] - 2s 7ms/step - loss: 0.9985 - categorical_accuracy: 0.5482 - val_loss: 1.2044 - val_categorical_accuracy: 0.4105\n",
            "Epoch 33/200\n",
            "258/258 [==============================] - 2s 7ms/step - loss: 0.9780 - categorical_accuracy: 0.5620 - val_loss: 1.1267 - val_categorical_accuracy: 0.4345\n",
            "Epoch 34/200\n",
            "258/258 [==============================] - 2s 7ms/step - loss: 0.9824 - categorical_accuracy: 0.5734 - val_loss: 1.0558 - val_categorical_accuracy: 0.5197\n",
            "Epoch 35/200\n",
            "258/258 [==============================] - 2s 7ms/step - loss: 0.9741 - categorical_accuracy: 0.5707 - val_loss: 1.0914 - val_categorical_accuracy: 0.4891\n",
            "Epoch 36/200\n",
            "258/258 [==============================] - 2s 7ms/step - loss: 0.9713 - categorical_accuracy: 0.5743 - val_loss: 1.1445 - val_categorical_accuracy: 0.4214\n",
            "Epoch 37/200\n",
            "258/258 [==============================] - 2s 7ms/step - loss: 0.9743 - categorical_accuracy: 0.5569 - val_loss: 1.1397 - val_categorical_accuracy: 0.4585\n",
            "Epoch 38/200\n",
            "258/258 [==============================] - 2s 7ms/step - loss: 0.9703 - categorical_accuracy: 0.5716 - val_loss: 1.2420 - val_categorical_accuracy: 0.4301\n",
            "Epoch 39/200\n",
            "258/258 [==============================] - 2s 7ms/step - loss: 0.9802 - categorical_accuracy: 0.5632 - val_loss: 1.1452 - val_categorical_accuracy: 0.4192\n",
            "Epoch 40/200\n",
            "258/258 [==============================] - 2s 7ms/step - loss: 0.9719 - categorical_accuracy: 0.5613 - val_loss: 1.1381 - val_categorical_accuracy: 0.4367\n",
            "Epoch 41/200\n",
            "258/258 [==============================] - 2s 7ms/step - loss: 0.9661 - categorical_accuracy: 0.5646 - val_loss: 1.0601 - val_categorical_accuracy: 0.4782\n",
            "Epoch 42/200\n",
            "258/258 [==============================] - 2s 7ms/step - loss: 0.9408 - categorical_accuracy: 0.5870 - val_loss: 1.2825 - val_categorical_accuracy: 0.4039\n",
            "Epoch 43/200\n",
            "258/258 [==============================] - 2s 7ms/step - loss: 0.9541 - categorical_accuracy: 0.5751 - val_loss: 1.2390 - val_categorical_accuracy: 0.4148\n",
            "Epoch 44/200\n",
            "258/258 [==============================] - 2s 7ms/step - loss: 0.9529 - categorical_accuracy: 0.5893 - val_loss: 1.0927 - val_categorical_accuracy: 0.4454\n",
            "Epoch 45/200\n",
            "258/258 [==============================] - 2s 7ms/step - loss: 0.9718 - categorical_accuracy: 0.5517 - val_loss: 1.3056 - val_categorical_accuracy: 0.3908\n",
            "Epoch 46/200\n",
            "258/258 [==============================] - 2s 7ms/step - loss: 0.9472 - categorical_accuracy: 0.5732 - val_loss: 1.1789 - val_categorical_accuracy: 0.4236\n",
            "Epoch 47/200\n",
            "258/258 [==============================] - 2s 7ms/step - loss: 0.9475 - categorical_accuracy: 0.5777 - val_loss: 1.1585 - val_categorical_accuracy: 0.4061\n",
            "Epoch 48/200\n",
            "258/258 [==============================] - 2s 7ms/step - loss: 0.9662 - categorical_accuracy: 0.5730 - val_loss: 1.0600 - val_categorical_accuracy: 0.4803\n",
            "Epoch 49/200\n",
            "258/258 [==============================] - 2s 7ms/step - loss: 0.9481 - categorical_accuracy: 0.5748 - val_loss: 1.1546 - val_categorical_accuracy: 0.4170\n",
            "Epoch 50/200\n",
            "258/258 [==============================] - 2s 7ms/step - loss: 0.9650 - categorical_accuracy: 0.5723 - val_loss: 1.0333 - val_categorical_accuracy: 0.5480\n",
            "Epoch 51/200\n",
            "258/258 [==============================] - 2s 7ms/step - loss: 0.9703 - categorical_accuracy: 0.5751 - val_loss: 1.1006 - val_categorical_accuracy: 0.4323\n",
            "Epoch 52/200\n",
            "258/258 [==============================] - 2s 7ms/step - loss: 0.9582 - categorical_accuracy: 0.5853 - val_loss: 1.1079 - val_categorical_accuracy: 0.4345\n",
            "Epoch 53/200\n",
            "258/258 [==============================] - 2s 7ms/step - loss: 0.9491 - categorical_accuracy: 0.5921 - val_loss: 1.0830 - val_categorical_accuracy: 0.4345\n",
            "Epoch 54/200\n",
            "258/258 [==============================] - 2s 7ms/step - loss: 0.9509 - categorical_accuracy: 0.5810 - val_loss: 1.1594 - val_categorical_accuracy: 0.4039\n",
            "Epoch 55/200\n",
            "258/258 [==============================] - 2s 7ms/step - loss: 0.9430 - categorical_accuracy: 0.5935 - val_loss: 1.0454 - val_categorical_accuracy: 0.4803\n",
            "Epoch 56/200\n",
            "258/258 [==============================] - 2s 7ms/step - loss: 0.9473 - categorical_accuracy: 0.5839 - val_loss: 1.1440 - val_categorical_accuracy: 0.4258\n",
            "Epoch 57/200\n",
            "258/258 [==============================] - 2s 7ms/step - loss: 0.9369 - categorical_accuracy: 0.6025 - val_loss: 1.0824 - val_categorical_accuracy: 0.4345\n",
            "Epoch 58/200\n",
            "258/258 [==============================] - 2s 7ms/step - loss: 0.9623 - categorical_accuracy: 0.5687 - val_loss: 1.0903 - val_categorical_accuracy: 0.4367\n",
            "Epoch 59/200\n",
            "258/258 [==============================] - 2s 7ms/step - loss: 0.9266 - categorical_accuracy: 0.5891 - val_loss: 1.0969 - val_categorical_accuracy: 0.4672\n",
            "Epoch 60/200\n",
            "258/258 [==============================] - 2s 7ms/step - loss: 0.9490 - categorical_accuracy: 0.5827 - val_loss: 1.1078 - val_categorical_accuracy: 0.4279\n",
            "Epoch 61/200\n",
            "258/258 [==============================] - 2s 7ms/step - loss: 0.9526 - categorical_accuracy: 0.5757 - val_loss: 1.1528 - val_categorical_accuracy: 0.4214\n",
            "Epoch 62/200\n",
            "258/258 [==============================] - 2s 7ms/step - loss: 0.9393 - categorical_accuracy: 0.5955 - val_loss: 1.0504 - val_categorical_accuracy: 0.4716\n",
            "Epoch 63/200\n",
            "258/258 [==============================] - 2s 7ms/step - loss: 0.9471 - categorical_accuracy: 0.5910 - val_loss: 1.0967 - val_categorical_accuracy: 0.4236\n",
            "Epoch 64/200\n",
            "258/258 [==============================] - 2s 7ms/step - loss: 0.9395 - categorical_accuracy: 0.5875 - val_loss: 1.1362 - val_categorical_accuracy: 0.4236\n",
            "Epoch 65/200\n",
            "258/258 [==============================] - 2s 7ms/step - loss: 0.9417 - categorical_accuracy: 0.5870 - val_loss: 1.0683 - val_categorical_accuracy: 0.4498\n",
            "Epoch 66/200\n",
            "258/258 [==============================] - 2s 7ms/step - loss: 0.9265 - categorical_accuracy: 0.5908 - val_loss: 1.1534 - val_categorical_accuracy: 0.4192\n",
            "Epoch 67/200\n",
            "258/258 [==============================] - 2s 7ms/step - loss: 0.9212 - categorical_accuracy: 0.5861 - val_loss: 1.0625 - val_categorical_accuracy: 0.4651\n",
            "Epoch 68/200\n",
            "258/258 [==============================] - 2s 7ms/step - loss: 0.9332 - categorical_accuracy: 0.5912 - val_loss: 1.2535 - val_categorical_accuracy: 0.4105\n",
            "Epoch 69/200\n",
            "258/258 [==============================] - 2s 7ms/step - loss: 0.9593 - categorical_accuracy: 0.5657 - val_loss: 1.2008 - val_categorical_accuracy: 0.4017\n",
            "Epoch 70/200\n",
            "258/258 [==============================] - 2s 7ms/step - loss: 0.9395 - categorical_accuracy: 0.5785 - val_loss: 1.1829 - val_categorical_accuracy: 0.4061\n",
            "Epoch 71/200\n",
            "258/258 [==============================] - 2s 7ms/step - loss: 0.9232 - categorical_accuracy: 0.5985 - val_loss: 1.1356 - val_categorical_accuracy: 0.4170\n",
            "Epoch 72/200\n",
            "258/258 [==============================] - 2s 7ms/step - loss: 0.9279 - categorical_accuracy: 0.5976 - val_loss: 1.1062 - val_categorical_accuracy: 0.4236\n",
            "Epoch 73/200\n",
            "258/258 [==============================] - 2s 7ms/step - loss: 0.9420 - categorical_accuracy: 0.5842 - val_loss: 1.0973 - val_categorical_accuracy: 0.4236\n",
            "Epoch 74/200\n",
            "258/258 [==============================] - 2s 7ms/step - loss: 0.9052 - categorical_accuracy: 0.6188 - val_loss: 1.1581 - val_categorical_accuracy: 0.4105\n",
            "Epoch 75/200\n",
            "258/258 [==============================] - 2s 7ms/step - loss: 0.9221 - categorical_accuracy: 0.5936 - val_loss: 1.1027 - val_categorical_accuracy: 0.4389\n",
            "Epoch 76/200\n",
            "258/258 [==============================] - 2s 7ms/step - loss: 0.9322 - categorical_accuracy: 0.5892 - val_loss: 1.0977 - val_categorical_accuracy: 0.4236\n",
            "Epoch 77/200\n",
            "258/258 [==============================] - 2s 7ms/step - loss: 0.9204 - categorical_accuracy: 0.5919 - val_loss: 1.1275 - val_categorical_accuracy: 0.4410\n",
            "Epoch 78/200\n",
            "258/258 [==============================] - 2s 7ms/step - loss: 0.9261 - categorical_accuracy: 0.6054 - val_loss: 1.1985 - val_categorical_accuracy: 0.3974\n",
            "Epoch 79/200\n",
            "258/258 [==============================] - 2s 7ms/step - loss: 0.9308 - categorical_accuracy: 0.5865 - val_loss: 1.0665 - val_categorical_accuracy: 0.4738\n",
            "Epoch 80/200\n",
            "258/258 [==============================] - 2s 7ms/step - loss: 0.9188 - categorical_accuracy: 0.5976 - val_loss: 1.1204 - val_categorical_accuracy: 0.4105\n",
            "Epoch 81/200\n",
            "258/258 [==============================] - 2s 7ms/step - loss: 0.9049 - categorical_accuracy: 0.6047 - val_loss: 1.1339 - val_categorical_accuracy: 0.4192\n",
            "Epoch 82/200\n",
            "258/258 [==============================] - 2s 7ms/step - loss: 0.8933 - categorical_accuracy: 0.5986 - val_loss: 1.0930 - val_categorical_accuracy: 0.4410\n",
            "Epoch 83/200\n",
            "258/258 [==============================] - 2s 7ms/step - loss: 0.9308 - categorical_accuracy: 0.5948 - val_loss: 1.0556 - val_categorical_accuracy: 0.4651\n",
            "Epoch 84/200\n",
            "258/258 [==============================] - 2s 7ms/step - loss: 0.9149 - categorical_accuracy: 0.6157 - val_loss: 1.0307 - val_categorical_accuracy: 0.4803\n",
            "Epoch 85/200\n",
            "258/258 [==============================] - 2s 7ms/step - loss: 0.9131 - categorical_accuracy: 0.5920 - val_loss: 1.0428 - val_categorical_accuracy: 0.4563\n",
            "Epoch 86/200\n",
            "258/258 [==============================] - 2s 7ms/step - loss: 0.9091 - categorical_accuracy: 0.5964 - val_loss: 1.1040 - val_categorical_accuracy: 0.4214\n",
            "Epoch 87/200\n",
            "258/258 [==============================] - 2s 7ms/step - loss: 0.9231 - categorical_accuracy: 0.5960 - val_loss: 0.9954 - val_categorical_accuracy: 0.5306\n",
            "Epoch 88/200\n",
            "258/258 [==============================] - 2s 7ms/step - loss: 0.9112 - categorical_accuracy: 0.6028 - val_loss: 1.1776 - val_categorical_accuracy: 0.4061\n",
            "Epoch 89/200\n",
            "258/258 [==============================] - 2s 7ms/step - loss: 0.8817 - categorical_accuracy: 0.6176 - val_loss: 1.1834 - val_categorical_accuracy: 0.4061\n",
            "Epoch 90/200\n",
            "258/258 [==============================] - 2s 7ms/step - loss: 0.9056 - categorical_accuracy: 0.6130 - val_loss: 1.1563 - val_categorical_accuracy: 0.4148\n",
            "Epoch 91/200\n",
            "258/258 [==============================] - 2s 7ms/step - loss: 0.8916 - categorical_accuracy: 0.6203 - val_loss: 1.0986 - val_categorical_accuracy: 0.4258\n",
            "Epoch 92/200\n",
            "258/258 [==============================] - 2s 7ms/step - loss: 0.9101 - categorical_accuracy: 0.6059 - val_loss: 1.1231 - val_categorical_accuracy: 0.4170\n",
            "Epoch 93/200\n",
            "258/258 [==============================] - 2s 7ms/step - loss: 0.9038 - categorical_accuracy: 0.6091 - val_loss: 1.1123 - val_categorical_accuracy: 0.4214\n",
            "Epoch 94/200\n",
            "258/258 [==============================] - 2s 8ms/step - loss: 0.8919 - categorical_accuracy: 0.6083 - val_loss: 1.2114 - val_categorical_accuracy: 0.3996\n",
            "Epoch 95/200\n",
            "258/258 [==============================] - 2s 7ms/step - loss: 0.8837 - categorical_accuracy: 0.6160 - val_loss: 1.1294 - val_categorical_accuracy: 0.4061\n",
            "Epoch 96/200\n",
            "258/258 [==============================] - 2s 7ms/step - loss: 0.8831 - categorical_accuracy: 0.6139 - val_loss: 0.9979 - val_categorical_accuracy: 0.5524\n",
            "Epoch 97/200\n",
            "258/258 [==============================] - 2s 7ms/step - loss: 0.9101 - categorical_accuracy: 0.5985 - val_loss: 1.1247 - val_categorical_accuracy: 0.4061\n",
            "Epoch 98/200\n",
            "258/258 [==============================] - 2s 8ms/step - loss: 0.9058 - categorical_accuracy: 0.6021 - val_loss: 1.3075 - val_categorical_accuracy: 0.3821\n",
            "Epoch 99/200\n",
            "258/258 [==============================] - 2s 7ms/step - loss: 0.9060 - categorical_accuracy: 0.6053 - val_loss: 1.0571 - val_categorical_accuracy: 0.4476\n",
            "Epoch 100/200\n",
            "258/258 [==============================] - 2s 7ms/step - loss: 0.8829 - categorical_accuracy: 0.6151 - val_loss: 1.0364 - val_categorical_accuracy: 0.4607\n",
            "Epoch 101/200\n",
            "258/258 [==============================] - 2s 7ms/step - loss: 0.8887 - categorical_accuracy: 0.6134 - val_loss: 1.0982 - val_categorical_accuracy: 0.4170\n",
            "Epoch 102/200\n",
            "258/258 [==============================] - 2s 7ms/step - loss: 0.9208 - categorical_accuracy: 0.5954 - val_loss: 1.0172 - val_categorical_accuracy: 0.5502\n",
            "Epoch 103/200\n",
            "258/258 [==============================] - 2s 7ms/step - loss: 0.8975 - categorical_accuracy: 0.6173 - val_loss: 1.0571 - val_categorical_accuracy: 0.4563\n",
            "Epoch 104/200\n",
            "258/258 [==============================] - 2s 7ms/step - loss: 0.8869 - categorical_accuracy: 0.6177 - val_loss: 1.1655 - val_categorical_accuracy: 0.4127\n",
            "Epoch 105/200\n",
            "258/258 [==============================] - 2s 7ms/step - loss: 0.9089 - categorical_accuracy: 0.5990 - val_loss: 1.0268 - val_categorical_accuracy: 0.4891\n",
            "Epoch 106/200\n",
            "258/258 [==============================] - 2s 7ms/step - loss: 0.8991 - categorical_accuracy: 0.6081 - val_loss: 0.9981 - val_categorical_accuracy: 0.5218\n",
            "Epoch 107/200\n",
            "258/258 [==============================] - 2s 7ms/step - loss: 0.8884 - categorical_accuracy: 0.6159 - val_loss: 1.0424 - val_categorical_accuracy: 0.4541\n",
            "Epoch 108/200\n",
            "258/258 [==============================] - 2s 7ms/step - loss: 0.8769 - categorical_accuracy: 0.6305 - val_loss: 1.0684 - val_categorical_accuracy: 0.4389\n",
            "Epoch 109/200\n",
            "258/258 [==============================] - 2s 7ms/step - loss: 0.8898 - categorical_accuracy: 0.6065 - val_loss: 0.9960 - val_categorical_accuracy: 0.5153\n",
            "Epoch 110/200\n",
            "258/258 [==============================] - 2s 7ms/step - loss: 0.8723 - categorical_accuracy: 0.6368 - val_loss: 1.1428 - val_categorical_accuracy: 0.4017\n",
            "Epoch 111/200\n",
            "258/258 [==============================] - 2s 7ms/step - loss: 0.8725 - categorical_accuracy: 0.6124 - val_loss: 1.0295 - val_categorical_accuracy: 0.4694\n",
            "Epoch 112/200\n",
            "258/258 [==============================] - 2s 7ms/step - loss: 0.8983 - categorical_accuracy: 0.6184 - val_loss: 1.0590 - val_categorical_accuracy: 0.4498\n",
            "Epoch 113/200\n",
            "258/258 [==============================] - 2s 7ms/step - loss: 0.8735 - categorical_accuracy: 0.6325 - val_loss: 1.0369 - val_categorical_accuracy: 0.4738\n",
            "Epoch 114/200\n",
            "258/258 [==============================] - 2s 7ms/step - loss: 0.8650 - categorical_accuracy: 0.6247 - val_loss: 1.1417 - val_categorical_accuracy: 0.3908\n",
            "Epoch 115/200\n",
            "258/258 [==============================] - 2s 8ms/step - loss: 0.8807 - categorical_accuracy: 0.6144 - val_loss: 1.0527 - val_categorical_accuracy: 0.4454\n",
            "Epoch 116/200\n",
            "258/258 [==============================] - 2s 7ms/step - loss: 0.8804 - categorical_accuracy: 0.6287 - val_loss: 1.0352 - val_categorical_accuracy: 0.4607\n",
            "Epoch 117/200\n",
            "258/258 [==============================] - 2s 8ms/step - loss: 0.8534 - categorical_accuracy: 0.6273 - val_loss: 1.0531 - val_categorical_accuracy: 0.4454\n",
            "Epoch 118/200\n",
            "258/258 [==============================] - 2s 7ms/step - loss: 0.9033 - categorical_accuracy: 0.6170 - val_loss: 1.0110 - val_categorical_accuracy: 0.5022\n",
            "Epoch 119/200\n",
            "258/258 [==============================] - 2s 8ms/step - loss: 0.8935 - categorical_accuracy: 0.6138 - val_loss: 1.0516 - val_categorical_accuracy: 0.4629\n",
            "Epoch 120/200\n",
            "258/258 [==============================] - 2s 7ms/step - loss: 0.8754 - categorical_accuracy: 0.6189 - val_loss: 1.0023 - val_categorical_accuracy: 0.4913\n",
            "Epoch 121/200\n",
            "258/258 [==============================] - 2s 8ms/step - loss: 0.8624 - categorical_accuracy: 0.6316 - val_loss: 1.0562 - val_categorical_accuracy: 0.4432\n",
            "Epoch 122/200\n",
            "258/258 [==============================] - 2s 7ms/step - loss: 0.8744 - categorical_accuracy: 0.6199 - val_loss: 1.0161 - val_categorical_accuracy: 0.4891\n",
            "Epoch 123/200\n",
            "258/258 [==============================] - 2s 7ms/step - loss: 0.8618 - categorical_accuracy: 0.6314 - val_loss: 1.0730 - val_categorical_accuracy: 0.4345\n",
            "Epoch 124/200\n",
            "258/258 [==============================] - 2s 7ms/step - loss: 0.8763 - categorical_accuracy: 0.6326 - val_loss: 0.9818 - val_categorical_accuracy: 0.5480\n",
            "Epoch 125/200\n",
            "258/258 [==============================] - 2s 7ms/step - loss: 0.8547 - categorical_accuracy: 0.6395 - val_loss: 1.0245 - val_categorical_accuracy: 0.4825\n",
            "Epoch 126/200\n",
            "258/258 [==============================] - 2s 7ms/step - loss: 0.8662 - categorical_accuracy: 0.6316 - val_loss: 1.0042 - val_categorical_accuracy: 0.5175\n",
            "Epoch 127/200\n",
            "258/258 [==============================] - 2s 7ms/step - loss: 0.8681 - categorical_accuracy: 0.6232 - val_loss: 0.9910 - val_categorical_accuracy: 0.5240\n",
            "Epoch 128/200\n",
            "258/258 [==============================] - 2s 7ms/step - loss: 0.8615 - categorical_accuracy: 0.6313 - val_loss: 1.0177 - val_categorical_accuracy: 0.4956\n",
            "Epoch 129/200\n",
            "258/258 [==============================] - 2s 7ms/step - loss: 0.8677 - categorical_accuracy: 0.6157 - val_loss: 1.0376 - val_categorical_accuracy: 0.4607\n",
            "Epoch 130/200\n",
            "258/258 [==============================] - 2s 8ms/step - loss: 0.8738 - categorical_accuracy: 0.6237 - val_loss: 0.9636 - val_categorical_accuracy: 0.5459\n",
            "Epoch 131/200\n",
            "258/258 [==============================] - 2s 8ms/step - loss: 0.8463 - categorical_accuracy: 0.6342 - val_loss: 1.0620 - val_categorical_accuracy: 0.4345\n",
            "Epoch 132/200\n",
            "258/258 [==============================] - 2s 8ms/step - loss: 0.8853 - categorical_accuracy: 0.6029 - val_loss: 0.9752 - val_categorical_accuracy: 0.5218\n",
            "Epoch 133/200\n",
            "258/258 [==============================] - 2s 7ms/step - loss: 0.8487 - categorical_accuracy: 0.6329 - val_loss: 1.0033 - val_categorical_accuracy: 0.4913\n",
            "Epoch 134/200\n",
            "258/258 [==============================] - 2s 8ms/step - loss: 0.8519 - categorical_accuracy: 0.6300 - val_loss: 1.0325 - val_categorical_accuracy: 0.4563\n",
            "Epoch 135/200\n",
            "258/258 [==============================] - 2s 8ms/step - loss: 0.8809 - categorical_accuracy: 0.6222 - val_loss: 1.0308 - val_categorical_accuracy: 0.4541\n",
            "Epoch 136/200\n",
            "258/258 [==============================] - 2s 8ms/step - loss: 0.8705 - categorical_accuracy: 0.6315 - val_loss: 1.0501 - val_categorical_accuracy: 0.4520\n",
            "Epoch 137/200\n",
            "258/258 [==============================] - 2s 7ms/step - loss: 0.8544 - categorical_accuracy: 0.6292 - val_loss: 1.0123 - val_categorical_accuracy: 0.4934\n",
            "Epoch 138/200\n",
            "258/258 [==============================] - 2s 7ms/step - loss: 0.8491 - categorical_accuracy: 0.6254 - val_loss: 1.0247 - val_categorical_accuracy: 0.5022\n",
            "Epoch 139/200\n",
            "258/258 [==============================] - 2s 7ms/step - loss: 0.8778 - categorical_accuracy: 0.6125 - val_loss: 1.0479 - val_categorical_accuracy: 0.4432\n",
            "Epoch 140/200\n",
            "258/258 [==============================] - 2s 8ms/step - loss: 0.8730 - categorical_accuracy: 0.6162 - val_loss: 0.9506 - val_categorical_accuracy: 0.5808\n",
            "Epoch 141/200\n",
            "258/258 [==============================] - 2s 8ms/step - loss: 0.8712 - categorical_accuracy: 0.6286 - val_loss: 1.0291 - val_categorical_accuracy: 0.4672\n",
            "Epoch 142/200\n",
            "258/258 [==============================] - 2s 8ms/step - loss: 0.8626 - categorical_accuracy: 0.6222 - val_loss: 1.0279 - val_categorical_accuracy: 0.4760\n",
            "Epoch 143/200\n",
            "258/258 [==============================] - 2s 8ms/step - loss: 0.8321 - categorical_accuracy: 0.6432 - val_loss: 1.0007 - val_categorical_accuracy: 0.4913\n",
            "Epoch 144/200\n",
            "258/258 [==============================] - 2s 7ms/step - loss: 0.8474 - categorical_accuracy: 0.6347 - val_loss: 1.0287 - val_categorical_accuracy: 0.4672\n",
            "Epoch 145/200\n",
            "258/258 [==============================] - 2s 8ms/step - loss: 0.8557 - categorical_accuracy: 0.6225 - val_loss: 1.0438 - val_categorical_accuracy: 0.4716\n",
            "Epoch 146/200\n",
            "258/258 [==============================] - 2s 8ms/step - loss: 0.8609 - categorical_accuracy: 0.6441 - val_loss: 1.0502 - val_categorical_accuracy: 0.4389\n",
            "Epoch 147/200\n",
            "258/258 [==============================] - 2s 8ms/step - loss: 0.8508 - categorical_accuracy: 0.6239 - val_loss: 1.0059 - val_categorical_accuracy: 0.4869\n",
            "Epoch 148/200\n",
            "258/258 [==============================] - 2s 8ms/step - loss: 0.8504 - categorical_accuracy: 0.6374 - val_loss: 1.0420 - val_categorical_accuracy: 0.4432\n",
            "Epoch 149/200\n",
            "258/258 [==============================] - 2s 8ms/step - loss: 0.8396 - categorical_accuracy: 0.6442 - val_loss: 1.0065 - val_categorical_accuracy: 0.4934\n",
            "Epoch 150/200\n",
            "258/258 [==============================] - 2s 8ms/step - loss: 0.8638 - categorical_accuracy: 0.6213 - val_loss: 0.9861 - val_categorical_accuracy: 0.5066\n",
            "Epoch 151/200\n",
            "258/258 [==============================] - 2s 8ms/step - loss: 0.8703 - categorical_accuracy: 0.6185 - val_loss: 0.9784 - val_categorical_accuracy: 0.5175\n",
            "Epoch 152/200\n",
            "258/258 [==============================] - 2s 8ms/step - loss: 0.8467 - categorical_accuracy: 0.6314 - val_loss: 1.0041 - val_categorical_accuracy: 0.4782\n",
            "Epoch 153/200\n",
            "258/258 [==============================] - 2s 7ms/step - loss: 0.8512 - categorical_accuracy: 0.6371 - val_loss: 0.9753 - val_categorical_accuracy: 0.5240\n",
            "Epoch 154/200\n",
            "258/258 [==============================] - 2s 8ms/step - loss: 0.8288 - categorical_accuracy: 0.6433 - val_loss: 1.0162 - val_categorical_accuracy: 0.4782\n",
            "Epoch 155/200\n",
            "258/258 [==============================] - 2s 7ms/step - loss: 0.8367 - categorical_accuracy: 0.6301 - val_loss: 0.9816 - val_categorical_accuracy: 0.5109\n",
            "Epoch 156/200\n",
            "258/258 [==============================] - 2s 8ms/step - loss: 0.8463 - categorical_accuracy: 0.6315 - val_loss: 0.9827 - val_categorical_accuracy: 0.5175\n",
            "Epoch 157/200\n",
            "258/258 [==============================] - 2s 8ms/step - loss: 0.8241 - categorical_accuracy: 0.6525 - val_loss: 0.9926 - val_categorical_accuracy: 0.5109\n",
            "Epoch 158/200\n",
            "258/258 [==============================] - 2s 7ms/step - loss: 0.8411 - categorical_accuracy: 0.6432 - val_loss: 1.0863 - val_categorical_accuracy: 0.4367\n",
            "Epoch 159/200\n",
            "258/258 [==============================] - 2s 8ms/step - loss: 0.8872 - categorical_accuracy: 0.6136 - val_loss: 0.9887 - val_categorical_accuracy: 0.5284\n",
            "Epoch 160/200\n",
            "258/258 [==============================] - 2s 8ms/step - loss: 0.8413 - categorical_accuracy: 0.6378 - val_loss: 0.9723 - val_categorical_accuracy: 0.5349\n",
            "Epoch 161/200\n",
            "258/258 [==============================] - 2s 8ms/step - loss: 0.8367 - categorical_accuracy: 0.6387 - val_loss: 0.9884 - val_categorical_accuracy: 0.5044\n",
            "Epoch 162/200\n",
            "258/258 [==============================] - 2s 8ms/step - loss: 0.8675 - categorical_accuracy: 0.6276 - val_loss: 0.9191 - val_categorical_accuracy: 0.5873\n",
            "Epoch 163/200\n",
            "258/258 [==============================] - 2s 8ms/step - loss: 0.8465 - categorical_accuracy: 0.6313 - val_loss: 0.9589 - val_categorical_accuracy: 0.5502\n",
            "Epoch 164/200\n",
            "258/258 [==============================] - 2s 8ms/step - loss: 0.8309 - categorical_accuracy: 0.6356 - val_loss: 0.9383 - val_categorical_accuracy: 0.5852\n",
            "Epoch 165/200\n",
            "258/258 [==============================] - 2s 7ms/step - loss: 0.8169 - categorical_accuracy: 0.6559 - val_loss: 0.9911 - val_categorical_accuracy: 0.5087\n",
            "Epoch 166/200\n",
            "258/258 [==============================] - 2s 7ms/step - loss: 0.8379 - categorical_accuracy: 0.6411 - val_loss: 0.9360 - val_categorical_accuracy: 0.5830\n",
            "Epoch 167/200\n",
            "258/258 [==============================] - 2s 7ms/step - loss: 0.8336 - categorical_accuracy: 0.6448 - val_loss: 0.9469 - val_categorical_accuracy: 0.5764\n",
            "Epoch 168/200\n",
            "258/258 [==============================] - 2s 8ms/step - loss: 0.8314 - categorical_accuracy: 0.6457 - val_loss: 0.9622 - val_categorical_accuracy: 0.5611\n",
            "Epoch 169/200\n",
            "258/258 [==============================] - 2s 8ms/step - loss: 0.8391 - categorical_accuracy: 0.6410 - val_loss: 0.9760 - val_categorical_accuracy: 0.5197\n",
            "Epoch 170/200\n",
            "258/258 [==============================] - 2s 7ms/step - loss: 0.8358 - categorical_accuracy: 0.6456 - val_loss: 0.9644 - val_categorical_accuracy: 0.5502\n",
            "Epoch 171/200\n",
            "258/258 [==============================] - 2s 7ms/step - loss: 0.8386 - categorical_accuracy: 0.6446 - val_loss: 0.9695 - val_categorical_accuracy: 0.5524\n",
            "Epoch 172/200\n",
            "258/258 [==============================] - 2s 8ms/step - loss: 0.8406 - categorical_accuracy: 0.6401 - val_loss: 0.9729 - val_categorical_accuracy: 0.5328\n",
            "Epoch 173/200\n",
            "258/258 [==============================] - 2s 8ms/step - loss: 0.8307 - categorical_accuracy: 0.6572 - val_loss: 0.9763 - val_categorical_accuracy: 0.5240\n",
            "Epoch 174/200\n",
            "258/258 [==============================] - 2s 8ms/step - loss: 0.8366 - categorical_accuracy: 0.6371 - val_loss: 0.9685 - val_categorical_accuracy: 0.5546\n",
            "Epoch 175/200\n",
            "258/258 [==============================] - 2s 8ms/step - loss: 0.8547 - categorical_accuracy: 0.6217 - val_loss: 0.9439 - val_categorical_accuracy: 0.5633\n",
            "Epoch 176/200\n",
            "258/258 [==============================] - 2s 8ms/step - loss: 0.8472 - categorical_accuracy: 0.6373 - val_loss: 1.0342 - val_categorical_accuracy: 0.4738\n",
            "Epoch 177/200\n",
            "258/258 [==============================] - 2s 7ms/step - loss: 0.8166 - categorical_accuracy: 0.6445 - val_loss: 0.9664 - val_categorical_accuracy: 0.5328\n",
            "Epoch 178/200\n",
            "258/258 [==============================] - 2s 7ms/step - loss: 0.8139 - categorical_accuracy: 0.6631 - val_loss: 0.9348 - val_categorical_accuracy: 0.5939\n",
            "Epoch 179/200\n",
            "258/258 [==============================] - 2s 7ms/step - loss: 0.8399 - categorical_accuracy: 0.6281 - val_loss: 0.9726 - val_categorical_accuracy: 0.5153\n",
            "Epoch 180/200\n",
            "258/258 [==============================] - 2s 7ms/step - loss: 0.8453 - categorical_accuracy: 0.6283 - val_loss: 0.9343 - val_categorical_accuracy: 0.5808\n",
            "Epoch 181/200\n",
            "258/258 [==============================] - 2s 7ms/step - loss: 0.8093 - categorical_accuracy: 0.6505 - val_loss: 0.9544 - val_categorical_accuracy: 0.5677\n",
            "Epoch 182/200\n",
            "258/258 [==============================] - 2s 7ms/step - loss: 0.8359 - categorical_accuracy: 0.6463 - val_loss: 0.9376 - val_categorical_accuracy: 0.5742\n",
            "Epoch 183/200\n",
            "258/258 [==============================] - 2s 8ms/step - loss: 0.8216 - categorical_accuracy: 0.6579 - val_loss: 0.9631 - val_categorical_accuracy: 0.5328\n",
            "Epoch 184/200\n",
            "258/258 [==============================] - 2s 8ms/step - loss: 0.8050 - categorical_accuracy: 0.6536 - val_loss: 0.9432 - val_categorical_accuracy: 0.5633\n",
            "Epoch 185/200\n",
            "258/258 [==============================] - 2s 7ms/step - loss: 0.8199 - categorical_accuracy: 0.6416 - val_loss: 0.9633 - val_categorical_accuracy: 0.5349\n",
            "Epoch 186/200\n",
            "258/258 [==============================] - 2s 8ms/step - loss: 0.8224 - categorical_accuracy: 0.6482 - val_loss: 0.9816 - val_categorical_accuracy: 0.5218\n",
            "Epoch 187/200\n",
            "258/258 [==============================] - 2s 7ms/step - loss: 0.8295 - categorical_accuracy: 0.6575 - val_loss: 1.0251 - val_categorical_accuracy: 0.4563\n",
            "Epoch 188/200\n",
            "258/258 [==============================] - 2s 8ms/step - loss: 0.8424 - categorical_accuracy: 0.6388 - val_loss: 0.9916 - val_categorical_accuracy: 0.5000\n",
            "Epoch 189/200\n",
            "258/258 [==============================] - 2s 7ms/step - loss: 0.8000 - categorical_accuracy: 0.6538 - val_loss: 0.9377 - val_categorical_accuracy: 0.5764\n",
            "Epoch 190/200\n",
            "258/258 [==============================] - 2s 7ms/step - loss: 0.8172 - categorical_accuracy: 0.6460 - val_loss: 0.9571 - val_categorical_accuracy: 0.5415\n",
            "Epoch 191/200\n",
            "258/258 [==============================] - 2s 8ms/step - loss: 0.8014 - categorical_accuracy: 0.6657 - val_loss: 0.9833 - val_categorical_accuracy: 0.5000\n",
            "Epoch 192/200\n",
            "258/258 [==============================] - 2s 8ms/step - loss: 0.8143 - categorical_accuracy: 0.6398 - val_loss: 1.0136 - val_categorical_accuracy: 0.4760\n",
            "Epoch 193/200\n",
            "258/258 [==============================] - 2s 7ms/step - loss: 0.8193 - categorical_accuracy: 0.6525 - val_loss: 0.9820 - val_categorical_accuracy: 0.5109\n",
            "Epoch 194/200\n",
            "258/258 [==============================] - 2s 8ms/step - loss: 0.8065 - categorical_accuracy: 0.6555 - val_loss: 0.9232 - val_categorical_accuracy: 0.5873\n",
            "Epoch 195/200\n",
            "258/258 [==============================] - 2s 8ms/step - loss: 0.8146 - categorical_accuracy: 0.6519 - val_loss: 0.9967 - val_categorical_accuracy: 0.4934\n",
            "Epoch 196/200\n",
            "258/258 [==============================] - 2s 8ms/step - loss: 0.8157 - categorical_accuracy: 0.6554 - val_loss: 0.9473 - val_categorical_accuracy: 0.5611\n",
            "Epoch 197/200\n",
            "258/258 [==============================] - 2s 8ms/step - loss: 0.8239 - categorical_accuracy: 0.6444 - val_loss: 1.0441 - val_categorical_accuracy: 0.4541\n",
            "Epoch 198/200\n",
            "258/258 [==============================] - 2s 8ms/step - loss: 0.8229 - categorical_accuracy: 0.6442 - val_loss: 1.0129 - val_categorical_accuracy: 0.4694\n",
            "Epoch 199/200\n",
            "258/258 [==============================] - 2s 8ms/step - loss: 0.7998 - categorical_accuracy: 0.6546 - val_loss: 0.9691 - val_categorical_accuracy: 0.5240\n",
            "Epoch 200/200\n",
            "258/258 [==============================] - 2s 8ms/step - loss: 0.8219 - categorical_accuracy: 0.6531 - val_loss: 0.9209 - val_categorical_accuracy: 0.5961\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_OrL-zoGu6J5"
      },
      "source": [
        "model.save('/content/drive/MyDrive/Colab Notebooks/SPEECH_EMOTION_Recognition/Nộp bài(chốt hạ)/model_saver/conv2D_mfcc39_cremad.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g5EYS3A1u6J6"
      },
      "source": [
        "###test_result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YPtmKPJgu6J6",
        "outputId": "95c75394-fca4-4538-d134-bb2d75c1a312"
      },
      "source": [
        "d = {0: 'happy',\n",
        "     1: 'sad',\n",
        "     2: 'angry',\n",
        "     3: 'fear'}\n",
        "Y_test_pred = np.argmax(model.predict(X_test), axis=-1)\n",
        "Y_test_pred = list(map(lambda x: d[x], Y_test_pred))\n",
        "y_test = np.argmax(y_test, axis=-1)\n",
        "y_test = list(map(lambda x: d[x], y_test))\n",
        "print(classification_report(y_test, Y_test_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.77      0.74      0.75       136\n",
            "        fear       0.53      0.65      0.58       134\n",
            "       happy       0.61      0.53      0.57       120\n",
            "         sad       0.68      0.62      0.65       119\n",
            "\n",
            "    accuracy                           0.64       509\n",
            "   macro avg       0.65      0.63      0.64       509\n",
            "weighted avg       0.65      0.64      0.64       509\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "1CUEP26Tu6J7",
        "outputId": "20a1521a-c6a3-47b1-9b06-6afe5322a0ed"
      },
      "source": [
        "import scikitplot as skplt\n",
        "\n",
        "skplt.metrics.plot_confusion_matrix(\n",
        "    y_test, \n",
        "    Y_test_pred,\n",
        "    figsize=(8,8))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fa4804ddc90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe0AAAHFCAYAAADfS6GgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dedyVc/7H8df7vouSCJXdEIpCSRJCZRlLaMa+M4YxdjNmGPMzljErM5ZhGMzYwti3kEjZi7IlxjJopNKmaKHF5/fHueLu1nK7O+e+zvne72eP8+hc3+s61/U5p7v7cz7f7/e6LkUEZmZmVv6q8g7AzMzM6sZJ28zMrEI4aZuZmVUIJ20zM7MK4aRtZmZWIZy0zczMKoSTtpmZWRFI+pekiZLeqNG2qqTHJb2b/b1K1i5JV0h6T9LrkrrW5RhO2mZmZsVxI7B7rbazgcERsTEwOFsG2APYOHscD1xdlwM4aZuZmRVBRDwNTK3VvC9wU/b8JqBfjfabo2AY0ErSmks7hpO2mZlZ6aweEeOz5xOA1bPnawMf1dhubNa2RE2KG5uZmVn+qlf6XsS82UXdZ8yeNBr4okbTtRFxbZ1fHxGSluna4U7aZmaWnJg3m+U7HFjUfX7x6lVfRES37/iyTyStGRHjs+7viVn7x8C6NbZbJ2tbInePm5lZggSqKu6jfh4EjsqeHwU8UKP9yGwWeQ9geo1u9MVypW1mZlYEkm4HegGtJY0FzgP+CNwp6VhgDLCg/H8E2BN4D5gFHFOXYzhpm5lZegRIDXrIiDhkMat2XsS2AZz0XY/h7nEzM7MK4UrbzMzSVP9x6LLlpG1mZmlq4O7xhpDe1xAzM7NEudI2M7MEKcnu8fTekZmZWaJcaZuZWZoSHNN20jYzs/QId4+bmZlZflxpm5lZgpRk97grbTMzswrhStvMzNKU4Ji2k7aZmaXJ3eNmZmaWF1faZmaWIF8RzczMzHLkStvMzNIjPKZtZmZm+XHSNisSSc0lPSRpuqS7lmE/h0kaVMzY8iDpUUlH5R2HNWKqKu6jDJRHFGYNSNKhkkZImiFpfJZcehZh1/sDqwOrRcQB9d1JRNwaEbsVIZ6FSOolKSTdV6u9c9Y+tI77OV9S/6VtFxF7RMRN9QzXbBnJSdus0kn6GXAZ8HsKCXY94O/AvkXY/feAdyJiXhH2VSqTgG0lrVaj7SjgnWIdQAX+3WJWAv6PZY2GpJWBC4GTIuLeiJgZEXMj4qGI+EW2zfKSLpM0LntcJmn5bF0vSWMl/VzSxKxKPyZbdwHwG+CgrII/tnZFKmn9rKJtki0fLel9SZ9L+kDSYTXan63xuu0kvZR1u78kabsa64ZK+q2k57L9DJLUegkfwxzgfuDg7PXVwEHArbU+q8slfSTpM0kjJe2Qte8OnFPjfb5WI47fSXoOmAW0y9p+nK2/WtI9Nfb/J0mDpQRnCln5qFJxH2XASdsak22BZsB9S9jm10APoAvQGegO/F+N9WsAKwNrA8cCV0laJSLOo1C93xERK0bEP5cUiKQWwBXAHhHREtgOeHUR260KPJxtuxrwV+DhWpXyocAxQFtgOeDMJR0buBk4Mnv+feANYFytbV6i8BmsCtwG3CWpWUQMrPU+O9d4zRHA8UBLYEyt/f0c2Dz7QrIDhc/uqIiIpcRqZjU4aVtjshoweSnd14cBF0bExIiYBFxAIRktMDdbPzciHgFmAB3qGc9XwGaSmkfE+IgYvYht9gLejYhbImJeRNwO/AfYu8Y2N0TEOxExG7iTQrJdrIh4HlhVUgcKyfvmRWzTPyKmZMf8C7A8S3+fN0bE6Ow1c2vtbxaFz/GvQH/glIgYu5T9mdXfgvtpe0zbrGJNAVov6J5ejLVYuEock7V9vY9aSX8WsOJ3DSQiZlLolj4BGC/pYUmb1CGeBTGtXWN5Qj3iuQU4GejNInoeJJ0p6a2sS34ahd6FJXW7A3y0pJURMRx4n8Kv0zvrEKPZspGK+ygDTtrWmLwAfAn0W8I24yhMKFtgPb7ddVxXM4EVaiyvUXNlRDwWEbsCa1Konq+rQzwLYvq4njEtcAtwIvBIVgV/Leu+/iVwILBKRLQCplNItgCL69JeYle3pJMoVOzjsv2b2XfkpG2NRkRMpzBZ7CpJ/SStIKmppD0k/Tnb7Hbg/yS1ySZ0/YZCd259vArsKGm9bBLcrxaskLS6pH2zse0vKXSzf7WIfTwCtM9OU2si6SCgIzCgnjEBEBEfADtRGMOvrSUwj8JM8yaSfgOsVGP9J8D632WGuKT2wEXA4RS6yX8paYnd+GbLxqd8mVW8bHz2ZxQml02i0KV7MoUZ1VBILCOA14FRwMtZW32O9ThwR7avkSycaKuyOMYBUykk0J8uYh9TgL4UJnJNoVCh9o2IyfWJqda+n42IRfUiPAYMpHAa2BjgCxbu+l5w4Zgpkl5e2nGy4Yj+wJ8i4rWIeJfCDPRbFszMN7O6kSdvmplZaqpWWieW3+aUou7ziyfOHhkR3Yq60+/INwwxM7M0lUmXdjGl947MzMwS5UrbzMzSU0anaRWTK20zM7MK4UrbzMzSlOCYdqNK2mrSPLRcy7zDSNrmHdbNO4RGYe68RZ3SbcXUfLnqvENI3pgxHzJ58uTS9WEn2D3euJL2ci1ZvsOBeYeRtMeG/jXvEBqFsVNn5x1C8jZbd+W8Q0je9tvkevZURWpUSdvMzBoLJdk9nt47MjMzS5QrbTMzS1OCY9qutM3MzCqEK20zM0uPSHJM20nbzMwS5IloZmZmliNX2mZmliZPRDMzM7O8uNI2M7M0JTim7aRtZmZpcve4mZmZ5cWVtpmZpUc+5cvMzMxy5ErbzMzSlOCYtpO2mZklSQkmbXePm5mZVQhX2mZmlhzhStvMzMxy5ErbzMzSo+yRGFfaZmZmFcKVtpmZJUhJjmk7aZuZWZJSTNruHjczM6sQrrTNzCxJrrTNzMwsN660zcwsSSlW2k7aZmaWHp+nbWZmZnlypW1mZslRoudpu9I2MzOrEK60zcwsSSlW2k7aZmaWpBSTtrvHzczMKoQrbTMzS5IrbTMzM8uNK20zM0uPL65iZmZmeXLSztE15x3GmMF/YMRd53zdtspKKzDg6pMZ9cBvGHD1ybRq2fzrdX/55f688cB5vHjHr+iyyTp5hFzxzjjpeDbbaB16bbvl122ffjqVg/rtwXZdO3JQvz2YNu3THCOsfBPGjeWEQ/ty4G7bcOD3e3D7DVcvtL7/9X9j63atmDZ1Sk4RpuWjjz7i+7v0ZsstOtK1cyeuvOLyvEMqG5KK+igHTto5uuWhYex70lULtZ15zK4MffFtNt/3Qoa++DZnHrMbAN/v2ZEN12vDZvtewMkX3c4V5xycR8gV78BDj+C2ux9aqO3KSy+m5059eP7lN+m5Ux+uvPTinKJLQ5MmTTj9nIu4c9Bwbrjnce6+5Xref/c/QCGhD39mCGus5S+dxdKkSRP++Oe/8Mrrb/LUs8P4xzVX8dabb+YdVu4WXBHNSbsMSEpiLP65l//L1OmzFmrr22sL+j80HID+Dw1n795bFNp32oLbBrwIwIujPmTlls1Zo/VKDRtwArbdfgdWWWWVhdoee+QhDjzkcAAOPORwBj78YB6hJaN12zXYZLMuALRYsSXrb9SeSRPGA3DpRedwytkXlM0vwBSsueaabNm1KwAtW7Zkk002Zdy4j3OOykqlQZK2pPsljZQ0WtLxWdsMSb+T9JqkYZJWz9o3zJZHSbpI0oysvZekZyQ9CLwp6UJJp9c4xu8kndYQ76eU2q7WkgmTPwNgwuTPaLtaSwDWatuKsRO+6bb9+JNprNW2VS4xpmbSxImsvsaaALRdfQ0mTZyYc0TpGDd2DG+PHkWnLlvx1OMP02aNNWm/6eZ5h5WsMR9+yKuvvsLW3bfJO5Sy4Eq7/n4UEVsB3YBTJa0GtACGRURn4GnguGzby4HLI2JzYGyt/XQFTouI9sC/gCMBJFUBBwP9ax9Y0vGSRkgaEfNml+CtlVZE3hE0LuX0n7PSzZo5g7NOPJKfnft7mjRpwg1//ysnnH7O0l9o9TJjxgwOOXA/Lv7LZay0knvhUtVQSftUSa8Bw4B1gY2BOcCAbP1IYP3s+bbAXdnz22rt58WI+AAgIj4EpkjaEtgNeCUivjWzJSKujYhuEdFNTZrXXl12Jk75/Otu7zVar8SkqZ8DMG7iNNZZ45tu3bVXb8W4idNyiTE1bdq25ZOs+/aTCeNp3aZNzhFVvnlz53LWiUey+z4H0Gf3fRg75gPGjR3DoXv1ZJ8dNmfihHEcvvdOTJ70Sd6hJmHu3LkccuB+HHTIYfT7wQ/zDqd8qMiPMlDypC2pF7ALsG1WVb8CNAPmRnxdR86nbueMz6y1fD1wNHAMhcq74j381CgO37vQtXX43tswYOjrX7cf2rc7AN03X5/PZsz+uhvdls1ue/TlztsLnTR33t6f7++5d84RVbaI4Ldnn8z6G7bnsB+fDMBGm3Ri0Evv8eAzo3jwmVG0XWMt+j/0FK3brJ5ztJUvIjjhuGPpsMmmnHbGz/IOp3won+5xSWdkQ8FvSLpdUjNJG0gaLuk9SXdIWq6+b6shKu2VgU8jYpakTYAeS9l+GLBf9nxpU6TvA3YHtgYeW6Yoc3DTH45m6E0/p/33Vue9gb/lqH7bcskNj9Nnm00Y9cBv6L1NBy654XEABj47mg/GTmH0g+dx1bmHctof7sw5+sr002OPoO9uO/Hfd9+ha8d23HbzDZx8xi94esgTbNe1I88MHczJZ/wi7zAr2msjhvHIfXcw4oWnOXSvnhy6V0+eGzIo77CS9fxzz3Hbrbfw1JAn2WarLmyzVRcGPvpI3mE1SpLWBk4FukXEZkA1hTz2J+DSiNgI+BQ4tr7HaIhZ2AOBEyS9BbxNISkvyelAf0m/zl47fXEbRsQcSUOAaRExv1gBN5SjfnXjItv3POFvi2w/449O1Mvq6n/essj2ux6suO98ZavL1tvy0vtLHrp58JlRDRRN+rbv2ZPZcz35ZVFymp/SBGguaS6wAjAe6AMcmq2/CTgfuHqRr67DzksqIr4E9ljEqhVrbHM3cHe2+DHQIyJC0sFAh2ybocDQmjvIJqD1AA4oeuBmZmbfQUR8LOkS4H/AbGAQhTlb0yJiXrbZWGDt+h6jHM933gq4UoWvSNOAHy1qI0kdKUxkuy8i3m3A+MzMrAKUoNJuLWlEjeVrI+LaGsdbBdgX2IBC/rqLwhBu0ZRd0o6IZ4DOddjuTaBd6SMyM7NKs+CKaEU2OSK6LWH9LsAHETEJQNK9wPZAK0lNsmp7HQo9yvVSkVdEMzMzK0P/A3pIWiHrLd4ZeBMYAuyfbXMU8EB9D+CkbWZmaWrg87QjYjiF+VkvA6Mo5NhrgbOAn0l6D1gN+Gd931LZdY+bmZlVqog4DzivVvP7QPdi7N9J28zM0qPcTvkqKXePm5mZVQhX2mZmlqQUK20nbTMzS1KKSdvd42ZmZhXClbaZmaUpvULblbaZmVmlcKVtZmZJSnFM20nbzMySI5Xk2uO5c/e4mZlZhXClbWZmSXKlbWZmZrlxpW1mZklKsdJ20jYzszSll7PdPW5mZlYpXGmbmVmSUuwed6VtZmZWIVxpm5lZeuRK28zMzHLkStvMzJIjIMFC20nbzMxS5GuPm5mZWY5caZuZWZISLLRdaZuZmVUKV9pmZpakFMe0nbTNzCw9cve4mZmZ5ciVtpmZJUdAVVV6pbYrbTMzswrhStvMzJKU4pi2k7aZmSUpxdnj7h43MzOrEK60zcwsPYme8tWokvbmHdblkSF/zTuMpG3wo1vyDqFReOe6w/MOIXlvfDQ97xCSN3vO/LxDqDiNKmmbmVnjULg1Z3qltse0zczMKoQrbTMzS1Ca99N20jYzsyQlmLPdPW5mZlYpXGmbmVmSUuwed6VtZmZWIVxpm5lZenxxFTMzs8rg87TNzMwsV660zcwsSQkW2q60zczMKoUrbTMzS1KKY9pO2mZmlqQEc7a7x83MzCqFK20zM0uP0uwed6VtZmZWIVxpm5lZcgoXV8k7iuJzpW1mZlYhXGmbmVmClOSYtpO2mZklKcGc7e5xMzOzSuFK28zMkpRi97grbTMzswrhStvMzNKjNMe0nbTNzCw5hfO008va7h43MzOrEK60zcwsSa60zczMLDeutM3MLEkJFtpO2mZmliZ3j5uZmVluXGmbmVl6Ej1P25W2mZlZhXClbWZmyZFvzWlmZlY5EszZ7h43MzOrFK60zcwsSVUJltqutM3MzCqEK20zM0tSgoW2K+1y8fOTj6fzxuuw87Zbft024P576LNtF9ZdtRmvvTIyx+jScUrfToy87IeMuPSH3HRGL5ZvWs0Tv92LYZf0Y9gl/Xj/uoO586xd8g6zop15yvFs2WFddtm+69dtvzvvV/TeZgt226Ebxx1xINOnT8sxwso3YdxYTji0Lwfutg0Hfr8Ht99w9ULr+1//N7Zu14ppU6fkFKGVSlkkbUmnSnpL0q15x5KXAw45gv53P7RQW4dNO3LdzXewzXY75BRVWtZadQVO3LMT2//yAbqdcS/VVeKAnu3Y5dyH6XHm/fQ4836GvzOR+4d9mHeoFe2AQ47g5jsfXKhth159ePy5lxn0zAg22HBjrrr04pyiS0OTJk04/ZyLuHPQcG6453HuvuV63n/3P0AhoQ9/ZghrrLVOzlHmSypcxrSYj3JQFkkbOBHYNSIOq+8OJFV0V3+P7Xeg1SqrLNS2cYdN2XDjDjlFlKYm1aL5ctVUV4nmyzVh/NRZX69r2bwpO222Fg+9OCbHCCvfNtt9+2d5x9670qRJ4b9o127dmTB+bB6hJaN12zXYZLMuALRYsSXrb9SeSRPGA3DpRedwytkXlE2SyVOVivsoB7knOknXAO2ARyX9G9gQ2AxoCpwfEQ9IWh+4BWiRvezkiHheUi/gt8CnwCZA+4aN3irJuKmzuOzBN3jnmoOZPWceg1/7mMGvffz1+r27f4+ho8bx+ey5OUaZvjtuu4m9++2fdxjJGDd2DG+PHkWnLlvx1OMP02aNNWm/6eZ5h2UlknulHREnAOOA3hSS8pMR0T1bvlhSC2AihUq8K3AQcEWNXXQFTosIJ2xbolYtlqPv1uux6Yl30u6422nRrCkH77jh1+sP7NmOO599P8cI0/e3v/yRJtVN+MEBh+QdShJmzZzBWSceyc/O/T1NmjThhr//lRNOPyfvsMqGu8dLbzfgbEmvAkOBZsB6FKru6ySNAu4COtZ4zYsR8cHidijpeEkjJI2YMnly6SK3stdni7X4cOLnTP7sC+bND+4f9iE9OqwOwGotl6fbxm14dORHOUeZrrtuu5nBgx7lin/cWDa/ACvZvLlzOevEI9l9nwPos/s+jB3zAePGjuHQvXqyzw6bM3HCOA7feycmT/ok71CtiHLvHq9FwH4R8fZCjdL5wCdAZwpfNL6osXrmknYYEdcC1wJ03nKrKGawVlk+mjyT7u3b0ny5ambPmU/vzdfi5f8Wvsj9YNsNeHTER3w5d37OUaZp6OBBXP23v3LXQ4/TfIUV8g6n4kUEvz37ZNbfsD2H/fhkADbapBODXnrv62322WFzbn5gKK1WXS2vMHOXx3dDSa2A6ykM8wbwI+Bt4A5gfeBD4MCI+LQ++y+3Svsx4BRlX8MlLTj/aWVgfER8BRwBVOcUX8mcdOwR7LvbTvz3vXfo1qkdt99yA48OeIBundrx8kvDOOqgfhy23155h1nRXnp3Eve98AEvXNKPEZf+kKoq8c/HCzNuD9i+HXc++9+cI0zDyccdQb/de/H+e+/QfbMN+Xf/Gzj3rNOZOeNzDttvL3bfqTu/+vnJeYdZ0V4bMYxH7ruDES88zaF79eTQvXry3JBBeYdVVkR205Ai/qmjy4GBEbEJhULzLeBsYHBEbAwMzpbr974i8i8+JX0IdKNQNV8GbEfhC8UHEdFX0sbAPRS+tQwEToqIFbOJaGdGRN+6HKfzllvFI0NeKME7sAU2OvaWvENoFN657vC8Q0jeJ9O/WPpGtkyO3KcXb456pST1cKvvbRo9z7m5qPt8+ITuIyOi2+LWS1oZeBVoFzWSq6S3gV4RMV7SmsDQiKjXqUFl0T0eEevXWPzJIta/C2xRo+msrH0ohbFvMzOzhZTgNK3WkkbUWL42G4JdYANgEnCDpM7ASOA0YPWIGJ9tMwFYvb4BlEXSNjMzqwCTl1RpU8ipXYFTImK4pMup1RUeESGp3l3c5TambWZmtuyKfLpXHc94GAuMjYjh2fLdFJL4J1m3ONnfE+v7tpy0zcwsSYVLmRbvsTQRMQH4SNKC8eqdgTeBB4GjsrajgAfq+57cPW5mZlY8pwC3SloOeB84hkKBfKekY4ExwIH13bmTtpmZJUdAVQ4nakfEqxTOhqpt52Ls393jZmZmFcKVtpmZJSnFq+W60jYzM6sQrrTNzCxJKd6YxknbzMySU9fTtCqNu8fNzMwqhCttMzNLUh6nfJWaK20zM7MK4UrbzMySlF6d7aRtZmaJSnH2uLvHzczMKoQrbTMzS07h2uN5R1F8i03akv4GLPZG3RFxakkiMjMzs0VaUqU9osGiMDMzKyYpyTHtxSbtiLip5rKkFSJiVulDMjMzW3YJ5uylT0STtK2kN4H/ZMudJf295JGZmZnZQuoye/wy4PvAFICIeA3YsZRBmZmZLStlXeTFepSDOp3yFREf1WqaX4JYzMzMbAnqcsrXR5K2A0JSU+A04K3ShmVmZlZ/qZ7yVZdK+wTgJGBtYBzQJVs2MzOzBrTUSjsiJgOHNUAsZmZmRVMu49DFVJfZ4+0kPSRpkqSJkh6Q1K4hgjMzM6svFflRDurSPX4bcCewJrAWcBdweymDMjMzs2+rS9JeISJuiYh52aM/0KzUgZmZmdWXBFVSUR/lYEnXHl81e/qopLOBf1O4FvlBwCMNEJuZmZnVsKSJaCMpJOkFXy9+UmNdAL8qVVBmZmbLqkyK46Ja0rXHN2jIQMzMzIopxdnjdbqftqTNgI7UGMuOiJtLFZSZmZl921KTtqTzgF4UkvYjwB7As4CTtpmZla0EC+06zR7fH9gZmBARxwCdgZVLGpWZmZl9S126x2dHxFeS5klaCZgIrFviuMzMzOpNlM9pWsVUl6Q9QlIr4DoKM8pnAC+UNCozM7NloTS7x+ty7fETs6fXSBoIrBQRr5c2LDMzM6ttSRdX6bqkdRHxcmlCMjMzW3aN7ZSvvyxhXQB9ihxLyX0VwZdz5+cdRtLuvqBv3iE0CkfeMjLvEJL372O2zjuE5DVtUpe50FbTki6u0rshAzEzMyumFL8SpPiezMzMklSnK6KZmZlVEtH4xrTNzMwqVlV6OXvp3eMqOFzSb7Ll9SR1L31oZmZmVlNdxrT/DmwLHJItfw5cVbKIzMzMiqBKxX2Ug7p0j28TEV0lvQIQEZ9KWq7EcZmZmVktdUnacyVVUzg3G0ltgK9KGpWZmdkykBrvRLQrgPuAtpJ+R+GuX/9X0qjMzMyWUbl0aRdTXa49fqukkRRuzymgX0S8VfLIzMzMbCFLTdqS1gNmAQ/VbIuI/5UyMDMzs2WRYO94nbrHH6Ywni2gGbAB8DbQqYRxmZmZWS116R7fvOZydvevExezuZmZWe4EVCVYan/nK6JFxMuStilFMGZmZsWS4s016jKm/bMai1VAV2BcySIyMzOzRapLpd2yxvN5FMa47ylNOGZmZsWRYO/4kpN2dlGVlhFxZgPFY2ZmZoux2KQtqUlEzJO0fUMGZGZmtqwkNbqJaC9SGL9+VdKDwF3AzAUrI+LeEsdmZmZmNdRlTLsZMAXowzfnawfgpG1mZmUrwUJ7iUm7bTZz/A2+SdYLREmjMjMzW0aN7drj1cCKLJysF3DSNjMza2BLStrjI+LCBovEzMysSFK9ItqSLhiT3rs1MzOrYEuqtHdusCjMzMyKLMFCe/FJOyKmNmQgZmZmRaM0J6KleD11MzOzJH3nu3yZmZlVAiU4NcuVtpmZWYVwpW1mZskpnPKVdxTF56RtZmZJSjFpu3vczMysQrjSNjOzJCnBE7VdaZuZmVUIV9pmZpacVCeiudI2MzOrEK60zcwsPWpk1x43MzOrZI3t1pxmZmZWRpy0y8RZp/2ErTt+j9137PZ12+V/vojtttiQvr23oW/vbRjyxMAcI6x8c778gjMO2Z2T9+vDif125Nar/gzAxWedyE/23p4Tf7ATl517OvPmzs050srXYrlqzt+zAzcd0YUbj+hCxzVW/HrdAVuuxZDTtmOlZu7oK5brrv4bO/Xowo7bdObav1+RdzhlYcFEtGI+ykHJkrak9SW9Uar9p2a/g4/ghn/f/632Y35yCgOGDGfAkOH03mX3HCJLR9Plluf3/7yHK+95kivuGszI54bwn9dG0muvH3LNg89y1b1DmfPlFwy699a8Q614p+y0AS+O+ZSjbnmVH9/6GmOmzgagzYrLsfX3VmbCZ1/mHGE63nrzDfrf9E8effJ5nnxuJI8PfIQP/vte3mFZibjSLhPdt+1Jq1ar5h1G0iTRfIUWAMybN5f58+Yhia133AVJSKL9Zlsy+ZPxOUda2VosV80Wa6/EI6MnAjDvq2DmnPkAnLTjBvzj2TFA5BhhWt59+z903ao7K6ywAk2aNGHbnjvw8EPfLgAaI6m4j3JQ6qRdLek6SaMlDZLUXNJxkl6S9JqkeyStACDpRknXSBoh6R1JfbP2oyU9IGmopHclnZe1Xyjp9AUHkvQ7SaeV+P00uFv+dQ177tSds077CdOnfZp3OBVv/vz5nLL/zhy+02Z06bEjHbbo+vW6eXPnMmTA3XTdvneOEVa+NVZanmmz53LWrhtx7SFbcObOG9KsSRXbt1uFyTO+5L+TZ+UdYlI26diJ4S88y9SpU5g1axaDBw1k3Mdj8w6rDIiqIj/KQamT9sbAVRHRCZgG7AfcGxFbR0Rn4C3g2Brbrw90B/YCrpHULGvvnr12C+AASd2AfwFHAkiqAg4G+pf4/TSow44+jiEvjmbAkGG0WX0Nfn/e2XmHVPGqq6v5292DufGJV6xYmuIAABYOSURBVHjnjVf48N23vl7399+dTaeterDZVj1yjLDyVVeJ9m1X5MHXJ3D87a/zxdz5HNVjXQ7beh1uGPZR3uElp32HTTn59F9wcL89OXS/vnTavDPV1dV5h2UlUuqk/UFEvJo9H0khKW8m6RlJo4DDgE41tr8zIr6KiHeB94FNsvbHI2JKRMwG7gV6RsSHwBRJWwK7Aa9ExJTaAUg6PqveR0ydMrkU77FkWrddnerqaqqqqjj48B/x2isj8w4pGSuutDJbbL09Lz83BIDbrr6Ez6ZO4ce/uCDnyCrfpBlzmDTjS976ZAYAT703hfZtW7DGSs24/rDO3H5MV9qsuDzXHtqZVVZomnO0aTj0yGMY9PRw7n/0SVq1akW7DTfOO6Tcify6xyVVS3pF0oBseQNJwyW9J+kOScvV932VOmnXnG0yn8J54TcCJ0fE5sAFQLMa29Qe6IqltF8PHA0cQ6Hy/paIuDYiukVEt1VXa/1d48/VxBpjq4MeeZD2m3TMMZrKN33qZGZ8Nh2AL7+YzSvDnmadDTbisXtu5eXnhvKLP19NVZWneSyrT2fNZeLnc1i3VeG/dtd1W/HOxJn88LqXOOSGlznkhpeZNONLjr/tNT6d5Zn6xTBpUmH+wNiP/scjD93PDw84OOeIGr3TKPQkL/An4NKI2Aj4lIV7mL+TPM65aAmMl9SUQqX9cY11B0i6CdgAaAe8DWwJ7CppVWA20A/4Ubb9fcCFQFPg0IYJvzRO+8lRDH/uaT6dOoXtO2/Eab/8P4Y/9wxvjn4dIdZZbz0uuuRveYdZ0aZOmsil/3cqX82fz1fxFTvstg/dd9qNfbqsTds11+HMw/sCsN3Oe3LIT3+ec7SV7Yqh7/Pr3dvTpFqMn/4Ff3rcs5lL6cdHHMTUqVNo2rQpf7jkClZu1SrvkPKX02laktahMMT7O+BnKtxqrA/f5KibgPOBq+uz/zyS9rnAcGBS9nfLGuv+B7wIrAScEBFfZLdWexG4B1gH6B8RIwAiYo6kIcC0iJjfcG+h+C7/x03fajvwsKMbPpCEbdChI1fc9cS32h989eNFbG3L4r+TZ3HCv19f7PpDbni5AaNJ3wMDh+QdQlnK6YpolwG/5JvcthqFHDUvWx4LrF3fnZcsaWdjzpvVWL6kxurFfcN4IiJOWET72IjoV7sxm4DWAzhgGUI1MzOri9aSRtRYvjYirl2wkJ31NDEiRkrqVYoAKvaSRJI6AgOA+7KJa2ZmZsA3E9GKbHJEdFvC+u2BfSTtSWG+1krA5UArSU2yansdFh4W/k7KJmlHxNGLab+RwuS12u1vUhj3NjMzy11E/Ar4FUBWaZ8ZEYdJugvYH/g3cBTwQH2P4amyZmaWpCqpqI9lcBaFSWnvURjj/md9d1Q2lbaZmVkqImIoMDR7/j6Fi4QtMydtMzNLUrlcL7yYnLTNzCw5Is3x3xTfk5mZWZJcaZuZWXpUuB1valxpm5mZVQhX2mZmlqT06mwnbTMzS5DI7drjJeXucTMzswrhStvMzJKUXp3tStvMzKxiuNI2M7MkJTik7aRtZmYpks/TNjMzs/y40jYzs+T42uNmZmaWK1faZmaWJI9pm5mZWW5caZuZWZLSq7OdtM3MLEW+NaeZmZnlyZW2mZklx6d8mZmZWa5caZuZWZJSHNN20jYzsySll7LdPW5mZlYxXGmbmVmSEuwdd6VtZmZWKVxpm5lZcgqnfKVXajtpm5lZktw9bmZmZrlxpW1mZgkSSrB73JW2mZlZhXClbWZmSUpxTNtJ28zMkpPq7HF3j5uZmVWIRlVpN62uou1Ky+cdRtJeHDsv7xAahQd+0iPvEJK31bmP5R1C8j4a/1npdq40u8ddaZuZmVWIRlVpm5lZ4+FK28zMzHLjStvMzJKU4sVVnLTNzCw5AqrSy9nuHjczM6sUrrTNzCxJKXaPu9I2MzOrEK60zcwsSSme8uWkbWZmSXL3uJmZmeXGlbaZmSXHp3yZmZlZrlxpm5lZgpTkmLaTtpmZpce35jQzM7M8udI2M7MkJVhou9I2MzOrFK60zcwsOYVTvtKrtV1pm5mZVQhX2mZmlqT06mwnbTMzS1WCWdvd42ZmZhXClbaZmSUpxSuiudI2MzOrEK60zcwsSQme8eWkbWZmaUowZ7t73MzMrFK40jYzszQlWGq70jYzM6sQrrTNzCw5Is1Tvpy0zcwsPUpz9ri7x83MzCqEK20zM0tSgoW2K20zM7NK4UrbzMzSlGCp7UrbzMysQrjSNjOzBMmnfJmZmVUKn/JlZmZmuXGlXcbmz5/Pjtt1Z8211uLu+x7KO5yKN+fLL7jwx/sxd84c5s+fzzY778kBPz2TiODOq/7MsCcGUFVVza4HHMHuhxybd7jJ2LxDO1Zs2ZLq6mqqmzThqedezDukirdBmxZcfniXr5fXXXUFLn/sXW589kMAfrTj+vxq703pft4TfDprbk5R5kskOQ8tjaQtaX1gQERslnMoRfX3K6+gQ4dN+Ozzz/IOJQlNl1ue//vHnTRboQXz5s7l/GN/QJfte/PxB+8x5ZNx/OXep6iqqmL61Ml5h5qcAQMHs1rr1nmHkYwPJs1kn0ufA6BK8Oy5fRj0xgQA1li5GT3bt+bjT2fnGaKViLvHy9THY8fy2KOPcNQxrviKRRLNVmgBwPx585g/bx6SeOLum/nhcadTVVX477Dyqk4uVjm227g1/5syi3HTvgDg1/tsyp8ffpuIyDmyMqAiP8pAWVXakloAdwLrANXAb4EOwN5Ac+B54CcREZK2Av6VvXRQDuGW1Fm/OIPf/v6PzPj887xDScpX8+dzzmF7MOGjD9ntwKPYaPOufDJ2DC8MeoiXhgxkpVVW5ahfXsia67XLO9R0SPTbe3ckccyxx3HMscfnHVFS9uq8JgNeGQfAzp3a8sn0L/jPeP/egDRvGFJulfbuwLiI6Jx1dQ8EroyIrbPl5kDfbNsbgFMiovOSdijpeEkjJI2YPGlSSYMvlkcfGUCbNm3ZsutWeYeSnKrqav7470FcNfAl/jv6VT567z/MnTOHpssvz+9vfYQ+PziUf5x/Zt5hJuWxwU/zzAsjuOf+h7n+H1fz3LNP5x1SMppWiz6d2vLo6xNo1rSKn/bZkMsGvZt3WI2WpHUlDZH0pqTRkk7L2leV9Likd7O/V6nvMcotaY8CdpX0J0k7RMR0oLek4ZJGAX2ATpJaAa0iYsH//lsWt8OIuDYiukVEt9Zt2pT+HRTBsOef55GHH6JT+3YcfeShPD10CD8++oi8w0pKi5Yr07Hbdrz2/FBWW31NuvfZA4Ct++zB/957K9/gErPW2msD0KZtW/ru04+RL72Uc0Tp2HGTNrz58WdMmTGH9VZbgXVWbc5DZ2zPkF/txBorN+P+07endcvl8g4zN1JxH3UwD/h5RHQEegAnSeoInA0MjoiNgcHZcr2UVdKOiHeArhSS90WSfgP8Hdg/IjYHrgOa5Rhig7jgot/z9n//x+h33ufGm29jx169uf7GxX4vsTr67NMpzPx8OgBzvpjNqGHPsNb6G9Gt1/cZ/dLzALw18gV3jRfRzJkz+Twb4pk5cyZPPvE4HTt1yjmqdPTt8k3X+DsTZtDjgifp/Yen6P2Hp5gw/Qv6XfYckz+fk3OUjUdEjI+Il7PnnwNvAWsD+wI3ZZvdBPSr7zHKbUx7LWBqRPSXNA34cbZqsqQVgf2BuyNimqRpknpGxLPAYXnFbJXj00mfcPV5Z/DV/PlEBD127UvXHXehw5Zbc+WvT+HR266jWfMWHP+bi/MONRkTJ37C4QftB8C8efPY/6BD2GW33XOOKg3Nm1az/catOfee0XmHUrbyHNHOzmraEhgOrB4R47NVE4DV67vfskrawObAxZK+AuYCP6XwjeQNCm+0Zr/aMcC/JAUJTkRbYIederHDTr3yDiMJ32vfkT/e/ti32lu0XJmzrrg5h4jSt8EG7XjuxVfyDiNJs+fOp/v5gxe7vvcfnmrAaMpQaWZ8t5Y0osbytRFx7bcOXSgy7wFOj4jPVKNvPZtIXe+p/WWVtCPiMaD2b9URwP8tYtuRQM1JaL8sYWhmZmaTI6LbkjaQ1JRCwr41Iu7Nmj+RtGZEjJe0JjCxvgGU1Zi2mZlZsajIf5Z6vEJJ/U/grYj4a41VDwJHZc+PAh6o73sqq0rbzMysgm0PHAGMkvRq1nYO8EfgTknHAmOAA+t7ACdtMzNLjmj4u3xlE6MXd9Sdi3EMd4+bmZlVCFfaZmaWpPQuYuqkbWZmqUowa7t73MzMrEK40jYzsyT5Ll9mZmaWG1faZmaWpIY+5ashOGmbmVmSEszZ7h43MzOrFK60zcwsTQmW2q60zczMKoQrbTMzS07hdtrpldpO2mZmlh6lOXvc3eNmZmYVwpW2mZklKcFC25W2mZlZpXClbWZmaUqw1HalbWZmViFcaZuZWYLkU77MzMwqhU/5MjMzs9y40jYzs+SIJOehudI2MzOrFK60zcwsTQmW2k7aZmaWpBRnj7t73MzMrEK40jYzsyT5lC8zMzPLjSttMzNLUoKFtpO2mZklSO4eNzMzsxy50jYzs0SlV2q70jYzM6sQrrTNzCw5wmPaZmZmliNX2mZmlqQEC+3GlbRfeXnk5JbNqsfkHcd31BqYnHcQifNnXHr+jBtGpX3O3yvlzlPsHm9USTsi2uQdw3claUREdMs7jpT5My49f8YNw59z+hpV0jYzs8bDd/kyMzOz3LjSLn/X5h1AI+DPuPT8GTcMf841pVdoO2mXu4jwf8IS82dcev6MG4Y/54UlmLPdPW5mZlYpnLQtaZJOlfSWpFvzjiUFktaX9EbecVjdNdZ/M6n4j3Lg7vEKJqlJRMzLO44ydyKwS0SMre8O/DmbWblwpd2AJN0vaaSk0ZKOz9pmSPqdpNckDZO0eta+YbY8StJFkmZk7b0kPSPpQeBNSRdKOr3GMX4n6bRc3mCZkXQN0A54VNKvJf1L0ouSXpG0b7bN+tnn+XL22C5rX+hzzvFtlKNqSddlP8eDJDWXdJykl7Kf43skrQAg6UZJ10gaIekdSX2z9qMlPSBpqKR3JZ2XtfvneTEktZD0cPYZvyHpIEm/yT73NyRdKxXqQUlbZdu9BpyUc+i5UZH/lAMn7Yb1o4jYCugGnCppNaAFMCwiOgNPA8dl214OXB4RmwO1q8SuwGkR0R74F3AkgKQq4GCgf8nfSQWIiBOAcUBvCp/zkxHRPVu+WFILYCKwa0R0BQ4Crqixi5qfs31jY+CqiOgETAP2A+6NiK2zn+O3gGNrbL8+0B3YC7hGUrOsvXv22i2AAyR1wz/PS7I7MC4iOkfEZsBA4Mrsc98MaA70zba9ATgl+/dovFTkRxlw0m5Yp2bffIcB61L45TcHGJCtH0nhFxzAtsBd2fPbau3nxYj4ACAiPgSmSNoS2A14JSKmlOoNVLDdgLMlvQoMBZoB6wFNgeskjaLweXes8ZqvP2dbyAcR8Wr2fMHP7GZZz8Qo4DCgU43t74yIryLiXeB9YJOs/fGImBIRs4F7gZ7+eV6iUcCukv4kaYeImA70ljQ8+9z7AJ0ktQJaRcTT2etuyStgKz6PaTcQSb2AXYBtI2KWpKEUEsfciIhss/nU7d9kZq3l64GjgTUoVCr2bQL2i4i3F2qUzgc+ATpT+BL7RY3VtT9nK/iyxvP5FCq8G4F+EfGapKOBXjW2CRYWS2n3z/MiRMQ7kroCewIXSRpMoeu7W0R8lP0sN1vSPhqbMimOi8qVdsNZGfg0S9ibAD2Wsv0wCl2HUOgiXJL7KHSdbQ08tkxRpusx4JQaY35bZu0rA+Mj4ivgCKA6p/gqXUtgvKSmFCrtmg6QVCVpQwpzDBZ8cdpV0qqSmgP9gOeydv88L4KktYBZEdEfuJjC8A3AZEkrAvsDRMQ0YJqkntn62v8eVsFcaTecgcAJkt6i8Etr2FK2Px3oL+nX2WunL27DiJgjaQgwLSLmFyvgxPwWuAx4PRsr/YDC+N/fgXskHUnhc3Z1XT/nAsOBSdnfLWus+x/wIrAScEJEfJF9d3oRuAdYB+gfESPAP89LsDmFuRhfAXOBn1L4svMGMAF4qca2xwD/khTAoIYOtFyUy2laxaRvematnGSzb2dHREg6GDgkIvZdzLZVwMvAAdm4oVlZkHQjMCAi7q7VfjSFbt2TF/Ea/zzbMuvSdasY/Mzwou6z9YpNR+Z9FzVX2uVrK+DKrDt3GvCjRW0kqSOFiWz3+RecVTr/PFvxlM9pWsXkStvMzJKzZddu8eSzxa20V23RJPdK2xPRzMzMKoSTtpmZWYVw0jYzM6sQTtpmSyFpvqRXs+s737Xgutr13NeNkvbPnl+fTbxa3La9FlwL/Tse40NJrevaXmubGd/xWOdLOvO7xmjWEFK8y5eTttnSzY6ILtn1necAJ9RcKaleZ2FExI8jYkk3I+kFfOekbWYFvmGImT0DbFT7LmCSqiVdnN1x6XVJPwFQwZWS3pb0BNB2wY6yO1x1y57vrsJdxl6TNFjS+hS+HJyRVfk7SGqjwh20Xsoe22evXU2Fu22NlnQ9dbh6oxZxx7ka6y7N2gdLapO1bShpYPaaZ7Kr+plZA/N52mZ1lFXUe1C4choULiO5WUR8kCW+6RGxtaTlgeckDQK2BDpQuBHJ6hRu8/mvWvttA1wH7Jjta9WImKrCrUVnRMQl2Xa3AZdGxLOS1qNwic9NgfOAZyPiQkl7sfAdthbnR9kxmgMvSbonuzFHC2BERJwh6TfZvk8GrqVwNbN3JW1D4UpyferxMZo1jDLq0i4mJ22zpWue3R0MCpX2Pyl0W9e8C9huwBYLxqspXNN8Y2BH4PbscpzjJD25iP33AJ6ucee2qYuJYxego775TbRSds3pHYEfZq99WNKndXhPp0r6QfZ8wR3npgBfAXdk7f2Be7NjbAfcVePYy9fhGGZWZE7aZks3OyK61GzIklfN65SLwv2LH6u13Z5FjKMK6BERNe9Ehr5jOaHF33FuUSI77rTan4FZOSujW2AXlce0zYrjMeCn2V2ukNReUgvgaeCgbMx7TaD3Il47DNhR0gbZa1fN2j9n4RtvDAJOWbAgaUESfRo4NGvbA1hlKbEu6Y5zVWR3i8r2+WxEfAZ8IOmA7BiS1HkpxzDLn4r8KANO2mbFcT2F8eqXJb0B/INCT9Z9wLvZupuBF2q/MCImAcdT6Ip+jW+6px8CfrBgIhpwKtAtm+j2Jt/MYr+AQtIfTaGb/H9LiXUg0ESFO879kYXvODcT6J69hz7AhVn7YcCxWXyjgUXevMbMSsvXHjczs+R03apbPP38S0vf8Dto2azK1x43MzOzuvFENDMzS1KKp3y50jYzM6sQrrTNzCxJCRbaTtpmZpaoBLO2u8fNzMwqhCttMzNLUrncmauYXGmbmZlVCFfaZmaWHJHmKV++IpqZmSVH0kCgdZF3Ozkidi/yPr8TJ20zM7MK4TFtMzOzCuGkbWZmViGctM3MzCqEk7aZmVmFcNI2MzOrEP8PoucO9fX3z6wAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 576x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gLdNsgaDu6J8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_7YOAt2TIKPI"
      },
      "source": [
        "# Mel Spectrogram + basic model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xr3mQSInIQ84"
      },
      "source": [
        "audio_duration = 3\n",
        "sampling_rate = 44100\n",
        "input_length = sampling_rate * audio_duration\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_mWyb8nIYyb"
      },
      "source": [
        "data = {'labels': [],\n",
        "        'features': []}\n",
        "\n",
        "for i in range(len(CREMA_D_df)):\n",
        "  if ((CREMA_D_df['Emotion'][i] == 'HAP') | (CREMA_D_df['Emotion'][i] == 'SAD') | \n",
        "      (CREMA_D_df['Emotion'][i] == 'ANG') | (CREMA_D_df['Emotion'][i] == 'FEA')):\n",
        "    \n",
        "    if CREMA_D_df['Emotion'][i] == 'HAP':\n",
        "      data['labels'].append(0)\n",
        "    elif CREMA_D_df['Emotion'][i] == 'SAD':\n",
        "      data['labels'].append(1)\n",
        "    elif CREMA_D_df['Emotion'][i] == 'ANG':\n",
        "      data['labels'].append(2)\n",
        "    elif CREMA_D_df['Emotion'][i] == 'FEA':\n",
        "      data['labels'].append(3)\n",
        "\n",
        "\n",
        "    signal, sr =  librosa.load(CREMA_D_df['Paths'][i])\n",
        "\n",
        "\n",
        "    if len(signal) > input_length:\n",
        "      signal = signal[0:input_length]\n",
        "    elif  input_length > len(signal):\n",
        "      max_offset = input_length - len(signal)  \n",
        "      signal = np.pad(signal, (0, max_offset), \"constant\")\n",
        "\n",
        "    melspec = librosa.feature.melspectrogram(signal, sr=sampling_rate, n_mels=128,n_fft=2048,hop_length=512)   \n",
        "    melspec = np.mean(melspec, axis=0)\n",
        "    data['features'].append(melspec)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6yk6fzByIY1W"
      },
      "source": [
        "X = data['features']\n",
        "y = data['labels']\n",
        "\n",
        "y = np.array(y)\n",
        "y = to_categorical(y)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=0)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=0)\n",
        "\n",
        "X_train = np.array(X_train)\n",
        "X_test = np.array(X_test)\n",
        "X_val = np.array(X_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aowUl_16N8b3",
        "outputId": "f62aa192-be77-4cbb-f841-62cebc102a50"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4117, 259)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TgEIFTMtNvym"
      },
      "source": [
        "## basic models:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-i-abjOsNvzH",
        "outputId": "b8ef7b44-f79f-45e5-92b8-14e47bb11640"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(259, input_shape=(259, ), activation = 'relu'))\n",
        "#model.add(Dropout(0.1))\n",
        "model.add(Dense(128, activation = 'relu'))\n",
        "#model.add(Dropout(0.25))\n",
        "model.add(Dense(128, activation = 'relu'))\n",
        "#model.add(Dropout(0.2))\n",
        "model.add(Dense(4, activation = 'softmax'))\n",
        "\n",
        "optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
        "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer=optimizer)\n",
        "early_stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=100, verbose=1, mode='auto')\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_5 (Dense)              (None, 259)               67340     \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 128)               33280     \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 4)                 516       \n",
            "=================================================================\n",
            "Total params: 117,648\n",
            "Trainable params: 117,648\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Q3G-i0jNvzI",
        "outputId": "ab1b3dec-aaa8-440d-c2a9-44f492736606"
      },
      "source": [
        "history = model.fit(X_train, y_train, batch_size=64, epochs=200, \n",
        "                    validation_data=(X_val, y_val))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "65/65 [==============================] - 1s 7ms/step - loss: 1.3363 - accuracy: 0.3656 - val_loss: 1.2311 - val_accuracy: 0.4782\n",
            "Epoch 2/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 1.0946 - accuracy: 0.5162 - val_loss: 1.1579 - val_accuracy: 0.4760\n",
            "Epoch 3/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 1.0161 - accuracy: 0.5575 - val_loss: 1.1622 - val_accuracy: 0.4803\n",
            "Epoch 4/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.9580 - accuracy: 0.5877 - val_loss: 1.1447 - val_accuracy: 0.5022\n",
            "Epoch 5/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.9333 - accuracy: 0.5887 - val_loss: 1.1802 - val_accuracy: 0.4760\n",
            "Epoch 6/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.9224 - accuracy: 0.5956 - val_loss: 1.1780 - val_accuracy: 0.4956\n",
            "Epoch 7/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.8901 - accuracy: 0.6157 - val_loss: 1.1910 - val_accuracy: 0.4978\n",
            "Epoch 8/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.8860 - accuracy: 0.6215 - val_loss: 1.2252 - val_accuracy: 0.5087\n",
            "Epoch 9/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.8749 - accuracy: 0.6186 - val_loss: 1.1953 - val_accuracy: 0.4869\n",
            "Epoch 10/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.8494 - accuracy: 0.6264 - val_loss: 1.3052 - val_accuracy: 0.4891\n",
            "Epoch 11/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.8107 - accuracy: 0.6505 - val_loss: 1.3591 - val_accuracy: 0.4934\n",
            "Epoch 12/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.8233 - accuracy: 0.6472 - val_loss: 1.3921 - val_accuracy: 0.4869\n",
            "Epoch 13/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.8081 - accuracy: 0.6535 - val_loss: 1.3585 - val_accuracy: 0.4847\n",
            "Epoch 14/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.7786 - accuracy: 0.6729 - val_loss: 1.4649 - val_accuracy: 0.4738\n",
            "Epoch 15/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.7515 - accuracy: 0.6868 - val_loss: 1.3848 - val_accuracy: 0.4934\n",
            "Epoch 16/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.7158 - accuracy: 0.6860 - val_loss: 1.5787 - val_accuracy: 0.4782\n",
            "Epoch 17/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.7029 - accuracy: 0.7033 - val_loss: 1.4709 - val_accuracy: 0.4891\n",
            "Epoch 18/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.7314 - accuracy: 0.6963 - val_loss: 1.4422 - val_accuracy: 0.4956\n",
            "Epoch 19/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.7008 - accuracy: 0.7081 - val_loss: 1.5519 - val_accuracy: 0.4978\n",
            "Epoch 20/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.6583 - accuracy: 0.7323 - val_loss: 1.6885 - val_accuracy: 0.4913\n",
            "Epoch 21/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.6211 - accuracy: 0.7485 - val_loss: 1.7559 - val_accuracy: 0.5066\n",
            "Epoch 22/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.6335 - accuracy: 0.7463 - val_loss: 1.7610 - val_accuracy: 0.4847\n",
            "Epoch 23/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.6187 - accuracy: 0.7499 - val_loss: 1.8245 - val_accuracy: 0.5044\n",
            "Epoch 24/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.5557 - accuracy: 0.7832 - val_loss: 1.8781 - val_accuracy: 0.4847\n",
            "Epoch 25/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.5603 - accuracy: 0.7856 - val_loss: 1.8788 - val_accuracy: 0.4913\n",
            "Epoch 26/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.6305 - accuracy: 0.7524 - val_loss: 1.9188 - val_accuracy: 0.4738\n",
            "Epoch 27/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.5646 - accuracy: 0.7873 - val_loss: 1.9515 - val_accuracy: 0.4891\n",
            "Epoch 28/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.5524 - accuracy: 0.7900 - val_loss: 1.8800 - val_accuracy: 0.5022\n",
            "Epoch 29/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.5213 - accuracy: 0.8028 - val_loss: 2.0813 - val_accuracy: 0.4803\n",
            "Epoch 30/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.4732 - accuracy: 0.8204 - val_loss: 2.0584 - val_accuracy: 0.5066\n",
            "Epoch 31/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.4495 - accuracy: 0.8338 - val_loss: 2.2017 - val_accuracy: 0.5000\n",
            "Epoch 32/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.4116 - accuracy: 0.8483 - val_loss: 2.3589 - val_accuracy: 0.4869\n",
            "Epoch 33/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.3846 - accuracy: 0.8550 - val_loss: 2.6288 - val_accuracy: 0.4803\n",
            "Epoch 34/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.5343 - accuracy: 0.7947 - val_loss: 2.1637 - val_accuracy: 0.4847\n",
            "Epoch 35/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.4349 - accuracy: 0.8311 - val_loss: 2.4289 - val_accuracy: 0.4869\n",
            "Epoch 36/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.4379 - accuracy: 0.8379 - val_loss: 2.5545 - val_accuracy: 0.4760\n",
            "Epoch 37/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.4473 - accuracy: 0.8431 - val_loss: 2.5153 - val_accuracy: 0.4760\n",
            "Epoch 38/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.3637 - accuracy: 0.8635 - val_loss: 2.6677 - val_accuracy: 0.5000\n",
            "Epoch 39/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.3266 - accuracy: 0.8868 - val_loss: 2.9810 - val_accuracy: 0.4651\n",
            "Epoch 40/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.3327 - accuracy: 0.8784 - val_loss: 2.9666 - val_accuracy: 0.4847\n",
            "Epoch 41/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.3121 - accuracy: 0.8832 - val_loss: 3.2832 - val_accuracy: 0.4825\n",
            "Epoch 42/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.3016 - accuracy: 0.8911 - val_loss: 3.0724 - val_accuracy: 0.4585\n",
            "Epoch 43/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.3573 - accuracy: 0.8712 - val_loss: 3.3691 - val_accuracy: 0.4607\n",
            "Epoch 44/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.4083 - accuracy: 0.8448 - val_loss: 2.8836 - val_accuracy: 0.4934\n",
            "Epoch 45/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.5005 - accuracy: 0.8351 - val_loss: 2.3584 - val_accuracy: 0.4869\n",
            "Epoch 46/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.4116 - accuracy: 0.8470 - val_loss: 2.5414 - val_accuracy: 0.4738\n",
            "Epoch 47/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.3140 - accuracy: 0.8825 - val_loss: 2.6400 - val_accuracy: 0.4934\n",
            "Epoch 48/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.2535 - accuracy: 0.9138 - val_loss: 2.9475 - val_accuracy: 0.5066\n",
            "Epoch 49/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.2389 - accuracy: 0.9216 - val_loss: 3.0949 - val_accuracy: 0.4891\n",
            "Epoch 50/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.2249 - accuracy: 0.9245 - val_loss: 3.2892 - val_accuracy: 0.5000\n",
            "Epoch 51/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.2054 - accuracy: 0.9318 - val_loss: 3.4455 - val_accuracy: 0.4585\n",
            "Epoch 52/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.2078 - accuracy: 0.9256 - val_loss: 3.6136 - val_accuracy: 0.5022\n",
            "Epoch 53/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.1837 - accuracy: 0.9391 - val_loss: 3.7200 - val_accuracy: 0.5131\n",
            "Epoch 54/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.1895 - accuracy: 0.9351 - val_loss: 3.9252 - val_accuracy: 0.5262\n",
            "Epoch 55/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.2044 - accuracy: 0.9316 - val_loss: 4.0849 - val_accuracy: 0.4607\n",
            "Epoch 56/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.2201 - accuracy: 0.9228 - val_loss: 3.7093 - val_accuracy: 0.5022\n",
            "Epoch 57/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.2254 - accuracy: 0.9188 - val_loss: 4.1240 - val_accuracy: 0.4978\n",
            "Epoch 58/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.2167 - accuracy: 0.9221 - val_loss: 3.8286 - val_accuracy: 0.4694\n",
            "Epoch 59/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.2227 - accuracy: 0.9194 - val_loss: 3.8319 - val_accuracy: 0.4716\n",
            "Epoch 60/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.2996 - accuracy: 0.9007 - val_loss: 3.5391 - val_accuracy: 0.4891\n",
            "Epoch 61/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.2522 - accuracy: 0.9046 - val_loss: 3.6199 - val_accuracy: 0.4978\n",
            "Epoch 62/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.2526 - accuracy: 0.9252 - val_loss: 3.5179 - val_accuracy: 0.4716\n",
            "Epoch 63/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.2429 - accuracy: 0.9138 - val_loss: 3.1890 - val_accuracy: 0.4803\n",
            "Epoch 64/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.1825 - accuracy: 0.9403 - val_loss: 3.5416 - val_accuracy: 0.4847\n",
            "Epoch 65/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.1459 - accuracy: 0.9508 - val_loss: 3.5915 - val_accuracy: 0.5087\n",
            "Epoch 66/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.1450 - accuracy: 0.9505 - val_loss: 3.9333 - val_accuracy: 0.4541\n",
            "Epoch 67/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.1269 - accuracy: 0.9578 - val_loss: 3.9606 - val_accuracy: 0.4651\n",
            "Epoch 68/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.1255 - accuracy: 0.9575 - val_loss: 4.0717 - val_accuracy: 0.4716\n",
            "Epoch 69/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.1142 - accuracy: 0.9640 - val_loss: 4.2081 - val_accuracy: 0.4803\n",
            "Epoch 70/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.1074 - accuracy: 0.9659 - val_loss: 4.4190 - val_accuracy: 0.4782\n",
            "Epoch 71/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.1243 - accuracy: 0.9526 - val_loss: 4.4678 - val_accuracy: 0.5044\n",
            "Epoch 72/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0974 - accuracy: 0.9710 - val_loss: 4.4808 - val_accuracy: 0.4803\n",
            "Epoch 73/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.1013 - accuracy: 0.9674 - val_loss: 4.6206 - val_accuracy: 0.4738\n",
            "Epoch 74/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.1058 - accuracy: 0.9624 - val_loss: 4.8039 - val_accuracy: 0.4869\n",
            "Epoch 75/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0911 - accuracy: 0.9695 - val_loss: 4.9165 - val_accuracy: 0.4825\n",
            "Epoch 76/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.0869 - accuracy: 0.9705 - val_loss: 4.9805 - val_accuracy: 0.4629\n",
            "Epoch 77/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0771 - accuracy: 0.9763 - val_loss: 5.0715 - val_accuracy: 0.4694\n",
            "Epoch 78/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0846 - accuracy: 0.9719 - val_loss: 5.1467 - val_accuracy: 0.4563\n",
            "Epoch 79/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.1187 - accuracy: 0.9618 - val_loss: 5.4195 - val_accuracy: 0.4410\n",
            "Epoch 80/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3197 - accuracy: 0.9108 - val_loss: 3.4724 - val_accuracy: 0.4454\n",
            "Epoch 81/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.2329 - accuracy: 0.9100 - val_loss: 3.8931 - val_accuracy: 0.4279\n",
            "Epoch 82/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.1829 - accuracy: 0.9419 - val_loss: 3.9089 - val_accuracy: 0.4498\n",
            "Epoch 83/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.1299 - accuracy: 0.9564 - val_loss: 3.9232 - val_accuracy: 0.5044\n",
            "Epoch 84/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.1504 - accuracy: 0.9521 - val_loss: 3.8287 - val_accuracy: 0.5022\n",
            "Epoch 85/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0958 - accuracy: 0.9646 - val_loss: 4.2839 - val_accuracy: 0.4585\n",
            "Epoch 86/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0875 - accuracy: 0.9697 - val_loss: 4.3553 - val_accuracy: 0.5022\n",
            "Epoch 87/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0656 - accuracy: 0.9821 - val_loss: 4.5091 - val_accuracy: 0.4847\n",
            "Epoch 88/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0743 - accuracy: 0.9739 - val_loss: 4.5762 - val_accuracy: 0.4803\n",
            "Epoch 89/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.0752 - accuracy: 0.9727 - val_loss: 4.7326 - val_accuracy: 0.5131\n",
            "Epoch 90/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0648 - accuracy: 0.9759 - val_loss: 4.9879 - val_accuracy: 0.4978\n",
            "Epoch 91/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0641 - accuracy: 0.9795 - val_loss: 4.9212 - val_accuracy: 0.4913\n",
            "Epoch 92/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.0547 - accuracy: 0.9859 - val_loss: 4.4435 - val_accuracy: 0.4716\n",
            "Epoch 93/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.1155 - accuracy: 0.9532 - val_loss: 4.3905 - val_accuracy: 0.4891\n",
            "Epoch 94/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0792 - accuracy: 0.9740 - val_loss: 4.6704 - val_accuracy: 0.4760\n",
            "Epoch 95/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.0509 - accuracy: 0.9840 - val_loss: 4.8422 - val_accuracy: 0.4672\n",
            "Epoch 96/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0511 - accuracy: 0.9855 - val_loss: 5.0017 - val_accuracy: 0.4389\n",
            "Epoch 97/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0457 - accuracy: 0.9863 - val_loss: 5.1858 - val_accuracy: 0.4651\n",
            "Epoch 98/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0403 - accuracy: 0.9886 - val_loss: 5.2210 - val_accuracy: 0.4869\n",
            "Epoch 99/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0538 - accuracy: 0.9790 - val_loss: 5.2993 - val_accuracy: 0.4738\n",
            "Epoch 100/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0370 - accuracy: 0.9910 - val_loss: 5.4326 - val_accuracy: 0.4629\n",
            "Epoch 101/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0336 - accuracy: 0.9919 - val_loss: 5.6016 - val_accuracy: 0.4716\n",
            "Epoch 102/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.0411 - accuracy: 0.9848 - val_loss: 5.7656 - val_accuracy: 0.4782\n",
            "Epoch 103/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0669 - accuracy: 0.9754 - val_loss: 5.6799 - val_accuracy: 0.4323\n",
            "Epoch 104/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0621 - accuracy: 0.9743 - val_loss: 5.7251 - val_accuracy: 0.4454\n",
            "Epoch 105/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0375 - accuracy: 0.9896 - val_loss: 5.8398 - val_accuracy: 0.4782\n",
            "Epoch 106/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0359 - accuracy: 0.9874 - val_loss: 6.0083 - val_accuracy: 0.4782\n",
            "Epoch 107/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0264 - accuracy: 0.9953 - val_loss: 6.1070 - val_accuracy: 0.4585\n",
            "Epoch 108/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0252 - accuracy: 0.9933 - val_loss: 6.3002 - val_accuracy: 0.4672\n",
            "Epoch 109/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.0282 - accuracy: 0.9908 - val_loss: 6.2387 - val_accuracy: 0.4563\n",
            "Epoch 110/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0335 - accuracy: 0.9881 - val_loss: 6.0867 - val_accuracy: 0.4738\n",
            "Epoch 111/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.1051 - accuracy: 0.9720 - val_loss: 5.6560 - val_accuracy: 0.4607\n",
            "Epoch 112/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.3687 - accuracy: 0.8946 - val_loss: 3.8231 - val_accuracy: 0.4694\n",
            "Epoch 113/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.1984 - accuracy: 0.9446 - val_loss: 4.1837 - val_accuracy: 0.4585\n",
            "Epoch 114/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.1277 - accuracy: 0.9574 - val_loss: 4.3798 - val_accuracy: 0.4367\n",
            "Epoch 115/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0826 - accuracy: 0.9694 - val_loss: 4.9284 - val_accuracy: 0.4607\n",
            "Epoch 116/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0861 - accuracy: 0.9762 - val_loss: 4.3716 - val_accuracy: 0.4782\n",
            "Epoch 117/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0893 - accuracy: 0.9744 - val_loss: 4.5523 - val_accuracy: 0.4913\n",
            "Epoch 118/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0454 - accuracy: 0.9863 - val_loss: 4.7549 - val_accuracy: 0.4891\n",
            "Epoch 119/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0337 - accuracy: 0.9901 - val_loss: 4.7779 - val_accuracy: 0.4825\n",
            "Epoch 120/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.0263 - accuracy: 0.9945 - val_loss: 4.9794 - val_accuracy: 0.4934\n",
            "Epoch 121/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0269 - accuracy: 0.9938 - val_loss: 5.0787 - val_accuracy: 0.4760\n",
            "Epoch 122/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0308 - accuracy: 0.9906 - val_loss: 5.1612 - val_accuracy: 0.4891\n",
            "Epoch 123/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.0333 - accuracy: 0.9876 - val_loss: 5.2450 - val_accuracy: 0.4956\n",
            "Epoch 124/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.0305 - accuracy: 0.9891 - val_loss: 5.3857 - val_accuracy: 0.4738\n",
            "Epoch 125/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.0170 - accuracy: 0.9985 - val_loss: 5.5022 - val_accuracy: 0.4607\n",
            "Epoch 126/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.0188 - accuracy: 0.9945 - val_loss: 5.6703 - val_accuracy: 0.5044\n",
            "Epoch 127/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.0332 - accuracy: 0.9883 - val_loss: 5.7033 - val_accuracy: 0.5000\n",
            "Epoch 128/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.0195 - accuracy: 0.9929 - val_loss: 5.8385 - val_accuracy: 0.4520\n",
            "Epoch 129/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0294 - accuracy: 0.9885 - val_loss: 5.7963 - val_accuracy: 0.4825\n",
            "Epoch 130/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.0174 - accuracy: 0.9951 - val_loss: 5.8988 - val_accuracy: 0.4738\n",
            "Epoch 131/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0263 - accuracy: 0.9892 - val_loss: 6.0231 - val_accuracy: 0.4978\n",
            "Epoch 132/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.0318 - accuracy: 0.9876 - val_loss: 6.0366 - val_accuracy: 0.4694\n",
            "Epoch 133/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.0456 - accuracy: 0.9844 - val_loss: 6.0305 - val_accuracy: 0.4782\n",
            "Epoch 134/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0200 - accuracy: 0.9944 - val_loss: 6.1032 - val_accuracy: 0.4869\n",
            "Epoch 135/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0214 - accuracy: 0.9941 - val_loss: 6.1893 - val_accuracy: 0.4956\n",
            "Epoch 136/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0188 - accuracy: 0.9936 - val_loss: 6.2954 - val_accuracy: 0.4956\n",
            "Epoch 137/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.0132 - accuracy: 0.9967 - val_loss: 6.3477 - val_accuracy: 0.4651\n",
            "Epoch 138/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0283 - accuracy: 0.9917 - val_loss: 5.3689 - val_accuracy: 0.4563\n",
            "Epoch 139/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.1519 - accuracy: 0.9574 - val_loss: 4.0585 - val_accuracy: 0.4782\n",
            "Epoch 140/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.2727 - accuracy: 0.9271 - val_loss: 3.8379 - val_accuracy: 0.4716\n",
            "Epoch 141/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.1606 - accuracy: 0.9413 - val_loss: 4.2711 - val_accuracy: 0.4913\n",
            "Epoch 142/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0937 - accuracy: 0.9733 - val_loss: 4.2939 - val_accuracy: 0.5022\n",
            "Epoch 143/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0514 - accuracy: 0.9851 - val_loss: 4.6050 - val_accuracy: 0.5066\n",
            "Epoch 144/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0239 - accuracy: 0.9940 - val_loss: 4.7441 - val_accuracy: 0.4803\n",
            "Epoch 145/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0181 - accuracy: 0.9955 - val_loss: 4.9631 - val_accuracy: 0.4891\n",
            "Epoch 146/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0166 - accuracy: 0.9955 - val_loss: 5.1267 - val_accuracy: 0.4934\n",
            "Epoch 147/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0187 - accuracy: 0.9939 - val_loss: 5.2556 - val_accuracy: 0.4978\n",
            "Epoch 148/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.0158 - accuracy: 0.9956 - val_loss: 5.3607 - val_accuracy: 0.5087\n",
            "Epoch 149/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0249 - accuracy: 0.9918 - val_loss: 5.4891 - val_accuracy: 0.5022\n",
            "Epoch 150/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.0305 - accuracy: 0.9888 - val_loss: 5.5164 - val_accuracy: 0.4913\n",
            "Epoch 151/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0160 - accuracy: 0.9953 - val_loss: 5.6319 - val_accuracy: 0.5022\n",
            "Epoch 152/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0102 - accuracy: 0.9977 - val_loss: 5.6881 - val_accuracy: 0.4891\n",
            "Epoch 153/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.0262 - accuracy: 0.9891 - val_loss: 5.7758 - val_accuracy: 0.4716\n",
            "Epoch 154/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0157 - accuracy: 0.9966 - val_loss: 5.7596 - val_accuracy: 0.4891\n",
            "Epoch 155/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.0108 - accuracy: 0.9979 - val_loss: 5.8928 - val_accuracy: 0.4934\n",
            "Epoch 156/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0098 - accuracy: 0.9979 - val_loss: 5.9637 - val_accuracy: 0.4782\n",
            "Epoch 157/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.0121 - accuracy: 0.9966 - val_loss: 6.0478 - val_accuracy: 0.4913\n",
            "Epoch 158/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.0086 - accuracy: 0.9984 - val_loss: 6.1499 - val_accuracy: 0.4782\n",
            "Epoch 159/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.0071 - accuracy: 0.9989 - val_loss: 6.1907 - val_accuracy: 0.4825\n",
            "Epoch 160/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0075 - accuracy: 0.9992 - val_loss: 6.3143 - val_accuracy: 0.4934\n",
            "Epoch 161/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0082 - accuracy: 0.9972 - val_loss: 6.4194 - val_accuracy: 0.4803\n",
            "Epoch 162/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0110 - accuracy: 0.9962 - val_loss: 6.4281 - val_accuracy: 0.4847\n",
            "Epoch 163/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0058 - accuracy: 0.9993 - val_loss: 6.4834 - val_accuracy: 0.4847\n",
            "Epoch 164/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0155 - accuracy: 0.9943 - val_loss: 6.5214 - val_accuracy: 0.4847\n",
            "Epoch 165/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0120 - accuracy: 0.9966 - val_loss: 6.5323 - val_accuracy: 0.5109\n",
            "Epoch 166/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.0138 - accuracy: 0.9951 - val_loss: 6.5956 - val_accuracy: 0.4956\n",
            "Epoch 167/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0143 - accuracy: 0.9934 - val_loss: 6.6041 - val_accuracy: 0.4891\n",
            "Epoch 168/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.0355 - accuracy: 0.9864 - val_loss: 6.1127 - val_accuracy: 0.5066\n",
            "Epoch 169/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.3526 - accuracy: 0.9136 - val_loss: 4.1527 - val_accuracy: 0.4389\n",
            "Epoch 170/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.2842 - accuracy: 0.9079 - val_loss: 4.1481 - val_accuracy: 0.4651\n",
            "Epoch 171/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.1016 - accuracy: 0.9677 - val_loss: 4.3623 - val_accuracy: 0.4607\n",
            "Epoch 172/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.0361 - accuracy: 0.9904 - val_loss: 4.9410 - val_accuracy: 0.4760\n",
            "Epoch 173/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.0137 - accuracy: 0.9981 - val_loss: 5.2793 - val_accuracy: 0.4585\n",
            "Epoch 174/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0103 - accuracy: 0.9987 - val_loss: 5.4224 - val_accuracy: 0.4476\n",
            "Epoch 175/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.0107 - accuracy: 0.9979 - val_loss: 5.5964 - val_accuracy: 0.4563\n",
            "Epoch 176/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.0111 - accuracy: 0.9983 - val_loss: 5.6514 - val_accuracy: 0.4716\n",
            "Epoch 177/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.0076 - accuracy: 0.9990 - val_loss: 5.7697 - val_accuracy: 0.4563\n",
            "Epoch 178/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0082 - accuracy: 0.9984 - val_loss: 5.8567 - val_accuracy: 0.4498\n",
            "Epoch 179/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.0215 - accuracy: 0.9910 - val_loss: 5.9241 - val_accuracy: 0.4694\n",
            "Epoch 180/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.0064 - accuracy: 0.9985 - val_loss: 6.0331 - val_accuracy: 0.4607\n",
            "Epoch 181/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.0067 - accuracy: 0.9992 - val_loss: 6.0907 - val_accuracy: 0.4694\n",
            "Epoch 182/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0066 - accuracy: 0.9993 - val_loss: 6.1505 - val_accuracy: 0.4563\n",
            "Epoch 183/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.0057 - accuracy: 0.9990 - val_loss: 6.2819 - val_accuracy: 0.4651\n",
            "Epoch 184/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0056 - accuracy: 0.9992 - val_loss: 6.3196 - val_accuracy: 0.4498\n",
            "Epoch 185/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.0052 - accuracy: 0.9998 - val_loss: 6.4134 - val_accuracy: 0.4607\n",
            "Epoch 186/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.0052 - accuracy: 0.9990 - val_loss: 6.4301 - val_accuracy: 0.4585\n",
            "Epoch 187/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0055 - accuracy: 0.9993 - val_loss: 6.5577 - val_accuracy: 0.4389\n",
            "Epoch 188/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0093 - accuracy: 0.9980 - val_loss: 6.6568 - val_accuracy: 0.4585\n",
            "Epoch 189/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.0052 - accuracy: 0.9989 - val_loss: 6.7050 - val_accuracy: 0.4738\n",
            "Epoch 190/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0058 - accuracy: 0.9985 - val_loss: 6.6852 - val_accuracy: 0.4651\n",
            "Epoch 191/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.0090 - accuracy: 0.9982 - val_loss: 6.7252 - val_accuracy: 0.4541\n",
            "Epoch 192/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0149 - accuracy: 0.9936 - val_loss: 6.8378 - val_accuracy: 0.4760\n",
            "Epoch 193/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.0438 - accuracy: 0.9830 - val_loss: 6.5292 - val_accuracy: 0.4520\n",
            "Epoch 194/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0550 - accuracy: 0.9807 - val_loss: 6.7446 - val_accuracy: 0.4651\n",
            "Epoch 195/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.1687 - accuracy: 0.9422 - val_loss: 5.1692 - val_accuracy: 0.4847\n",
            "Epoch 196/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.1801 - accuracy: 0.9389 - val_loss: 4.3585 - val_accuracy: 0.4694\n",
            "Epoch 197/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.0674 - accuracy: 0.9776 - val_loss: 4.9575 - val_accuracy: 0.4607\n",
            "Epoch 198/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0335 - accuracy: 0.9879 - val_loss: 5.1948 - val_accuracy: 0.4476\n",
            "Epoch 199/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.0083 - accuracy: 0.9983 - val_loss: 5.4001 - val_accuracy: 0.4454\n",
            "Epoch 200/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 5.5959 - val_accuracy: 0.4541\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OcxSAMrpWwn6"
      },
      "source": [
        "model.save('/content/drive/MyDrive/Colab Notebooks/SPEECH_EMOTION_Recognition/Nộp bài(chốt hạ)/model_saver/basic_melspec_cremad.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JY0Ki_DJNvzK"
      },
      "source": [
        "###test_result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_syQ5_c5NvzL",
        "outputId": "b529185f-106e-4f38-c2c7-5838b667ba69"
      },
      "source": [
        "d = {0: 'happy',\n",
        "     1: 'sad',\n",
        "     2: 'angry',\n",
        "     3: 'fear'}\n",
        "Y_test_pred = np.argmax(model.predict(X_test), axis=-1)\n",
        "Y_test_pred = list(map(lambda x: d[x], Y_test_pred))\n",
        "y_test = np.argmax(y_test, axis=-1)\n",
        "y_test = list(map(lambda x: d[x], y_test))\n",
        "print(classification_report(y_test, Y_test_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.61      0.57      0.59       136\n",
            "        fear       0.35      0.28      0.31       134\n",
            "       happy       0.38      0.42      0.40       120\n",
            "         sad       0.49      0.60      0.54       119\n",
            "\n",
            "    accuracy                           0.46       509\n",
            "   macro avg       0.46      0.46      0.46       509\n",
            "weighted avg       0.46      0.46      0.46       509\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 483
        },
        "id": "cFY-fvMRNvzL",
        "outputId": "fcf04e00-3085-4caa-a10b-cccc1c7c94b1"
      },
      "source": [
        "import scikitplot as skplt\n",
        "\n",
        "skplt.metrics.plot_confusion_matrix(\n",
        "    y_test, \n",
        "    Y_test_pred,\n",
        "    figsize=(8,8))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fa48008c890>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jNEbmeonPxXR"
      },
      "source": [
        "# Mel Spectrogram + conv1D"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j8K-0mOcPxXm"
      },
      "source": [
        "audio_duration = 3\n",
        "sampling_rate = 44100\n",
        "input_length = sampling_rate * audio_duration\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eKTGQBGrPxXo"
      },
      "source": [
        "data = {'labels': [],\n",
        "        'features': []}\n",
        "\n",
        "for i in range(len(CREMA_D_df)):\n",
        "  if ((CREMA_D_df['Emotion'][i] == 'HAP') | (CREMA_D_df['Emotion'][i] == 'SAD') | \n",
        "      (CREMA_D_df['Emotion'][i] == 'ANG') | (CREMA_D_df['Emotion'][i] == 'FEA')):\n",
        "    \n",
        "    if CREMA_D_df['Emotion'][i] == 'HAP':\n",
        "      data['labels'].append(0)\n",
        "    elif CREMA_D_df['Emotion'][i] == 'SAD':\n",
        "      data['labels'].append(1)\n",
        "    elif CREMA_D_df['Emotion'][i] == 'ANG':\n",
        "      data['labels'].append(2)\n",
        "    elif CREMA_D_df['Emotion'][i] == 'FEA':\n",
        "      data['labels'].append(3)\n",
        "\n",
        "\n",
        "    signal, sr =  librosa.load(CREMA_D_df['Paths'][i])\n",
        "\n",
        "    if len(signal) > input_length:\n",
        "      signal = signal[0:input_length]\n",
        "    elif  input_length > len(signal):\n",
        "      max_offset = input_length - len(signal)  \n",
        "      signal = np.pad(signal, (0, max_offset), \"constant\")\n",
        "\n",
        "    melspec = librosa.feature.melspectrogram(signal, sr=sampling_rate, n_mels=128,n_fft=2048,hop_length=512)   \n",
        "    melspec = melspec.reshape(-1,1)\n",
        "    data['features'].append(melspec)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1inUhrfPxXp"
      },
      "source": [
        "X = data['features']\n",
        "y = data['labels']\n",
        "\n",
        "y = np.array(y)\n",
        "y = to_categorical(y)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=0)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=0)\n",
        "\n",
        "X_train = np.array(X_train)\n",
        "X_test = np.array(X_test)\n",
        "X_val = np.array(X_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75dgiNuHPxXq",
        "outputId": "44a82d0e-f1e1-400f-a22f-3866752c0c66"
      },
      "source": [
        "X_train.shape,X_test.shape,y_train.shape,y_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((4117, 33152, 1), (509, 33152, 1), (4117, 4), (509, 4))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oh_OiXY_Yg4_"
      },
      "source": [
        "### conv1D"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0YU2uUSwQXSk"
      },
      "source": [
        "\n",
        "# CNN I/P Config\n",
        "num_classes = 4\n",
        "input_shape = X_train.shape[1:]\n",
        "learning_rate = 0.0001\n",
        "decay = 1e-6\n",
        "momentum = 0.9\n",
        "\n",
        "#LSTM Configuration\n",
        "num_lstm = 256"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SqfS1FIXQYZc",
        "outputId": "d646c098-b3ad-4032-a3b8-58fd89f9f6f5"
      },
      "source": [
        "model = Sequential(name='Audio_CNN_1D')\n",
        "\n",
        "# LFLB1\n",
        "model.add(Conv1D(filters=64, kernel_size=(3), strides=1, padding='same', data_format='channels_last',input_shape=input_shape))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('elu'))\n",
        "model.add(MaxPooling1D(pool_size=4, strides=4))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "# LFLB2\n",
        "model.add(Conv1D(filters=64, kernel_size=3, strides=1, padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('elu'))\n",
        "model.add(MaxPooling1D(pool_size=4, strides=4))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# LFLB3\n",
        "model.add(Conv1D(filters=128, kernel_size=3, strides=1, padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('elu'))\n",
        "model.add(MaxPooling1D(pool_size=4, strides=4))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# LFLB4\n",
        "model.add(Conv1D(filters=128, kernel_size=3, strides=1, padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('elu'))\n",
        "model.add(MaxPooling1D(pool_size=4, strides=4))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# LSTM\n",
        "model.add(LSTM(units=num_lstm))\n",
        "\n",
        "# FC\n",
        "model.add(Dense(units=num_classes, activation='softmax'))\n",
        "\n",
        "# Model compilation\n",
        "opt= keras.optimizers.Adam(lr=0.01, beta_1=0.9,  beta_2=0.999, amsgrad=False)\n",
        "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
        "\n",
        "model.summary()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"Audio_CNN_1D\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_8 (Conv1D)            (None, 33152, 64)         256       \n",
            "_________________________________________________________________\n",
            "batch_normalization_14 (Batc (None, 33152, 64)         256       \n",
            "_________________________________________________________________\n",
            "activation_14 (Activation)   (None, 33152, 64)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_8 (MaxPooling1 (None, 8288, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_14 (Dropout)         (None, 8288, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv1d_9 (Conv1D)            (None, 8288, 64)          12352     \n",
            "_________________________________________________________________\n",
            "batch_normalization_15 (Batc (None, 8288, 64)          256       \n",
            "_________________________________________________________________\n",
            "activation_15 (Activation)   (None, 8288, 64)          0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_9 (MaxPooling1 (None, 2072, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_15 (Dropout)         (None, 2072, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv1d_10 (Conv1D)           (None, 2072, 128)         24704     \n",
            "_________________________________________________________________\n",
            "batch_normalization_16 (Batc (None, 2072, 128)         512       \n",
            "_________________________________________________________________\n",
            "activation_16 (Activation)   (None, 2072, 128)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_10 (MaxPooling (None, 518, 128)          0         \n",
            "_________________________________________________________________\n",
            "dropout_16 (Dropout)         (None, 518, 128)          0         \n",
            "_________________________________________________________________\n",
            "conv1d_11 (Conv1D)           (None, 518, 128)          49280     \n",
            "_________________________________________________________________\n",
            "batch_normalization_17 (Batc (None, 518, 128)          512       \n",
            "_________________________________________________________________\n",
            "activation_17 (Activation)   (None, 518, 128)          0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_11 (MaxPooling (None, 129, 128)          0         \n",
            "_________________________________________________________________\n",
            "dropout_17 (Dropout)         (None, 129, 128)          0         \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 256)               394240    \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 4)                 1028      \n",
            "=================================================================\n",
            "Total params: 483,396\n",
            "Trainable params: 482,628\n",
            "Non-trainable params: 768\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "StwxbTydQegU",
        "outputId": "235ed219-c215-4174-ddec-96749f141aad"
      },
      "source": [
        "#Train Config\n",
        "\n",
        "batch_size = 16\n",
        "num_epochs = 200\n",
        "\n",
        "# Model Training\n",
        "lr_reduce = ReduceLROnPlateau(monitor='val_loss', factor=0.9, patience=20, min_lr=0.000001)\n",
        "# Please change the model name accordingly.\n",
        "mcp_save = ModelCheckpoint('/content/Audio_1DCNN.h5', save_best_only=True, monitor='val_categorical_accuracy', mode='max')\n",
        "cnnhistory=model.fit(X_train, y_train, batch_size=batch_size, epochs=num_epochs,validation_data=(X_val, y_val), callbacks=[mcp_save, lr_reduce])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "258/258 [==============================] - 24s 79ms/step - loss: 1.4625 - categorical_accuracy: 0.2614 - val_loss: 1.3501 - val_categorical_accuracy: 0.4127\n",
            "Epoch 2/200\n",
            "258/258 [==============================] - 19s 75ms/step - loss: 1.2508 - categorical_accuracy: 0.4250 - val_loss: 1.2921 - val_categorical_accuracy: 0.3428\n",
            "Epoch 3/200\n",
            "258/258 [==============================] - 19s 75ms/step - loss: 1.1852 - categorical_accuracy: 0.4522 - val_loss: 1.2456 - val_categorical_accuracy: 0.4389\n",
            "Epoch 4/200\n",
            "258/258 [==============================] - 19s 75ms/step - loss: 1.1931 - categorical_accuracy: 0.4474 - val_loss: 1.4076 - val_categorical_accuracy: 0.4148\n",
            "Epoch 5/200\n",
            "258/258 [==============================] - 19s 75ms/step - loss: 1.1934 - categorical_accuracy: 0.4569 - val_loss: 1.1471 - val_categorical_accuracy: 0.4847\n",
            "Epoch 6/200\n",
            "258/258 [==============================] - 19s 75ms/step - loss: 1.2734 - categorical_accuracy: 0.4299 - val_loss: 1.2264 - val_categorical_accuracy: 0.4389\n",
            "Epoch 7/200\n",
            "258/258 [==============================] - 19s 75ms/step - loss: 1.2243 - categorical_accuracy: 0.4157 - val_loss: 1.2108 - val_categorical_accuracy: 0.4083\n",
            "Epoch 8/200\n",
            "258/258 [==============================] - 19s 75ms/step - loss: 1.2047 - categorical_accuracy: 0.4567 - val_loss: 1.2495 - val_categorical_accuracy: 0.4432\n",
            "Epoch 9/200\n",
            "258/258 [==============================] - 19s 75ms/step - loss: 1.1994 - categorical_accuracy: 0.4629 - val_loss: 1.5345 - val_categorical_accuracy: 0.3341\n",
            "Epoch 10/200\n",
            "258/258 [==============================] - 19s 75ms/step - loss: 1.2492 - categorical_accuracy: 0.4138 - val_loss: 1.2479 - val_categorical_accuracy: 0.3406\n",
            "Epoch 11/200\n",
            "258/258 [==============================] - 19s 75ms/step - loss: 1.2358 - categorical_accuracy: 0.4217 - val_loss: 1.4960 - val_categorical_accuracy: 0.3624\n",
            "Epoch 12/200\n",
            "258/258 [==============================] - 19s 75ms/step - loss: 1.1995 - categorical_accuracy: 0.4453 - val_loss: 1.5355 - val_categorical_accuracy: 0.3734\n",
            "Epoch 13/200\n",
            "258/258 [==============================] - 19s 75ms/step - loss: 1.1973 - categorical_accuracy: 0.4505 - val_loss: 1.1885 - val_categorical_accuracy: 0.4694\n",
            "Epoch 14/200\n",
            "258/258 [==============================] - 19s 75ms/step - loss: 1.1568 - categorical_accuracy: 0.4558 - val_loss: 1.2171 - val_categorical_accuracy: 0.4585\n",
            "Epoch 15/200\n",
            "258/258 [==============================] - 19s 75ms/step - loss: 1.1734 - categorical_accuracy: 0.4550 - val_loss: 1.2538 - val_categorical_accuracy: 0.4279\n",
            "Epoch 16/200\n",
            "258/258 [==============================] - 19s 76ms/step - loss: 1.1639 - categorical_accuracy: 0.4491 - val_loss: 1.5155 - val_categorical_accuracy: 0.3668\n",
            "Epoch 17/200\n",
            "258/258 [==============================] - 19s 75ms/step - loss: 1.2038 - categorical_accuracy: 0.4478 - val_loss: 1.4488 - val_categorical_accuracy: 0.3603\n",
            "Epoch 18/200\n",
            "258/258 [==============================] - 19s 75ms/step - loss: 1.2093 - categorical_accuracy: 0.4328 - val_loss: 1.2332 - val_categorical_accuracy: 0.4563\n",
            "Epoch 19/200\n",
            "258/258 [==============================] - 19s 75ms/step - loss: 1.1936 - categorical_accuracy: 0.4685 - val_loss: 1.1703 - val_categorical_accuracy: 0.4760\n",
            "Epoch 20/200\n",
            "258/258 [==============================] - 19s 75ms/step - loss: 1.1822 - categorical_accuracy: 0.4548 - val_loss: 1.2323 - val_categorical_accuracy: 0.4541\n",
            "Epoch 21/200\n",
            "258/258 [==============================] - 19s 75ms/step - loss: 1.1836 - categorical_accuracy: 0.4637 - val_loss: 1.2291 - val_categorical_accuracy: 0.4629\n",
            "Epoch 22/200\n",
            "258/258 [==============================] - 19s 75ms/step - loss: 1.2033 - categorical_accuracy: 0.4437 - val_loss: 1.2566 - val_categorical_accuracy: 0.4432\n",
            "Epoch 23/200\n",
            "258/258 [==============================] - 19s 75ms/step - loss: 1.1718 - categorical_accuracy: 0.4642 - val_loss: 1.2253 - val_categorical_accuracy: 0.4127\n",
            "Epoch 24/200\n",
            "258/258 [==============================] - 19s 75ms/step - loss: 1.2004 - categorical_accuracy: 0.4624 - val_loss: 1.1858 - val_categorical_accuracy: 0.4432\n",
            "Epoch 25/200\n",
            "258/258 [==============================] - 19s 75ms/step - loss: 1.1859 - categorical_accuracy: 0.4616 - val_loss: 1.2361 - val_categorical_accuracy: 0.4716\n",
            "Epoch 26/200\n",
            "258/258 [==============================] - 19s 75ms/step - loss: 1.1962 - categorical_accuracy: 0.4551 - val_loss: 1.3098 - val_categorical_accuracy: 0.4017\n",
            "Epoch 27/200\n",
            "258/258 [==============================] - 19s 75ms/step - loss: 1.1772 - categorical_accuracy: 0.4643 - val_loss: 1.3351 - val_categorical_accuracy: 0.4214\n",
            "Epoch 28/200\n",
            "258/258 [==============================] - 19s 75ms/step - loss: 1.1661 - categorical_accuracy: 0.4596 - val_loss: 1.3383 - val_categorical_accuracy: 0.4476\n",
            "Epoch 29/200\n",
            "258/258 [==============================] - 19s 75ms/step - loss: 1.2307 - categorical_accuracy: 0.4450 - val_loss: 1.2883 - val_categorical_accuracy: 0.4847\n",
            "Epoch 30/200\n",
            "258/258 [==============================] - 19s 75ms/step - loss: 1.2000 - categorical_accuracy: 0.4544 - val_loss: 1.3862 - val_categorical_accuracy: 0.3886\n",
            "Epoch 31/200\n",
            "258/258 [==============================] - 19s 75ms/step - loss: 1.1505 - categorical_accuracy: 0.4515 - val_loss: 1.1451 - val_categorical_accuracy: 0.5066\n",
            "Epoch 32/200\n",
            "258/258 [==============================] - 19s 76ms/step - loss: 1.1400 - categorical_accuracy: 0.4628 - val_loss: 1.2528 - val_categorical_accuracy: 0.4410\n",
            "Epoch 33/200\n",
            "258/258 [==============================] - 19s 75ms/step - loss: 1.1820 - categorical_accuracy: 0.4762 - val_loss: 1.2735 - val_categorical_accuracy: 0.4607\n",
            "Epoch 34/200\n",
            "258/258 [==============================] - 19s 76ms/step - loss: 1.1799 - categorical_accuracy: 0.4552 - val_loss: 1.2253 - val_categorical_accuracy: 0.4454\n",
            "Epoch 35/200\n",
            "258/258 [==============================] - 19s 75ms/step - loss: 1.1457 - categorical_accuracy: 0.4708 - val_loss: 1.2334 - val_categorical_accuracy: 0.4389\n",
            "Epoch 36/200\n",
            "258/258 [==============================] - 20s 76ms/step - loss: 1.1641 - categorical_accuracy: 0.4702 - val_loss: 1.1792 - val_categorical_accuracy: 0.4782\n",
            "Epoch 37/200\n",
            "258/258 [==============================] - 19s 75ms/step - loss: 1.1496 - categorical_accuracy: 0.4788 - val_loss: 1.2579 - val_categorical_accuracy: 0.4039\n",
            "Epoch 38/200\n",
            "258/258 [==============================] - 19s 76ms/step - loss: 1.1738 - categorical_accuracy: 0.4614 - val_loss: 1.4476 - val_categorical_accuracy: 0.4148\n",
            "Epoch 39/200\n",
            "258/258 [==============================] - 19s 75ms/step - loss: 1.1948 - categorical_accuracy: 0.4613 - val_loss: 1.1654 - val_categorical_accuracy: 0.4782\n",
            "Epoch 40/200\n",
            "258/258 [==============================] - 19s 75ms/step - loss: 1.1245 - categorical_accuracy: 0.5004 - val_loss: 1.2022 - val_categorical_accuracy: 0.4389\n",
            "Epoch 41/200\n",
            "258/258 [==============================] - 19s 75ms/step - loss: 1.1645 - categorical_accuracy: 0.4770 - val_loss: 1.3785 - val_categorical_accuracy: 0.3821\n",
            "Epoch 42/200\n",
            "258/258 [==============================] - 19s 75ms/step - loss: 1.1663 - categorical_accuracy: 0.4712 - val_loss: 1.2013 - val_categorical_accuracy: 0.4825\n",
            "Epoch 43/200\n",
            "258/258 [==============================] - 19s 76ms/step - loss: 1.1461 - categorical_accuracy: 0.4852 - val_loss: 1.3059 - val_categorical_accuracy: 0.4323\n",
            "Epoch 44/200\n",
            "258/258 [==============================] - 20s 77ms/step - loss: 1.1104 - categorical_accuracy: 0.4885 - val_loss: 1.3589 - val_categorical_accuracy: 0.4279\n",
            "Epoch 45/200\n",
            "258/258 [==============================] - 20s 76ms/step - loss: 1.1582 - categorical_accuracy: 0.4720 - val_loss: 1.2655 - val_categorical_accuracy: 0.4607\n",
            "Epoch 46/200\n",
            "258/258 [==============================] - 20s 76ms/step - loss: 1.1649 - categorical_accuracy: 0.4818 - val_loss: 1.1918 - val_categorical_accuracy: 0.4869\n",
            "Epoch 47/200\n",
            "258/258 [==============================] - 20s 76ms/step - loss: 1.1511 - categorical_accuracy: 0.4849 - val_loss: 1.2516 - val_categorical_accuracy: 0.4192\n",
            "Epoch 48/200\n",
            "258/258 [==============================] - 20s 76ms/step - loss: 1.1412 - categorical_accuracy: 0.4915 - val_loss: 1.2213 - val_categorical_accuracy: 0.4410\n",
            "Epoch 49/200\n",
            "258/258 [==============================] - 20s 79ms/step - loss: 1.1507 - categorical_accuracy: 0.4690 - val_loss: 1.2566 - val_categorical_accuracy: 0.4476\n",
            "Epoch 50/200\n",
            "258/258 [==============================] - 20s 76ms/step - loss: 1.1296 - categorical_accuracy: 0.4863 - val_loss: 1.2132 - val_categorical_accuracy: 0.4410\n",
            "Epoch 51/200\n",
            "258/258 [==============================] - 20s 76ms/step - loss: 1.1312 - categorical_accuracy: 0.4873 - val_loss: 1.2307 - val_categorical_accuracy: 0.4651\n",
            "Epoch 52/200\n",
            "258/258 [==============================] - 20s 76ms/step - loss: 1.1643 - categorical_accuracy: 0.4824 - val_loss: 1.2513 - val_categorical_accuracy: 0.4760\n",
            "Epoch 53/200\n",
            "258/258 [==============================] - 20s 76ms/step - loss: 1.1601 - categorical_accuracy: 0.4646 - val_loss: 1.2424 - val_categorical_accuracy: 0.3799\n",
            "Epoch 54/200\n",
            "258/258 [==============================] - 20s 76ms/step - loss: 1.1459 - categorical_accuracy: 0.4713 - val_loss: 1.2028 - val_categorical_accuracy: 0.4694\n",
            "Epoch 55/200\n",
            "258/258 [==============================] - 20s 76ms/step - loss: 1.1179 - categorical_accuracy: 0.4969 - val_loss: 1.1994 - val_categorical_accuracy: 0.4738\n",
            "Epoch 56/200\n",
            "258/258 [==============================] - 20s 76ms/step - loss: 1.1617 - categorical_accuracy: 0.4619 - val_loss: 1.2118 - val_categorical_accuracy: 0.4476\n",
            "Epoch 57/200\n",
            "258/258 [==============================] - 20s 76ms/step - loss: 1.1202 - categorical_accuracy: 0.4822 - val_loss: 1.1512 - val_categorical_accuracy: 0.4782\n",
            "Epoch 58/200\n",
            "258/258 [==============================] - 20s 77ms/step - loss: 1.1288 - categorical_accuracy: 0.4929 - val_loss: 1.2133 - val_categorical_accuracy: 0.4389\n",
            "Epoch 59/200\n",
            "258/258 [==============================] - 20s 77ms/step - loss: 1.1564 - categorical_accuracy: 0.4679 - val_loss: 1.2008 - val_categorical_accuracy: 0.4738\n",
            "Epoch 60/200\n",
            "258/258 [==============================] - 20s 77ms/step - loss: 1.1144 - categorical_accuracy: 0.4876 - val_loss: 1.1679 - val_categorical_accuracy: 0.4716\n",
            "Epoch 61/200\n",
            "258/258 [==============================] - 20s 77ms/step - loss: 1.1412 - categorical_accuracy: 0.4748 - val_loss: 1.3375 - val_categorical_accuracy: 0.4367\n",
            "Epoch 62/200\n",
            "258/258 [==============================] - 20s 77ms/step - loss: 1.1498 - categorical_accuracy: 0.4765 - val_loss: 1.2451 - val_categorical_accuracy: 0.4301\n",
            "Epoch 63/200\n",
            "258/258 [==============================] - 20s 77ms/step - loss: 1.1272 - categorical_accuracy: 0.4878 - val_loss: 1.1565 - val_categorical_accuracy: 0.4913\n",
            "Epoch 64/200\n",
            "258/258 [==============================] - 20s 77ms/step - loss: 1.1249 - categorical_accuracy: 0.4905 - val_loss: 1.1622 - val_categorical_accuracy: 0.5044\n",
            "Epoch 65/200\n",
            "258/258 [==============================] - 20s 77ms/step - loss: 1.1418 - categorical_accuracy: 0.4898 - val_loss: 1.1690 - val_categorical_accuracy: 0.4629\n",
            "Epoch 66/200\n",
            "258/258 [==============================] - 20s 77ms/step - loss: 1.1487 - categorical_accuracy: 0.4744 - val_loss: 1.1597 - val_categorical_accuracy: 0.4956\n",
            "Epoch 67/200\n",
            "258/258 [==============================] - 20s 77ms/step - loss: 1.1377 - categorical_accuracy: 0.4856 - val_loss: 1.2313 - val_categorical_accuracy: 0.4258\n",
            "Epoch 68/200\n",
            "258/258 [==============================] - 20s 77ms/step - loss: 1.1085 - categorical_accuracy: 0.4952 - val_loss: 1.2868 - val_categorical_accuracy: 0.4279\n",
            "Epoch 69/200\n",
            "258/258 [==============================] - 20s 77ms/step - loss: 1.1266 - categorical_accuracy: 0.4862 - val_loss: 1.1830 - val_categorical_accuracy: 0.4520\n",
            "Epoch 70/200\n",
            "258/258 [==============================] - 20s 77ms/step - loss: 1.1409 - categorical_accuracy: 0.4928 - val_loss: 1.1650 - val_categorical_accuracy: 0.4956\n",
            "Epoch 71/200\n",
            "258/258 [==============================] - 20s 77ms/step - loss: 1.1445 - categorical_accuracy: 0.4804 - val_loss: 1.2511 - val_categorical_accuracy: 0.4694\n",
            "Epoch 72/200\n",
            "258/258 [==============================] - 20s 77ms/step - loss: 1.1203 - categorical_accuracy: 0.4909 - val_loss: 1.2231 - val_categorical_accuracy: 0.4476\n",
            "Epoch 73/200\n",
            "258/258 [==============================] - 20s 77ms/step - loss: 1.1229 - categorical_accuracy: 0.4751 - val_loss: 1.2129 - val_categorical_accuracy: 0.4782\n",
            "Epoch 74/200\n",
            "258/258 [==============================] - 20s 77ms/step - loss: 1.1227 - categorical_accuracy: 0.4761 - val_loss: 1.2885 - val_categorical_accuracy: 0.4454\n",
            "Epoch 75/200\n",
            "258/258 [==============================] - 20s 77ms/step - loss: 1.1625 - categorical_accuracy: 0.4795 - val_loss: 1.2301 - val_categorical_accuracy: 0.4607\n",
            "Epoch 76/200\n",
            "258/258 [==============================] - 20s 77ms/step - loss: 1.1405 - categorical_accuracy: 0.4858 - val_loss: 1.1663 - val_categorical_accuracy: 0.4651\n",
            "Epoch 77/200\n",
            "258/258 [==============================] - 20s 77ms/step - loss: 1.1358 - categorical_accuracy: 0.4917 - val_loss: 1.2474 - val_categorical_accuracy: 0.4148\n",
            "Epoch 78/200\n",
            "258/258 [==============================] - 20s 77ms/step - loss: 1.1112 - categorical_accuracy: 0.4922 - val_loss: 1.4250 - val_categorical_accuracy: 0.3908\n",
            "Epoch 79/200\n",
            "258/258 [==============================] - 20s 77ms/step - loss: 1.1098 - categorical_accuracy: 0.4997 - val_loss: 1.2407 - val_categorical_accuracy: 0.4651\n",
            "Epoch 80/200\n",
            "258/258 [==============================] - 20s 77ms/step - loss: 1.1340 - categorical_accuracy: 0.4869 - val_loss: 1.2193 - val_categorical_accuracy: 0.4476\n",
            "Epoch 81/200\n",
            "258/258 [==============================] - 20s 77ms/step - loss: 1.1435 - categorical_accuracy: 0.4971 - val_loss: 1.3195 - val_categorical_accuracy: 0.4148\n",
            "Epoch 82/200\n",
            "258/258 [==============================] - 20s 77ms/step - loss: 1.1287 - categorical_accuracy: 0.4900 - val_loss: 1.2236 - val_categorical_accuracy: 0.4258\n",
            "Epoch 83/200\n",
            "258/258 [==============================] - 20s 77ms/step - loss: 1.1074 - categorical_accuracy: 0.4791 - val_loss: 1.1822 - val_categorical_accuracy: 0.4520\n",
            "Epoch 84/200\n",
            "258/258 [==============================] - 20s 77ms/step - loss: 1.1281 - categorical_accuracy: 0.4935 - val_loss: 1.1505 - val_categorical_accuracy: 0.4913\n",
            "Epoch 85/200\n",
            "258/258 [==============================] - 20s 77ms/step - loss: 1.1431 - categorical_accuracy: 0.4685 - val_loss: 1.3323 - val_categorical_accuracy: 0.4345\n",
            "Epoch 86/200\n",
            "258/258 [==============================] - 20s 77ms/step - loss: 1.1334 - categorical_accuracy: 0.4992 - val_loss: 1.2624 - val_categorical_accuracy: 0.4454\n",
            "Epoch 87/200\n",
            "258/258 [==============================] - 20s 77ms/step - loss: 1.1077 - categorical_accuracy: 0.5072 - val_loss: 1.2303 - val_categorical_accuracy: 0.4520\n",
            "Epoch 88/200\n",
            "258/258 [==============================] - 20s 77ms/step - loss: 1.1216 - categorical_accuracy: 0.4899 - val_loss: 1.2204 - val_categorical_accuracy: 0.4410\n",
            "Epoch 89/200\n",
            "258/258 [==============================] - 20s 77ms/step - loss: 1.1398 - categorical_accuracy: 0.4690 - val_loss: 1.1582 - val_categorical_accuracy: 0.4651\n",
            "Epoch 90/200\n",
            "258/258 [==============================] - 20s 77ms/step - loss: 1.1379 - categorical_accuracy: 0.4904 - val_loss: 1.2187 - val_categorical_accuracy: 0.4389\n",
            "Epoch 91/200\n",
            "258/258 [==============================] - 20s 76ms/step - loss: 1.1207 - categorical_accuracy: 0.4858 - val_loss: 1.1890 - val_categorical_accuracy: 0.4760\n",
            "Epoch 92/200\n",
            "258/258 [==============================] - 20s 76ms/step - loss: 1.1113 - categorical_accuracy: 0.4886 - val_loss: 1.3860 - val_categorical_accuracy: 0.4061\n",
            "Epoch 93/200\n",
            "258/258 [==============================] - 20s 77ms/step - loss: 1.1340 - categorical_accuracy: 0.4778 - val_loss: 1.3209 - val_categorical_accuracy: 0.4585\n",
            "Epoch 94/200\n",
            "258/258 [==============================] - 20s 77ms/step - loss: 1.1175 - categorical_accuracy: 0.5046 - val_loss: 1.1979 - val_categorical_accuracy: 0.4651\n",
            "Epoch 95/200\n",
            "258/258 [==============================] - 20s 76ms/step - loss: 1.1103 - categorical_accuracy: 0.4944 - val_loss: 1.1663 - val_categorical_accuracy: 0.4520\n",
            "Epoch 96/200\n",
            "258/258 [==============================] - 20s 79ms/step - loss: 1.1121 - categorical_accuracy: 0.4918 - val_loss: 1.1943 - val_categorical_accuracy: 0.4607\n",
            "Epoch 97/200\n",
            "258/258 [==============================] - 20s 77ms/step - loss: 1.1080 - categorical_accuracy: 0.4892 - val_loss: 1.1957 - val_categorical_accuracy: 0.4716\n",
            "Epoch 98/200\n",
            "258/258 [==============================] - 20s 77ms/step - loss: 1.0989 - categorical_accuracy: 0.4947 - val_loss: 1.1883 - val_categorical_accuracy: 0.4432\n",
            "Epoch 99/200\n",
            "258/258 [==============================] - 20s 77ms/step - loss: 1.1221 - categorical_accuracy: 0.4877 - val_loss: 1.2589 - val_categorical_accuracy: 0.3384\n",
            "Epoch 100/200\n",
            "258/258 [==============================] - 20s 77ms/step - loss: 1.1726 - categorical_accuracy: 0.4637 - val_loss: 1.1377 - val_categorical_accuracy: 0.4803\n",
            "Epoch 101/200\n",
            "258/258 [==============================] - 20s 77ms/step - loss: 1.0995 - categorical_accuracy: 0.5097 - val_loss: 1.2530 - val_categorical_accuracy: 0.4520\n",
            "Epoch 102/200\n",
            "258/258 [==============================] - 20s 77ms/step - loss: 1.1135 - categorical_accuracy: 0.4861 - val_loss: 1.1922 - val_categorical_accuracy: 0.4585\n",
            "Epoch 103/200\n",
            "258/258 [==============================] - 20s 77ms/step - loss: 1.1168 - categorical_accuracy: 0.4954 - val_loss: 1.3999 - val_categorical_accuracy: 0.4389\n",
            "Epoch 104/200\n",
            "258/258 [==============================] - 20s 77ms/step - loss: 1.1052 - categorical_accuracy: 0.5027 - val_loss: 1.1527 - val_categorical_accuracy: 0.4694\n",
            "Epoch 105/200\n",
            "258/258 [==============================] - 20s 77ms/step - loss: 1.0863 - categorical_accuracy: 0.5133 - val_loss: 1.2671 - val_categorical_accuracy: 0.4410\n",
            "Epoch 106/200\n",
            "258/258 [==============================] - 20s 77ms/step - loss: 1.1395 - categorical_accuracy: 0.4891 - val_loss: 1.3432 - val_categorical_accuracy: 0.4192\n",
            "Epoch 107/200\n",
            "258/258 [==============================] - 20s 77ms/step - loss: 1.1215 - categorical_accuracy: 0.4920 - val_loss: 1.2254 - val_categorical_accuracy: 0.4279\n",
            "Epoch 108/200\n",
            "258/258 [==============================] - 20s 77ms/step - loss: 1.1038 - categorical_accuracy: 0.4875 - val_loss: 1.1422 - val_categorical_accuracy: 0.4738\n",
            "Epoch 109/200\n",
            "258/258 [==============================] - 20s 77ms/step - loss: 1.1070 - categorical_accuracy: 0.4959 - val_loss: 1.2492 - val_categorical_accuracy: 0.3100\n",
            "Epoch 110/200\n",
            "258/258 [==============================] - 20s 77ms/step - loss: 1.1007 - categorical_accuracy: 0.5018 - val_loss: 1.1629 - val_categorical_accuracy: 0.4738\n",
            "Epoch 111/200\n",
            "258/258 [==============================] - 20s 77ms/step - loss: 1.1154 - categorical_accuracy: 0.4941 - val_loss: 1.1801 - val_categorical_accuracy: 0.4694\n",
            "Epoch 112/200\n",
            "258/258 [==============================] - 20s 77ms/step - loss: 1.1200 - categorical_accuracy: 0.4896 - val_loss: 1.2307 - val_categorical_accuracy: 0.4432\n",
            "Epoch 113/200\n",
            "258/258 [==============================] - 20s 77ms/step - loss: 1.0992 - categorical_accuracy: 0.5050 - val_loss: 1.1545 - val_categorical_accuracy: 0.4869\n",
            "Epoch 114/200\n",
            "258/258 [==============================] - 20s 77ms/step - loss: 1.1512 - categorical_accuracy: 0.4601 - val_loss: 1.1295 - val_categorical_accuracy: 0.5000\n",
            "Epoch 115/200\n",
            "258/258 [==============================] - 20s 77ms/step - loss: 1.0982 - categorical_accuracy: 0.4961 - val_loss: 1.3615 - val_categorical_accuracy: 0.4410\n",
            "Epoch 116/200\n",
            "258/258 [==============================] - 20s 77ms/step - loss: 1.1187 - categorical_accuracy: 0.4808 - val_loss: 1.2101 - val_categorical_accuracy: 0.4585\n",
            "Epoch 117/200\n",
            "258/258 [==============================] - 20s 77ms/step - loss: 1.1134 - categorical_accuracy: 0.4989 - val_loss: 1.1761 - val_categorical_accuracy: 0.4389\n",
            "Epoch 118/200\n",
            "258/258 [==============================] - 20s 77ms/step - loss: 1.1103 - categorical_accuracy: 0.4865 - val_loss: 1.2143 - val_categorical_accuracy: 0.4716\n",
            "Epoch 119/200\n",
            "258/258 [==============================] - 20s 77ms/step - loss: 1.0930 - categorical_accuracy: 0.4891 - val_loss: 1.1663 - val_categorical_accuracy: 0.4716\n",
            "Epoch 120/200\n",
            "258/258 [==============================] - 20s 77ms/step - loss: 1.0856 - categorical_accuracy: 0.5178 - val_loss: 1.2067 - val_categorical_accuracy: 0.4694\n",
            "Epoch 121/200\n",
            "258/258 [==============================] - 21s 80ms/step - loss: 1.0879 - categorical_accuracy: 0.5006 - val_loss: 1.1687 - val_categorical_accuracy: 0.4563\n",
            "Epoch 122/200\n",
            "258/258 [==============================] - 20s 77ms/step - loss: 1.0905 - categorical_accuracy: 0.4928 - val_loss: 1.1562 - val_categorical_accuracy: 0.4694\n",
            "Epoch 123/200\n",
            "258/258 [==============================] - 20s 77ms/step - loss: 1.1036 - categorical_accuracy: 0.4900 - val_loss: 1.1535 - val_categorical_accuracy: 0.4891\n",
            "Epoch 124/200\n",
            "258/258 [==============================] - 20s 77ms/step - loss: 1.1080 - categorical_accuracy: 0.4897 - val_loss: 1.2590 - val_categorical_accuracy: 0.4301\n",
            "Epoch 125/200\n",
            "258/258 [==============================] - 20s 77ms/step - loss: 1.1092 - categorical_accuracy: 0.5048 - val_loss: 1.2074 - val_categorical_accuracy: 0.4476\n",
            "Epoch 126/200\n",
            "258/258 [==============================] - 20s 77ms/step - loss: 1.1019 - categorical_accuracy: 0.4985 - val_loss: 1.2050 - val_categorical_accuracy: 0.4454\n",
            "Epoch 127/200\n",
            "258/258 [==============================] - 20s 77ms/step - loss: 1.0951 - categorical_accuracy: 0.4847 - val_loss: 1.2482 - val_categorical_accuracy: 0.4476\n",
            "Epoch 128/200\n",
            "258/258 [==============================] - 20s 77ms/step - loss: 1.0945 - categorical_accuracy: 0.4900 - val_loss: 1.1863 - val_categorical_accuracy: 0.4629\n",
            "Epoch 129/200\n",
            "258/258 [==============================] - 20s 77ms/step - loss: 1.0916 - categorical_accuracy: 0.4957 - val_loss: 1.2953 - val_categorical_accuracy: 0.4694\n",
            "Epoch 130/200\n",
            "258/258 [==============================] - 20s 77ms/step - loss: 1.1319 - categorical_accuracy: 0.4720 - val_loss: 1.2278 - val_categorical_accuracy: 0.4847\n",
            "Epoch 131/200\n",
            "258/258 [==============================] - 20s 77ms/step - loss: 1.1182 - categorical_accuracy: 0.4799 - val_loss: 1.1590 - val_categorical_accuracy: 0.4738\n",
            "Epoch 132/200\n",
            "258/258 [==============================] - 20s 77ms/step - loss: 1.1026 - categorical_accuracy: 0.4851 - val_loss: 1.1869 - val_categorical_accuracy: 0.4825\n",
            "Epoch 133/200\n",
            "258/258 [==============================] - 20s 77ms/step - loss: 1.1062 - categorical_accuracy: 0.4849 - val_loss: 1.2085 - val_categorical_accuracy: 0.4651\n",
            "Epoch 134/200\n",
            "258/258 [==============================] - 20s 77ms/step - loss: 1.0772 - categorical_accuracy: 0.5015 - val_loss: 1.2722 - val_categorical_accuracy: 0.4214\n",
            "Epoch 135/200\n",
            "258/258 [==============================] - 20s 77ms/step - loss: 1.0737 - categorical_accuracy: 0.5087 - val_loss: 1.2581 - val_categorical_accuracy: 0.4432\n",
            "Epoch 136/200\n",
            "258/258 [==============================] - 20s 78ms/step - loss: 1.1102 - categorical_accuracy: 0.4787 - val_loss: 1.1605 - val_categorical_accuracy: 0.4651\n",
            "Epoch 137/200\n",
            "258/258 [==============================] - 20s 77ms/step - loss: 1.1024 - categorical_accuracy: 0.4971 - val_loss: 1.2544 - val_categorical_accuracy: 0.4498\n",
            "Epoch 138/200\n",
            "258/258 [==============================] - 20s 77ms/step - loss: 1.0829 - categorical_accuracy: 0.5031 - val_loss: 1.1833 - val_categorical_accuracy: 0.4585\n",
            "Epoch 139/200\n",
            "258/258 [==============================] - 20s 77ms/step - loss: 1.0746 - categorical_accuracy: 0.4961 - val_loss: 1.1632 - val_categorical_accuracy: 0.4651\n",
            "Epoch 140/200\n",
            "258/258 [==============================] - 20s 78ms/step - loss: 1.0678 - categorical_accuracy: 0.5160 - val_loss: 1.1764 - val_categorical_accuracy: 0.4869\n",
            "Epoch 141/200\n",
            "258/258 [==============================] - 20s 77ms/step - loss: 1.0920 - categorical_accuracy: 0.4926 - val_loss: 1.2347 - val_categorical_accuracy: 0.4541\n",
            "Epoch 142/200\n",
            "258/258 [==============================] - 20s 77ms/step - loss: 1.0541 - categorical_accuracy: 0.5308 - val_loss: 1.1283 - val_categorical_accuracy: 0.4716\n",
            "Epoch 143/200\n",
            "258/258 [==============================] - 20s 77ms/step - loss: 1.0802 - categorical_accuracy: 0.5062 - val_loss: 1.1498 - val_categorical_accuracy: 0.4716\n",
            "Epoch 144/200\n",
            "258/258 [==============================] - 20s 77ms/step - loss: 1.0798 - categorical_accuracy: 0.5104 - val_loss: 1.1915 - val_categorical_accuracy: 0.4803\n",
            "Epoch 145/200\n",
            "258/258 [==============================] - 20s 77ms/step - loss: 1.0713 - categorical_accuracy: 0.5151 - val_loss: 1.2002 - val_categorical_accuracy: 0.4651\n",
            "Epoch 146/200\n",
            "258/258 [==============================] - 20s 77ms/step - loss: 1.0752 - categorical_accuracy: 0.5251 - val_loss: 1.3060 - val_categorical_accuracy: 0.4214\n",
            "Epoch 147/200\n",
            "258/258 [==============================] - 20s 77ms/step - loss: 1.0795 - categorical_accuracy: 0.5127 - val_loss: 1.1546 - val_categorical_accuracy: 0.4629\n",
            "Epoch 148/200\n",
            "258/258 [==============================] - 20s 77ms/step - loss: 1.0959 - categorical_accuracy: 0.5013 - val_loss: 1.1758 - val_categorical_accuracy: 0.4716\n",
            "Epoch 149/200\n",
            "258/258 [==============================] - 20s 77ms/step - loss: 1.0818 - categorical_accuracy: 0.5116 - val_loss: 1.2575 - val_categorical_accuracy: 0.4323\n",
            "Epoch 150/200\n",
            "258/258 [==============================] - 20s 77ms/step - loss: 1.0882 - categorical_accuracy: 0.5132 - val_loss: 1.1792 - val_categorical_accuracy: 0.4607\n",
            "Epoch 151/200\n",
            "258/258 [==============================] - 20s 77ms/step - loss: 1.1108 - categorical_accuracy: 0.4799 - val_loss: 1.1841 - val_categorical_accuracy: 0.4607\n",
            "Epoch 152/200\n",
            "258/258 [==============================] - 20s 77ms/step - loss: 1.1040 - categorical_accuracy: 0.4938 - val_loss: 1.2057 - val_categorical_accuracy: 0.4672\n",
            "Epoch 153/200\n",
            "258/258 [==============================] - 20s 78ms/step - loss: 1.0930 - categorical_accuracy: 0.5023 - val_loss: 1.2040 - val_categorical_accuracy: 0.4105\n",
            "Epoch 154/200\n",
            "258/258 [==============================] - 20s 78ms/step - loss: 1.0775 - categorical_accuracy: 0.5141 - val_loss: 1.2604 - val_categorical_accuracy: 0.4258\n",
            "Epoch 155/200\n",
            "258/258 [==============================] - 20s 78ms/step - loss: 1.0931 - categorical_accuracy: 0.5068 - val_loss: 1.1679 - val_categorical_accuracy: 0.4498\n",
            "Epoch 156/200\n",
            "258/258 [==============================] - 20s 77ms/step - loss: 1.0617 - categorical_accuracy: 0.5173 - val_loss: 1.3030 - val_categorical_accuracy: 0.4476\n",
            "Epoch 157/200\n",
            "258/258 [==============================] - 20s 78ms/step - loss: 1.1068 - categorical_accuracy: 0.5036 - val_loss: 1.2235 - val_categorical_accuracy: 0.3384\n",
            "Epoch 158/200\n",
            "258/258 [==============================] - 20s 78ms/step - loss: 1.0907 - categorical_accuracy: 0.4994 - val_loss: 1.1382 - val_categorical_accuracy: 0.4847\n",
            "Epoch 159/200\n",
            "258/258 [==============================] - 20s 77ms/step - loss: 1.0984 - categorical_accuracy: 0.4789 - val_loss: 1.1520 - val_categorical_accuracy: 0.4607\n",
            "Epoch 160/200\n",
            "258/258 [==============================] - 20s 77ms/step - loss: 1.0998 - categorical_accuracy: 0.5188 - val_loss: 1.2413 - val_categorical_accuracy: 0.4541\n",
            "Epoch 161/200\n",
            "258/258 [==============================] - 20s 77ms/step - loss: 1.1041 - categorical_accuracy: 0.4989 - val_loss: 1.1689 - val_categorical_accuracy: 0.4651\n",
            "Epoch 162/200\n",
            "258/258 [==============================] - 20s 77ms/step - loss: 1.1010 - categorical_accuracy: 0.4838 - val_loss: 1.1810 - val_categorical_accuracy: 0.4563\n",
            "Epoch 163/200\n",
            "258/258 [==============================] - 20s 77ms/step - loss: 1.0447 - categorical_accuracy: 0.5208 - val_loss: 1.1448 - val_categorical_accuracy: 0.4738\n",
            "Epoch 164/200\n",
            "258/258 [==============================] - 20s 77ms/step - loss: 1.0859 - categorical_accuracy: 0.5043 - val_loss: 1.1248 - val_categorical_accuracy: 0.4782\n",
            "Epoch 165/200\n",
            "258/258 [==============================] - 20s 77ms/step - loss: 1.0844 - categorical_accuracy: 0.5046 - val_loss: 1.2564 - val_categorical_accuracy: 0.4476\n",
            "Epoch 166/200\n",
            "258/258 [==============================] - 20s 77ms/step - loss: 1.0819 - categorical_accuracy: 0.4970 - val_loss: 1.1836 - val_categorical_accuracy: 0.4607\n",
            "Epoch 167/200\n",
            "258/258 [==============================] - 20s 77ms/step - loss: 1.0933 - categorical_accuracy: 0.5089 - val_loss: 1.1491 - val_categorical_accuracy: 0.4956\n",
            "Epoch 168/200\n",
            "258/258 [==============================] - 20s 77ms/step - loss: 1.0763 - categorical_accuracy: 0.4939 - val_loss: 1.1464 - val_categorical_accuracy: 0.4847\n",
            "Epoch 169/200\n",
            "258/258 [==============================] - 20s 78ms/step - loss: 1.0880 - categorical_accuracy: 0.4960 - val_loss: 1.2060 - val_categorical_accuracy: 0.4629\n",
            "Epoch 170/200\n",
            "258/258 [==============================] - 20s 77ms/step - loss: 1.0537 - categorical_accuracy: 0.5104 - val_loss: 1.1312 - val_categorical_accuracy: 0.4934\n",
            "Epoch 171/200\n",
            "258/258 [==============================] - 20s 77ms/step - loss: 1.0939 - categorical_accuracy: 0.4863 - val_loss: 1.2051 - val_categorical_accuracy: 0.4389\n",
            "Epoch 172/200\n",
            "258/258 [==============================] - 20s 77ms/step - loss: 1.0840 - categorical_accuracy: 0.5138 - val_loss: 1.2578 - val_categorical_accuracy: 0.4629\n",
            "Epoch 173/200\n",
            "258/258 [==============================] - 20s 78ms/step - loss: 1.0935 - categorical_accuracy: 0.4973 - val_loss: 1.1870 - val_categorical_accuracy: 0.4454\n",
            "Epoch 174/200\n",
            "258/258 [==============================] - 20s 77ms/step - loss: 1.0655 - categorical_accuracy: 0.5122 - val_loss: 1.1316 - val_categorical_accuracy: 0.4869\n",
            "Epoch 175/200\n",
            "258/258 [==============================] - 20s 78ms/step - loss: 1.0720 - categorical_accuracy: 0.5184 - val_loss: 1.2069 - val_categorical_accuracy: 0.4192\n",
            "Epoch 176/200\n",
            "258/258 [==============================] - 20s 77ms/step - loss: 1.0489 - categorical_accuracy: 0.5205 - val_loss: 1.1405 - val_categorical_accuracy: 0.5044\n",
            "Epoch 177/200\n",
            "258/258 [==============================] - 20s 78ms/step - loss: 1.0794 - categorical_accuracy: 0.5121 - val_loss: 1.1621 - val_categorical_accuracy: 0.4541\n",
            "Epoch 178/200\n",
            "258/258 [==============================] - 20s 78ms/step - loss: 1.0689 - categorical_accuracy: 0.5190 - val_loss: 1.1457 - val_categorical_accuracy: 0.4847\n",
            "Epoch 179/200\n",
            "258/258 [==============================] - 20s 78ms/step - loss: 1.0745 - categorical_accuracy: 0.5126 - val_loss: 1.2044 - val_categorical_accuracy: 0.4389\n",
            "Epoch 180/200\n",
            "258/258 [==============================] - 20s 78ms/step - loss: 1.0962 - categorical_accuracy: 0.4956 - val_loss: 1.1655 - val_categorical_accuracy: 0.4694\n",
            "Epoch 181/200\n",
            "258/258 [==============================] - 20s 78ms/step - loss: 1.0650 - categorical_accuracy: 0.4934 - val_loss: 1.2172 - val_categorical_accuracy: 0.4651\n",
            "Epoch 182/200\n",
            "258/258 [==============================] - 20s 78ms/step - loss: 1.0694 - categorical_accuracy: 0.5031 - val_loss: 1.2025 - val_categorical_accuracy: 0.4738\n",
            "Epoch 183/200\n",
            "258/258 [==============================] - 20s 77ms/step - loss: 1.0551 - categorical_accuracy: 0.5160 - val_loss: 1.2135 - val_categorical_accuracy: 0.4520\n",
            "Epoch 184/200\n",
            "258/258 [==============================] - 20s 78ms/step - loss: 1.0973 - categorical_accuracy: 0.5096 - val_loss: 1.1582 - val_categorical_accuracy: 0.4629\n",
            "Epoch 185/200\n",
            "258/258 [==============================] - 20s 78ms/step - loss: 1.0717 - categorical_accuracy: 0.5095 - val_loss: 1.1567 - val_categorical_accuracy: 0.4672\n",
            "Epoch 186/200\n",
            "258/258 [==============================] - 20s 78ms/step - loss: 1.0752 - categorical_accuracy: 0.5023 - val_loss: 1.1584 - val_categorical_accuracy: 0.4760\n",
            "Epoch 187/200\n",
            "258/258 [==============================] - 20s 78ms/step - loss: 1.0811 - categorical_accuracy: 0.5091 - val_loss: 1.2105 - val_categorical_accuracy: 0.4651\n",
            "Epoch 188/200\n",
            "258/258 [==============================] - 20s 78ms/step - loss: 1.0826 - categorical_accuracy: 0.5085 - val_loss: 1.1371 - val_categorical_accuracy: 0.4782\n",
            "Epoch 189/200\n",
            "258/258 [==============================] - 20s 78ms/step - loss: 1.0435 - categorical_accuracy: 0.5220 - val_loss: 1.2229 - val_categorical_accuracy: 0.4389\n",
            "Epoch 190/200\n",
            "258/258 [==============================] - 20s 78ms/step - loss: 1.0463 - categorical_accuracy: 0.5188 - val_loss: 1.1340 - val_categorical_accuracy: 0.4803\n",
            "Epoch 191/200\n",
            "258/258 [==============================] - 20s 78ms/step - loss: 1.0978 - categorical_accuracy: 0.4841 - val_loss: 1.2078 - val_categorical_accuracy: 0.4563\n",
            "Epoch 192/200\n",
            "258/258 [==============================] - 20s 78ms/step - loss: 1.0961 - categorical_accuracy: 0.4907 - val_loss: 1.2224 - val_categorical_accuracy: 0.4563\n",
            "Epoch 193/200\n",
            "258/258 [==============================] - 20s 78ms/step - loss: 1.0976 - categorical_accuracy: 0.4929 - val_loss: 1.3060 - val_categorical_accuracy: 0.4454\n",
            "Epoch 194/200\n",
            "258/258 [==============================] - 20s 78ms/step - loss: 1.0857 - categorical_accuracy: 0.5059 - val_loss: 1.1426 - val_categorical_accuracy: 0.4869\n",
            "Epoch 195/200\n",
            "258/258 [==============================] - 20s 77ms/step - loss: 1.0854 - categorical_accuracy: 0.5179 - val_loss: 1.1386 - val_categorical_accuracy: 0.4694\n",
            "Epoch 196/200\n",
            "258/258 [==============================] - 20s 77ms/step - loss: 1.0973 - categorical_accuracy: 0.4989 - val_loss: 1.1981 - val_categorical_accuracy: 0.4410\n",
            "Epoch 197/200\n",
            "258/258 [==============================] - 20s 78ms/step - loss: 1.0926 - categorical_accuracy: 0.4967 - val_loss: 1.1950 - val_categorical_accuracy: 0.4629\n",
            "Epoch 198/200\n",
            "258/258 [==============================] - 20s 78ms/step - loss: 1.0662 - categorical_accuracy: 0.5136 - val_loss: 1.1461 - val_categorical_accuracy: 0.4869\n",
            "Epoch 199/200\n",
            "258/258 [==============================] - 20s 78ms/step - loss: 1.0628 - categorical_accuracy: 0.5082 - val_loss: 1.1704 - val_categorical_accuracy: 0.4694\n",
            "Epoch 200/200\n",
            "258/258 [==============================] - 20s 78ms/step - loss: 1.0560 - categorical_accuracy: 0.4995 - val_loss: 1.2470 - val_categorical_accuracy: 0.4454\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBXg3gsrQei2"
      },
      "source": [
        "model.save('/content/drive/MyDrive/Colab Notebooks/SPEECH_EMOTION_Recognition/Nộp bài(chốt hạ)/model_saver/conv1D_melspec_cremad.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SyfTyHY2mRsz"
      },
      "source": [
        "###test_result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aC1K1ol-mRs1",
        "outputId": "ad15113e-8660-43e7-e9bf-666bd5a5d413"
      },
      "source": [
        "d = {0: 'happy',\n",
        "     1: 'sad',\n",
        "     2: 'angry',\n",
        "     3: 'fear'}\n",
        "Y_test_pred = np.argmax(model.predict(X_test), axis=-1)\n",
        "Y_test_pred = list(map(lambda x: d[x], Y_test_pred))\n",
        "y_test = np.argmax(y_test, axis=-1)\n",
        "y_test = list(map(lambda x: d[x], y_test))\n",
        "print(classification_report(y_test, Y_test_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.63      0.34      0.44       136\n",
            "        fear       0.43      0.02      0.04       134\n",
            "       happy       0.38      0.53      0.44       120\n",
            "         sad       0.42      0.94      0.58       119\n",
            "\n",
            "    accuracy                           0.44       509\n",
            "   macro avg       0.47      0.46      0.38       509\n",
            "weighted avg       0.47      0.44      0.37       509\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "svW2gQfTmRs2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "outputId": "c3cfac5f-43bb-4f4f-a5c5-ce0b996e95af"
      },
      "source": [
        "import scikitplot as skplt\n",
        "\n",
        "skplt.metrics.plot_confusion_matrix(\n",
        "    y_test, \n",
        "    Y_test_pred,\n",
        "    figsize=(8,8))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fa47df9e650>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vOFxBO2mRs3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vQHiqzXuW3ay"
      },
      "source": [
        "# Mel Spectrogram + conv2D:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AbvUHwMIW3bV"
      },
      "source": [
        "audio_duration = 3\n",
        "sampling_rate = 44100\n",
        "input_length = sampling_rate * audio_duration\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTz4bJz0XfIR"
      },
      "source": [
        "data = {'labels': [],\n",
        "        'features': []}\n",
        "\n",
        "for i in range(len(CREMA_D_df)):\n",
        "  if ((CREMA_D_df['Emotion'][i] == 'HAP') | (CREMA_D_df['Emotion'][i] == 'SAD') | \n",
        "      (CREMA_D_df['Emotion'][i] == 'ANG') | (CREMA_D_df['Emotion'][i] == 'FEA')):\n",
        "    \n",
        "    if CREMA_D_df['Emotion'][i] == 'HAP':\n",
        "      data['labels'].append(0)\n",
        "    elif CREMA_D_df['Emotion'][i] == 'SAD':\n",
        "      data['labels'].append(1)\n",
        "    elif CREMA_D_df['Emotion'][i] == 'ANG':\n",
        "      data['labels'].append(2)\n",
        "    elif CREMA_D_df['Emotion'][i] == 'FEA':\n",
        "      data['labels'].append(3)\n",
        "\n",
        "\n",
        "    signal, sr =  librosa.load(CREMA_D_df['Paths'][i])\n",
        "\n",
        "    if len(signal) > input_length:\n",
        "      signal = signal[0:input_length]\n",
        "    elif  input_length > len(signal):\n",
        "      max_offset = input_length - len(signal)  \n",
        "      signal = np.pad(signal, (0, max_offset), \"constant\")\n",
        "\n",
        "    melspec = librosa.feature.melspectrogram(signal, sr=sampling_rate, n_mels=128,n_fft=2048,hop_length=512)   \n",
        "    melspec = np.expand_dims(melspec, axis=-1)\n",
        "\n",
        "    data['features'].append(melspec)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fzmHePCaZiM"
      },
      "source": [
        "X = data['features']\n",
        "y = data['labels']\n",
        "\n",
        "y = np.array(y)\n",
        "y = to_categorical(y)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=0)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=0)\n",
        "\n",
        "X_train = np.array(X_train)\n",
        "X_test = np.array(X_test)\n",
        "X_val = np.array(X_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lsI1T1_wW3bX",
        "outputId": "5a58ea6c-bf96-471b-e85b-d5d9d39636f5"
      },
      "source": [
        "X_train.shape,X_test.shape,y_train.shape,y_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((4117, 128, 259, 1), (509, 128, 259, 1), (4117, 4), (509, 4))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LzVUl83kaRQt"
      },
      "source": [
        "### conv2D"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KvxTuJHKW3bY"
      },
      "source": [
        "# CNN I/P Config\n",
        "num_classes = 4\n",
        "input_shape = X_train.shape[1:]\n",
        "learning_rate = 0.0001\n",
        "decay = 1e-6\n",
        "momentum = 0.9"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LAcvZf5UW3bY",
        "outputId": "2ff5ef48-1ae9-4c04-d9f2-bf7a4b62d194"
      },
      "source": [
        "model = Sequential(name='Audio_CNN_2D')\n",
        "\n",
        "# LFLB1\n",
        "model.add(Conv2D(filters=64, kernel_size=(3,3), strides=(1,1), padding='same',input_shape=input_shape))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Conv2D(filters=64, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(4,4), strides=(4,4)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(units=num_classes, activation='softmax'))\n",
        "\n",
        "# Model compilation\n",
        "opt = optimizers.SGD(lr=learning_rate, decay=decay, momentum=momentum, nesterov=True)\n",
        "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"Audio_CNN_2D\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_6 (Conv2D)            (None, 128, 259, 64)      640       \n",
            "_________________________________________________________________\n",
            "batch_normalization_18 (Batc (None, 128, 259, 64)      256       \n",
            "_________________________________________________________________\n",
            "activation_18 (Activation)   (None, 128, 259, 64)      0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 64, 129, 64)       0         \n",
            "_________________________________________________________________\n",
            "dropout_18 (Dropout)         (None, 64, 129, 64)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 64, 129, 64)       36928     \n",
            "_________________________________________________________________\n",
            "batch_normalization_19 (Batc (None, 64, 129, 64)       256       \n",
            "_________________________________________________________________\n",
            "activation_19 (Activation)   (None, 64, 129, 64)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 16, 32, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_19 (Dropout)         (None, 16, 32, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 32768)             0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 4)                 131076    \n",
            "=================================================================\n",
            "Total params: 169,156\n",
            "Trainable params: 168,900\n",
            "Non-trainable params: 256\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wpkX6KUYW3bb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a38c920-3877-4062-bd51-3326b9e4e560"
      },
      "source": [
        "#Train Config\n",
        "\n",
        "batch_size = 16\n",
        "num_epochs = 200\n",
        "\n",
        "# Model Training\n",
        "lr_reduce = ReduceLROnPlateau(monitor='val_loss', factor=0.9, patience=20, min_lr=0.000001)\n",
        "# Please change the model name accordingly.\n",
        "mcp_save = ModelCheckpoint('/content/Modelfull_2_1.h5', save_best_only=True, monitor='val_categorical_accuracy', mode='max')\n",
        "cnnhistory=model.fit(X_train, y_train, batch_size=batch_size, epochs=num_epochs,validation_data=(X_val, y_val), callbacks=[mcp_save, lr_reduce])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "258/258 [==============================] - 11s 35ms/step - loss: 3.0638 - categorical_accuracy: 0.3682 - val_loss: 1.3190 - val_categorical_accuracy: 0.4061\n",
            "Epoch 2/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 1.4415 - categorical_accuracy: 0.4591 - val_loss: 1.2920 - val_categorical_accuracy: 0.3624\n",
            "Epoch 3/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 1.3072 - categorical_accuracy: 0.4675 - val_loss: 1.3284 - val_categorical_accuracy: 0.3144\n",
            "Epoch 4/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 1.2463 - categorical_accuracy: 0.4544 - val_loss: 1.3349 - val_categorical_accuracy: 0.3144\n",
            "Epoch 5/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 1.2519 - categorical_accuracy: 0.4581 - val_loss: 1.3700 - val_categorical_accuracy: 0.3013\n",
            "Epoch 6/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 1.2097 - categorical_accuracy: 0.4577 - val_loss: 1.3802 - val_categorical_accuracy: 0.2991\n",
            "Epoch 7/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 1.2126 - categorical_accuracy: 0.4626 - val_loss: 1.3507 - val_categorical_accuracy: 0.3144\n",
            "Epoch 8/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 1.2041 - categorical_accuracy: 0.4598 - val_loss: 1.3409 - val_categorical_accuracy: 0.3166\n",
            "Epoch 9/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 1.1852 - categorical_accuracy: 0.4812 - val_loss: 1.3660 - val_categorical_accuracy: 0.2969\n",
            "Epoch 10/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 1.1848 - categorical_accuracy: 0.4795 - val_loss: 1.3488 - val_categorical_accuracy: 0.3144\n",
            "Epoch 11/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 1.1726 - categorical_accuracy: 0.4736 - val_loss: 1.3691 - val_categorical_accuracy: 0.3013\n",
            "Epoch 12/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 1.1568 - categorical_accuracy: 0.4797 - val_loss: 1.3608 - val_categorical_accuracy: 0.2969\n",
            "Epoch 13/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 1.1652 - categorical_accuracy: 0.4713 - val_loss: 1.3641 - val_categorical_accuracy: 0.3079\n",
            "Epoch 14/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 1.1355 - categorical_accuracy: 0.4946 - val_loss: 1.3374 - val_categorical_accuracy: 0.3253\n",
            "Epoch 15/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 1.1494 - categorical_accuracy: 0.4910 - val_loss: 1.3600 - val_categorical_accuracy: 0.3079\n",
            "Epoch 16/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 1.1759 - categorical_accuracy: 0.4847 - val_loss: 1.3419 - val_categorical_accuracy: 0.3144\n",
            "Epoch 17/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 1.1459 - categorical_accuracy: 0.4932 - val_loss: 1.3490 - val_categorical_accuracy: 0.3166\n",
            "Epoch 18/200\n",
            "258/258 [==============================] - 8s 31ms/step - loss: 1.1240 - categorical_accuracy: 0.5058 - val_loss: 1.3334 - val_categorical_accuracy: 0.3144\n",
            "Epoch 19/200\n",
            "258/258 [==============================] - 8s 31ms/step - loss: 1.1370 - categorical_accuracy: 0.4773 - val_loss: 1.3566 - val_categorical_accuracy: 0.3210\n",
            "Epoch 20/200\n",
            "258/258 [==============================] - 8s 31ms/step - loss: 1.1434 - categorical_accuracy: 0.4924 - val_loss: 1.3445 - val_categorical_accuracy: 0.3231\n",
            "Epoch 21/200\n",
            "258/258 [==============================] - 8s 31ms/step - loss: 1.1215 - categorical_accuracy: 0.4993 - val_loss: 1.3407 - val_categorical_accuracy: 0.3253\n",
            "Epoch 22/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 1.1540 - categorical_accuracy: 0.4989 - val_loss: 1.3331 - val_categorical_accuracy: 0.3341\n",
            "Epoch 23/200\n",
            "258/258 [==============================] - 8s 31ms/step - loss: 1.1152 - categorical_accuracy: 0.4972 - val_loss: 1.3435 - val_categorical_accuracy: 0.3297\n",
            "Epoch 24/200\n",
            "258/258 [==============================] - 8s 31ms/step - loss: 1.1426 - categorical_accuracy: 0.4973 - val_loss: 1.3183 - val_categorical_accuracy: 0.3362\n",
            "Epoch 25/200\n",
            "258/258 [==============================] - 8s 31ms/step - loss: 1.1272 - categorical_accuracy: 0.4981 - val_loss: 1.3072 - val_categorical_accuracy: 0.3341\n",
            "Epoch 26/200\n",
            "258/258 [==============================] - 8s 31ms/step - loss: 1.1195 - categorical_accuracy: 0.5160 - val_loss: 1.3190 - val_categorical_accuracy: 0.3341\n",
            "Epoch 27/200\n",
            "258/258 [==============================] - 8s 31ms/step - loss: 1.1161 - categorical_accuracy: 0.5092 - val_loss: 1.3324 - val_categorical_accuracy: 0.3319\n",
            "Epoch 28/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 1.1485 - categorical_accuracy: 0.4934 - val_loss: 1.3105 - val_categorical_accuracy: 0.3450\n",
            "Epoch 29/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 1.1707 - categorical_accuracy: 0.5035 - val_loss: 1.3154 - val_categorical_accuracy: 0.3384\n",
            "Epoch 30/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 1.1257 - categorical_accuracy: 0.4873 - val_loss: 1.3176 - val_categorical_accuracy: 0.3406\n",
            "Epoch 31/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 1.1002 - categorical_accuracy: 0.5154 - val_loss: 1.3368 - val_categorical_accuracy: 0.3341\n",
            "Epoch 32/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 1.1170 - categorical_accuracy: 0.5036 - val_loss: 1.3111 - val_categorical_accuracy: 0.3515\n",
            "Epoch 33/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 1.1505 - categorical_accuracy: 0.4994 - val_loss: 1.3106 - val_categorical_accuracy: 0.3493\n",
            "Epoch 34/200\n",
            "258/258 [==============================] - 8s 31ms/step - loss: 1.0853 - categorical_accuracy: 0.5048 - val_loss: 1.3086 - val_categorical_accuracy: 0.3537\n",
            "Epoch 35/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 1.1429 - categorical_accuracy: 0.4954 - val_loss: 1.2959 - val_categorical_accuracy: 0.3603\n",
            "Epoch 36/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 1.0974 - categorical_accuracy: 0.5245 - val_loss: 1.2979 - val_categorical_accuracy: 0.3581\n",
            "Epoch 37/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 1.1029 - categorical_accuracy: 0.4986 - val_loss: 1.2877 - val_categorical_accuracy: 0.3755\n",
            "Epoch 38/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 1.1158 - categorical_accuracy: 0.5065 - val_loss: 1.2819 - val_categorical_accuracy: 0.3668\n",
            "Epoch 39/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 1.1124 - categorical_accuracy: 0.4987 - val_loss: 1.2802 - val_categorical_accuracy: 0.3755\n",
            "Epoch 40/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 1.1176 - categorical_accuracy: 0.5122 - val_loss: 1.3037 - val_categorical_accuracy: 0.3668\n",
            "Epoch 41/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 1.1130 - categorical_accuracy: 0.5149 - val_loss: 1.3175 - val_categorical_accuracy: 0.3559\n",
            "Epoch 42/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 1.1010 - categorical_accuracy: 0.5137 - val_loss: 1.2788 - val_categorical_accuracy: 0.3777\n",
            "Epoch 43/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 1.0810 - categorical_accuracy: 0.5301 - val_loss: 1.2723 - val_categorical_accuracy: 0.3755\n",
            "Epoch 44/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 1.1011 - categorical_accuracy: 0.5060 - val_loss: 1.2936 - val_categorical_accuracy: 0.3668\n",
            "Epoch 45/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 1.0753 - categorical_accuracy: 0.5269 - val_loss: 1.2734 - val_categorical_accuracy: 0.3886\n",
            "Epoch 46/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 1.1059 - categorical_accuracy: 0.5230 - val_loss: 1.2739 - val_categorical_accuracy: 0.3799\n",
            "Epoch 47/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 1.0866 - categorical_accuracy: 0.5201 - val_loss: 1.2900 - val_categorical_accuracy: 0.3755\n",
            "Epoch 48/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 1.1085 - categorical_accuracy: 0.5058 - val_loss: 1.2784 - val_categorical_accuracy: 0.3777\n",
            "Epoch 49/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 1.0699 - categorical_accuracy: 0.5178 - val_loss: 1.2816 - val_categorical_accuracy: 0.3755\n",
            "Epoch 50/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 1.0827 - categorical_accuracy: 0.5089 - val_loss: 1.2742 - val_categorical_accuracy: 0.3886\n",
            "Epoch 51/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 1.0980 - categorical_accuracy: 0.5306 - val_loss: 1.2682 - val_categorical_accuracy: 0.4017\n",
            "Epoch 52/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 1.0845 - categorical_accuracy: 0.5267 - val_loss: 1.2588 - val_categorical_accuracy: 0.4017\n",
            "Epoch 53/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 1.0704 - categorical_accuracy: 0.5348 - val_loss: 1.2777 - val_categorical_accuracy: 0.3755\n",
            "Epoch 54/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 1.1010 - categorical_accuracy: 0.5192 - val_loss: 1.2693 - val_categorical_accuracy: 0.3843\n",
            "Epoch 55/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 1.0903 - categorical_accuracy: 0.5133 - val_loss: 1.2734 - val_categorical_accuracy: 0.3777\n",
            "Epoch 56/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 1.0682 - categorical_accuracy: 0.5316 - val_loss: 1.2579 - val_categorical_accuracy: 0.3865\n",
            "Epoch 57/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 1.0802 - categorical_accuracy: 0.5339 - val_loss: 1.2761 - val_categorical_accuracy: 0.3734\n",
            "Epoch 58/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 1.0836 - categorical_accuracy: 0.5227 - val_loss: 1.2842 - val_categorical_accuracy: 0.3821\n",
            "Epoch 59/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 1.1000 - categorical_accuracy: 0.5177 - val_loss: 1.2684 - val_categorical_accuracy: 0.3930\n",
            "Epoch 60/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 1.0608 - categorical_accuracy: 0.5366 - val_loss: 1.2706 - val_categorical_accuracy: 0.3865\n",
            "Epoch 61/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 1.0649 - categorical_accuracy: 0.5274 - val_loss: 1.2649 - val_categorical_accuracy: 0.3930\n",
            "Epoch 62/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 1.0224 - categorical_accuracy: 0.5568 - val_loss: 1.2553 - val_categorical_accuracy: 0.4105\n",
            "Epoch 63/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 1.0674 - categorical_accuracy: 0.5413 - val_loss: 1.2746 - val_categorical_accuracy: 0.3908\n",
            "Epoch 64/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 1.0710 - categorical_accuracy: 0.5254 - val_loss: 1.2712 - val_categorical_accuracy: 0.3996\n",
            "Epoch 65/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 1.0484 - categorical_accuracy: 0.5458 - val_loss: 1.2758 - val_categorical_accuracy: 0.3821\n",
            "Epoch 66/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 1.0570 - categorical_accuracy: 0.5331 - val_loss: 1.2787 - val_categorical_accuracy: 0.3930\n",
            "Epoch 67/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 1.0453 - categorical_accuracy: 0.5473 - val_loss: 1.2904 - val_categorical_accuracy: 0.3952\n",
            "Epoch 68/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 1.0626 - categorical_accuracy: 0.5274 - val_loss: 1.2702 - val_categorical_accuracy: 0.3908\n",
            "Epoch 69/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 1.0729 - categorical_accuracy: 0.5346 - val_loss: 1.2779 - val_categorical_accuracy: 0.3952\n",
            "Epoch 70/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 1.0781 - categorical_accuracy: 0.5295 - val_loss: 1.2689 - val_categorical_accuracy: 0.4061\n",
            "Epoch 71/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 1.0526 - categorical_accuracy: 0.5424 - val_loss: 1.3049 - val_categorical_accuracy: 0.3843\n",
            "Epoch 72/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 1.0572 - categorical_accuracy: 0.5363 - val_loss: 1.2662 - val_categorical_accuracy: 0.3996\n",
            "Epoch 73/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 1.0372 - categorical_accuracy: 0.5481 - val_loss: 1.2840 - val_categorical_accuracy: 0.3843\n",
            "Epoch 74/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 1.0667 - categorical_accuracy: 0.5364 - val_loss: 1.2641 - val_categorical_accuracy: 0.4039\n",
            "Epoch 75/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 1.0853 - categorical_accuracy: 0.5265 - val_loss: 1.2610 - val_categorical_accuracy: 0.4105\n",
            "Epoch 76/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 1.0529 - categorical_accuracy: 0.5456 - val_loss: 1.2758 - val_categorical_accuracy: 0.4017\n",
            "Epoch 77/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 1.0533 - categorical_accuracy: 0.5459 - val_loss: 1.2628 - val_categorical_accuracy: 0.4170\n",
            "Epoch 78/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 1.0345 - categorical_accuracy: 0.5591 - val_loss: 1.2731 - val_categorical_accuracy: 0.4061\n",
            "Epoch 79/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 1.0343 - categorical_accuracy: 0.5567 - val_loss: 1.2625 - val_categorical_accuracy: 0.4083\n",
            "Epoch 80/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 1.0409 - categorical_accuracy: 0.5368 - val_loss: 1.2759 - val_categorical_accuracy: 0.4105\n",
            "Epoch 81/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 1.0495 - categorical_accuracy: 0.5418 - val_loss: 1.2835 - val_categorical_accuracy: 0.4017\n",
            "Epoch 82/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 1.0433 - categorical_accuracy: 0.5494 - val_loss: 1.2808 - val_categorical_accuracy: 0.4061\n",
            "Epoch 83/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 1.0456 - categorical_accuracy: 0.5453 - val_loss: 1.2610 - val_categorical_accuracy: 0.4105\n",
            "Epoch 84/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 1.0601 - categorical_accuracy: 0.5366 - val_loss: 1.2650 - val_categorical_accuracy: 0.4083\n",
            "Epoch 85/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 1.0412 - categorical_accuracy: 0.5478 - val_loss: 1.2680 - val_categorical_accuracy: 0.4127\n",
            "Epoch 86/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 1.0492 - categorical_accuracy: 0.5497 - val_loss: 1.2557 - val_categorical_accuracy: 0.4039\n",
            "Epoch 87/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 1.0317 - categorical_accuracy: 0.5547 - val_loss: 1.2654 - val_categorical_accuracy: 0.4214\n",
            "Epoch 88/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 1.0375 - categorical_accuracy: 0.5566 - val_loss: 1.2608 - val_categorical_accuracy: 0.4061\n",
            "Epoch 89/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 1.0313 - categorical_accuracy: 0.5567 - val_loss: 1.2560 - val_categorical_accuracy: 0.4127\n",
            "Epoch 90/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 1.0432 - categorical_accuracy: 0.5551 - val_loss: 1.2838 - val_categorical_accuracy: 0.3974\n",
            "Epoch 91/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 1.0329 - categorical_accuracy: 0.5469 - val_loss: 1.2534 - val_categorical_accuracy: 0.4083\n",
            "Epoch 92/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 1.0281 - categorical_accuracy: 0.5410 - val_loss: 1.2666 - val_categorical_accuracy: 0.4105\n",
            "Epoch 93/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 1.0413 - categorical_accuracy: 0.5482 - val_loss: 1.2585 - val_categorical_accuracy: 0.4105\n",
            "Epoch 94/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 1.0332 - categorical_accuracy: 0.5662 - val_loss: 1.2497 - val_categorical_accuracy: 0.4214\n",
            "Epoch 95/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 1.0278 - categorical_accuracy: 0.5534 - val_loss: 1.2726 - val_categorical_accuracy: 0.4017\n",
            "Epoch 96/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 1.0347 - categorical_accuracy: 0.5663 - val_loss: 1.2580 - val_categorical_accuracy: 0.4214\n",
            "Epoch 97/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 1.0435 - categorical_accuracy: 0.5527 - val_loss: 1.2741 - val_categorical_accuracy: 0.4105\n",
            "Epoch 98/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 1.0349 - categorical_accuracy: 0.5518 - val_loss: 1.2775 - val_categorical_accuracy: 0.4083\n",
            "Epoch 99/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 1.0347 - categorical_accuracy: 0.5543 - val_loss: 1.2715 - val_categorical_accuracy: 0.4061\n",
            "Epoch 100/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 1.0494 - categorical_accuracy: 0.5242 - val_loss: 1.2644 - val_categorical_accuracy: 0.4061\n",
            "Epoch 101/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 1.0271 - categorical_accuracy: 0.5656 - val_loss: 1.2622 - val_categorical_accuracy: 0.4170\n",
            "Epoch 102/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 1.0393 - categorical_accuracy: 0.5604 - val_loss: 1.2623 - val_categorical_accuracy: 0.4214\n",
            "Epoch 103/200\n",
            "258/258 [==============================] - 8s 31ms/step - loss: 1.0366 - categorical_accuracy: 0.5700 - val_loss: 1.2757 - val_categorical_accuracy: 0.4061\n",
            "Epoch 104/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 1.0056 - categorical_accuracy: 0.5600 - val_loss: 1.2771 - val_categorical_accuracy: 0.4127\n",
            "Epoch 105/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 1.0376 - categorical_accuracy: 0.5497 - val_loss: 1.2636 - val_categorical_accuracy: 0.4148\n",
            "Epoch 106/200\n",
            "258/258 [==============================] - 8s 31ms/step - loss: 1.0134 - categorical_accuracy: 0.5708 - val_loss: 1.2652 - val_categorical_accuracy: 0.4127\n",
            "Epoch 107/200\n",
            "258/258 [==============================] - 8s 31ms/step - loss: 1.0089 - categorical_accuracy: 0.5584 - val_loss: 1.2557 - val_categorical_accuracy: 0.4236\n",
            "Epoch 108/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 1.0155 - categorical_accuracy: 0.5647 - val_loss: 1.2570 - val_categorical_accuracy: 0.4214\n",
            "Epoch 109/200\n",
            "258/258 [==============================] - 8s 31ms/step - loss: 1.0317 - categorical_accuracy: 0.5433 - val_loss: 1.2650 - val_categorical_accuracy: 0.4323\n",
            "Epoch 110/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 1.0204 - categorical_accuracy: 0.5457 - val_loss: 1.2723 - val_categorical_accuracy: 0.4301\n",
            "Epoch 111/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 1.0093 - categorical_accuracy: 0.5687 - val_loss: 1.2620 - val_categorical_accuracy: 0.4192\n",
            "Epoch 112/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 1.0205 - categorical_accuracy: 0.5624 - val_loss: 1.2678 - val_categorical_accuracy: 0.4148\n",
            "Epoch 113/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 1.0056 - categorical_accuracy: 0.5757 - val_loss: 1.2778 - val_categorical_accuracy: 0.4192\n",
            "Epoch 114/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 1.0095 - categorical_accuracy: 0.5631 - val_loss: 1.2659 - val_categorical_accuracy: 0.4236\n",
            "Epoch 115/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 1.0428 - categorical_accuracy: 0.5463 - val_loss: 1.2794 - val_categorical_accuracy: 0.4039\n",
            "Epoch 116/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 0.9992 - categorical_accuracy: 0.5713 - val_loss: 1.2643 - val_categorical_accuracy: 0.4214\n",
            "Epoch 117/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 0.9950 - categorical_accuracy: 0.5636 - val_loss: 1.2645 - val_categorical_accuracy: 0.4105\n",
            "Epoch 118/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 1.0174 - categorical_accuracy: 0.5542 - val_loss: 1.2673 - val_categorical_accuracy: 0.4170\n",
            "Epoch 119/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 1.0079 - categorical_accuracy: 0.5646 - val_loss: 1.2504 - val_categorical_accuracy: 0.4236\n",
            "Epoch 120/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 1.0354 - categorical_accuracy: 0.5648 - val_loss: 1.2724 - val_categorical_accuracy: 0.4061\n",
            "Epoch 121/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 1.0237 - categorical_accuracy: 0.5489 - val_loss: 1.2622 - val_categorical_accuracy: 0.4258\n",
            "Epoch 122/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 0.9969 - categorical_accuracy: 0.5616 - val_loss: 1.2710 - val_categorical_accuracy: 0.4083\n",
            "Epoch 123/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 1.0049 - categorical_accuracy: 0.5755 - val_loss: 1.2545 - val_categorical_accuracy: 0.4214\n",
            "Epoch 124/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 1.0266 - categorical_accuracy: 0.5515 - val_loss: 1.2447 - val_categorical_accuracy: 0.4279\n",
            "Epoch 125/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 1.0267 - categorical_accuracy: 0.5583 - val_loss: 1.2583 - val_categorical_accuracy: 0.4279\n",
            "Epoch 126/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 1.0148 - categorical_accuracy: 0.5628 - val_loss: 1.2592 - val_categorical_accuracy: 0.4301\n",
            "Epoch 127/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 1.0105 - categorical_accuracy: 0.5710 - val_loss: 1.2578 - val_categorical_accuracy: 0.4345\n",
            "Epoch 128/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 0.9909 - categorical_accuracy: 0.5750 - val_loss: 1.2817 - val_categorical_accuracy: 0.4083\n",
            "Epoch 129/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 1.0246 - categorical_accuracy: 0.5546 - val_loss: 1.2750 - val_categorical_accuracy: 0.4148\n",
            "Epoch 130/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 1.0069 - categorical_accuracy: 0.5664 - val_loss: 1.2563 - val_categorical_accuracy: 0.4148\n",
            "Epoch 131/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 1.0067 - categorical_accuracy: 0.5541 - val_loss: 1.2641 - val_categorical_accuracy: 0.4214\n",
            "Epoch 132/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 0.9878 - categorical_accuracy: 0.5761 - val_loss: 1.2714 - val_categorical_accuracy: 0.4105\n",
            "Epoch 133/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 0.9946 - categorical_accuracy: 0.5685 - val_loss: 1.2564 - val_categorical_accuracy: 0.4301\n",
            "Epoch 134/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 0.9961 - categorical_accuracy: 0.5768 - val_loss: 1.2629 - val_categorical_accuracy: 0.4279\n",
            "Epoch 135/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 1.0324 - categorical_accuracy: 0.5526 - val_loss: 1.2638 - val_categorical_accuracy: 0.4214\n",
            "Epoch 136/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 0.9911 - categorical_accuracy: 0.5863 - val_loss: 1.2716 - val_categorical_accuracy: 0.4170\n",
            "Epoch 137/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 0.9996 - categorical_accuracy: 0.5677 - val_loss: 1.2611 - val_categorical_accuracy: 0.4214\n",
            "Epoch 138/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 1.0111 - categorical_accuracy: 0.5876 - val_loss: 1.2799 - val_categorical_accuracy: 0.4192\n",
            "Epoch 139/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 0.9666 - categorical_accuracy: 0.5871 - val_loss: 1.2641 - val_categorical_accuracy: 0.4323\n",
            "Epoch 140/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 1.0040 - categorical_accuracy: 0.5642 - val_loss: 1.2547 - val_categorical_accuracy: 0.4279\n",
            "Epoch 141/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 0.9962 - categorical_accuracy: 0.5697 - val_loss: 1.2560 - val_categorical_accuracy: 0.4323\n",
            "Epoch 142/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 0.9902 - categorical_accuracy: 0.5896 - val_loss: 1.2734 - val_categorical_accuracy: 0.4258\n",
            "Epoch 143/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 0.9650 - categorical_accuracy: 0.5984 - val_loss: 1.2613 - val_categorical_accuracy: 0.4105\n",
            "Epoch 144/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 1.0396 - categorical_accuracy: 0.5473 - val_loss: 1.2651 - val_categorical_accuracy: 0.4258\n",
            "Epoch 145/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 0.9911 - categorical_accuracy: 0.5674 - val_loss: 1.2637 - val_categorical_accuracy: 0.4323\n",
            "Epoch 146/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 0.9596 - categorical_accuracy: 0.5913 - val_loss: 1.2670 - val_categorical_accuracy: 0.4367\n",
            "Epoch 147/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 0.9750 - categorical_accuracy: 0.5782 - val_loss: 1.2680 - val_categorical_accuracy: 0.4367\n",
            "Epoch 148/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 0.9966 - categorical_accuracy: 0.5773 - val_loss: 1.2683 - val_categorical_accuracy: 0.4279\n",
            "Epoch 149/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 1.0254 - categorical_accuracy: 0.5796 - val_loss: 1.2561 - val_categorical_accuracy: 0.4214\n",
            "Epoch 150/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 0.9872 - categorical_accuracy: 0.5834 - val_loss: 1.2666 - val_categorical_accuracy: 0.4170\n",
            "Epoch 151/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 0.9962 - categorical_accuracy: 0.5750 - val_loss: 1.2583 - val_categorical_accuracy: 0.4432\n",
            "Epoch 152/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 0.9899 - categorical_accuracy: 0.5724 - val_loss: 1.2609 - val_categorical_accuracy: 0.4345\n",
            "Epoch 153/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 0.9864 - categorical_accuracy: 0.5775 - val_loss: 1.2717 - val_categorical_accuracy: 0.4105\n",
            "Epoch 154/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 0.9759 - categorical_accuracy: 0.5775 - val_loss: 1.2556 - val_categorical_accuracy: 0.4214\n",
            "Epoch 155/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 1.0313 - categorical_accuracy: 0.5716 - val_loss: 1.2489 - val_categorical_accuracy: 0.4389\n",
            "Epoch 156/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 0.9990 - categorical_accuracy: 0.5855 - val_loss: 1.2726 - val_categorical_accuracy: 0.4279\n",
            "Epoch 157/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 0.9588 - categorical_accuracy: 0.5917 - val_loss: 1.2644 - val_categorical_accuracy: 0.4345\n",
            "Epoch 158/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 1.0144 - categorical_accuracy: 0.5723 - val_loss: 1.2694 - val_categorical_accuracy: 0.4410\n",
            "Epoch 159/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 1.0166 - categorical_accuracy: 0.5849 - val_loss: 1.2687 - val_categorical_accuracy: 0.4345\n",
            "Epoch 160/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 1.0043 - categorical_accuracy: 0.5695 - val_loss: 1.2876 - val_categorical_accuracy: 0.4279\n",
            "Epoch 161/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 0.9962 - categorical_accuracy: 0.5752 - val_loss: 1.2681 - val_categorical_accuracy: 0.4432\n",
            "Epoch 162/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 1.0056 - categorical_accuracy: 0.5731 - val_loss: 1.2649 - val_categorical_accuracy: 0.4323\n",
            "Epoch 163/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 0.9833 - categorical_accuracy: 0.5731 - val_loss: 1.2725 - val_categorical_accuracy: 0.4301\n",
            "Epoch 164/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 0.9864 - categorical_accuracy: 0.5761 - val_loss: 1.2618 - val_categorical_accuracy: 0.4367\n",
            "Epoch 165/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 0.9818 - categorical_accuracy: 0.5815 - val_loss: 1.2611 - val_categorical_accuracy: 0.4476\n",
            "Epoch 166/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 0.9873 - categorical_accuracy: 0.5797 - val_loss: 1.2697 - val_categorical_accuracy: 0.4410\n",
            "Epoch 167/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 1.0133 - categorical_accuracy: 0.5771 - val_loss: 1.2459 - val_categorical_accuracy: 0.4454\n",
            "Epoch 168/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 0.9789 - categorical_accuracy: 0.5921 - val_loss: 1.2632 - val_categorical_accuracy: 0.4432\n",
            "Epoch 169/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 0.9749 - categorical_accuracy: 0.5800 - val_loss: 1.2642 - val_categorical_accuracy: 0.4323\n",
            "Epoch 170/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 0.9781 - categorical_accuracy: 0.5816 - val_loss: 1.2593 - val_categorical_accuracy: 0.4367\n",
            "Epoch 171/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 0.9797 - categorical_accuracy: 0.5725 - val_loss: 1.2619 - val_categorical_accuracy: 0.4410\n",
            "Epoch 172/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 0.9922 - categorical_accuracy: 0.5796 - val_loss: 1.2644 - val_categorical_accuracy: 0.4214\n",
            "Epoch 173/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 0.9645 - categorical_accuracy: 0.5830 - val_loss: 1.2549 - val_categorical_accuracy: 0.4389\n",
            "Epoch 174/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 0.9764 - categorical_accuracy: 0.5957 - val_loss: 1.2634 - val_categorical_accuracy: 0.4367\n",
            "Epoch 175/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 0.9626 - categorical_accuracy: 0.5779 - val_loss: 1.2651 - val_categorical_accuracy: 0.4389\n",
            "Epoch 176/200\n",
            "258/258 [==============================] - 8s 33ms/step - loss: 0.9645 - categorical_accuracy: 0.5827 - val_loss: 1.2670 - val_categorical_accuracy: 0.4389\n",
            "Epoch 177/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 0.9943 - categorical_accuracy: 0.5674 - val_loss: 1.2662 - val_categorical_accuracy: 0.4498\n",
            "Epoch 178/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 0.9675 - categorical_accuracy: 0.5825 - val_loss: 1.2625 - val_categorical_accuracy: 0.4323\n",
            "Epoch 179/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 0.9768 - categorical_accuracy: 0.5880 - val_loss: 1.2697 - val_categorical_accuracy: 0.4345\n",
            "Epoch 180/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 0.9731 - categorical_accuracy: 0.5834 - val_loss: 1.2692 - val_categorical_accuracy: 0.4367\n",
            "Epoch 181/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 0.9703 - categorical_accuracy: 0.5724 - val_loss: 1.2647 - val_categorical_accuracy: 0.4345\n",
            "Epoch 182/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 0.9834 - categorical_accuracy: 0.5821 - val_loss: 1.2726 - val_categorical_accuracy: 0.4258\n",
            "Epoch 183/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 0.9863 - categorical_accuracy: 0.5841 - val_loss: 1.2552 - val_categorical_accuracy: 0.4410\n",
            "Epoch 184/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 0.9786 - categorical_accuracy: 0.5855 - val_loss: 1.2558 - val_categorical_accuracy: 0.4410\n",
            "Epoch 185/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 0.9994 - categorical_accuracy: 0.5841 - val_loss: 1.2751 - val_categorical_accuracy: 0.4389\n",
            "Epoch 186/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 0.9457 - categorical_accuracy: 0.6021 - val_loss: 1.2767 - val_categorical_accuracy: 0.4236\n",
            "Epoch 187/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 0.9700 - categorical_accuracy: 0.5898 - val_loss: 1.2776 - val_categorical_accuracy: 0.4410\n",
            "Epoch 188/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 0.9820 - categorical_accuracy: 0.5803 - val_loss: 1.2701 - val_categorical_accuracy: 0.4367\n",
            "Epoch 189/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 0.9921 - categorical_accuracy: 0.5936 - val_loss: 1.2725 - val_categorical_accuracy: 0.4432\n",
            "Epoch 190/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 0.9621 - categorical_accuracy: 0.5906 - val_loss: 1.2793 - val_categorical_accuracy: 0.4410\n",
            "Epoch 191/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 0.9643 - categorical_accuracy: 0.5879 - val_loss: 1.2590 - val_categorical_accuracy: 0.4454\n",
            "Epoch 192/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 0.9761 - categorical_accuracy: 0.5805 - val_loss: 1.2723 - val_categorical_accuracy: 0.4432\n",
            "Epoch 193/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 0.9808 - categorical_accuracy: 0.5825 - val_loss: 1.2667 - val_categorical_accuracy: 0.4432\n",
            "Epoch 194/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 0.9628 - categorical_accuracy: 0.5908 - val_loss: 1.2756 - val_categorical_accuracy: 0.4389\n",
            "Epoch 195/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 1.0018 - categorical_accuracy: 0.5796 - val_loss: 1.2593 - val_categorical_accuracy: 0.4279\n",
            "Epoch 196/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 0.9578 - categorical_accuracy: 0.5784 - val_loss: 1.2716 - val_categorical_accuracy: 0.4345\n",
            "Epoch 197/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 0.9704 - categorical_accuracy: 0.5874 - val_loss: 1.2674 - val_categorical_accuracy: 0.4454\n",
            "Epoch 198/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 0.9578 - categorical_accuracy: 0.5956 - val_loss: 1.2767 - val_categorical_accuracy: 0.4345\n",
            "Epoch 199/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 0.9620 - categorical_accuracy: 0.5865 - val_loss: 1.2641 - val_categorical_accuracy: 0.4301\n",
            "Epoch 200/200\n",
            "258/258 [==============================] - 8s 32ms/step - loss: 0.9604 - categorical_accuracy: 0.5890 - val_loss: 1.2690 - val_categorical_accuracy: 0.4410\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_CZ-oFJW3bd"
      },
      "source": [
        "model.save('/content/drive/MyDrive/Colab Notebooks/SPEECH_EMOTION_Recognition/Nộp bài(chốt hạ)/model_saver/conv2D_melspec_cremad.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "onU0xMuWmGmQ"
      },
      "source": [
        "###test_result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9cTZvr8tmGmS",
        "outputId": "57531930-2230-4704-9930-1b91602845c2"
      },
      "source": [
        "d = {0: 'happy',\n",
        "     1: 'sad',\n",
        "     2: 'angry',\n",
        "     3: 'fear'}\n",
        "Y_test_pred = np.argmax(model.predict(X_test), axis=-1)\n",
        "Y_test_pred = list(map(lambda x: d[x], Y_test_pred))\n",
        "y_test = np.argmax(y_test, axis=-1)\n",
        "y_test = list(map(lambda x: d[x], y_test))\n",
        "print(classification_report(y_test, Y_test_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.66      0.34      0.45       136\n",
            "        fear       0.33      0.13      0.18       134\n",
            "       happy       0.45      0.45      0.45       120\n",
            "         sad       0.43      0.97      0.60       119\n",
            "\n",
            "    accuracy                           0.46       509\n",
            "   macro avg       0.47      0.47      0.42       509\n",
            "weighted avg       0.47      0.46      0.41       509\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N6d8QlF3mGmT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "outputId": "ad9d3808-42ad-48f2-f941-727160e48c78"
      },
      "source": [
        "import scikitplot as skplt\n",
        "\n",
        "skplt.metrics.plot_confusion_matrix(\n",
        "    y_test, \n",
        "    Y_test_pred,\n",
        "    figsize=(8,8))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fa47db68350>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8FTW3csmGmU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52xgoS68UfhO"
      },
      "source": [
        "# Tempogram + basic model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRIEg1lhUfhZ"
      },
      "source": [
        "data = {'labels': [],\n",
        "        'features': []}\n",
        "\n",
        "for i in range(len(CREMA_D_df)):\n",
        "  if ((CREMA_D_df['Emotion'][i] == 'HAP') | (CREMA_D_df['Emotion'][i] == 'SAD') | \n",
        "      (CREMA_D_df['Emotion'][i] == 'ANG') | (CREMA_D_df['Emotion'][i] == 'FEA')):\n",
        "    \n",
        "    if CREMA_D_df['Emotion'][i] == 'HAP':\n",
        "      data['labels'].append(0)\n",
        "    elif CREMA_D_df['Emotion'][i] == 'SAD':\n",
        "      data['labels'].append(1)\n",
        "    elif CREMA_D_df['Emotion'][i] == 'ANG':\n",
        "      data['labels'].append(2)\n",
        "    elif CREMA_D_df['Emotion'][i] == 'FEA':\n",
        "      data['labels'].append(3)\n",
        "\n",
        "\n",
        "    signal, sr =  librosa.load(CREMA_D_df['Paths'][i])\n",
        "\n",
        "    tempogram = np.mean(librosa.feature.tempogram(signal, sr).T, axis=0)\n",
        "    data['features'].append(tempogram)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_thKlW8Ufhb"
      },
      "source": [
        "X = data['features']\n",
        "y = data['labels']\n",
        "\n",
        "y = np.array(y)\n",
        "y = to_categorical(y)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=0)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=0)\n",
        "\n",
        "X_train = np.array(X_train)\n",
        "X_test = np.array(X_test)\n",
        "X_val = np.array(X_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dOcjtFWYUfhc"
      },
      "source": [
        "## basic models:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rkfYHWSJUfhd",
        "outputId": "3ee95fe0-99d6-4354-9f10-cfa878766dc9"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(384, input_shape=(384, ), activation = 'relu'))\n",
        "#model.add(Dropout(0.1))\n",
        "model.add(Dense(128, activation = 'relu'))\n",
        "#model.add(Dropout(0.25))\n",
        "model.add(Dense(128, activation = 'relu'))\n",
        "#model.add(Dropout(0.2))\n",
        "model.add(Dense(4, activation = 'softmax'))\n",
        "\n",
        "optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
        "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer=optimizer)\n",
        "early_stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=100, verbose=1, mode='auto')\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_11 (Dense)             (None, 384)               147840    \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 128)               49280     \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 4)                 516       \n",
            "=================================================================\n",
            "Total params: 214,148\n",
            "Trainable params: 214,148\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RtMiNrW1Ufhf",
        "outputId": "058ac763-232c-49b4-8f95-2c8d6a0a8421"
      },
      "source": [
        "history = model.fit(X_train, y_train, batch_size=64, epochs=200, \n",
        "                    validation_data=(X_val, y_val))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "65/65 [==============================] - 1s 8ms/step - loss: 1.3233 - accuracy: 0.3312 - val_loss: 1.2187 - val_accuracy: 0.4127\n",
            "Epoch 2/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 1.1546 - accuracy: 0.4527 - val_loss: 1.1056 - val_accuracy: 0.5044\n",
            "Epoch 3/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 1.0584 - accuracy: 0.5068 - val_loss: 1.1246 - val_accuracy: 0.4956\n",
            "Epoch 4/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 1.0643 - accuracy: 0.5013 - val_loss: 1.1241 - val_accuracy: 0.4803\n",
            "Epoch 5/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 1.0560 - accuracy: 0.5062 - val_loss: 1.1080 - val_accuracy: 0.5087\n",
            "Epoch 6/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 1.0492 - accuracy: 0.5206 - val_loss: 1.1498 - val_accuracy: 0.4934\n",
            "Epoch 7/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 1.0642 - accuracy: 0.5103 - val_loss: 1.1523 - val_accuracy: 0.4803\n",
            "Epoch 8/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 1.0602 - accuracy: 0.5066 - val_loss: 1.0821 - val_accuracy: 0.5218\n",
            "Epoch 9/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 1.0424 - accuracy: 0.5131 - val_loss: 1.1050 - val_accuracy: 0.4847\n",
            "Epoch 10/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 1.0590 - accuracy: 0.5091 - val_loss: 1.0762 - val_accuracy: 0.5131\n",
            "Epoch 11/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 1.0344 - accuracy: 0.5325 - val_loss: 1.0781 - val_accuracy: 0.5109\n",
            "Epoch 12/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 1.0320 - accuracy: 0.5436 - val_loss: 1.0788 - val_accuracy: 0.5087\n",
            "Epoch 13/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 1.0398 - accuracy: 0.5155 - val_loss: 1.0859 - val_accuracy: 0.5240\n",
            "Epoch 14/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 1.0405 - accuracy: 0.5309 - val_loss: 1.1026 - val_accuracy: 0.5153\n",
            "Epoch 15/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 1.0506 - accuracy: 0.5175 - val_loss: 1.1119 - val_accuracy: 0.5109\n",
            "Epoch 16/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 1.0072 - accuracy: 0.5488 - val_loss: 1.0743 - val_accuracy: 0.5131\n",
            "Epoch 17/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 1.0017 - accuracy: 0.5411 - val_loss: 1.0686 - val_accuracy: 0.5197\n",
            "Epoch 18/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 1.0240 - accuracy: 0.5365 - val_loss: 1.0655 - val_accuracy: 0.5153\n",
            "Epoch 19/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 1.0183 - accuracy: 0.5351 - val_loss: 1.0621 - val_accuracy: 0.5153\n",
            "Epoch 20/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 1.0171 - accuracy: 0.5381 - val_loss: 1.1084 - val_accuracy: 0.5066\n",
            "Epoch 21/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 1.0257 - accuracy: 0.5473 - val_loss: 1.1341 - val_accuracy: 0.4782\n",
            "Epoch 22/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 1.0355 - accuracy: 0.5401 - val_loss: 1.0964 - val_accuracy: 0.4978\n",
            "Epoch 23/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 1.0097 - accuracy: 0.5323 - val_loss: 1.0654 - val_accuracy: 0.5022\n",
            "Epoch 24/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 1.0102 - accuracy: 0.5326 - val_loss: 1.1073 - val_accuracy: 0.4956\n",
            "Epoch 25/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 1.0103 - accuracy: 0.5371 - val_loss: 1.0688 - val_accuracy: 0.5066\n",
            "Epoch 26/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 1.0232 - accuracy: 0.5317 - val_loss: 1.1155 - val_accuracy: 0.5022\n",
            "Epoch 27/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 1.0406 - accuracy: 0.5235 - val_loss: 1.0619 - val_accuracy: 0.5218\n",
            "Epoch 28/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 1.0039 - accuracy: 0.5415 - val_loss: 1.0704 - val_accuracy: 0.5284\n",
            "Epoch 29/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.9856 - accuracy: 0.5554 - val_loss: 1.0614 - val_accuracy: 0.5175\n",
            "Epoch 30/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.9985 - accuracy: 0.5483 - val_loss: 1.0863 - val_accuracy: 0.4956\n",
            "Epoch 31/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 1.0269 - accuracy: 0.5377 - val_loss: 1.0645 - val_accuracy: 0.5153\n",
            "Epoch 32/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.9829 - accuracy: 0.5669 - val_loss: 1.1192 - val_accuracy: 0.4760\n",
            "Epoch 33/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 1.0018 - accuracy: 0.5387 - val_loss: 1.1309 - val_accuracy: 0.4803\n",
            "Epoch 34/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 1.0117 - accuracy: 0.5464 - val_loss: 1.0837 - val_accuracy: 0.5044\n",
            "Epoch 35/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.9872 - accuracy: 0.5435 - val_loss: 1.1024 - val_accuracy: 0.5087\n",
            "Epoch 36/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 1.0109 - accuracy: 0.5405 - val_loss: 1.0823 - val_accuracy: 0.5109\n",
            "Epoch 37/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 1.0078 - accuracy: 0.5393 - val_loss: 1.1082 - val_accuracy: 0.5087\n",
            "Epoch 38/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 1.0213 - accuracy: 0.5320 - val_loss: 1.0799 - val_accuracy: 0.5022\n",
            "Epoch 39/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.9942 - accuracy: 0.5630 - val_loss: 1.0751 - val_accuracy: 0.5000\n",
            "Epoch 40/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.9933 - accuracy: 0.5563 - val_loss: 1.1054 - val_accuracy: 0.4978\n",
            "Epoch 41/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 1.0043 - accuracy: 0.5447 - val_loss: 1.0726 - val_accuracy: 0.5175\n",
            "Epoch 42/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.9925 - accuracy: 0.5513 - val_loss: 1.0811 - val_accuracy: 0.5153\n",
            "Epoch 43/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.9784 - accuracy: 0.5585 - val_loss: 1.0724 - val_accuracy: 0.5131\n",
            "Epoch 44/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.9962 - accuracy: 0.5475 - val_loss: 1.1109 - val_accuracy: 0.4869\n",
            "Epoch 45/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.9885 - accuracy: 0.5482 - val_loss: 1.0915 - val_accuracy: 0.4825\n",
            "Epoch 46/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.9995 - accuracy: 0.5608 - val_loss: 1.0814 - val_accuracy: 0.5153\n",
            "Epoch 47/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 1.0009 - accuracy: 0.5458 - val_loss: 1.0913 - val_accuracy: 0.4760\n",
            "Epoch 48/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 1.0089 - accuracy: 0.5415 - val_loss: 1.0689 - val_accuracy: 0.5109\n",
            "Epoch 49/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.9948 - accuracy: 0.5507 - val_loss: 1.0660 - val_accuracy: 0.5262\n",
            "Epoch 50/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.9711 - accuracy: 0.5533 - val_loss: 1.0745 - val_accuracy: 0.5197\n",
            "Epoch 51/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.9779 - accuracy: 0.5623 - val_loss: 1.0732 - val_accuracy: 0.5175\n",
            "Epoch 52/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.9728 - accuracy: 0.5685 - val_loss: 1.0956 - val_accuracy: 0.5131\n",
            "Epoch 53/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.9975 - accuracy: 0.5487 - val_loss: 1.0759 - val_accuracy: 0.5131\n",
            "Epoch 54/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.9791 - accuracy: 0.5628 - val_loss: 1.0830 - val_accuracy: 0.5109\n",
            "Epoch 55/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.9747 - accuracy: 0.5631 - val_loss: 1.0657 - val_accuracy: 0.5197\n",
            "Epoch 56/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.9612 - accuracy: 0.5651 - val_loss: 1.0943 - val_accuracy: 0.5066\n",
            "Epoch 57/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.9683 - accuracy: 0.5744 - val_loss: 1.1374 - val_accuracy: 0.4869\n",
            "Epoch 58/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.9930 - accuracy: 0.5686 - val_loss: 1.1171 - val_accuracy: 0.4913\n",
            "Epoch 59/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 1.0002 - accuracy: 0.5480 - val_loss: 1.0654 - val_accuracy: 0.5240\n",
            "Epoch 60/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.9696 - accuracy: 0.5667 - val_loss: 1.0872 - val_accuracy: 0.5087\n",
            "Epoch 61/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.9679 - accuracy: 0.5588 - val_loss: 1.1031 - val_accuracy: 0.5022\n",
            "Epoch 62/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.9723 - accuracy: 0.5629 - val_loss: 1.0788 - val_accuracy: 0.5197\n",
            "Epoch 63/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 1.0128 - accuracy: 0.5339 - val_loss: 1.0849 - val_accuracy: 0.5066\n",
            "Epoch 64/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.9750 - accuracy: 0.5684 - val_loss: 1.1098 - val_accuracy: 0.4782\n",
            "Epoch 65/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.9877 - accuracy: 0.5544 - val_loss: 1.0837 - val_accuracy: 0.5175\n",
            "Epoch 66/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.9659 - accuracy: 0.5680 - val_loss: 1.0849 - val_accuracy: 0.5218\n",
            "Epoch 67/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.9700 - accuracy: 0.5694 - val_loss: 1.0941 - val_accuracy: 0.5022\n",
            "Epoch 68/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.9664 - accuracy: 0.5753 - val_loss: 1.0977 - val_accuracy: 0.5240\n",
            "Epoch 69/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.9875 - accuracy: 0.5645 - val_loss: 1.0737 - val_accuracy: 0.5131\n",
            "Epoch 70/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.9633 - accuracy: 0.5720 - val_loss: 1.0761 - val_accuracy: 0.5153\n",
            "Epoch 71/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.9671 - accuracy: 0.5625 - val_loss: 1.0766 - val_accuracy: 0.5066\n",
            "Epoch 72/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.9512 - accuracy: 0.5747 - val_loss: 1.1106 - val_accuracy: 0.4956\n",
            "Epoch 73/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.9688 - accuracy: 0.5700 - val_loss: 1.0838 - val_accuracy: 0.5044\n",
            "Epoch 74/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.9545 - accuracy: 0.5702 - val_loss: 1.0821 - val_accuracy: 0.5218\n",
            "Epoch 75/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.9746 - accuracy: 0.5597 - val_loss: 1.1042 - val_accuracy: 0.5109\n",
            "Epoch 76/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.9839 - accuracy: 0.5577 - val_loss: 1.0798 - val_accuracy: 0.5262\n",
            "Epoch 77/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.9366 - accuracy: 0.5767 - val_loss: 1.1082 - val_accuracy: 0.5131\n",
            "Epoch 78/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.9597 - accuracy: 0.5710 - val_loss: 1.0682 - val_accuracy: 0.5153\n",
            "Epoch 79/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.9608 - accuracy: 0.5836 - val_loss: 1.0900 - val_accuracy: 0.5044\n",
            "Epoch 80/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.9674 - accuracy: 0.5634 - val_loss: 1.0823 - val_accuracy: 0.5262\n",
            "Epoch 81/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.9670 - accuracy: 0.5629 - val_loss: 1.1129 - val_accuracy: 0.5153\n",
            "Epoch 82/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.9807 - accuracy: 0.5594 - val_loss: 1.0992 - val_accuracy: 0.5175\n",
            "Epoch 83/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.9791 - accuracy: 0.5570 - val_loss: 1.1023 - val_accuracy: 0.4913\n",
            "Epoch 84/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.9738 - accuracy: 0.5587 - val_loss: 1.0888 - val_accuracy: 0.4978\n",
            "Epoch 85/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.9739 - accuracy: 0.5545 - val_loss: 1.1333 - val_accuracy: 0.5066\n",
            "Epoch 86/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.9883 - accuracy: 0.5641 - val_loss: 1.0849 - val_accuracy: 0.5175\n",
            "Epoch 87/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.9244 - accuracy: 0.5844 - val_loss: 1.0933 - val_accuracy: 0.5153\n",
            "Epoch 88/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.9538 - accuracy: 0.5670 - val_loss: 1.1001 - val_accuracy: 0.5087\n",
            "Epoch 89/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.9371 - accuracy: 0.5728 - val_loss: 1.1017 - val_accuracy: 0.5000\n",
            "Epoch 90/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.9682 - accuracy: 0.5686 - val_loss: 1.0979 - val_accuracy: 0.5087\n",
            "Epoch 91/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.9545 - accuracy: 0.5715 - val_loss: 1.0902 - val_accuracy: 0.5218\n",
            "Epoch 92/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.9289 - accuracy: 0.5930 - val_loss: 1.0728 - val_accuracy: 0.5175\n",
            "Epoch 93/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.9512 - accuracy: 0.5728 - val_loss: 1.0801 - val_accuracy: 0.5262\n",
            "Epoch 94/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.9361 - accuracy: 0.5780 - val_loss: 1.1026 - val_accuracy: 0.5240\n",
            "Epoch 95/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.9418 - accuracy: 0.5804 - val_loss: 1.1156 - val_accuracy: 0.5044\n",
            "Epoch 96/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.9788 - accuracy: 0.5701 - val_loss: 1.0984 - val_accuracy: 0.5218\n",
            "Epoch 97/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.9540 - accuracy: 0.5742 - val_loss: 1.0895 - val_accuracy: 0.5197\n",
            "Epoch 98/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.9480 - accuracy: 0.5790 - val_loss: 1.0849 - val_accuracy: 0.5066\n",
            "Epoch 99/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.9473 - accuracy: 0.5728 - val_loss: 1.0800 - val_accuracy: 0.5087\n",
            "Epoch 100/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.9618 - accuracy: 0.5634 - val_loss: 1.1082 - val_accuracy: 0.4913\n",
            "Epoch 101/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.9697 - accuracy: 0.5635 - val_loss: 1.1236 - val_accuracy: 0.5022\n",
            "Epoch 102/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.9406 - accuracy: 0.5742 - val_loss: 1.0779 - val_accuracy: 0.5306\n",
            "Epoch 103/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.9234 - accuracy: 0.5859 - val_loss: 1.0809 - val_accuracy: 0.5131\n",
            "Epoch 104/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.9149 - accuracy: 0.5922 - val_loss: 1.0770 - val_accuracy: 0.5349\n",
            "Epoch 105/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.9439 - accuracy: 0.5755 - val_loss: 1.0953 - val_accuracy: 0.5044\n",
            "Epoch 106/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.9299 - accuracy: 0.5901 - val_loss: 1.0901 - val_accuracy: 0.5109\n",
            "Epoch 107/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.9346 - accuracy: 0.5788 - val_loss: 1.1123 - val_accuracy: 0.4934\n",
            "Epoch 108/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.9545 - accuracy: 0.5710 - val_loss: 1.1205 - val_accuracy: 0.5218\n",
            "Epoch 109/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.9487 - accuracy: 0.5748 - val_loss: 1.0843 - val_accuracy: 0.5306\n",
            "Epoch 110/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.9298 - accuracy: 0.5827 - val_loss: 1.0833 - val_accuracy: 0.5218\n",
            "Epoch 111/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.9166 - accuracy: 0.5943 - val_loss: 1.0934 - val_accuracy: 0.5153\n",
            "Epoch 112/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.9486 - accuracy: 0.5788 - val_loss: 1.0996 - val_accuracy: 0.5044\n",
            "Epoch 113/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.9745 - accuracy: 0.5812 - val_loss: 1.1031 - val_accuracy: 0.5066\n",
            "Epoch 114/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.9172 - accuracy: 0.5956 - val_loss: 1.0877 - val_accuracy: 0.5218\n",
            "Epoch 115/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.9432 - accuracy: 0.5782 - val_loss: 1.0882 - val_accuracy: 0.5131\n",
            "Epoch 116/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.9331 - accuracy: 0.5896 - val_loss: 1.0907 - val_accuracy: 0.5197\n",
            "Epoch 117/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.9434 - accuracy: 0.5817 - val_loss: 1.0964 - val_accuracy: 0.5175\n",
            "Epoch 118/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.9264 - accuracy: 0.5931 - val_loss: 1.1066 - val_accuracy: 0.5240\n",
            "Epoch 119/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.9286 - accuracy: 0.5913 - val_loss: 1.1241 - val_accuracy: 0.5328\n",
            "Epoch 120/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.9130 - accuracy: 0.5870 - val_loss: 1.0804 - val_accuracy: 0.5066\n",
            "Epoch 121/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.9209 - accuracy: 0.5846 - val_loss: 1.0815 - val_accuracy: 0.5218\n",
            "Epoch 122/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.9113 - accuracy: 0.5984 - val_loss: 1.1056 - val_accuracy: 0.5044\n",
            "Epoch 123/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.9303 - accuracy: 0.5985 - val_loss: 1.0864 - val_accuracy: 0.5240\n",
            "Epoch 124/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.9107 - accuracy: 0.5905 - val_loss: 1.1290 - val_accuracy: 0.5218\n",
            "Epoch 125/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.9408 - accuracy: 0.5831 - val_loss: 1.1085 - val_accuracy: 0.5197\n",
            "Epoch 126/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.9184 - accuracy: 0.5925 - val_loss: 1.1229 - val_accuracy: 0.5218\n",
            "Epoch 127/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.9211 - accuracy: 0.5945 - val_loss: 1.0848 - val_accuracy: 0.5218\n",
            "Epoch 128/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.9104 - accuracy: 0.5939 - val_loss: 1.1040 - val_accuracy: 0.5153\n",
            "Epoch 129/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.9104 - accuracy: 0.5916 - val_loss: 1.1038 - val_accuracy: 0.5044\n",
            "Epoch 130/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.9133 - accuracy: 0.5951 - val_loss: 1.0950 - val_accuracy: 0.5000\n",
            "Epoch 131/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.9011 - accuracy: 0.5956 - val_loss: 1.0986 - val_accuracy: 0.5109\n",
            "Epoch 132/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.9244 - accuracy: 0.5884 - val_loss: 1.0968 - val_accuracy: 0.5087\n",
            "Epoch 133/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.9157 - accuracy: 0.5980 - val_loss: 1.1023 - val_accuracy: 0.5218\n",
            "Epoch 134/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.9209 - accuracy: 0.5872 - val_loss: 1.0988 - val_accuracy: 0.5000\n",
            "Epoch 135/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.9234 - accuracy: 0.5882 - val_loss: 1.1126 - val_accuracy: 0.5262\n",
            "Epoch 136/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.8886 - accuracy: 0.6096 - val_loss: 1.1231 - val_accuracy: 0.5131\n",
            "Epoch 137/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.8988 - accuracy: 0.6153 - val_loss: 1.2024 - val_accuracy: 0.4913\n",
            "Epoch 138/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.9195 - accuracy: 0.5933 - val_loss: 1.1121 - val_accuracy: 0.5000\n",
            "Epoch 139/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.8994 - accuracy: 0.5929 - val_loss: 1.1017 - val_accuracy: 0.5109\n",
            "Epoch 140/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.8925 - accuracy: 0.6081 - val_loss: 1.0890 - val_accuracy: 0.5066\n",
            "Epoch 141/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.9192 - accuracy: 0.5970 - val_loss: 1.1015 - val_accuracy: 0.4978\n",
            "Epoch 142/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.9110 - accuracy: 0.5983 - val_loss: 1.1469 - val_accuracy: 0.5087\n",
            "Epoch 143/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.9071 - accuracy: 0.5926 - val_loss: 1.1142 - val_accuracy: 0.5240\n",
            "Epoch 144/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.9120 - accuracy: 0.6003 - val_loss: 1.1397 - val_accuracy: 0.5328\n",
            "Epoch 145/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.9075 - accuracy: 0.5944 - val_loss: 1.0954 - val_accuracy: 0.5131\n",
            "Epoch 146/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.8780 - accuracy: 0.6207 - val_loss: 1.0840 - val_accuracy: 0.5262\n",
            "Epoch 147/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.8932 - accuracy: 0.5963 - val_loss: 1.1048 - val_accuracy: 0.5175\n",
            "Epoch 148/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.9106 - accuracy: 0.5944 - val_loss: 1.1436 - val_accuracy: 0.5218\n",
            "Epoch 149/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.8727 - accuracy: 0.6175 - val_loss: 1.1012 - val_accuracy: 0.5087\n",
            "Epoch 150/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.8841 - accuracy: 0.6048 - val_loss: 1.1031 - val_accuracy: 0.5153\n",
            "Epoch 151/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.8781 - accuracy: 0.6191 - val_loss: 1.1221 - val_accuracy: 0.5218\n",
            "Epoch 152/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.8759 - accuracy: 0.6037 - val_loss: 1.1382 - val_accuracy: 0.5131\n",
            "Epoch 153/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.8891 - accuracy: 0.6063 - val_loss: 1.1396 - val_accuracy: 0.5153\n",
            "Epoch 154/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.9048 - accuracy: 0.5992 - val_loss: 1.0942 - val_accuracy: 0.5087\n",
            "Epoch 155/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.8884 - accuracy: 0.6100 - val_loss: 1.1006 - val_accuracy: 0.5197\n",
            "Epoch 156/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.8744 - accuracy: 0.6150 - val_loss: 1.1343 - val_accuracy: 0.5087\n",
            "Epoch 157/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.8666 - accuracy: 0.6242 - val_loss: 1.1243 - val_accuracy: 0.4760\n",
            "Epoch 158/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.9144 - accuracy: 0.5910 - val_loss: 1.1125 - val_accuracy: 0.5044\n",
            "Epoch 159/200\n",
            "65/65 [==============================] - 0s 5ms/step - loss: 0.8854 - accuracy: 0.6145 - val_loss: 1.1130 - val_accuracy: 0.5131\n",
            "Epoch 160/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.8671 - accuracy: 0.6216 - val_loss: 1.1095 - val_accuracy: 0.4913\n",
            "Epoch 161/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.8767 - accuracy: 0.6128 - val_loss: 1.1132 - val_accuracy: 0.5066\n",
            "Epoch 162/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.8925 - accuracy: 0.5961 - val_loss: 1.1147 - val_accuracy: 0.5175\n",
            "Epoch 163/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.8828 - accuracy: 0.6153 - val_loss: 1.1346 - val_accuracy: 0.5153\n",
            "Epoch 164/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.8462 - accuracy: 0.6307 - val_loss: 1.1138 - val_accuracy: 0.5218\n",
            "Epoch 165/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.8737 - accuracy: 0.6123 - val_loss: 1.1061 - val_accuracy: 0.5131\n",
            "Epoch 166/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.8695 - accuracy: 0.6078 - val_loss: 1.1129 - val_accuracy: 0.5240\n",
            "Epoch 167/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.8956 - accuracy: 0.5982 - val_loss: 1.1158 - val_accuracy: 0.5066\n",
            "Epoch 168/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.8855 - accuracy: 0.6016 - val_loss: 1.1572 - val_accuracy: 0.4672\n",
            "Epoch 169/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.8731 - accuracy: 0.6231 - val_loss: 1.1228 - val_accuracy: 0.4934\n",
            "Epoch 170/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.8995 - accuracy: 0.5944 - val_loss: 1.1272 - val_accuracy: 0.5240\n",
            "Epoch 171/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.8748 - accuracy: 0.6171 - val_loss: 1.1116 - val_accuracy: 0.5000\n",
            "Epoch 172/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.8722 - accuracy: 0.6127 - val_loss: 1.1365 - val_accuracy: 0.5240\n",
            "Epoch 173/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.9135 - accuracy: 0.5945 - val_loss: 1.1401 - val_accuracy: 0.5197\n",
            "Epoch 174/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.8762 - accuracy: 0.6079 - val_loss: 1.1605 - val_accuracy: 0.4956\n",
            "Epoch 175/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.8654 - accuracy: 0.6129 - val_loss: 1.0937 - val_accuracy: 0.5109\n",
            "Epoch 176/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.8865 - accuracy: 0.5996 - val_loss: 1.1523 - val_accuracy: 0.5197\n",
            "Epoch 177/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.8699 - accuracy: 0.6223 - val_loss: 1.1340 - val_accuracy: 0.4847\n",
            "Epoch 178/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.8693 - accuracy: 0.6211 - val_loss: 1.1307 - val_accuracy: 0.5175\n",
            "Epoch 179/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.8498 - accuracy: 0.6295 - val_loss: 1.1551 - val_accuracy: 0.5306\n",
            "Epoch 180/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.8871 - accuracy: 0.6021 - val_loss: 1.1217 - val_accuracy: 0.5066\n",
            "Epoch 181/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.8597 - accuracy: 0.6200 - val_loss: 1.1233 - val_accuracy: 0.5131\n",
            "Epoch 182/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.8432 - accuracy: 0.6282 - val_loss: 1.1378 - val_accuracy: 0.5262\n",
            "Epoch 183/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.8383 - accuracy: 0.6357 - val_loss: 1.1703 - val_accuracy: 0.5131\n",
            "Epoch 184/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.8724 - accuracy: 0.6180 - val_loss: 1.1507 - val_accuracy: 0.5087\n",
            "Epoch 185/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.8377 - accuracy: 0.6212 - val_loss: 1.1301 - val_accuracy: 0.5131\n",
            "Epoch 186/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.8672 - accuracy: 0.6175 - val_loss: 1.1597 - val_accuracy: 0.4934\n",
            "Epoch 187/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.8544 - accuracy: 0.6241 - val_loss: 1.1563 - val_accuracy: 0.4913\n",
            "Epoch 188/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.8387 - accuracy: 0.6232 - val_loss: 1.1787 - val_accuracy: 0.5044\n",
            "Epoch 189/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.8518 - accuracy: 0.6137 - val_loss: 1.1449 - val_accuracy: 0.4847\n",
            "Epoch 190/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.8372 - accuracy: 0.6376 - val_loss: 1.1586 - val_accuracy: 0.4913\n",
            "Epoch 191/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.8437 - accuracy: 0.6311 - val_loss: 1.1275 - val_accuracy: 0.5044\n",
            "Epoch 192/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.8270 - accuracy: 0.6373 - val_loss: 1.1366 - val_accuracy: 0.5066\n",
            "Epoch 193/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.8420 - accuracy: 0.6260 - val_loss: 1.1685 - val_accuracy: 0.5175\n",
            "Epoch 194/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.8345 - accuracy: 0.6407 - val_loss: 1.1508 - val_accuracy: 0.5218\n",
            "Epoch 195/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.8649 - accuracy: 0.6093 - val_loss: 1.1674 - val_accuracy: 0.4869\n",
            "Epoch 196/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.8211 - accuracy: 0.6360 - val_loss: 1.1528 - val_accuracy: 0.5175\n",
            "Epoch 197/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.8538 - accuracy: 0.6280 - val_loss: 1.1627 - val_accuracy: 0.5197\n",
            "Epoch 198/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.8591 - accuracy: 0.6229 - val_loss: 1.1678 - val_accuracy: 0.5066\n",
            "Epoch 199/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.8276 - accuracy: 0.6343 - val_loss: 1.1858 - val_accuracy: 0.5066\n",
            "Epoch 200/200\n",
            "65/65 [==============================] - 0s 4ms/step - loss: 0.8271 - accuracy: 0.6470 - val_loss: 1.1741 - val_accuracy: 0.5044\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eMBkex9tUfhf"
      },
      "source": [
        "model.save('/content/drive/MyDrive/Colab Notebooks/SPEECH_EMOTION_Recognition/Nộp bài(chốt hạ)/model_saver/basic_tempogram_cremad.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IkazhV_OUfhg"
      },
      "source": [
        "###test_result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AHzPRDEUUfhh",
        "outputId": "3ff6e420-0334-4396-95a3-c0f8f597b9a5"
      },
      "source": [
        "d = {0: 'happy',\n",
        "     1: 'sad',\n",
        "     2: 'angry',\n",
        "     3: 'fear'}\n",
        "Y_test_pred = np.argmax(model.predict(X_test), axis=-1)\n",
        "Y_test_pred = list(map(lambda x: d[x], Y_test_pred))\n",
        "y_test = np.argmax(y_test, axis=-1)\n",
        "y_test = list(map(lambda x: d[x], y_test))\n",
        "print(classification_report(y_test, Y_test_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.65      0.66      0.65       136\n",
            "        fear       0.39      0.35      0.37       134\n",
            "       happy       0.48      0.53      0.50       120\n",
            "         sad       0.59      0.59      0.59       119\n",
            "\n",
            "    accuracy                           0.53       509\n",
            "   macro avg       0.53      0.53      0.53       509\n",
            "weighted avg       0.53      0.53      0.53       509\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "fPqHBDBhUfhj",
        "outputId": "640f9862-8258-4d0d-8971-9d46b2533884"
      },
      "source": [
        "skplt.metrics.plot_confusion_matrix(\n",
        "    y_test, \n",
        "    Y_test_pred,\n",
        "    figsize=(8,8))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fa4e6f29750>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y4YWk4_ZW4wc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q8JULeSZXNcL"
      },
      "source": [
        "# Tempogram + conv1D"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n5SzG82sSkaQ"
      },
      "source": [
        "audio_duration = 3\n",
        "sampling_rate = 22050\n",
        "input_length = sampling_rate * audio_duration"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sOUqwufbXNcd"
      },
      "source": [
        "data = {'labels': [],\n",
        "        'features': []}\n",
        "\n",
        "for i in range(len(CREMA_D_df)):\n",
        "  if ((CREMA_D_df['Emotion'][i] == 'HAP') | (CREMA_D_df['Emotion'][i] == 'SAD') | \n",
        "      (CREMA_D_df['Emotion'][i] == 'ANG') | (CREMA_D_df['Emotion'][i] == 'FEA')):\n",
        "    \n",
        "    if CREMA_D_df['Emotion'][i] == 'HAP':\n",
        "      data['labels'].append(0)\n",
        "    elif CREMA_D_df['Emotion'][i] == 'SAD':\n",
        "      data['labels'].append(1)\n",
        "    elif CREMA_D_df['Emotion'][i] == 'ANG':\n",
        "      data['labels'].append(2)\n",
        "    elif CREMA_D_df['Emotion'][i] == 'FEA':\n",
        "      data['labels'].append(3)\n",
        "\n",
        "\n",
        "    signal, sr =  librosa.load(CREMA_D_df['Paths'][i])\n",
        "    if len(signal) > input_length:\n",
        "        signal = signal[0:input_length]\n",
        "    elif  input_length > len(signal):\n",
        "        max_offset = input_length - len(signal)  \n",
        "        signal = np.pad(signal, (0, max_offset), \"constant\")\n",
        "    tempogram = librosa.feature.tempogram(signal, sr)\n",
        "    data['features'].append(tempogram)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDZ1IDBSXNce"
      },
      "source": [
        "X = data['features']\n",
        "y = data['labels']\n",
        "\n",
        "y = np.array(y)\n",
        "y = to_categorical(y)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=0)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=0)\n",
        "\n",
        "X_train = np.array(X_train)\n",
        "X_test = np.array(X_test)\n",
        "X_val = np.array(X_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ytS1moepYT3l",
        "outputId": "993f60b7-0fee-43af-fb2e-cafb3129fad7"
      },
      "source": [
        "X_train.shape,X_test.shape,y_train.shape,y_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((4117, 384, 130), (509, 384, 130), (4117, 4), (509, 4))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RKGOhIllYlwH"
      },
      "source": [
        "### conv1D"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0yrT1F9IYlwI"
      },
      "source": [
        "\n",
        "# CNN I/P Config\n",
        "num_classes = 4\n",
        "input_shape = X_train.shape[1:]\n",
        "learning_rate = 0.0001\n",
        "decay = 1e-6\n",
        "momentum = 0.9\n",
        "\n",
        "#LSTM Configuration\n",
        "num_lstm = 256"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EHg7H9sOYlwK",
        "outputId": "cb9acd53-93ac-4588-bf5d-c48b53bfcbae"
      },
      "source": [
        "model = Sequential(name='Audio_CNN_1D')\n",
        "\n",
        "# LFLB1\n",
        "model.add(Conv1D(filters=64, kernel_size=(3), strides=1, padding='same', data_format='channels_last',input_shape=input_shape))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('elu'))\n",
        "model.add(MaxPooling1D(pool_size=4, strides=4))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "# LFLB2\n",
        "model.add(Conv1D(filters=64, kernel_size=3, strides=1, padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('elu'))\n",
        "model.add(MaxPooling1D(pool_size=4, strides=4))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# LFLB3\n",
        "model.add(Conv1D(filters=128, kernel_size=3, strides=1, padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('elu'))\n",
        "model.add(MaxPooling1D(pool_size=4, strides=4))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# LFLB4\n",
        "model.add(Conv1D(filters=128, kernel_size=3, strides=1, padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('elu'))\n",
        "model.add(MaxPooling1D(pool_size=4, strides=4))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# LSTM\n",
        "model.add(LSTM(units=num_lstm))\n",
        "\n",
        "# FC\n",
        "model.add(Dense(units=num_classes, activation='softmax'))\n",
        "\n",
        "# Model compilation\n",
        "opt= keras.optimizers.Adam(lr=0.01, beta_1=0.9,  beta_2=0.999, amsgrad=False)\n",
        "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
        "\n",
        "model.summary()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"Audio_CNN_1D\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 384, 64)           25024     \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 384, 64)           256       \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 384, 64)           0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D) (None, 96, 64)            0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 96, 64)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 96, 64)            12352     \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 96, 64)            256       \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 96, 64)            0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1 (None, 24, 64)            0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 24, 64)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 24, 128)           24704     \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 24, 128)           512       \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 24, 128)           0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_2 (MaxPooling1 (None, 6, 128)            0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 6, 128)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 6, 128)            49280     \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 6, 128)            512       \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 6, 128)            0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_3 (MaxPooling1 (None, 1, 128)            0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 1, 128)            0         \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 256)               394240    \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 4)                 1028      \n",
            "=================================================================\n",
            "Total params: 508,164\n",
            "Trainable params: 507,396\n",
            "Non-trainable params: 768\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xGb90pjgYlwM",
        "outputId": "a3c6d76c-e18a-4a80-db46-2939c3d13e25"
      },
      "source": [
        "#Train Config\n",
        "\n",
        "batch_size = 16\n",
        "num_epochs = 200\n",
        "\n",
        "# Model Training\n",
        "lr_reduce = ReduceLROnPlateau(monitor='val_loss', factor=0.9, patience=20, min_lr=0.000001)\n",
        "# Please change the model name accordingly.\n",
        "mcp_save = ModelCheckpoint('/content/Audio_1DCNN.h5', save_best_only=True, monitor='val_categorical_accuracy', mode='max')\n",
        "cnnhistory=model.fit(X_train, y_train, batch_size=batch_size, epochs=num_epochs,validation_data=(X_val, y_val), callbacks=[mcp_save, lr_reduce])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "258/258 [==============================] - 57s 17ms/step - loss: 1.3297 - categorical_accuracy: 0.3860 - val_loss: 1.2660 - val_categorical_accuracy: 0.4039\n",
            "Epoch 2/200\n",
            "258/258 [==============================] - 3s 11ms/step - loss: 1.2090 - categorical_accuracy: 0.4363 - val_loss: 1.3157 - val_categorical_accuracy: 0.3515\n",
            "Epoch 3/200\n",
            "258/258 [==============================] - 3s 11ms/step - loss: 1.1967 - categorical_accuracy: 0.4283 - val_loss: 1.4915 - val_categorical_accuracy: 0.2860\n",
            "Epoch 4/200\n",
            "258/258 [==============================] - 3s 11ms/step - loss: 1.1713 - categorical_accuracy: 0.4635 - val_loss: 1.2189 - val_categorical_accuracy: 0.4192\n",
            "Epoch 5/200\n",
            "258/258 [==============================] - 3s 11ms/step - loss: 1.1597 - categorical_accuracy: 0.4676 - val_loss: 1.5529 - val_categorical_accuracy: 0.2511\n",
            "Epoch 6/200\n",
            "258/258 [==============================] - 3s 11ms/step - loss: 1.1648 - categorical_accuracy: 0.4532 - val_loss: 1.1561 - val_categorical_accuracy: 0.4913\n",
            "Epoch 7/200\n",
            "258/258 [==============================] - 3s 11ms/step - loss: 1.1795 - categorical_accuracy: 0.4560 - val_loss: 1.2665 - val_categorical_accuracy: 0.3668\n",
            "Epoch 8/200\n",
            "258/258 [==============================] - 3s 11ms/step - loss: 1.1577 - categorical_accuracy: 0.4729 - val_loss: 1.5471 - val_categorical_accuracy: 0.2707\n",
            "Epoch 9/200\n",
            "258/258 [==============================] - 3s 11ms/step - loss: 1.1428 - categorical_accuracy: 0.4653 - val_loss: 1.4431 - val_categorical_accuracy: 0.3122\n",
            "Epoch 10/200\n",
            "258/258 [==============================] - 3s 11ms/step - loss: 1.1636 - categorical_accuracy: 0.4568 - val_loss: 1.8658 - val_categorical_accuracy: 0.2598\n",
            "Epoch 11/200\n",
            "258/258 [==============================] - 3s 11ms/step - loss: 1.1430 - categorical_accuracy: 0.4821 - val_loss: 1.6159 - val_categorical_accuracy: 0.2489\n",
            "Epoch 12/200\n",
            "258/258 [==============================] - 3s 11ms/step - loss: 1.1769 - categorical_accuracy: 0.4495 - val_loss: 1.3429 - val_categorical_accuracy: 0.3777\n",
            "Epoch 13/200\n",
            "258/258 [==============================] - 3s 11ms/step - loss: 1.1292 - categorical_accuracy: 0.4800 - val_loss: 1.4536 - val_categorical_accuracy: 0.2773\n",
            "Epoch 14/200\n",
            "258/258 [==============================] - 3s 11ms/step - loss: 1.1492 - categorical_accuracy: 0.4811 - val_loss: 1.2906 - val_categorical_accuracy: 0.3668\n",
            "Epoch 15/200\n",
            "258/258 [==============================] - 3s 11ms/step - loss: 1.1458 - categorical_accuracy: 0.4770 - val_loss: 1.8200 - val_categorical_accuracy: 0.2817\n",
            "Epoch 16/200\n",
            "258/258 [==============================] - 3s 11ms/step - loss: 1.1651 - categorical_accuracy: 0.4631 - val_loss: 1.4943 - val_categorical_accuracy: 0.2991\n",
            "Epoch 17/200\n",
            "258/258 [==============================] - 3s 11ms/step - loss: 1.1507 - categorical_accuracy: 0.4688 - val_loss: 1.5275 - val_categorical_accuracy: 0.3166\n",
            "Epoch 18/200\n",
            "258/258 [==============================] - 3s 11ms/step - loss: 1.1561 - categorical_accuracy: 0.4675 - val_loss: 1.1374 - val_categorical_accuracy: 0.5066\n",
            "Epoch 19/200\n",
            "258/258 [==============================] - 3s 11ms/step - loss: 1.1601 - categorical_accuracy: 0.4633 - val_loss: 1.4182 - val_categorical_accuracy: 0.3275\n",
            "Epoch 20/200\n",
            "258/258 [==============================] - 3s 11ms/step - loss: 1.1668 - categorical_accuracy: 0.4505 - val_loss: 1.5871 - val_categorical_accuracy: 0.2620\n",
            "Epoch 21/200\n",
            "258/258 [==============================] - 3s 11ms/step - loss: 1.1460 - categorical_accuracy: 0.4648 - val_loss: 1.5741 - val_categorical_accuracy: 0.2489\n",
            "Epoch 22/200\n",
            "258/258 [==============================] - 3s 10ms/step - loss: 1.1585 - categorical_accuracy: 0.4596 - val_loss: 1.3523 - val_categorical_accuracy: 0.3603\n",
            "Epoch 23/200\n",
            "258/258 [==============================] - 3s 11ms/step - loss: 1.1450 - categorical_accuracy: 0.4739 - val_loss: 1.5933 - val_categorical_accuracy: 0.2817\n",
            "Epoch 24/200\n",
            "258/258 [==============================] - 3s 11ms/step - loss: 1.1174 - categorical_accuracy: 0.4572 - val_loss: 1.3566 - val_categorical_accuracy: 0.3624\n",
            "Epoch 25/200\n",
            "258/258 [==============================] - 3s 11ms/step - loss: 1.1466 - categorical_accuracy: 0.4823 - val_loss: 1.3021 - val_categorical_accuracy: 0.3734\n",
            "Epoch 26/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.1443 - categorical_accuracy: 0.4743 - val_loss: 1.5703 - val_categorical_accuracy: 0.3231\n",
            "Epoch 27/200\n",
            "258/258 [==============================] - 3s 11ms/step - loss: 1.1411 - categorical_accuracy: 0.4731 - val_loss: 1.3198 - val_categorical_accuracy: 0.3493\n",
            "Epoch 28/200\n",
            "258/258 [==============================] - 3s 11ms/step - loss: 1.1284 - categorical_accuracy: 0.4854 - val_loss: 1.3173 - val_categorical_accuracy: 0.3690\n",
            "Epoch 29/200\n",
            "258/258 [==============================] - 3s 11ms/step - loss: 1.1173 - categorical_accuracy: 0.4870 - val_loss: 1.2784 - val_categorical_accuracy: 0.3952\n",
            "Epoch 30/200\n",
            "258/258 [==============================] - 3s 11ms/step - loss: 1.1298 - categorical_accuracy: 0.4904 - val_loss: 1.2520 - val_categorical_accuracy: 0.4170\n",
            "Epoch 31/200\n",
            "258/258 [==============================] - 3s 11ms/step - loss: 1.1340 - categorical_accuracy: 0.4735 - val_loss: 1.5275 - val_categorical_accuracy: 0.2991\n",
            "Epoch 32/200\n",
            "258/258 [==============================] - 3s 11ms/step - loss: 1.1584 - categorical_accuracy: 0.4497 - val_loss: 1.2976 - val_categorical_accuracy: 0.3777\n",
            "Epoch 33/200\n",
            "258/258 [==============================] - 3s 11ms/step - loss: 1.1598 - categorical_accuracy: 0.4619 - val_loss: 1.7251 - val_categorical_accuracy: 0.2576\n",
            "Epoch 34/200\n",
            "258/258 [==============================] - 3s 11ms/step - loss: 1.1619 - categorical_accuracy: 0.4567 - val_loss: 1.3507 - val_categorical_accuracy: 0.3603\n",
            "Epoch 35/200\n",
            "258/258 [==============================] - 3s 11ms/step - loss: 1.1322 - categorical_accuracy: 0.4642 - val_loss: 1.2735 - val_categorical_accuracy: 0.3712\n",
            "Epoch 36/200\n",
            "258/258 [==============================] - 3s 11ms/step - loss: 1.1513 - categorical_accuracy: 0.4698 - val_loss: 1.3386 - val_categorical_accuracy: 0.4017\n",
            "Epoch 37/200\n",
            "258/258 [==============================] - 3s 11ms/step - loss: 1.1254 - categorical_accuracy: 0.4966 - val_loss: 2.1417 - val_categorical_accuracy: 0.2380\n",
            "Epoch 38/200\n",
            "258/258 [==============================] - 3s 11ms/step - loss: 1.1131 - categorical_accuracy: 0.4922 - val_loss: 1.2716 - val_categorical_accuracy: 0.4039\n",
            "Epoch 39/200\n",
            "258/258 [==============================] - 3s 11ms/step - loss: 1.1368 - categorical_accuracy: 0.4880 - val_loss: 1.4883 - val_categorical_accuracy: 0.3035\n",
            "Epoch 40/200\n",
            "258/258 [==============================] - 3s 11ms/step - loss: 1.1206 - categorical_accuracy: 0.4765 - val_loss: 1.5279 - val_categorical_accuracy: 0.3013\n",
            "Epoch 41/200\n",
            "258/258 [==============================] - 3s 11ms/step - loss: 1.1383 - categorical_accuracy: 0.4781 - val_loss: 1.7362 - val_categorical_accuracy: 0.2664\n",
            "Epoch 42/200\n",
            "258/258 [==============================] - 3s 11ms/step - loss: 1.1242 - categorical_accuracy: 0.4935 - val_loss: 1.1443 - val_categorical_accuracy: 0.4454\n",
            "Epoch 43/200\n",
            "258/258 [==============================] - 3s 11ms/step - loss: 1.1608 - categorical_accuracy: 0.4603 - val_loss: 1.4728 - val_categorical_accuracy: 0.3188\n",
            "Epoch 44/200\n",
            "258/258 [==============================] - 3s 11ms/step - loss: 1.1245 - categorical_accuracy: 0.4656 - val_loss: 1.6169 - val_categorical_accuracy: 0.3231\n",
            "Epoch 45/200\n",
            "258/258 [==============================] - 3s 11ms/step - loss: 1.1345 - categorical_accuracy: 0.4805 - val_loss: 1.2484 - val_categorical_accuracy: 0.4345\n",
            "Epoch 46/200\n",
            "258/258 [==============================] - 3s 11ms/step - loss: 1.1384 - categorical_accuracy: 0.4931 - val_loss: 1.1971 - val_categorical_accuracy: 0.4061\n",
            "Epoch 47/200\n",
            "258/258 [==============================] - 3s 11ms/step - loss: 1.1427 - categorical_accuracy: 0.4857 - val_loss: 1.3865 - val_categorical_accuracy: 0.3559\n",
            "Epoch 48/200\n",
            "258/258 [==============================] - 3s 11ms/step - loss: 1.1365 - categorical_accuracy: 0.4739 - val_loss: 1.5623 - val_categorical_accuracy: 0.2904\n",
            "Epoch 49/200\n",
            "258/258 [==============================] - 3s 11ms/step - loss: 1.1261 - categorical_accuracy: 0.4826 - val_loss: 1.4842 - val_categorical_accuracy: 0.2969\n",
            "Epoch 50/200\n",
            "258/258 [==============================] - 3s 11ms/step - loss: 1.1400 - categorical_accuracy: 0.4655 - val_loss: 1.7932 - val_categorical_accuracy: 0.2664\n",
            "Epoch 51/200\n",
            "258/258 [==============================] - 3s 11ms/step - loss: 1.1490 - categorical_accuracy: 0.4765 - val_loss: 1.2300 - val_categorical_accuracy: 0.4061\n",
            "Epoch 52/200\n",
            "258/258 [==============================] - 3s 11ms/step - loss: 1.1183 - categorical_accuracy: 0.4918 - val_loss: 1.4241 - val_categorical_accuracy: 0.3755\n",
            "Epoch 53/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.1221 - categorical_accuracy: 0.4836 - val_loss: 1.3045 - val_categorical_accuracy: 0.3843\n",
            "Epoch 54/200\n",
            "258/258 [==============================] - 3s 11ms/step - loss: 1.1207 - categorical_accuracy: 0.4839 - val_loss: 1.2180 - val_categorical_accuracy: 0.4345\n",
            "Epoch 55/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.1374 - categorical_accuracy: 0.4823 - val_loss: 1.3796 - val_categorical_accuracy: 0.3734\n",
            "Epoch 56/200\n",
            "258/258 [==============================] - 3s 11ms/step - loss: 1.1224 - categorical_accuracy: 0.4990 - val_loss: 1.2239 - val_categorical_accuracy: 0.4367\n",
            "Epoch 57/200\n",
            "258/258 [==============================] - 3s 11ms/step - loss: 1.1356 - categorical_accuracy: 0.4817 - val_loss: 1.3849 - val_categorical_accuracy: 0.3013\n",
            "Epoch 58/200\n",
            "258/258 [==============================] - 3s 11ms/step - loss: 1.1455 - categorical_accuracy: 0.4584 - val_loss: 1.6214 - val_categorical_accuracy: 0.2707\n",
            "Epoch 59/200\n",
            "258/258 [==============================] - 3s 11ms/step - loss: 1.1174 - categorical_accuracy: 0.4948 - val_loss: 1.2010 - val_categorical_accuracy: 0.4389\n",
            "Epoch 60/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.1183 - categorical_accuracy: 0.4892 - val_loss: 1.2310 - val_categorical_accuracy: 0.3996\n",
            "Epoch 61/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.1176 - categorical_accuracy: 0.4876 - val_loss: 1.1179 - val_categorical_accuracy: 0.5044\n",
            "Epoch 62/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.1176 - categorical_accuracy: 0.4917 - val_loss: 1.3507 - val_categorical_accuracy: 0.3319\n",
            "Epoch 63/200\n",
            "258/258 [==============================] - 3s 11ms/step - loss: 1.1309 - categorical_accuracy: 0.4838 - val_loss: 1.3509 - val_categorical_accuracy: 0.3690\n",
            "Epoch 64/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.1120 - categorical_accuracy: 0.4984 - val_loss: 1.4065 - val_categorical_accuracy: 0.3472\n",
            "Epoch 65/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.1040 - categorical_accuracy: 0.4958 - val_loss: 1.4664 - val_categorical_accuracy: 0.3384\n",
            "Epoch 66/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.1181 - categorical_accuracy: 0.4888 - val_loss: 1.2958 - val_categorical_accuracy: 0.3690\n",
            "Epoch 67/200\n",
            "258/258 [==============================] - 3s 11ms/step - loss: 1.1172 - categorical_accuracy: 0.4931 - val_loss: 1.3735 - val_categorical_accuracy: 0.3406\n",
            "Epoch 68/200\n",
            "258/258 [==============================] - 3s 11ms/step - loss: 1.1177 - categorical_accuracy: 0.4839 - val_loss: 1.5543 - val_categorical_accuracy: 0.3057\n",
            "Epoch 69/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.1465 - categorical_accuracy: 0.4628 - val_loss: 1.5916 - val_categorical_accuracy: 0.2991\n",
            "Epoch 70/200\n",
            "258/258 [==============================] - 3s 11ms/step - loss: 1.1368 - categorical_accuracy: 0.4720 - val_loss: 1.1383 - val_categorical_accuracy: 0.4672\n",
            "Epoch 71/200\n",
            "258/258 [==============================] - 3s 11ms/step - loss: 1.1378 - categorical_accuracy: 0.4616 - val_loss: 1.1706 - val_categorical_accuracy: 0.4629\n",
            "Epoch 72/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.1086 - categorical_accuracy: 0.4952 - val_loss: 1.2960 - val_categorical_accuracy: 0.3908\n",
            "Epoch 73/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.1045 - categorical_accuracy: 0.4927 - val_loss: 1.2106 - val_categorical_accuracy: 0.3908\n",
            "Epoch 74/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0815 - categorical_accuracy: 0.5039 - val_loss: 1.5038 - val_categorical_accuracy: 0.3253\n",
            "Epoch 75/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0975 - categorical_accuracy: 0.5005 - val_loss: 1.3563 - val_categorical_accuracy: 0.3384\n",
            "Epoch 76/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.1072 - categorical_accuracy: 0.4905 - val_loss: 1.1414 - val_categorical_accuracy: 0.4432\n",
            "Epoch 77/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.1154 - categorical_accuracy: 0.4664 - val_loss: 1.1636 - val_categorical_accuracy: 0.4454\n",
            "Epoch 78/200\n",
            "258/258 [==============================] - 3s 13ms/step - loss: 1.1123 - categorical_accuracy: 0.4786 - val_loss: 1.1584 - val_categorical_accuracy: 0.4432\n",
            "Epoch 79/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0860 - categorical_accuracy: 0.5017 - val_loss: 1.9847 - val_categorical_accuracy: 0.2380\n",
            "Epoch 80/200\n",
            "258/258 [==============================] - 3s 13ms/step - loss: 1.1495 - categorical_accuracy: 0.4635 - val_loss: 1.3710 - val_categorical_accuracy: 0.3319\n",
            "Epoch 81/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0867 - categorical_accuracy: 0.5159 - val_loss: 1.2647 - val_categorical_accuracy: 0.3821\n",
            "Epoch 82/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0980 - categorical_accuracy: 0.4990 - val_loss: 1.4404 - val_categorical_accuracy: 0.3603\n",
            "Epoch 83/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0874 - categorical_accuracy: 0.5013 - val_loss: 1.2890 - val_categorical_accuracy: 0.3384\n",
            "Epoch 84/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0979 - categorical_accuracy: 0.4871 - val_loss: 1.5044 - val_categorical_accuracy: 0.3341\n",
            "Epoch 85/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.1344 - categorical_accuracy: 0.4744 - val_loss: 1.6975 - val_categorical_accuracy: 0.2926\n",
            "Epoch 86/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0820 - categorical_accuracy: 0.4986 - val_loss: 1.1046 - val_categorical_accuracy: 0.4803\n",
            "Epoch 87/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.1188 - categorical_accuracy: 0.4901 - val_loss: 1.3130 - val_categorical_accuracy: 0.3974\n",
            "Epoch 88/200\n",
            "258/258 [==============================] - 3s 11ms/step - loss: 1.0943 - categorical_accuracy: 0.4874 - val_loss: 1.3487 - val_categorical_accuracy: 0.3712\n",
            "Epoch 89/200\n",
            "258/258 [==============================] - 3s 11ms/step - loss: 1.1095 - categorical_accuracy: 0.4835 - val_loss: 1.3268 - val_categorical_accuracy: 0.3712\n",
            "Epoch 90/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.1307 - categorical_accuracy: 0.4886 - val_loss: 1.3894 - val_categorical_accuracy: 0.3275\n",
            "Epoch 91/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0870 - categorical_accuracy: 0.4933 - val_loss: 1.5554 - val_categorical_accuracy: 0.3450\n",
            "Epoch 92/200\n",
            "258/258 [==============================] - 3s 11ms/step - loss: 1.0930 - categorical_accuracy: 0.4968 - val_loss: 1.4811 - val_categorical_accuracy: 0.2926\n",
            "Epoch 93/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0974 - categorical_accuracy: 0.4987 - val_loss: 1.2681 - val_categorical_accuracy: 0.3930\n",
            "Epoch 94/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.1285 - categorical_accuracy: 0.4749 - val_loss: 1.2688 - val_categorical_accuracy: 0.4541\n",
            "Epoch 95/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.1154 - categorical_accuracy: 0.4818 - val_loss: 1.1725 - val_categorical_accuracy: 0.4541\n",
            "Epoch 96/200\n",
            "258/258 [==============================] - 3s 11ms/step - loss: 1.1057 - categorical_accuracy: 0.4801 - val_loss: 1.5191 - val_categorical_accuracy: 0.3253\n",
            "Epoch 97/200\n",
            "258/258 [==============================] - 3s 11ms/step - loss: 1.1045 - categorical_accuracy: 0.4903 - val_loss: 1.3672 - val_categorical_accuracy: 0.3799\n",
            "Epoch 98/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0844 - categorical_accuracy: 0.5031 - val_loss: 1.1528 - val_categorical_accuracy: 0.4585\n",
            "Epoch 99/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.1231 - categorical_accuracy: 0.4841 - val_loss: 1.3069 - val_categorical_accuracy: 0.3974\n",
            "Epoch 100/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.1076 - categorical_accuracy: 0.5028 - val_loss: 1.3793 - val_categorical_accuracy: 0.3537\n",
            "Epoch 101/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.1067 - categorical_accuracy: 0.5132 - val_loss: 1.1404 - val_categorical_accuracy: 0.4760\n",
            "Epoch 102/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0879 - categorical_accuracy: 0.5046 - val_loss: 1.1916 - val_categorical_accuracy: 0.4672\n",
            "Epoch 103/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0943 - categorical_accuracy: 0.4904 - val_loss: 1.1838 - val_categorical_accuracy: 0.4148\n",
            "Epoch 104/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.1096 - categorical_accuracy: 0.5073 - val_loss: 1.1227 - val_categorical_accuracy: 0.4651\n",
            "Epoch 105/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.1173 - categorical_accuracy: 0.4955 - val_loss: 1.2628 - val_categorical_accuracy: 0.4170\n",
            "Epoch 106/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0726 - categorical_accuracy: 0.5064 - val_loss: 1.2931 - val_categorical_accuracy: 0.3930\n",
            "Epoch 107/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0971 - categorical_accuracy: 0.5054 - val_loss: 1.2831 - val_categorical_accuracy: 0.3799\n",
            "Epoch 108/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0931 - categorical_accuracy: 0.5092 - val_loss: 1.6116 - val_categorical_accuracy: 0.2817\n",
            "Epoch 109/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.1009 - categorical_accuracy: 0.4936 - val_loss: 1.2534 - val_categorical_accuracy: 0.4323\n",
            "Epoch 110/200\n",
            "258/258 [==============================] - 3s 11ms/step - loss: 1.0903 - categorical_accuracy: 0.4905 - val_loss: 1.1541 - val_categorical_accuracy: 0.4563\n",
            "Epoch 111/200\n",
            "258/258 [==============================] - 3s 11ms/step - loss: 1.0857 - categorical_accuracy: 0.4935 - val_loss: 1.4095 - val_categorical_accuracy: 0.3537\n",
            "Epoch 112/200\n",
            "258/258 [==============================] - 3s 11ms/step - loss: 1.1149 - categorical_accuracy: 0.4933 - val_loss: 1.1620 - val_categorical_accuracy: 0.4367\n",
            "Epoch 113/200\n",
            "258/258 [==============================] - 3s 11ms/step - loss: 1.0939 - categorical_accuracy: 0.4894 - val_loss: 1.2527 - val_categorical_accuracy: 0.3843\n",
            "Epoch 114/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0885 - categorical_accuracy: 0.4967 - val_loss: 1.4400 - val_categorical_accuracy: 0.3493\n",
            "Epoch 115/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.1016 - categorical_accuracy: 0.4888 - val_loss: 1.3300 - val_categorical_accuracy: 0.3755\n",
            "Epoch 116/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0875 - categorical_accuracy: 0.4958 - val_loss: 1.2171 - val_categorical_accuracy: 0.4105\n",
            "Epoch 117/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0963 - categorical_accuracy: 0.4877 - val_loss: 1.3966 - val_categorical_accuracy: 0.3821\n",
            "Epoch 118/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0974 - categorical_accuracy: 0.4974 - val_loss: 1.1679 - val_categorical_accuracy: 0.4563\n",
            "Epoch 119/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0877 - categorical_accuracy: 0.5080 - val_loss: 1.2320 - val_categorical_accuracy: 0.4148\n",
            "Epoch 120/200\n",
            "258/258 [==============================] - 3s 11ms/step - loss: 1.0992 - categorical_accuracy: 0.4940 - val_loss: 1.1328 - val_categorical_accuracy: 0.4367\n",
            "Epoch 121/200\n",
            "258/258 [==============================] - 3s 11ms/step - loss: 1.0996 - categorical_accuracy: 0.4926 - val_loss: 1.2485 - val_categorical_accuracy: 0.3843\n",
            "Epoch 122/200\n",
            "258/258 [==============================] - 3s 11ms/step - loss: 1.0941 - categorical_accuracy: 0.4869 - val_loss: 1.4294 - val_categorical_accuracy: 0.3559\n",
            "Epoch 123/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0851 - categorical_accuracy: 0.4966 - val_loss: 1.2264 - val_categorical_accuracy: 0.4301\n",
            "Epoch 124/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0781 - categorical_accuracy: 0.5020 - val_loss: 1.1874 - val_categorical_accuracy: 0.4454\n",
            "Epoch 125/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0944 - categorical_accuracy: 0.4961 - val_loss: 1.4922 - val_categorical_accuracy: 0.3493\n",
            "Epoch 126/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.1105 - categorical_accuracy: 0.4942 - val_loss: 1.1672 - val_categorical_accuracy: 0.4760\n",
            "Epoch 127/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0678 - categorical_accuracy: 0.5110 - val_loss: 1.1306 - val_categorical_accuracy: 0.4869\n",
            "Epoch 128/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0988 - categorical_accuracy: 0.4878 - val_loss: 1.3244 - val_categorical_accuracy: 0.3734\n",
            "Epoch 129/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0768 - categorical_accuracy: 0.5153 - val_loss: 1.3001 - val_categorical_accuracy: 0.3865\n",
            "Epoch 130/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0776 - categorical_accuracy: 0.5174 - val_loss: 1.1848 - val_categorical_accuracy: 0.4760\n",
            "Epoch 131/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0982 - categorical_accuracy: 0.4877 - val_loss: 1.4285 - val_categorical_accuracy: 0.3079\n",
            "Epoch 132/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0920 - categorical_accuracy: 0.4989 - val_loss: 1.3208 - val_categorical_accuracy: 0.4105\n",
            "Epoch 133/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0814 - categorical_accuracy: 0.5124 - val_loss: 1.1522 - val_categorical_accuracy: 0.4825\n",
            "Epoch 134/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0713 - categorical_accuracy: 0.5150 - val_loss: 1.1268 - val_categorical_accuracy: 0.4672\n",
            "Epoch 135/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0940 - categorical_accuracy: 0.4835 - val_loss: 1.0989 - val_categorical_accuracy: 0.4934\n",
            "Epoch 136/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0783 - categorical_accuracy: 0.5102 - val_loss: 1.3763 - val_categorical_accuracy: 0.3777\n",
            "Epoch 137/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0441 - categorical_accuracy: 0.5318 - val_loss: 1.1563 - val_categorical_accuracy: 0.4607\n",
            "Epoch 138/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0703 - categorical_accuracy: 0.5177 - val_loss: 1.1657 - val_categorical_accuracy: 0.4651\n",
            "Epoch 139/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0881 - categorical_accuracy: 0.5048 - val_loss: 1.2448 - val_categorical_accuracy: 0.3996\n",
            "Epoch 140/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0755 - categorical_accuracy: 0.4913 - val_loss: 1.1832 - val_categorical_accuracy: 0.4039\n",
            "Epoch 141/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0968 - categorical_accuracy: 0.5006 - val_loss: 1.2340 - val_categorical_accuracy: 0.4039\n",
            "Epoch 142/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0771 - categorical_accuracy: 0.5217 - val_loss: 1.1595 - val_categorical_accuracy: 0.4629\n",
            "Epoch 143/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0992 - categorical_accuracy: 0.5012 - val_loss: 1.2371 - val_categorical_accuracy: 0.3952\n",
            "Epoch 144/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0865 - categorical_accuracy: 0.4939 - val_loss: 1.1469 - val_categorical_accuracy: 0.4672\n",
            "Epoch 145/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0853 - categorical_accuracy: 0.5073 - val_loss: 1.1160 - val_categorical_accuracy: 0.4760\n",
            "Epoch 146/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0849 - categorical_accuracy: 0.5106 - val_loss: 1.1444 - val_categorical_accuracy: 0.4367\n",
            "Epoch 147/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0788 - categorical_accuracy: 0.5211 - val_loss: 1.1896 - val_categorical_accuracy: 0.4454\n",
            "Epoch 148/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0660 - categorical_accuracy: 0.5217 - val_loss: 1.0974 - val_categorical_accuracy: 0.5044\n",
            "Epoch 149/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0907 - categorical_accuracy: 0.4954 - val_loss: 1.1732 - val_categorical_accuracy: 0.4432\n",
            "Epoch 150/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0837 - categorical_accuracy: 0.5059 - val_loss: 1.5319 - val_categorical_accuracy: 0.2991\n",
            "Epoch 151/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0705 - categorical_accuracy: 0.5074 - val_loss: 1.2779 - val_categorical_accuracy: 0.3886\n",
            "Epoch 152/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0955 - categorical_accuracy: 0.5027 - val_loss: 1.2951 - val_categorical_accuracy: 0.3755\n",
            "Epoch 153/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0904 - categorical_accuracy: 0.4877 - val_loss: 1.2370 - val_categorical_accuracy: 0.4258\n",
            "Epoch 154/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0837 - categorical_accuracy: 0.4936 - val_loss: 1.1228 - val_categorical_accuracy: 0.4891\n",
            "Epoch 155/200\n",
            "258/258 [==============================] - 3s 13ms/step - loss: 1.1033 - categorical_accuracy: 0.4962 - val_loss: 1.3340 - val_categorical_accuracy: 0.3974\n",
            "Epoch 156/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0982 - categorical_accuracy: 0.5232 - val_loss: 1.2867 - val_categorical_accuracy: 0.4148\n",
            "Epoch 157/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0841 - categorical_accuracy: 0.5059 - val_loss: 1.1563 - val_categorical_accuracy: 0.4694\n",
            "Epoch 158/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0652 - categorical_accuracy: 0.5196 - val_loss: 1.3179 - val_categorical_accuracy: 0.3624\n",
            "Epoch 159/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0820 - categorical_accuracy: 0.4901 - val_loss: 1.1686 - val_categorical_accuracy: 0.4279\n",
            "Epoch 160/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0745 - categorical_accuracy: 0.4962 - val_loss: 1.3407 - val_categorical_accuracy: 0.3603\n",
            "Epoch 161/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0782 - categorical_accuracy: 0.5215 - val_loss: 1.2557 - val_categorical_accuracy: 0.3799\n",
            "Epoch 162/200\n",
            "258/258 [==============================] - 3s 11ms/step - loss: 1.0888 - categorical_accuracy: 0.5165 - val_loss: 1.1931 - val_categorical_accuracy: 0.4258\n",
            "Epoch 163/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0759 - categorical_accuracy: 0.5100 - val_loss: 1.2578 - val_categorical_accuracy: 0.3821\n",
            "Epoch 164/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0939 - categorical_accuracy: 0.5027 - val_loss: 1.1225 - val_categorical_accuracy: 0.4738\n",
            "Epoch 165/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0661 - categorical_accuracy: 0.5023 - val_loss: 1.3052 - val_categorical_accuracy: 0.3974\n",
            "Epoch 166/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0781 - categorical_accuracy: 0.4974 - val_loss: 1.2288 - val_categorical_accuracy: 0.4039\n",
            "Epoch 167/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0798 - categorical_accuracy: 0.5093 - val_loss: 1.2051 - val_categorical_accuracy: 0.4323\n",
            "Epoch 168/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0872 - categorical_accuracy: 0.5058 - val_loss: 1.1006 - val_categorical_accuracy: 0.4913\n",
            "Epoch 169/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0714 - categorical_accuracy: 0.5087 - val_loss: 1.3184 - val_categorical_accuracy: 0.3603\n",
            "Epoch 170/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0864 - categorical_accuracy: 0.4922 - val_loss: 1.2778 - val_categorical_accuracy: 0.4148\n",
            "Epoch 171/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0871 - categorical_accuracy: 0.4947 - val_loss: 1.2386 - val_categorical_accuracy: 0.4061\n",
            "Epoch 172/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0849 - categorical_accuracy: 0.4938 - val_loss: 1.4105 - val_categorical_accuracy: 0.3384\n",
            "Epoch 173/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0734 - categorical_accuracy: 0.5159 - val_loss: 1.0961 - val_categorical_accuracy: 0.4607\n",
            "Epoch 174/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0751 - categorical_accuracy: 0.5061 - val_loss: 1.1959 - val_categorical_accuracy: 0.4214\n",
            "Epoch 175/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0954 - categorical_accuracy: 0.4898 - val_loss: 1.2011 - val_categorical_accuracy: 0.4236\n",
            "Epoch 176/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0558 - categorical_accuracy: 0.5170 - val_loss: 1.3195 - val_categorical_accuracy: 0.3646\n",
            "Epoch 177/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0761 - categorical_accuracy: 0.5159 - val_loss: 1.1735 - val_categorical_accuracy: 0.4410\n",
            "Epoch 178/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0531 - categorical_accuracy: 0.5042 - val_loss: 1.1462 - val_categorical_accuracy: 0.4672\n",
            "Epoch 179/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0591 - categorical_accuracy: 0.5266 - val_loss: 1.1921 - val_categorical_accuracy: 0.4127\n",
            "Epoch 180/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0737 - categorical_accuracy: 0.5108 - val_loss: 1.2471 - val_categorical_accuracy: 0.4148\n",
            "Epoch 181/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0791 - categorical_accuracy: 0.5100 - val_loss: 1.2054 - val_categorical_accuracy: 0.4258\n",
            "Epoch 182/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0752 - categorical_accuracy: 0.5070 - val_loss: 1.1062 - val_categorical_accuracy: 0.4913\n",
            "Epoch 183/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0683 - categorical_accuracy: 0.5112 - val_loss: 1.1639 - val_categorical_accuracy: 0.4607\n",
            "Epoch 184/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0658 - categorical_accuracy: 0.5084 - val_loss: 1.1394 - val_categorical_accuracy: 0.4607\n",
            "Epoch 185/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0987 - categorical_accuracy: 0.4949 - val_loss: 1.1460 - val_categorical_accuracy: 0.4585\n",
            "Epoch 186/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0846 - categorical_accuracy: 0.4987 - val_loss: 1.2741 - val_categorical_accuracy: 0.3886\n",
            "Epoch 187/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0537 - categorical_accuracy: 0.5203 - val_loss: 1.1964 - val_categorical_accuracy: 0.4541\n",
            "Epoch 188/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0691 - categorical_accuracy: 0.5022 - val_loss: 1.1658 - val_categorical_accuracy: 0.4563\n",
            "Epoch 189/200\n",
            "258/258 [==============================] - 3s 13ms/step - loss: 1.0695 - categorical_accuracy: 0.5004 - val_loss: 1.1570 - val_categorical_accuracy: 0.4541\n",
            "Epoch 190/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0631 - categorical_accuracy: 0.5051 - val_loss: 1.2647 - val_categorical_accuracy: 0.4039\n",
            "Epoch 191/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0779 - categorical_accuracy: 0.5119 - val_loss: 1.0926 - val_categorical_accuracy: 0.4607\n",
            "Epoch 192/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0745 - categorical_accuracy: 0.5157 - val_loss: 1.1365 - val_categorical_accuracy: 0.4498\n",
            "Epoch 193/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0705 - categorical_accuracy: 0.5043 - val_loss: 1.0653 - val_categorical_accuracy: 0.5066\n",
            "Epoch 194/200\n",
            "258/258 [==============================] - 3s 13ms/step - loss: 1.0718 - categorical_accuracy: 0.5174 - val_loss: 1.1569 - val_categorical_accuracy: 0.4585\n",
            "Epoch 195/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0734 - categorical_accuracy: 0.5095 - val_loss: 1.2396 - val_categorical_accuracy: 0.4258\n",
            "Epoch 196/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0662 - categorical_accuracy: 0.5198 - val_loss: 1.1612 - val_categorical_accuracy: 0.4389\n",
            "Epoch 197/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0738 - categorical_accuracy: 0.5120 - val_loss: 1.2542 - val_categorical_accuracy: 0.4170\n",
            "Epoch 198/200\n",
            "258/258 [==============================] - 3s 13ms/step - loss: 1.0831 - categorical_accuracy: 0.5079 - val_loss: 1.1490 - val_categorical_accuracy: 0.4651\n",
            "Epoch 199/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0587 - categorical_accuracy: 0.5322 - val_loss: 1.1774 - val_categorical_accuracy: 0.4476\n",
            "Epoch 200/200\n",
            "258/258 [==============================] - 3s 12ms/step - loss: 1.0785 - categorical_accuracy: 0.5162 - val_loss: 1.2719 - val_categorical_accuracy: 0.3537\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7EK00Y1YlwN"
      },
      "source": [
        "model.save('/content/drive/MyDrive/Colab Notebooks/SPEECH_EMOTION_Recognition/Nộp bài(chốt hạ)/model_saver/conv1D_tempogram_cremad.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-IJkqk5GYqZv"
      },
      "source": [
        "###test_result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6xsvUv0uYqZw",
        "outputId": "5ab0a59a-3ab6-4862-a2e1-0c32b6467a76"
      },
      "source": [
        "d = {0: 'happy',\n",
        "     1: 'sad',\n",
        "     2: 'angry',\n",
        "     3: 'fear'}\n",
        "Y_test_pred = np.argmax(model.predict(X_test), axis=-1)\n",
        "Y_test_pred = list(map(lambda x: d[x], Y_test_pred))\n",
        "y_test = np.argmax(y_test, axis=-1)\n",
        "y_test = list(map(lambda x: d[x], y_test))\n",
        "print(classification_report(y_test, Y_test_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.41      0.97      0.58       136\n",
            "        fear       0.42      0.23      0.30       134\n",
            "       happy       0.24      0.11      0.15       120\n",
            "         sad       0.60      0.30      0.40       119\n",
            "\n",
            "    accuracy                           0.42       509\n",
            "   macro avg       0.42      0.40      0.36       509\n",
            "weighted avg       0.42      0.42      0.36       509\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "id": "4BqxboO8YqZx",
        "outputId": "2cdac8b8-ccf4-4331-c3b6-25a83bc9c865"
      },
      "source": [
        "import scikitplot as skplt\n",
        "\n",
        "skplt.metrics.plot_confusion_matrix(\n",
        "    y_test, \n",
        "    Y_test_pred,\n",
        "    figsize=(8,8))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f311a2c1810>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPjLuB-oYqZ_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ncl1wszZ1Ds"
      },
      "source": [
        "# Tempogram + conv2D"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6Ur96d1Z1D0"
      },
      "source": [
        "data = {'labels': [],\n",
        "        'features': []}\n",
        "\n",
        "for i in range(len(CREMA_D_df)):\n",
        "  if ((CREMA_D_df['Emotion'][i] == 'HAP') | (CREMA_D_df['Emotion'][i] == 'SAD') | \n",
        "      (CREMA_D_df['Emotion'][i] == 'ANG') | (CREMA_D_df['Emotion'][i] == 'FEA')):\n",
        "    \n",
        "    if CREMA_D_df['Emotion'][i] == 'HAP':\n",
        "      data['labels'].append(0)\n",
        "    elif CREMA_D_df['Emotion'][i] == 'SAD':\n",
        "      data['labels'].append(1)\n",
        "    elif CREMA_D_df['Emotion'][i] == 'ANG':\n",
        "      data['labels'].append(2)\n",
        "    elif CREMA_D_df['Emotion'][i] == 'FEA':\n",
        "      data['labels'].append(3)\n",
        "\n",
        "\n",
        "    signal, sr =  librosa.load(CREMA_D_df['Paths'][i])\n",
        "    if len(signal) > input_length:\n",
        "        signal = signal[0:input_length]\n",
        "    elif  input_length > len(signal):\n",
        "        max_offset = input_length - len(signal)  \n",
        "        signal = np.pad(signal, (0, max_offset), \"constant\")\n",
        "    tempogram = librosa.feature.tempogram(signal, sr)\n",
        "    tempogram = np.expand_dims(tempogram, axis=-1)\n",
        "    data['features'].append(tempogram)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bnzxRACvZ1D1"
      },
      "source": [
        "X = data['features']\n",
        "y = data['labels']\n",
        "\n",
        "y = np.array(y)\n",
        "y = to_categorical(y)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=0)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=0)\n",
        "\n",
        "X_train = np.array(X_train)\n",
        "X_test = np.array(X_test)\n",
        "X_val = np.array(X_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YZkj391HZ1D1",
        "outputId": "ea03b0a0-aa9e-4732-b817-dbb8872d46fe"
      },
      "source": [
        "X_train.shape,X_test.shape,y_train.shape,y_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((4117, 384, 130, 1), (509, 384, 130, 1), (4117, 4), (509, 4))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OAXECwCLaYWp"
      },
      "source": [
        "### conv2D"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c4RsyEHoaYW5"
      },
      "source": [
        "# CNN I/P Config\n",
        "num_classes = 4\n",
        "input_shape = X_train.shape[1:]\n",
        "learning_rate = 0.0001\n",
        "decay = 1e-6\n",
        "momentum = 0.9"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6xX_1MaMaYW7",
        "outputId": "1c287733-c943-4288-da59-280c77bf8880"
      },
      "source": [
        "model = Sequential(name='Audio_CNN_2D')\n",
        "\n",
        "# LFLB1\n",
        "model.add(Conv2D(filters=64, kernel_size=(3,3), strides=(1,1), padding='same',input_shape=input_shape))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Conv2D(filters=64, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(4,4), strides=(4,4)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(units=num_classes, activation='softmax'))\n",
        "\n",
        "# Model compilation\n",
        "opt = optimizers.SGD(lr=learning_rate, decay=decay, momentum=momentum, nesterov=True)\n",
        "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"Audio_CNN_2D\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 384, 130, 64)      640       \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 384, 130, 64)      256       \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 384, 130, 64)      0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 192, 65, 64)       0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 192, 65, 64)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 192, 65, 64)       36928     \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 192, 65, 64)       256       \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 192, 65, 64)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 48, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 48, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 49152)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 4)                 196612    \n",
            "=================================================================\n",
            "Total params: 234,692\n",
            "Trainable params: 234,436\n",
            "Non-trainable params: 256\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yHM3CD7YaYW9",
        "outputId": "5f4984e8-3cba-4645-edc0-101130808755"
      },
      "source": [
        "#Train Config\n",
        "\n",
        "batch_size = 16\n",
        "num_epochs = 200\n",
        "\n",
        "# Model Training\n",
        "lr_reduce = ReduceLROnPlateau(monitor='val_loss', factor=0.9, patience=20, min_lr=0.000001)\n",
        "# Please change the model name accordingly.\n",
        "mcp_save = ModelCheckpoint('/content/Modelfull_2_1.h5', save_best_only=True, monitor='val_categorical_accuracy', mode='max')\n",
        "cnnhistory=model.fit(X_train, y_train, batch_size=batch_size, epochs=num_epochs,validation_data=(X_val, y_val), callbacks=[mcp_save, lr_reduce])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "258/258 [==============================] - 59s 51ms/step - loss: 3.6280 - categorical_accuracy: 0.3540 - val_loss: 2.2346 - val_categorical_accuracy: 0.2380\n",
            "Epoch 2/200\n",
            "258/258 [==============================] - 12s 47ms/step - loss: 1.8571 - categorical_accuracy: 0.4071 - val_loss: 1.1795 - val_categorical_accuracy: 0.4563\n",
            "Epoch 3/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.7286 - categorical_accuracy: 0.4275 - val_loss: 1.6968 - val_categorical_accuracy: 0.3755\n",
            "Epoch 4/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.5730 - categorical_accuracy: 0.4307 - val_loss: 2.2555 - val_categorical_accuracy: 0.2860\n",
            "Epoch 5/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.5309 - categorical_accuracy: 0.4413 - val_loss: 1.4101 - val_categorical_accuracy: 0.3952\n",
            "Epoch 6/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.5309 - categorical_accuracy: 0.4319 - val_loss: 1.3643 - val_categorical_accuracy: 0.3319\n",
            "Epoch 7/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.4202 - categorical_accuracy: 0.4643 - val_loss: 1.5257 - val_categorical_accuracy: 0.3974\n",
            "Epoch 8/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.3770 - categorical_accuracy: 0.4638 - val_loss: 1.7569 - val_categorical_accuracy: 0.3930\n",
            "Epoch 9/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.3790 - categorical_accuracy: 0.4417 - val_loss: 1.5948 - val_categorical_accuracy: 0.3930\n",
            "Epoch 10/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.3903 - categorical_accuracy: 0.4512 - val_loss: 1.2890 - val_categorical_accuracy: 0.3821\n",
            "Epoch 11/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.3586 - categorical_accuracy: 0.4552 - val_loss: 1.7070 - val_categorical_accuracy: 0.3231\n",
            "Epoch 12/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.3190 - categorical_accuracy: 0.4650 - val_loss: 2.5978 - val_categorical_accuracy: 0.2817\n",
            "Epoch 13/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.3650 - categorical_accuracy: 0.4563 - val_loss: 1.9832 - val_categorical_accuracy: 0.2991\n",
            "Epoch 14/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.3595 - categorical_accuracy: 0.4543 - val_loss: 1.8204 - val_categorical_accuracy: 0.3035\n",
            "Epoch 15/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.2909 - categorical_accuracy: 0.4671 - val_loss: 1.6206 - val_categorical_accuracy: 0.3166\n",
            "Epoch 16/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.3003 - categorical_accuracy: 0.4617 - val_loss: 1.4859 - val_categorical_accuracy: 0.2969\n",
            "Epoch 17/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.2936 - categorical_accuracy: 0.4689 - val_loss: 1.6672 - val_categorical_accuracy: 0.3712\n",
            "Epoch 18/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.2503 - categorical_accuracy: 0.4803 - val_loss: 1.5516 - val_categorical_accuracy: 0.3646\n",
            "Epoch 19/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.2587 - categorical_accuracy: 0.4751 - val_loss: 1.5647 - val_categorical_accuracy: 0.3035\n",
            "Epoch 20/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.2435 - categorical_accuracy: 0.4669 - val_loss: 1.5066 - val_categorical_accuracy: 0.3013\n",
            "Epoch 21/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.2401 - categorical_accuracy: 0.4775 - val_loss: 1.8447 - val_categorical_accuracy: 0.3100\n",
            "Epoch 22/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.2552 - categorical_accuracy: 0.4619 - val_loss: 1.3170 - val_categorical_accuracy: 0.3603\n",
            "Epoch 23/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.1925 - categorical_accuracy: 0.4957 - val_loss: 1.7083 - val_categorical_accuracy: 0.3253\n",
            "Epoch 24/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.2306 - categorical_accuracy: 0.4827 - val_loss: 1.7682 - val_categorical_accuracy: 0.2969\n",
            "Epoch 25/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.2197 - categorical_accuracy: 0.4797 - val_loss: 1.6216 - val_categorical_accuracy: 0.3450\n",
            "Epoch 26/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.2328 - categorical_accuracy: 0.4669 - val_loss: 1.5263 - val_categorical_accuracy: 0.3537\n",
            "Epoch 27/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.2574 - categorical_accuracy: 0.4460 - val_loss: 2.0160 - val_categorical_accuracy: 0.2598\n",
            "Epoch 28/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.2114 - categorical_accuracy: 0.4768 - val_loss: 1.5809 - val_categorical_accuracy: 0.3079\n",
            "Epoch 29/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.1668 - categorical_accuracy: 0.4907 - val_loss: 1.8401 - val_categorical_accuracy: 0.2969\n",
            "Epoch 30/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.1882 - categorical_accuracy: 0.4776 - val_loss: 1.5488 - val_categorical_accuracy: 0.3515\n",
            "Epoch 31/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.1451 - categorical_accuracy: 0.4869 - val_loss: 1.6081 - val_categorical_accuracy: 0.3188\n",
            "Epoch 32/200\n",
            "258/258 [==============================] - 12s 47ms/step - loss: 1.2022 - categorical_accuracy: 0.4781 - val_loss: 1.4259 - val_categorical_accuracy: 0.3428\n",
            "Epoch 33/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.1607 - categorical_accuracy: 0.4780 - val_loss: 1.9060 - val_categorical_accuracy: 0.3079\n",
            "Epoch 34/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.1814 - categorical_accuracy: 0.4865 - val_loss: 1.8327 - val_categorical_accuracy: 0.3188\n",
            "Epoch 35/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.1969 - categorical_accuracy: 0.4635 - val_loss: 1.6004 - val_categorical_accuracy: 0.3559\n",
            "Epoch 36/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.1846 - categorical_accuracy: 0.4811 - val_loss: 1.3970 - val_categorical_accuracy: 0.3930\n",
            "Epoch 37/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.1489 - categorical_accuracy: 0.4966 - val_loss: 1.5786 - val_categorical_accuracy: 0.3341\n",
            "Epoch 38/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.1871 - categorical_accuracy: 0.4874 - val_loss: 1.7935 - val_categorical_accuracy: 0.2555\n",
            "Epoch 39/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.1619 - categorical_accuracy: 0.4868 - val_loss: 1.6536 - val_categorical_accuracy: 0.3428\n",
            "Epoch 40/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.1807 - categorical_accuracy: 0.4715 - val_loss: 1.5022 - val_categorical_accuracy: 0.3450\n",
            "Epoch 41/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.1720 - categorical_accuracy: 0.4890 - val_loss: 1.6929 - val_categorical_accuracy: 0.2620\n",
            "Epoch 42/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.1731 - categorical_accuracy: 0.4801 - val_loss: 1.5848 - val_categorical_accuracy: 0.3406\n",
            "Epoch 43/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.1832 - categorical_accuracy: 0.4727 - val_loss: 1.8893 - val_categorical_accuracy: 0.2576\n",
            "Epoch 44/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.1788 - categorical_accuracy: 0.4890 - val_loss: 1.6212 - val_categorical_accuracy: 0.3144\n",
            "Epoch 45/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.1593 - categorical_accuracy: 0.4813 - val_loss: 1.5499 - val_categorical_accuracy: 0.3428\n",
            "Epoch 46/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.1659 - categorical_accuracy: 0.4833 - val_loss: 1.4703 - val_categorical_accuracy: 0.3341\n",
            "Epoch 47/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.1548 - categorical_accuracy: 0.5043 - val_loss: 1.3890 - val_categorical_accuracy: 0.3275\n",
            "Epoch 48/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.1502 - categorical_accuracy: 0.4838 - val_loss: 1.5990 - val_categorical_accuracy: 0.3690\n",
            "Epoch 49/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.1536 - categorical_accuracy: 0.5055 - val_loss: 1.5376 - val_categorical_accuracy: 0.3428\n",
            "Epoch 50/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.1585 - categorical_accuracy: 0.4967 - val_loss: 1.7584 - val_categorical_accuracy: 0.3559\n",
            "Epoch 51/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.1622 - categorical_accuracy: 0.4915 - val_loss: 1.3287 - val_categorical_accuracy: 0.3908\n",
            "Epoch 52/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.1566 - categorical_accuracy: 0.4839 - val_loss: 1.4571 - val_categorical_accuracy: 0.3537\n",
            "Epoch 53/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.1590 - categorical_accuracy: 0.4701 - val_loss: 1.5783 - val_categorical_accuracy: 0.2729\n",
            "Epoch 54/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.1609 - categorical_accuracy: 0.4816 - val_loss: 1.3200 - val_categorical_accuracy: 0.3865\n",
            "Epoch 55/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.1455 - categorical_accuracy: 0.4878 - val_loss: 1.5151 - val_categorical_accuracy: 0.3406\n",
            "Epoch 56/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.1240 - categorical_accuracy: 0.5072 - val_loss: 1.3713 - val_categorical_accuracy: 0.3734\n",
            "Epoch 57/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.1015 - categorical_accuracy: 0.5015 - val_loss: 1.5230 - val_categorical_accuracy: 0.2838\n",
            "Epoch 58/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.1682 - categorical_accuracy: 0.4795 - val_loss: 1.4455 - val_categorical_accuracy: 0.3712\n",
            "Epoch 59/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.1113 - categorical_accuracy: 0.4956 - val_loss: 1.7528 - val_categorical_accuracy: 0.2576\n",
            "Epoch 60/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.1312 - categorical_accuracy: 0.4917 - val_loss: 1.3045 - val_categorical_accuracy: 0.3974\n",
            "Epoch 61/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.1544 - categorical_accuracy: 0.4941 - val_loss: 1.5998 - val_categorical_accuracy: 0.3166\n",
            "Epoch 62/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.1178 - categorical_accuracy: 0.5048 - val_loss: 1.6190 - val_categorical_accuracy: 0.3362\n",
            "Epoch 63/200\n",
            "258/258 [==============================] - 12s 47ms/step - loss: 1.1203 - categorical_accuracy: 0.4935 - val_loss: 1.7776 - val_categorical_accuracy: 0.3035\n",
            "Epoch 64/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.1366 - categorical_accuracy: 0.4910 - val_loss: 1.5379 - val_categorical_accuracy: 0.3472\n",
            "Epoch 65/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.1359 - categorical_accuracy: 0.4895 - val_loss: 1.6241 - val_categorical_accuracy: 0.3450\n",
            "Epoch 66/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.1276 - categorical_accuracy: 0.4998 - val_loss: 1.6869 - val_categorical_accuracy: 0.3319\n",
            "Epoch 67/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.1236 - categorical_accuracy: 0.4953 - val_loss: 1.6270 - val_categorical_accuracy: 0.3210\n",
            "Epoch 68/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.1042 - categorical_accuracy: 0.5143 - val_loss: 1.4026 - val_categorical_accuracy: 0.3384\n",
            "Epoch 69/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.1170 - categorical_accuracy: 0.5068 - val_loss: 1.3457 - val_categorical_accuracy: 0.3668\n",
            "Epoch 70/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.1146 - categorical_accuracy: 0.4973 - val_loss: 1.5792 - val_categorical_accuracy: 0.3275\n",
            "Epoch 71/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.1287 - categorical_accuracy: 0.4890 - val_loss: 1.3252 - val_categorical_accuracy: 0.4017\n",
            "Epoch 72/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.1098 - categorical_accuracy: 0.5113 - val_loss: 1.3417 - val_categorical_accuracy: 0.3777\n",
            "Epoch 73/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.1257 - categorical_accuracy: 0.5028 - val_loss: 1.5638 - val_categorical_accuracy: 0.3188\n",
            "Epoch 74/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.0909 - categorical_accuracy: 0.5147 - val_loss: 1.4537 - val_categorical_accuracy: 0.3843\n",
            "Epoch 75/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.1099 - categorical_accuracy: 0.4956 - val_loss: 1.2697 - val_categorical_accuracy: 0.3668\n",
            "Epoch 76/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.1099 - categorical_accuracy: 0.5018 - val_loss: 1.5145 - val_categorical_accuracy: 0.3319\n",
            "Epoch 77/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.1189 - categorical_accuracy: 0.5030 - val_loss: 1.4787 - val_categorical_accuracy: 0.3253\n",
            "Epoch 78/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.1077 - categorical_accuracy: 0.4983 - val_loss: 1.6578 - val_categorical_accuracy: 0.2598\n",
            "Epoch 79/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.0945 - categorical_accuracy: 0.4969 - val_loss: 1.4185 - val_categorical_accuracy: 0.3668\n",
            "Epoch 80/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.1234 - categorical_accuracy: 0.4786 - val_loss: 1.3189 - val_categorical_accuracy: 0.3799\n",
            "Epoch 81/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.1125 - categorical_accuracy: 0.5140 - val_loss: 1.4391 - val_categorical_accuracy: 0.3384\n",
            "Epoch 82/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.0876 - categorical_accuracy: 0.5009 - val_loss: 1.4601 - val_categorical_accuracy: 0.3515\n",
            "Epoch 83/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.0711 - categorical_accuracy: 0.5167 - val_loss: 1.5252 - val_categorical_accuracy: 0.3472\n",
            "Epoch 84/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.1026 - categorical_accuracy: 0.4996 - val_loss: 1.4397 - val_categorical_accuracy: 0.3624\n",
            "Epoch 85/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.1075 - categorical_accuracy: 0.5009 - val_loss: 1.3275 - val_categorical_accuracy: 0.3777\n",
            "Epoch 86/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.0963 - categorical_accuracy: 0.5029 - val_loss: 1.4233 - val_categorical_accuracy: 0.3843\n",
            "Epoch 87/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.1003 - categorical_accuracy: 0.5069 - val_loss: 1.7588 - val_categorical_accuracy: 0.3035\n",
            "Epoch 88/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.0951 - categorical_accuracy: 0.5107 - val_loss: 1.4974 - val_categorical_accuracy: 0.3472\n",
            "Epoch 89/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.1003 - categorical_accuracy: 0.5005 - val_loss: 1.5448 - val_categorical_accuracy: 0.3406\n",
            "Epoch 90/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.0922 - categorical_accuracy: 0.5042 - val_loss: 1.3832 - val_categorical_accuracy: 0.3537\n",
            "Epoch 91/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.0857 - categorical_accuracy: 0.5056 - val_loss: 1.5157 - val_categorical_accuracy: 0.2904\n",
            "Epoch 92/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.0739 - categorical_accuracy: 0.5091 - val_loss: 1.5875 - val_categorical_accuracy: 0.3253\n",
            "Epoch 93/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.0760 - categorical_accuracy: 0.4982 - val_loss: 1.3791 - val_categorical_accuracy: 0.4061\n",
            "Epoch 94/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.1076 - categorical_accuracy: 0.5114 - val_loss: 1.6949 - val_categorical_accuracy: 0.3166\n",
            "Epoch 95/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.0669 - categorical_accuracy: 0.5170 - val_loss: 1.6811 - val_categorical_accuracy: 0.3253\n",
            "Epoch 96/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.1059 - categorical_accuracy: 0.5018 - val_loss: 1.5819 - val_categorical_accuracy: 0.3406\n",
            "Epoch 97/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.0645 - categorical_accuracy: 0.5079 - val_loss: 1.3864 - val_categorical_accuracy: 0.3515\n",
            "Epoch 98/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.1044 - categorical_accuracy: 0.5067 - val_loss: 1.3273 - val_categorical_accuracy: 0.3537\n",
            "Epoch 99/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.1002 - categorical_accuracy: 0.4995 - val_loss: 1.5518 - val_categorical_accuracy: 0.3253\n",
            "Epoch 100/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.0649 - categorical_accuracy: 0.5157 - val_loss: 1.3944 - val_categorical_accuracy: 0.4127\n",
            "Epoch 101/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.1084 - categorical_accuracy: 0.4938 - val_loss: 1.4437 - val_categorical_accuracy: 0.3537\n",
            "Epoch 102/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.0778 - categorical_accuracy: 0.5132 - val_loss: 1.4840 - val_categorical_accuracy: 0.3362\n",
            "Epoch 103/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.0836 - categorical_accuracy: 0.5146 - val_loss: 1.4580 - val_categorical_accuracy: 0.3493\n",
            "Epoch 104/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.0557 - categorical_accuracy: 0.5280 - val_loss: 1.4952 - val_categorical_accuracy: 0.3537\n",
            "Epoch 105/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.0702 - categorical_accuracy: 0.5129 - val_loss: 1.4368 - val_categorical_accuracy: 0.3537\n",
            "Epoch 106/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.0773 - categorical_accuracy: 0.5164 - val_loss: 1.3842 - val_categorical_accuracy: 0.3559\n",
            "Epoch 107/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.0792 - categorical_accuracy: 0.5167 - val_loss: 1.3615 - val_categorical_accuracy: 0.3952\n",
            "Epoch 108/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.0801 - categorical_accuracy: 0.5024 - val_loss: 1.3574 - val_categorical_accuracy: 0.3690\n",
            "Epoch 109/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.0773 - categorical_accuracy: 0.5161 - val_loss: 1.3152 - val_categorical_accuracy: 0.4214\n",
            "Epoch 110/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.0685 - categorical_accuracy: 0.5152 - val_loss: 1.2857 - val_categorical_accuracy: 0.3734\n",
            "Epoch 111/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.0864 - categorical_accuracy: 0.5013 - val_loss: 1.3147 - val_categorical_accuracy: 0.3690\n",
            "Epoch 112/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.0798 - categorical_accuracy: 0.5148 - val_loss: 1.4732 - val_categorical_accuracy: 0.3799\n",
            "Epoch 113/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.0718 - categorical_accuracy: 0.5197 - val_loss: 1.5343 - val_categorical_accuracy: 0.3166\n",
            "Epoch 114/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.0483 - categorical_accuracy: 0.5173 - val_loss: 1.5782 - val_categorical_accuracy: 0.3450\n",
            "Epoch 115/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.1069 - categorical_accuracy: 0.5110 - val_loss: 1.2868 - val_categorical_accuracy: 0.3821\n",
            "Epoch 116/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.0612 - categorical_accuracy: 0.5277 - val_loss: 1.5242 - val_categorical_accuracy: 0.3275\n",
            "Epoch 117/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.0532 - categorical_accuracy: 0.5276 - val_loss: 1.4808 - val_categorical_accuracy: 0.3384\n",
            "Epoch 118/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.0633 - categorical_accuracy: 0.5261 - val_loss: 1.4389 - val_categorical_accuracy: 0.3646\n",
            "Epoch 119/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.0645 - categorical_accuracy: 0.5183 - val_loss: 1.4493 - val_categorical_accuracy: 0.3515\n",
            "Epoch 120/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.0767 - categorical_accuracy: 0.5091 - val_loss: 1.2879 - val_categorical_accuracy: 0.4061\n",
            "Epoch 121/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.0484 - categorical_accuracy: 0.5219 - val_loss: 1.2729 - val_categorical_accuracy: 0.4105\n",
            "Epoch 122/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.0649 - categorical_accuracy: 0.5161 - val_loss: 1.5830 - val_categorical_accuracy: 0.3275\n",
            "Epoch 123/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.0609 - categorical_accuracy: 0.5169 - val_loss: 1.4079 - val_categorical_accuracy: 0.3581\n",
            "Epoch 124/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.0562 - categorical_accuracy: 0.5148 - val_loss: 1.5291 - val_categorical_accuracy: 0.3603\n",
            "Epoch 125/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.0586 - categorical_accuracy: 0.5108 - val_loss: 1.4461 - val_categorical_accuracy: 0.3537\n",
            "Epoch 126/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.0807 - categorical_accuracy: 0.5117 - val_loss: 1.3700 - val_categorical_accuracy: 0.3821\n",
            "Epoch 127/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.0575 - categorical_accuracy: 0.5091 - val_loss: 1.6980 - val_categorical_accuracy: 0.3144\n",
            "Epoch 128/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.0728 - categorical_accuracy: 0.5093 - val_loss: 1.3551 - val_categorical_accuracy: 0.3581\n",
            "Epoch 129/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.0502 - categorical_accuracy: 0.5128 - val_loss: 1.3957 - val_categorical_accuracy: 0.3712\n",
            "Epoch 130/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.0728 - categorical_accuracy: 0.5098 - val_loss: 1.3594 - val_categorical_accuracy: 0.3952\n",
            "Epoch 131/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.0822 - categorical_accuracy: 0.5030 - val_loss: 1.4543 - val_categorical_accuracy: 0.3755\n",
            "Epoch 132/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.0409 - categorical_accuracy: 0.5283 - val_loss: 1.5372 - val_categorical_accuracy: 0.3384\n",
            "Epoch 133/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.0645 - categorical_accuracy: 0.5164 - val_loss: 1.6004 - val_categorical_accuracy: 0.3253\n",
            "Epoch 134/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.0461 - categorical_accuracy: 0.5365 - val_loss: 1.4705 - val_categorical_accuracy: 0.3319\n",
            "Epoch 135/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.0577 - categorical_accuracy: 0.5176 - val_loss: 1.3271 - val_categorical_accuracy: 0.3865\n",
            "Epoch 136/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.0456 - categorical_accuracy: 0.5313 - val_loss: 1.3706 - val_categorical_accuracy: 0.3253\n",
            "Epoch 137/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.0811 - categorical_accuracy: 0.5050 - val_loss: 1.4167 - val_categorical_accuracy: 0.3712\n",
            "Epoch 138/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.0790 - categorical_accuracy: 0.5126 - val_loss: 1.4014 - val_categorical_accuracy: 0.3603\n",
            "Epoch 139/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.0477 - categorical_accuracy: 0.5249 - val_loss: 1.3908 - val_categorical_accuracy: 0.3624\n",
            "Epoch 140/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.0720 - categorical_accuracy: 0.5179 - val_loss: 1.4101 - val_categorical_accuracy: 0.3581\n",
            "Epoch 141/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.0569 - categorical_accuracy: 0.5165 - val_loss: 1.3537 - val_categorical_accuracy: 0.3646\n",
            "Epoch 142/200\n",
            "258/258 [==============================] - 12s 47ms/step - loss: 1.0843 - categorical_accuracy: 0.5135 - val_loss: 1.3455 - val_categorical_accuracy: 0.3821\n",
            "Epoch 143/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.0591 - categorical_accuracy: 0.5159 - val_loss: 1.4291 - val_categorical_accuracy: 0.3472\n",
            "Epoch 144/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.0620 - categorical_accuracy: 0.5198 - val_loss: 1.2905 - val_categorical_accuracy: 0.3996\n",
            "Epoch 145/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.0493 - categorical_accuracy: 0.5180 - val_loss: 1.3301 - val_categorical_accuracy: 0.3690\n",
            "Epoch 146/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.0710 - categorical_accuracy: 0.5214 - val_loss: 1.3369 - val_categorical_accuracy: 0.3930\n",
            "Epoch 147/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.0636 - categorical_accuracy: 0.5206 - val_loss: 1.4266 - val_categorical_accuracy: 0.3559\n",
            "Epoch 148/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.0437 - categorical_accuracy: 0.5171 - val_loss: 1.3507 - val_categorical_accuracy: 0.3821\n",
            "Epoch 149/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.0347 - categorical_accuracy: 0.5166 - val_loss: 1.3730 - val_categorical_accuracy: 0.3668\n",
            "Epoch 150/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.0549 - categorical_accuracy: 0.5193 - val_loss: 1.3187 - val_categorical_accuracy: 0.3974\n",
            "Epoch 151/200\n",
            "258/258 [==============================] - 12s 47ms/step - loss: 1.0458 - categorical_accuracy: 0.5292 - val_loss: 1.4064 - val_categorical_accuracy: 0.3712\n",
            "Epoch 152/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.0570 - categorical_accuracy: 0.5197 - val_loss: 1.4079 - val_categorical_accuracy: 0.3668\n",
            "Epoch 153/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.0534 - categorical_accuracy: 0.5122 - val_loss: 1.3322 - val_categorical_accuracy: 0.3755\n",
            "Epoch 154/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.0424 - categorical_accuracy: 0.5249 - val_loss: 1.2538 - val_categorical_accuracy: 0.4432\n",
            "Epoch 155/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.0374 - categorical_accuracy: 0.5381 - val_loss: 1.3024 - val_categorical_accuracy: 0.3472\n",
            "Epoch 156/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.0669 - categorical_accuracy: 0.5034 - val_loss: 1.3047 - val_categorical_accuracy: 0.3952\n",
            "Epoch 157/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.0694 - categorical_accuracy: 0.5171 - val_loss: 1.3680 - val_categorical_accuracy: 0.3624\n",
            "Epoch 158/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.0420 - categorical_accuracy: 0.5232 - val_loss: 1.4159 - val_categorical_accuracy: 0.3537\n",
            "Epoch 159/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.0212 - categorical_accuracy: 0.5242 - val_loss: 1.4691 - val_categorical_accuracy: 0.3777\n",
            "Epoch 160/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.0825 - categorical_accuracy: 0.5131 - val_loss: 1.3169 - val_categorical_accuracy: 0.4017\n",
            "Epoch 161/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.0489 - categorical_accuracy: 0.5120 - val_loss: 1.4648 - val_categorical_accuracy: 0.3734\n",
            "Epoch 162/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.0722 - categorical_accuracy: 0.5099 - val_loss: 1.5440 - val_categorical_accuracy: 0.3493\n",
            "Epoch 163/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.0449 - categorical_accuracy: 0.5267 - val_loss: 1.4692 - val_categorical_accuracy: 0.3624\n",
            "Epoch 164/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.0591 - categorical_accuracy: 0.5057 - val_loss: 1.3375 - val_categorical_accuracy: 0.3930\n",
            "Epoch 165/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.0617 - categorical_accuracy: 0.5060 - val_loss: 1.3469 - val_categorical_accuracy: 0.3777\n",
            "Epoch 166/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.0445 - categorical_accuracy: 0.5206 - val_loss: 1.5737 - val_categorical_accuracy: 0.3384\n",
            "Epoch 167/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.0470 - categorical_accuracy: 0.5180 - val_loss: 1.2957 - val_categorical_accuracy: 0.4105\n",
            "Epoch 168/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.0559 - categorical_accuracy: 0.5295 - val_loss: 1.4007 - val_categorical_accuracy: 0.3734\n",
            "Epoch 169/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.0339 - categorical_accuracy: 0.5209 - val_loss: 1.4627 - val_categorical_accuracy: 0.3472\n",
            "Epoch 170/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.0050 - categorical_accuracy: 0.5447 - val_loss: 1.3619 - val_categorical_accuracy: 0.3799\n",
            "Epoch 171/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.0568 - categorical_accuracy: 0.5210 - val_loss: 1.3981 - val_categorical_accuracy: 0.3755\n",
            "Epoch 172/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.0420 - categorical_accuracy: 0.5231 - val_loss: 1.3606 - val_categorical_accuracy: 0.3755\n",
            "Epoch 173/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.0557 - categorical_accuracy: 0.5059 - val_loss: 1.4237 - val_categorical_accuracy: 0.3865\n",
            "Epoch 174/200\n",
            "258/258 [==============================] - 12s 47ms/step - loss: 1.0376 - categorical_accuracy: 0.5248 - val_loss: 1.5290 - val_categorical_accuracy: 0.3515\n",
            "Epoch 175/200\n",
            "258/258 [==============================] - 12s 47ms/step - loss: 1.0374 - categorical_accuracy: 0.5240 - val_loss: 1.4621 - val_categorical_accuracy: 0.3493\n",
            "Epoch 176/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.0246 - categorical_accuracy: 0.5503 - val_loss: 1.4329 - val_categorical_accuracy: 0.3537\n",
            "Epoch 177/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.0308 - categorical_accuracy: 0.5253 - val_loss: 1.3371 - val_categorical_accuracy: 0.3755\n",
            "Epoch 178/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.0308 - categorical_accuracy: 0.5446 - val_loss: 1.3956 - val_categorical_accuracy: 0.3690\n",
            "Epoch 179/200\n",
            "258/258 [==============================] - 12s 47ms/step - loss: 1.0414 - categorical_accuracy: 0.5201 - val_loss: 1.1892 - val_categorical_accuracy: 0.4279\n",
            "Epoch 180/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.0486 - categorical_accuracy: 0.5212 - val_loss: 1.3774 - val_categorical_accuracy: 0.3668\n",
            "Epoch 181/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.0466 - categorical_accuracy: 0.5090 - val_loss: 1.3935 - val_categorical_accuracy: 0.3712\n",
            "Epoch 182/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.0462 - categorical_accuracy: 0.5160 - val_loss: 1.4360 - val_categorical_accuracy: 0.3537\n",
            "Epoch 183/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.0229 - categorical_accuracy: 0.5327 - val_loss: 1.4530 - val_categorical_accuracy: 0.3581\n",
            "Epoch 184/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.0357 - categorical_accuracy: 0.5347 - val_loss: 1.4139 - val_categorical_accuracy: 0.3624\n",
            "Epoch 185/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.0512 - categorical_accuracy: 0.5278 - val_loss: 1.3856 - val_categorical_accuracy: 0.3821\n",
            "Epoch 186/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.0388 - categorical_accuracy: 0.5272 - val_loss: 1.2877 - val_categorical_accuracy: 0.4192\n",
            "Epoch 187/200\n",
            "258/258 [==============================] - 12s 47ms/step - loss: 1.0414 - categorical_accuracy: 0.5131 - val_loss: 1.4561 - val_categorical_accuracy: 0.3515\n",
            "Epoch 188/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.0148 - categorical_accuracy: 0.5427 - val_loss: 1.2765 - val_categorical_accuracy: 0.3974\n",
            "Epoch 189/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.0391 - categorical_accuracy: 0.5097 - val_loss: 1.6151 - val_categorical_accuracy: 0.3166\n",
            "Epoch 190/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.0380 - categorical_accuracy: 0.5201 - val_loss: 1.3281 - val_categorical_accuracy: 0.3799\n",
            "Epoch 191/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.0310 - categorical_accuracy: 0.5331 - val_loss: 1.3312 - val_categorical_accuracy: 0.3843\n",
            "Epoch 192/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.0124 - categorical_accuracy: 0.5474 - val_loss: 1.2201 - val_categorical_accuracy: 0.4148\n",
            "Epoch 193/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.0386 - categorical_accuracy: 0.5288 - val_loss: 1.3618 - val_categorical_accuracy: 0.3799\n",
            "Epoch 194/200\n",
            "258/258 [==============================] - 12s 47ms/step - loss: 1.0263 - categorical_accuracy: 0.5390 - val_loss: 1.3507 - val_categorical_accuracy: 0.3821\n",
            "Epoch 195/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.0252 - categorical_accuracy: 0.5204 - val_loss: 1.4290 - val_categorical_accuracy: 0.3777\n",
            "Epoch 196/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.0362 - categorical_accuracy: 0.5172 - val_loss: 1.3790 - val_categorical_accuracy: 0.3581\n",
            "Epoch 197/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.0337 - categorical_accuracy: 0.5264 - val_loss: 1.3794 - val_categorical_accuracy: 0.3952\n",
            "Epoch 198/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.0213 - categorical_accuracy: 0.5378 - val_loss: 1.4386 - val_categorical_accuracy: 0.3886\n",
            "Epoch 199/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.0300 - categorical_accuracy: 0.5307 - val_loss: 1.2688 - val_categorical_accuracy: 0.4105\n",
            "Epoch 200/200\n",
            "258/258 [==============================] - 12s 46ms/step - loss: 1.0179 - categorical_accuracy: 0.5322 - val_loss: 1.3544 - val_categorical_accuracy: 0.3777\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wbd4kBYxaYW-"
      },
      "source": [
        "model.save('/content/drive/MyDrive/Colab Notebooks/SPEECH_EMOTION_Recognition/Nộp bài(chốt hạ)/model_saver/conv2D_tempogram_cremad.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BFVwS5gkZ1D6"
      },
      "source": [
        "###test_result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ayz0uTrCZ1D7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2c2464e-6cf3-4a52-cda6-a47983f8a26a"
      },
      "source": [
        "d = {0: 'happy',\n",
        "     1: 'sad',\n",
        "     2: 'angry',\n",
        "     3: 'fear'}\n",
        "Y_test_pred = np.argmax(model.predict(X_test), axis=-1)\n",
        "Y_test_pred = list(map(lambda x: d[x], Y_test_pred))\n",
        "y_test = np.argmax(y_test, axis=-1)\n",
        "y_test = list(map(lambda x: d[x], y_test))\n",
        "print(classification_report(y_test, Y_test_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.65      0.10      0.17       136\n",
            "        fear       0.33      0.37      0.35       134\n",
            "       happy       0.24      0.27      0.25       120\n",
            "         sad       0.39      0.67      0.49       119\n",
            "\n",
            "    accuracy                           0.34       509\n",
            "   macro avg       0.40      0.35      0.32       509\n",
            "weighted avg       0.41      0.34      0.31       509\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQ2f7Tp7Z1D8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "outputId": "1551abb8-6bc1-4efe-aed8-5d52d7e10ad8"
      },
      "source": [
        "import scikitplot as skplt\n",
        "\n",
        "skplt.metrics.plot_confusion_matrix(\n",
        "    y_test, \n",
        "    Y_test_pred,\n",
        "    figsize=(8,8))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f8885a013d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2x9nMZ6DZ1D8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qLKgMiv0bNC8"
      },
      "source": [
        "# Combined feature + basic model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVHB0C0fbNDK"
      },
      "source": [
        "data = {'labels': [],\n",
        "        'features': []}\n",
        "\n",
        "for i in range(len(CREMA_D_df)):\n",
        "  if ((CREMA_D_df['Emotion'][i] == 'HAP') | (CREMA_D_df['Emotion'][i] == 'SAD') | \n",
        "      (CREMA_D_df['Emotion'][i] == 'ANG') | (CREMA_D_df['Emotion'][i] == 'FEA')):\n",
        "    \n",
        "    if CREMA_D_df['Emotion'][i] == 'HAP':\n",
        "      data['labels'].append(0)\n",
        "    elif CREMA_D_df['Emotion'][i] == 'SAD':\n",
        "      data['labels'].append(1)\n",
        "    elif CREMA_D_df['Emotion'][i] == 'ANG':\n",
        "      data['labels'].append(2)\n",
        "    elif CREMA_D_df['Emotion'][i] == 'FEA':\n",
        "      data['labels'].append(3)\n",
        "\n",
        "\n",
        "    signal, sr =  librosa.load(CREMA_D_df['Paths'][i])\n",
        "    if len(signal) > input_length:\n",
        "        signal = signal[0:input_length]\n",
        "    elif  input_length > len(signal):\n",
        "        max_offset = input_length - len(signal)  \n",
        "        signal = np.pad(signal, (0, max_offset), \"constant\")\n",
        "    mfcc = np.mean(librosa.feature.mfcc(y=signal, sr=sr, n_mfcc=39).T,axis=0)\n",
        "    mel_spec = np.mean(librosa.feature.melspectrogram(signal, sr, n_mels=28).T, axis=0)\n",
        "    tempogram = np.mean(librosa.feature.tempogram(signal, sr, win_length=24).T, axis=0)\n",
        "\n",
        "    mfcc = pd.DataFrame(mfcc)\n",
        "    mel_spec = pd.DataFrame(mel_spec)\n",
        "    tempogram = pd.DataFrame(tempogram)\n",
        "    feature = mfcc.append(mel_spec).append(tempogram)\n",
        "    feature = np.array(feature[0])\n",
        "    data['features'].append(feature)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6e2Kzf1whcUF"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "sc = StandardScaler()\n",
        "data['features'] = sc.fit_transform(data['features'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HdJCV4lVbNDL"
      },
      "source": [
        "X = data['features']\n",
        "y = data['labels']\n",
        "\n",
        "y = np.array(y)\n",
        "y = to_categorical(y)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=0)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=0)\n",
        "\n",
        "X_train = np.array(X_train)\n",
        "X_test = np.array(X_test)\n",
        "X_val = np.array(X_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "raK241T-jG41",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2801161a-5dbb-4c38-cb70-dd8bd371ce93"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4117, 91)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XSNUyBRPbNDM"
      },
      "source": [
        "## basic models:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MtpRYpB3bNDN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74ab8bdf-333b-4f70-9c2f-a35230accaac"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(91, input_shape=(91, ), activation = 'relu'))\n",
        "#model.add(Dropout(0.1))\n",
        "model.add(Dense(128, activation = 'relu'))\n",
        "#model.add(Dropout(0.25))\n",
        "model.add(Dense(128, activation = 'relu'))\n",
        "#model.add(Dropout(0.2))\n",
        "model.add(Dense(4, activation = 'softmax'))\n",
        "\n",
        "optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
        "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer=optimizer)\n",
        "early_stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=100, verbose=1, mode='auto')\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 91)                8372      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 128)               11776     \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 4)                 516       \n",
            "=================================================================\n",
            "Total params: 37,176\n",
            "Trainable params: 37,176\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xwrMDDGabNDN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b77d42ca-b6ea-4c35-e8be-7cd3d98533bd"
      },
      "source": [
        "history = model.fit(X_train, y_train, batch_size=64, epochs=200, \n",
        "                    validation_data=(X_val, y_val))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "65/65 [==============================] - 1s 6ms/step - loss: 1.1581 - accuracy: 0.4873 - val_loss: 1.0182 - val_accuracy: 0.5524\n",
            "Epoch 2/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.9013 - accuracy: 0.6021 - val_loss: 0.9970 - val_accuracy: 0.5677\n",
            "Epoch 3/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.8402 - accuracy: 0.6462 - val_loss: 0.9428 - val_accuracy: 0.5961\n",
            "Epoch 4/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.7738 - accuracy: 0.6800 - val_loss: 0.9652 - val_accuracy: 0.5742\n",
            "Epoch 5/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.7298 - accuracy: 0.7018 - val_loss: 0.9275 - val_accuracy: 0.6332\n",
            "Epoch 6/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.6968 - accuracy: 0.7070 - val_loss: 1.0159 - val_accuracy: 0.5917\n",
            "Epoch 7/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.6387 - accuracy: 0.7402 - val_loss: 0.9589 - val_accuracy: 0.6223\n",
            "Epoch 8/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.5970 - accuracy: 0.7651 - val_loss: 0.9768 - val_accuracy: 0.6201\n",
            "Epoch 9/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.5317 - accuracy: 0.7783 - val_loss: 1.0051 - val_accuracy: 0.5830\n",
            "Epoch 10/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.8019 - val_loss: 0.9782 - val_accuracy: 0.6179\n",
            "Epoch 11/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.4741 - accuracy: 0.8139 - val_loss: 1.0664 - val_accuracy: 0.6070\n",
            "Epoch 12/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.4551 - accuracy: 0.8258 - val_loss: 1.0868 - val_accuracy: 0.5939\n",
            "Epoch 13/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.3846 - accuracy: 0.8581 - val_loss: 1.0982 - val_accuracy: 0.6266\n",
            "Epoch 14/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.3693 - accuracy: 0.8737 - val_loss: 1.1539 - val_accuracy: 0.6048\n",
            "Epoch 15/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.3446 - accuracy: 0.8756 - val_loss: 1.2213 - val_accuracy: 0.6026\n",
            "Epoch 16/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.3117 - accuracy: 0.8928 - val_loss: 1.2255 - val_accuracy: 0.6332\n",
            "Epoch 17/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.2834 - accuracy: 0.8968 - val_loss: 1.2763 - val_accuracy: 0.6288\n",
            "Epoch 18/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.2814 - accuracy: 0.8989 - val_loss: 1.4067 - val_accuracy: 0.5939\n",
            "Epoch 19/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.2449 - accuracy: 0.9167 - val_loss: 1.3374 - val_accuracy: 0.6332\n",
            "Epoch 20/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.2216 - accuracy: 0.9266 - val_loss: 1.4450 - val_accuracy: 0.6223\n",
            "Epoch 21/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.2033 - accuracy: 0.9319 - val_loss: 1.6368 - val_accuracy: 0.5895\n",
            "Epoch 22/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.2290 - accuracy: 0.9186 - val_loss: 1.5037 - val_accuracy: 0.6245\n",
            "Epoch 23/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.1695 - accuracy: 0.9477 - val_loss: 1.6019 - val_accuracy: 0.6201\n",
            "Epoch 24/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.1569 - accuracy: 0.9506 - val_loss: 1.6939 - val_accuracy: 0.6048\n",
            "Epoch 25/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.1249 - accuracy: 0.9652 - val_loss: 1.8133 - val_accuracy: 0.6026\n",
            "Epoch 26/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.1472 - accuracy: 0.9491 - val_loss: 1.7642 - val_accuracy: 0.6157\n",
            "Epoch 27/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.1036 - accuracy: 0.9713 - val_loss: 1.8437 - val_accuracy: 0.6092\n",
            "Epoch 28/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.1084 - accuracy: 0.9677 - val_loss: 1.8918 - val_accuracy: 0.6179\n",
            "Epoch 29/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0873 - accuracy: 0.9772 - val_loss: 1.9280 - val_accuracy: 0.6114\n",
            "Epoch 30/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0647 - accuracy: 0.9888 - val_loss: 2.0689 - val_accuracy: 0.6179\n",
            "Epoch 31/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0839 - accuracy: 0.9749 - val_loss: 2.0666 - val_accuracy: 0.6310\n",
            "Epoch 32/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0649 - accuracy: 0.9854 - val_loss: 2.1720 - val_accuracy: 0.6026\n",
            "Epoch 33/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0881 - accuracy: 0.9776 - val_loss: 2.1802 - val_accuracy: 0.5830\n",
            "Epoch 34/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.1186 - accuracy: 0.9612 - val_loss: 2.0575 - val_accuracy: 0.6157\n",
            "Epoch 35/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0853 - accuracy: 0.9768 - val_loss: 2.0279 - val_accuracy: 0.6223\n",
            "Epoch 36/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0678 - accuracy: 0.9826 - val_loss: 2.1139 - val_accuracy: 0.6397\n",
            "Epoch 37/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0579 - accuracy: 0.9886 - val_loss: 2.1533 - val_accuracy: 0.6376\n",
            "Epoch 38/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0301 - accuracy: 0.9970 - val_loss: 2.2926 - val_accuracy: 0.6135\n",
            "Epoch 39/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0212 - accuracy: 0.9984 - val_loss: 2.3141 - val_accuracy: 0.6332\n",
            "Epoch 40/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0193 - accuracy: 0.9979 - val_loss: 2.3379 - val_accuracy: 0.6223\n",
            "Epoch 41/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0155 - accuracy: 0.9986 - val_loss: 2.4577 - val_accuracy: 0.6223\n",
            "Epoch 42/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0147 - accuracy: 0.9986 - val_loss: 2.4896 - val_accuracy: 0.6376\n",
            "Epoch 43/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0133 - accuracy: 0.9992 - val_loss: 2.5495 - val_accuracy: 0.6266\n",
            "Epoch 44/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0115 - accuracy: 0.9989 - val_loss: 2.5408 - val_accuracy: 0.6376\n",
            "Epoch 45/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0093 - accuracy: 0.9991 - val_loss: 2.6186 - val_accuracy: 0.6354\n",
            "Epoch 46/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0081 - accuracy: 0.9996 - val_loss: 2.6354 - val_accuracy: 0.6332\n",
            "Epoch 47/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0071 - accuracy: 0.9994 - val_loss: 2.7061 - val_accuracy: 0.6441\n",
            "Epoch 48/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0067 - accuracy: 0.9992 - val_loss: 2.7371 - val_accuracy: 0.6441\n",
            "Epoch 49/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0063 - accuracy: 0.9995 - val_loss: 2.7608 - val_accuracy: 0.6310\n",
            "Epoch 50/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0061 - accuracy: 0.9987 - val_loss: 2.7923 - val_accuracy: 0.6376\n",
            "Epoch 51/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0046 - accuracy: 0.9996 - val_loss: 2.8555 - val_accuracy: 0.6266\n",
            "Epoch 52/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0041 - accuracy: 0.9999 - val_loss: 2.8546 - val_accuracy: 0.6266\n",
            "Epoch 53/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0038 - accuracy: 0.9997 - val_loss: 2.9004 - val_accuracy: 0.6266\n",
            "Epoch 54/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0032 - accuracy: 0.9999 - val_loss: 2.9690 - val_accuracy: 0.6376\n",
            "Epoch 55/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0035 - accuracy: 0.9996 - val_loss: 2.9826 - val_accuracy: 0.6310\n",
            "Epoch 56/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0035 - accuracy: 0.9997 - val_loss: 2.9889 - val_accuracy: 0.6376\n",
            "Epoch 57/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0027 - accuracy: 0.9998 - val_loss: 3.0313 - val_accuracy: 0.6266\n",
            "Epoch 58/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0025 - accuracy: 0.9999 - val_loss: 3.0203 - val_accuracy: 0.6310\n",
            "Epoch 59/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0032 - accuracy: 0.9994 - val_loss: 3.0771 - val_accuracy: 0.6266\n",
            "Epoch 60/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0023 - accuracy: 0.9999 - val_loss: 3.1238 - val_accuracy: 0.6288\n",
            "Epoch 61/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0035 - accuracy: 0.9994 - val_loss: 3.1391 - val_accuracy: 0.6310\n",
            "Epoch 62/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0019 - accuracy: 0.9999 - val_loss: 3.1806 - val_accuracy: 0.6310\n",
            "Epoch 63/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0036 - accuracy: 0.9993 - val_loss: 3.2270 - val_accuracy: 0.6310\n",
            "Epoch 64/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0029 - accuracy: 0.9999 - val_loss: 3.1783 - val_accuracy: 0.6354\n",
            "Epoch 65/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0025 - accuracy: 0.9998 - val_loss: 3.2289 - val_accuracy: 0.6201\n",
            "Epoch 66/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 3.2657 - val_accuracy: 0.6288\n",
            "Epoch 67/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0018 - accuracy: 0.9998 - val_loss: 3.2677 - val_accuracy: 0.6310\n",
            "Epoch 68/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0041 - accuracy: 0.9983 - val_loss: 3.3056 - val_accuracy: 0.6354\n",
            "Epoch 69/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0017 - accuracy: 0.9996 - val_loss: 3.3401 - val_accuracy: 0.6376\n",
            "Epoch 70/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 3.3816 - val_accuracy: 0.6223\n",
            "Epoch 71/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0015 - accuracy: 0.9999 - val_loss: 3.3648 - val_accuracy: 0.6397\n",
            "Epoch 72/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 3.4646 - val_accuracy: 0.6223\n",
            "Epoch 73/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0019 - accuracy: 0.9999 - val_loss: 3.4545 - val_accuracy: 0.6354\n",
            "Epoch 74/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0019 - accuracy: 0.9997 - val_loss: 3.4350 - val_accuracy: 0.6354\n",
            "Epoch 75/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0016 - accuracy: 0.9998 - val_loss: 3.4942 - val_accuracy: 0.6245\n",
            "Epoch 76/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 3.5688 - val_accuracy: 0.6288\n",
            "Epoch 77/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0028 - accuracy: 0.9990 - val_loss: 3.5278 - val_accuracy: 0.6310\n",
            "Epoch 78/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 9.7169e-04 - accuracy: 0.9999 - val_loss: 3.5324 - val_accuracy: 0.6245\n",
            "Epoch 79/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 3.5816 - val_accuracy: 0.6310\n",
            "Epoch 80/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0018 - accuracy: 0.9993 - val_loss: 3.5831 - val_accuracy: 0.6288\n",
            "Epoch 81/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 8.8908e-04 - accuracy: 1.0000 - val_loss: 3.6664 - val_accuracy: 0.6201\n",
            "Epoch 82/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 9.9494e-04 - accuracy: 1.0000 - val_loss: 3.6016 - val_accuracy: 0.6376\n",
            "Epoch 83/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.4811 - accuracy: 0.8972 - val_loss: 1.4674 - val_accuracy: 0.6048\n",
            "Epoch 84/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.3080 - accuracy: 0.8896 - val_loss: 1.9839 - val_accuracy: 0.6135\n",
            "Epoch 85/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.1413 - accuracy: 0.9518 - val_loss: 2.0782 - val_accuracy: 0.6048\n",
            "Epoch 86/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0673 - accuracy: 0.9825 - val_loss: 2.2590 - val_accuracy: 0.5961\n",
            "Epoch 87/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0300 - accuracy: 0.9959 - val_loss: 2.5198 - val_accuracy: 0.6223\n",
            "Epoch 88/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0148 - accuracy: 0.9987 - val_loss: 2.6432 - val_accuracy: 0.6245\n",
            "Epoch 89/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0103 - accuracy: 0.9992 - val_loss: 2.7536 - val_accuracy: 0.6310\n",
            "Epoch 90/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0086 - accuracy: 0.9996 - val_loss: 2.8066 - val_accuracy: 0.6266\n",
            "Epoch 91/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0822 - accuracy: 0.9781 - val_loss: 2.6751 - val_accuracy: 0.6310\n",
            "Epoch 92/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0228 - accuracy: 0.9944 - val_loss: 2.8254 - val_accuracy: 0.6114\n",
            "Epoch 93/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0206 - accuracy: 0.9947 - val_loss: 2.8442 - val_accuracy: 0.6048\n",
            "Epoch 94/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0262 - accuracy: 0.9925 - val_loss: 3.0015 - val_accuracy: 0.6157\n",
            "Epoch 95/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0248 - accuracy: 0.9951 - val_loss: 3.0508 - val_accuracy: 0.6157\n",
            "Epoch 96/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0197 - accuracy: 0.9939 - val_loss: 3.2245 - val_accuracy: 0.6157\n",
            "Epoch 97/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0178 - accuracy: 0.9950 - val_loss: 3.1910 - val_accuracy: 0.6245\n",
            "Epoch 98/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0077 - accuracy: 0.9988 - val_loss: 3.2114 - val_accuracy: 0.6288\n",
            "Epoch 99/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0036 - accuracy: 0.9993 - val_loss: 3.2221 - val_accuracy: 0.6245\n",
            "Epoch 100/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0019 - accuracy: 0.9997 - val_loss: 3.2457 - val_accuracy: 0.6332\n",
            "Epoch 101/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0018 - accuracy: 0.9998 - val_loss: 3.2840 - val_accuracy: 0.6245\n",
            "Epoch 102/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0017 - accuracy: 0.9998 - val_loss: 3.2959 - val_accuracy: 0.6310\n",
            "Epoch 103/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 3.3303 - val_accuracy: 0.6354\n",
            "Epoch 104/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 3.3478 - val_accuracy: 0.6157\n",
            "Epoch 105/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 3.3918 - val_accuracy: 0.6376\n",
            "Epoch 106/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 3.4003 - val_accuracy: 0.6332\n",
            "Epoch 107/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 3.4108 - val_accuracy: 0.6288\n",
            "Epoch 108/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 8.8694e-04 - accuracy: 0.9999 - val_loss: 3.4458 - val_accuracy: 0.6266\n",
            "Epoch 109/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 9.7389e-04 - accuracy: 0.9998 - val_loss: 3.4533 - val_accuracy: 0.6310\n",
            "Epoch 110/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 7.3449e-04 - accuracy: 1.0000 - val_loss: 3.4731 - val_accuracy: 0.6179\n",
            "Epoch 111/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0011 - accuracy: 0.9996 - val_loss: 3.4919 - val_accuracy: 0.6245\n",
            "Epoch 112/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 6.8112e-04 - accuracy: 0.9999 - val_loss: 3.5096 - val_accuracy: 0.6201\n",
            "Epoch 113/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 8.5599e-04 - accuracy: 0.9999 - val_loss: 3.5249 - val_accuracy: 0.6332\n",
            "Epoch 114/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0020 - accuracy: 0.9992 - val_loss: 3.5287 - val_accuracy: 0.6310\n",
            "Epoch 115/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 8.3808e-04 - accuracy: 0.9999 - val_loss: 3.5681 - val_accuracy: 0.6201\n",
            "Epoch 116/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 8.2084e-04 - accuracy: 0.9999 - val_loss: 3.5797 - val_accuracy: 0.6376\n",
            "Epoch 117/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 7.6162e-04 - accuracy: 0.9998 - val_loss: 3.6004 - val_accuracy: 0.6288\n",
            "Epoch 118/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0016 - accuracy: 0.9996 - val_loss: 3.6160 - val_accuracy: 0.6179\n",
            "Epoch 119/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 7.7743e-04 - accuracy: 0.9998 - val_loss: 3.6105 - val_accuracy: 0.6135\n",
            "Epoch 120/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0019 - accuracy: 0.9990 - val_loss: 3.6434 - val_accuracy: 0.6201\n",
            "Epoch 121/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0019 - accuracy: 0.9993 - val_loss: 3.6485 - val_accuracy: 0.6179\n",
            "Epoch 122/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 7.9941e-04 - accuracy: 0.9998 - val_loss: 3.6488 - val_accuracy: 0.6354\n",
            "Epoch 123/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 9.8188e-04 - accuracy: 0.9997 - val_loss: 3.7024 - val_accuracy: 0.6245\n",
            "Epoch 124/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 3.6930 - val_accuracy: 0.6310\n",
            "Epoch 125/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 5.0719e-04 - accuracy: 0.9999 - val_loss: 3.7158 - val_accuracy: 0.6092\n",
            "Epoch 126/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 5.8206e-04 - accuracy: 0.9999 - val_loss: 3.7092 - val_accuracy: 0.6245\n",
            "Epoch 127/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 8.1973e-04 - accuracy: 0.9998 - val_loss: 3.7231 - val_accuracy: 0.6245\n",
            "Epoch 128/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0017 - accuracy: 0.9991 - val_loss: 3.7453 - val_accuracy: 0.6223\n",
            "Epoch 129/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 3.9613e-04 - accuracy: 0.9999 - val_loss: 3.7689 - val_accuracy: 0.6157\n",
            "Epoch 130/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0010 - accuracy: 0.9995 - val_loss: 3.7710 - val_accuracy: 0.6245\n",
            "Epoch 131/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 6.2005e-04 - accuracy: 0.9998 - val_loss: 3.7642 - val_accuracy: 0.6157\n",
            "Epoch 132/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0012 - accuracy: 0.9991 - val_loss: 3.7618 - val_accuracy: 0.6223\n",
            "Epoch 133/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 3.8024 - val_accuracy: 0.6135\n",
            "Epoch 134/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 7.4956e-04 - accuracy: 0.9996 - val_loss: 3.8350 - val_accuracy: 0.6135\n",
            "Epoch 135/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0022 - accuracy: 0.9991 - val_loss: 3.8466 - val_accuracy: 0.6048\n",
            "Epoch 136/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0010 - accuracy: 0.9997 - val_loss: 3.8366 - val_accuracy: 0.6201\n",
            "Epoch 137/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 3.8706 - val_accuracy: 0.6092\n",
            "Epoch 138/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 7.4911e-04 - accuracy: 0.9998 - val_loss: 3.8549 - val_accuracy: 0.6135\n",
            "Epoch 139/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 8.9020e-04 - accuracy: 0.9999 - val_loss: 3.8551 - val_accuracy: 0.6223\n",
            "Epoch 140/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 9.0566e-04 - accuracy: 0.9995 - val_loss: 3.8918 - val_accuracy: 0.6179\n",
            "Epoch 141/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 4.0089e-04 - accuracy: 1.0000 - val_loss: 3.9211 - val_accuracy: 0.6004\n",
            "Epoch 142/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 8.1238e-04 - accuracy: 0.9998 - val_loss: 3.9139 - val_accuracy: 0.6135\n",
            "Epoch 143/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0015 - accuracy: 0.9994 - val_loss: 3.9262 - val_accuracy: 0.6135\n",
            "Epoch 144/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 9.6505e-04 - accuracy: 0.9996 - val_loss: 3.9502 - val_accuracy: 0.6157\n",
            "Epoch 145/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 2.6368e-04 - accuracy: 1.0000 - val_loss: 3.9828 - val_accuracy: 0.6048\n",
            "Epoch 146/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 6.1390e-04 - accuracy: 0.9997 - val_loss: 3.9648 - val_accuracy: 0.6048\n",
            "Epoch 147/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 7.6983e-04 - accuracy: 0.9996 - val_loss: 3.9802 - val_accuracy: 0.6201\n",
            "Epoch 148/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 4.8473e-04 - accuracy: 0.9999 - val_loss: 4.0066 - val_accuracy: 0.6266\n",
            "Epoch 149/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 8.0166e-04 - accuracy: 0.9997 - val_loss: 4.0142 - val_accuracy: 0.6157\n",
            "Epoch 150/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 2.1933e-04 - accuracy: 1.0000 - val_loss: 4.0419 - val_accuracy: 0.6223\n",
            "Epoch 151/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 3.2501e-04 - accuracy: 1.0000 - val_loss: 4.0576 - val_accuracy: 0.6004\n",
            "Epoch 152/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 8.7954e-04 - accuracy: 0.9997 - val_loss: 4.0579 - val_accuracy: 0.6135\n",
            "Epoch 153/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 5.0319e-04 - accuracy: 0.9998 - val_loss: 4.0524 - val_accuracy: 0.6070\n",
            "Epoch 154/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 3.7169e-04 - accuracy: 0.9999 - val_loss: 4.0898 - val_accuracy: 0.6201\n",
            "Epoch 155/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 5.5714e-04 - accuracy: 0.9998 - val_loss: 4.1115 - val_accuracy: 0.6223\n",
            "Epoch 156/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 4.9752e-04 - accuracy: 0.9999 - val_loss: 4.1365 - val_accuracy: 0.6092\n",
            "Epoch 157/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 4.4794e-04 - accuracy: 0.9999 - val_loss: 4.0813 - val_accuracy: 0.6026\n",
            "Epoch 158/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.5626 - accuracy: 0.8749 - val_loss: 1.6328 - val_accuracy: 0.6135\n",
            "Epoch 159/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.2472 - accuracy: 0.9134 - val_loss: 1.8320 - val_accuracy: 0.6179\n",
            "Epoch 160/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.1026 - accuracy: 0.9674 - val_loss: 2.2582 - val_accuracy: 0.6135\n",
            "Epoch 161/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0532 - accuracy: 0.9829 - val_loss: 2.3706 - val_accuracy: 0.6376\n",
            "Epoch 162/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0185 - accuracy: 0.9990 - val_loss: 2.5437 - val_accuracy: 0.6354\n",
            "Epoch 163/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0094 - accuracy: 0.9989 - val_loss: 2.6716 - val_accuracy: 0.6376\n",
            "Epoch 164/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0056 - accuracy: 0.9999 - val_loss: 2.7483 - val_accuracy: 0.6332\n",
            "Epoch 165/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0039 - accuracy: 0.9998 - val_loss: 2.8275 - val_accuracy: 0.6223\n",
            "Epoch 166/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0024 - accuracy: 0.9999 - val_loss: 2.8698 - val_accuracy: 0.6397\n",
            "Epoch 167/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0023 - accuracy: 0.9996 - val_loss: 2.9334 - val_accuracy: 0.6266\n",
            "Epoch 168/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0019 - accuracy: 0.9999 - val_loss: 2.9738 - val_accuracy: 0.6332\n",
            "Epoch 169/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 3.0172 - val_accuracy: 0.6245\n",
            "Epoch 170/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0015 - accuracy: 0.9996 - val_loss: 3.0608 - val_accuracy: 0.6245\n",
            "Epoch 171/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0019 - accuracy: 0.9992 - val_loss: 3.0904 - val_accuracy: 0.6223\n",
            "Epoch 172/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0011 - accuracy: 0.9999 - val_loss: 3.1254 - val_accuracy: 0.6354\n",
            "Epoch 173/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 3.1617 - val_accuracy: 0.6354\n",
            "Epoch 174/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 3.1836 - val_accuracy: 0.6245\n",
            "Epoch 175/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 9.6888e-04 - accuracy: 0.9998 - val_loss: 3.2096 - val_accuracy: 0.6245\n",
            "Epoch 176/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0011 - accuracy: 0.9996 - val_loss: 3.2406 - val_accuracy: 0.6288\n",
            "Epoch 177/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 9.5337e-04 - accuracy: 0.9997 - val_loss: 3.2629 - val_accuracy: 0.6288\n",
            "Epoch 178/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 9.8926e-04 - accuracy: 0.9996 - val_loss: 3.2939 - val_accuracy: 0.6288\n",
            "Epoch 179/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0013 - accuracy: 0.9997 - val_loss: 3.3215 - val_accuracy: 0.6223\n",
            "Epoch 180/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0015 - accuracy: 0.9998 - val_loss: 3.3335 - val_accuracy: 0.6223\n",
            "Epoch 181/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0010 - accuracy: 0.9994 - val_loss: 3.3612 - val_accuracy: 0.6223\n",
            "Epoch 182/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 8.5984e-04 - accuracy: 0.9998 - val_loss: 3.3892 - val_accuracy: 0.6266\n",
            "Epoch 183/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 9.6387e-04 - accuracy: 0.9995 - val_loss: 3.4147 - val_accuracy: 0.6223\n",
            "Epoch 184/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 6.7048e-04 - accuracy: 0.9998 - val_loss: 3.4264 - val_accuracy: 0.6245\n",
            "Epoch 185/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 6.9955e-04 - accuracy: 0.9997 - val_loss: 3.4552 - val_accuracy: 0.6223\n",
            "Epoch 186/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 5.2212e-04 - accuracy: 0.9998 - val_loss: 3.4794 - val_accuracy: 0.6245\n",
            "Epoch 187/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 5.5345e-04 - accuracy: 0.9998 - val_loss: 3.4988 - val_accuracy: 0.6245\n",
            "Epoch 188/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 4.8903e-04 - accuracy: 1.0000 - val_loss: 3.5123 - val_accuracy: 0.6288\n",
            "Epoch 189/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 9.9350e-04 - accuracy: 0.9997 - val_loss: 3.5252 - val_accuracy: 0.6223\n",
            "Epoch 190/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 5.6205e-04 - accuracy: 0.9999 - val_loss: 3.5677 - val_accuracy: 0.6223\n",
            "Epoch 191/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 3.7950e-04 - accuracy: 0.9999 - val_loss: 3.5715 - val_accuracy: 0.6266\n",
            "Epoch 192/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 5.2190e-04 - accuracy: 0.9999 - val_loss: 3.5847 - val_accuracy: 0.6266\n",
            "Epoch 193/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 6.0211e-04 - accuracy: 0.9999 - val_loss: 3.6092 - val_accuracy: 0.6245\n",
            "Epoch 194/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 0.0013 - accuracy: 0.9988 - val_loss: 3.6303 - val_accuracy: 0.6245\n",
            "Epoch 195/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 5.5602e-04 - accuracy: 0.9999 - val_loss: 3.6482 - val_accuracy: 0.6266\n",
            "Epoch 196/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 7.3337e-04 - accuracy: 0.9999 - val_loss: 3.6627 - val_accuracy: 0.6245\n",
            "Epoch 197/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 5.8745e-04 - accuracy: 0.9996 - val_loss: 3.6839 - val_accuracy: 0.6245\n",
            "Epoch 198/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 3.7936e-04 - accuracy: 0.9999 - val_loss: 3.6935 - val_accuracy: 0.6245\n",
            "Epoch 199/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 5.7796e-04 - accuracy: 0.9998 - val_loss: 3.7165 - val_accuracy: 0.6245\n",
            "Epoch 200/200\n",
            "65/65 [==============================] - 0s 3ms/step - loss: 3.2063e-04 - accuracy: 1.0000 - val_loss: 3.7239 - val_accuracy: 0.6288\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ktsOoIOXbNDO"
      },
      "source": [
        "model.save('/content/drive/MyDrive/Colab Notebooks/SPEECH_EMOTION_Recognition/Nộp bài(chốt hạ)/model_saver/basic_combined_cremad.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FwsQwDu7bNDQ"
      },
      "source": [
        "###test_result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vej6UJ74bNDQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7dbe9c7a-3db9-4322-aa99-55bebfe1fb61"
      },
      "source": [
        "d = {0: 'happy',\n",
        "     1: 'sad',\n",
        "     2: 'angry',\n",
        "     3: 'fear'}\n",
        "Y_test_pred = np.argmax(model.predict(X_test), axis=-1)\n",
        "Y_test_pred = list(map(lambda x: d[x], Y_test_pred))\n",
        "y_test = np.argmax(y_test, axis=-1)\n",
        "y_test = list(map(lambda x: d[x], y_test))\n",
        "print(classification_report(y_test, Y_test_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.70      0.68      0.69       136\n",
            "        fear       0.58      0.44      0.50       134\n",
            "       happy       0.47      0.57      0.52       120\n",
            "         sad       0.65      0.71      0.67       119\n",
            "\n",
            "    accuracy                           0.60       509\n",
            "   macro avg       0.60      0.60      0.60       509\n",
            "weighted avg       0.60      0.60      0.60       509\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1DdBxgcIbNDR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 483
        },
        "outputId": "a4117c48-fa48-488d-aa7a-24c019c3c440"
      },
      "source": [
        "skplt.metrics.plot_confusion_matrix(\n",
        "    y_test, \n",
        "    Y_test_pred,\n",
        "    figsize=(8,8))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f8830053590>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ExtfqtTnbNDS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}